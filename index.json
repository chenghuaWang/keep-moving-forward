[{"content":"0x00 å‚è€ƒèµ„æ–™ æœ¬æ–‡æ˜¯å¯¹RoPEçš„å­¦ä¹ ç¬”è®°ï¼Œå…¶ä¸­æœ‰ä¸å°‘å†…å®¹æ˜¯æ‘˜è‡ªä¸šå†…çš„å‰è¾ˆä»¬çš„æ–‡ç« ï¼Œåœ¨æ­¤ä¸€å¹¶æ„Ÿè°¢ã€‚æ‰€å‚è€ƒçš„èµ„æ–™ã€æ‘˜å½•çš„æ–‡ç« æ¥æºåœ¨ä¸‹é¢åˆ—å‡ºï¼š\nè‹è€å¸ˆçš„Blogï¼ŒTransformerå‡çº§ä¹‹è·¯ï¼š2ã€åšé‡‡ä¼—é•¿çš„æ—‹è½¬å¼ä½ç½®ç¼–ç \nReformerï¼ŒGithub repo\nè§†å±è®²è§£ï¼Œã€è§£å¯†æ—‹è½¬ä½ç½®ç¼–ç ï¼šæ•°å­¦åŸºç¡€ã€ä»£ç å®ç°ä¸ç»å¯¹ç¼–ç ä¸€ä½“åŒ–æ¢ç´¢ã€‘ 0x01 ä¸ºä»€ä¹ˆéœ€è¦ä½ç½®ç¼–ç  åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼ŒAttentionæœºåˆ¶æ˜¯ä¸€ç§ç”¨äºå»ºç«‹è¾“å…¥åºåˆ—ä¸­ä¸åŒå…ƒç´ é—´å…³è”çš„æ–¹æ³•ï¼Œå®ƒå…è®¸æ¨¡å‹åœ¨å¤„ç†åºåˆ—æ•°æ®æ—¶ï¼Œèƒ½å¤Ÿå…³æ³¨åˆ°å½“å‰å…ƒç´ ä¹‹å¤–çš„å…¶ä»–å…ƒç´ ã€‚ç„¶è€Œï¼ŒåŸå§‹çš„Attentionæœºåˆ¶å­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼šå®ƒæ²¡æœ‰è€ƒè™‘åºåˆ—ä¸­å…ƒç´ çš„é¡ºåºä¿¡æ¯ã€‚ åœ¨å¤„ç†åºåˆ—æ•°æ®æ—¶ï¼Œå…ƒç´ çš„é¡ºåºæ˜¯éå¸¸é‡è¦çš„ï¼Œå› ä¸ºä¸åŒçš„é¡ºåºå¯èƒ½ä¼šè¡¨è¾¾å®Œå…¨ä¸åŒçš„æ„ä¹‰ã€‚ä¾‹å¦‚ï¼Œåœ¨å¥å­ä¸­ï¼Œ\u0026ldquo;I saw the man with the telescope\u0026rdquo; å’Œ \u0026ldquo;The man saw I with the telescope\u0026rdquo; è™½ç„¶ä½¿ç”¨äº†ç›¸åŒçš„è¯æ±‡ï¼Œä½†æ„ä¹‰å´å¤§ç›¸å¾„åº­ï¼Œè¿™æ­£æ˜¯å› ä¸ºè¯åºä¸åŒã€‚\nä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¼•å…¥äº†ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰ã€‚ä½ç½®ç¼–ç æ˜¯ä¸€ç§å‘é‡ï¼Œå®ƒä¸åŸå§‹çš„è¾“å…¥åºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ ç›¸ä¹˜ï¼Œä¸ºæ¨¡å‹æä¾›å…³äºæ¯ä¸ªå…ƒç´ åœ¨åºåˆ—ä¸­ä½ç½®çš„ä¿¡æ¯ã€‚è¿™æ ·ï¼Œå³ä½¿åœ¨è®¡ç®—Attentionæƒé‡æ—¶ï¼Œæ¨¡å‹ä¹Ÿèƒ½å¤ŸåŒºåˆ†ä¸åŒä½ç½®çš„å…ƒç´ ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£åºåˆ—æ•°æ®ä¸­çš„é¡ºåºä¿¡æ¯ã€‚\n0x02 ç»å¯¹ä½ç½®ç¼–ç  å¯å­¦ä¹ çš„ç»å¯¹ä½ç½®ç¼–ç  BERTæ¨¡å‹ä¸­å¼•å…¥äº†å¯å­¦ä¹ çš„ç»å¯¹ä½ç½®ç¼–ç ï¼ˆposition embeddingsï¼‰ï¼Œå…¶ç›®çš„æ˜¯åœ¨æ¨¡å‹ä¸­ä¸ºæ¯ä¸ªä½ç½®æä¾›åºåˆ—ä¸­å•è¯çš„ä½ç½®ä¿¡æ¯ã€‚è¿™ç§ä½ç½®ç¼–ç æ˜¯æ¨¡å‹å‚æ•°çš„ä¸€éƒ¨åˆ†ï¼Œå¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨å­¦ä¹ å¾—åˆ°æœ€ä¼˜çš„è¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼ŒBERTä½¿ç”¨äº†ä¸€ä¸ªå¯è®­ç»ƒçš„åµŒå…¥å±‚æ¥ç”Ÿæˆä½ç½®ç¼–ç ï¼Œè¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°åºåˆ—ä¸­å•è¯çš„é¡ºåºä¿¡æ¯ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£å¥å­ç»“æ„å’Œè¯­ä¹‰ã€‚\nä½†æ˜¯ï¼Œå¯å­¦ä¹ çš„ä½ç½®ç¼–ç å—é•¿åº¦é™åˆ¶ï¼Œæ— æ³•åº”ç”¨åœ¨é•¿æ–‡æœ¬ã€‚\nSinusoidalä½ç½®ç¼–ç  Sinusoidalä½ç½®ç¼–ç çš„åŸºæœ¬æ€æƒ³æ˜¯åˆ©ç”¨æ­£å¼¦å’Œä½™å¼¦å‡½æ•°çš„å‘¨æœŸæ€§æ¥ç¼–ç ä½ç½®ä¿¡æ¯ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºåºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œä½ç½®ç¼–ç ä¼šç”Ÿæˆä¸€ä¸ªä¸ä½ç½®ç›¸å…³çš„å‘é‡ï¼š\n$$PE_{(p, 2i)} = \\sin\\left(\\frac{p}{10000^{(i/d)}}\\right)$$\n$$PE_{(p, 2i+1)} = \\cos\\left(\\frac{p}{10000^{(i/d)}}\\right)$$\nå…¶ä¸­ï¼Œ$p$è¡¨ç¤ºä½ç½®ï¼Œ$i$è¡¨ç¤ºç»´åº¦ä¿¡æ¯ã€‚\n0x03 RoPE è¿™é‡Œçš„å…¬å¼å€Ÿç”¨è‹è€å¸ˆæ–‡ç« ä¸­çš„ç”¨æ³•ã€‚å‡è®¾æˆ‘ä»¬éœ€è¦å¯¹$\\boldsymbol{q},\\boldsymbol{k}$æ·»åŠ ä¸Šä½ç½®ä¿¡æ¯$m,n$ï¼Œæˆ‘ä»¬å¯ä»¥å‡è®¾æœ‰$\\boldsymbol{f}(\\cdot, \\text{pos})$è¿™æ ·çš„æ“ä½œå¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼š\n$$\\tilde{\\boldsymbol{q}}_m=\\boldsymbol{f}(\\boldsymbol{q},m),\\quad\\tilde{\\boldsymbol{k}}_n=\\boldsymbol{f}(\\boldsymbol{k},n)$$\nåœ¨Attentionæ“ä½œä¸­ï¼Œ$q,k^*$ä¼šåšå†…ç§¯ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨åšå†…ç§¯çš„æ—¶å€™å¯ä»¥ä½“ç°å‡ºç›¸å¯¹ä½ç½®å…³ç³»ï¼Œä¹Ÿå°±æ˜¯ä¸‹é¢çš„å¼å­å±•ç¤ºçš„ï¼š\n$$\\langle \\boldsymbol{f}(\\boldsymbol{q},m), \\boldsymbol{f}(\\boldsymbol{k},n) \\rangle = \\boldsymbol{g}(\\boldsymbol{q},\\boldsymbol{k}, m-n)$$\nå…¶ä¸­$m-n$å°±æ˜¯ç›¸å¯¹ä½ç½®å…³ç³»ã€‚\n$\\langle \\boldsymbol{x}, \\boldsymbol{y} \\rangle$è¡¨ç¤ºå¸Œå°”ä¼¯ç‰¹ç©ºé—´çš„å†…ç§¯ï¼Œå³é«˜ç»´åº¦æ¬§å‡ é‡Œå¾—ç©ºé—´ã€‚\né‚£ä¹ˆæ¥ä¸‹æ¥çš„é—®é¢˜å°±æ˜¯å¦‚ä½•æ‰¾åˆ°è¿™æ ·çš„$\\boldsymbol{f}$ä»¥æ»¡è¶³æˆ‘ä»¬ä¸Šé¢çš„å‡è®¾ã€‚ä¸ºäº†ç®€åŒ–é—®é¢˜ï¼Œæˆ‘ä»¬ä¸å¦¨å‡è®¾\n$$\\boldsymbol{f}(\\boldsymbol{q},0) = q, \\boldsymbol{f}(\\boldsymbol{k},0)=k$$ã€‚\næˆ‘ä»¬å¯ä»¥å€Ÿç”¨å¤æ•°çš„æ¦‚å¿µæ¥æ±‚è§£è¿™ä¸ªé—®é¢˜ï¼Œåœ¨æ­¤ï¼Œæˆ‘ä»¬å…ˆè€ƒè™‘äºŒç»´æƒ…å†µä¸‹ã€‚\nåœ¨å¤æ•°ä¸­æœ‰$\\langle \\boldsymbol{q} ,\\boldsymbol{k} \\rangle = \\text{Re}[\\boldsymbol{q} \\boldsymbol{k}^*]$ï¼Œå³\n$$\\text{Re}[ \\boldsymbol{f}(\\boldsymbol{q},m)\\boldsymbol{f}^*(\\boldsymbol{k},n)]= \\boldsymbol{g}(\\boldsymbol{q},\\boldsymbol{k}, m-n)$$\nä¸ºäº†ç®€åŒ–é—®é¢˜ï¼Œæˆ‘ä»¬å‡è®¾å­˜åœ¨å¤æ•°$\\boldsymbol{g}(\\boldsymbol{q},\\boldsymbol{k}, m-n)$ä½¿å¾—ï¼š\n$$\\boldsymbol{f}(\\boldsymbol{q},m)\\boldsymbol{f}^*(\\boldsymbol{k},n)= \\boldsymbol{g}(\\boldsymbol{q},\\boldsymbol{k}, m-n)$$\næˆ‘ä»¬ä½¿ç”¨å¤æ•°çš„æŒ‡æ•°å½¢å¼å¯ä»¥å¾—åˆ°ï¼š\n$$\\boldsymbol{f}(\\boldsymbol{q},m) = R_f(\\boldsymbol{q},m)e^{i \\Theta_f(\\boldsymbol{q},m)}$$\n$$\\boldsymbol{f}(\\boldsymbol{k},n) = R_f(\\boldsymbol{k},n)e^{i \\Theta_f(\\boldsymbol{k},m)}$$\n$$\\boldsymbol{g}(\\boldsymbol{q},\\boldsymbol{k}, m-n) = R_g(\\boldsymbol{q},\\boldsymbol{k},m-n)e^{i \\Theta_g(\\boldsymbol{q},\\boldsymbol{k},m-n)}$$\nå¸¦å…¥ä¹‹å‰çš„æ–¹ç¨‹åå¯ä»¥å¾—åˆ°ä¸‹è¿°æ–¹ç¨‹ç»„ï¼š\n$$R_f(\\boldsymbol{q},m)R_f(\\boldsymbol{k},n)=R_g(\\boldsymbol{q},\\boldsymbol{k},m-n)$$\n$$\\Theta_f(\\boldsymbol{q},m) - \\Theta_f(\\boldsymbol{k},n) = \\Theta_g(\\boldsymbol{q},\\boldsymbol{k},m-n)$$\nå¯¹äºä¸Šè¿°ä¸¤ä¸ªæ–¹ç¨‹ï¼Œæˆ‘ä»¬å¸¦å…¥$m=n$ï¼Œç”±äºä¸€å¼€å§‹çš„å‡è®¾$\\boldsymbol{f}(\\boldsymbol{q},0) = q, \\boldsymbol{f}(\\boldsymbol{k},0)=k$ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸‹é¢çš„æ–¹ç¨‹:\n$$R_f(\\boldsymbol{q},m)R_f(\\boldsymbol{k},m)=R_g(\\boldsymbol{q},\\boldsymbol{k},0)=R_f(\\boldsymbol{q},0)R_f(\\boldsymbol{k},0)=\\Vert \\boldsymbol{q} \\Vert \\Vert \\boldsymbol{k} \\Vert$$\n$$\\Theta_f(\\boldsymbol{q},m) - \\Theta_f(\\boldsymbol{k},m) = \\Theta_g(\\boldsymbol{q},\\boldsymbol{k},0)=\\Theta_f(\\boldsymbol{q},0) - \\Theta_f(\\boldsymbol{k},0)=\\Theta_f(\\boldsymbol{q}) - \\Theta_f(\\boldsymbol{k})$$\nç°åœ¨ï¼Œå¯¹äºç¬¬ä¸€ä¸ªå¼å­ï¼Œæˆ‘ä»¬ç®€å•çš„å‡è®¾\n$$R_f(\\boldsymbol{q},m)=\\Vert \\boldsymbol{q} \\Vert,R_f(\\boldsymbol{k},n)=\\Vert \\boldsymbol{k} \\Vert$$\nå¯¹äºç¬¬äºŒä¸ªå¼å­ï¼Œç»è¿‡å˜æ¢å¾—åˆ°ï¼š\n$$\\Theta_f(\\boldsymbol{q},m) - \\Theta_f(\\boldsymbol{q}) = 0,\\Theta_f(\\boldsymbol{k},m) - \\Theta_f(\\boldsymbol{k}) = 0$$\næ‰€ä»¥ï¼Œ$\\Theta_f(\\boldsymbol{q},m) - \\Theta_f(\\boldsymbol{q})$æ˜¯ä¸€ä¸ªä¸$\\boldsymbol{q}$æ— å…³ï¼Œä¸$\\boldsymbol{m}$ç›¸å…³çš„ä¸€ä¸ªå‡½æ•°ï¼Œæˆ‘ä»¬è®¾å®ƒä¸º$\\varphi(m)$ï¼Œå³:\n$$\\Theta_f(\\boldsymbol{q},m) = \\Theta_f(\\boldsymbol{q}) + \\varphi(m)$$\næ­¤æ—¶ï¼Œ\n$$\\varphi(m) - \\varphi(m-1) = \\Theta(\\boldsymbol{q},\\boldsymbol{k},1)+\\Theta(\\boldsymbol{k}) - \\Theta(\\boldsymbol{q})$$\nå³${\\varphi(m)}$æ˜¯ç­‰å·®æ•°åˆ—ï¼Œè®¾å³ç«¯æ˜¯$\\theta$ï¼Œé‚£ä¹ˆ$\\varphi(m) = \\theta m$\næ­¤æ—¶å°±å¾—åˆ°äº†äºŒç»´æƒ…å†µä¸‹çš„RoPEï¼š\n$$\\boldsymbol{f}(\\boldsymbol{q}, m) = \\boldsymbol{q}e^{im\\theta}$$\nè¿™å®é™…ä¸Šå°±æ˜¯å¯¹äº$\\boldsymbol{q}$çš„æ—‹è½¬å…¬å¼ï¼š\n$$\\boldsymbol{f}(\\boldsymbol{q}, m) = \\begin{pmatrix} \\cos m\\theta \u0026 -\\sin m \\theta \\\\ \\sin m \\theta \u0026 \\cos m \\theta \\end{pmatrix} \\begin{pmatrix} q_0 \\\\ q_1 \\end{pmatrix}$$ $\\text{Re}$è¡¨ç¤ºå¤æ•°çš„Realéƒ¨åˆ†ã€‚ $Z = \\text{a} + \\text{b}i=r(\\cos(\\Theta) + i\\sin(\\Theta)) = re^{i\\Theta}$ï¼Œå¤æ•°å½¢å¼å˜æ¢\nç”±äºå†…ç§¯æ»¡è¶³çº¿æ€§å åŠ æ€§ï¼Œå› æ­¤ä»»æ„å¶æ•°ç»´çš„RoPEï¼Œæˆ‘ä»¬éƒ½å¯ä»¥è¡¨ç¤ºä¸ºäºŒç»´æƒ…å½¢çš„æ‹¼æ¥\n$$\\underbrace{\\begin{pmatrix}\\cos m\\theta_0\u0026-\\sin m\\theta_0\u00260\u00260\u0026\\cdots\u00260\u00260\\\\\\sin m\\theta_0\u0026\\cos m\\theta_0\u00260\u00260\u0026\\cdots\u00260\u00260\\\\0\u00260\u0026\\cos m\\theta_1\u0026-\\sin m\\theta_1\u0026\\cdots\u00260\u00260\\\\0\u00260\u0026\\sin m\\theta_1\u0026\\cos m\\theta_1\u0026\\cdots\u00260\u00260\\\\\\vdots\u0026\\vdots\u0026\\vdots\u0026\\vdots\u0026\\ddots\u0026\\vdots\u0026\\vdots\\\\0\u00260\u00260\u00260\u0026\\cdots\u0026\\cos m\\theta_{d/2-1}\u0026-\\sin m\\theta_{d/2-1}\\\\0\u00260\u00260\u00260\u0026\\cdots\u0026\\sin m\\theta_{d/2-1}\u0026\\cos m\\theta_{d/2-1}\\end{pmatrix}}_{\\mathbf{W}_m}\\begin{pmatrix}q_0\\\\q_1\\\\q_2\\\\q_3\\\\\\vdots\\\\q_{d-2}\\\\q_{d-1}\\end{pmatrix}$$ å¯ä»¥çœ‹åˆ°ï¼ŒRoPEå½¢å¼ä¸Šå’ŒSinusoidalä½ç½®ç¼–ç æœ‰ç‚¹ç›¸ä¼¼ï¼Œåªä¸è¿‡Sinusoidalä½ç½®ç¼–ç æ˜¯åŠ æ€§çš„ï¼Œè€ŒRoPEå¯ä»¥è§†ä¸ºä¹˜æ€§çš„ã€‚\nå¯¹äºè¿œç¨‹è¡°å‡ï¼Œåœ¨$\\theta_i$çš„é€‰æ‹©ä¸Šï¼ŒRoPEsåŒæ ·æ²¿ç”¨äº†Sinusoidalä½ç½®ç¼–ç çš„æ–¹æ¡ˆï¼Œå³:\n$$\\theta_i = 10000^{-\\frac{2i}{d}}$$\nè¿œç¨‹è¡°å‡ï¼š å¯¹äº$q,k$ï¼Œæˆ‘ä»¬å¸Œæœ›è·ç¦»è¿‘çš„$q,k$æœ‰è¾ƒå¤§çš„ç›¸å…³æ€§ï¼Œè·ç¦»è¿œçš„$q,k$ç›¸å…³æ€§å°ã€‚\n0x04 æ€è€ƒ æ—¢ç„¶æ˜¯æ—‹è½¬ï¼Œä¼šå‡ºç°æ—‹è½¬è§’åº¦é‡å¤çš„ç°è±¡å—ï¼Ÿ åœ¨ä»»æ„çš„ç¬¬$k$ä¸ªå­ç©ºé—´ä¸Šï¼Œåªè¦$\\theta_k$ä¸­ä¸åŒ…å«$\\pi$ï¼Œé‚£ä¹ˆæ—‹è½¬è§’åº¦åºåˆ—${ i \\theta_k }$å°±ä¸ä¼šæœ‰è§’åº¦é‡å¤ã€‚\n$\\theta_i$ä¸­10000çš„è®¾ç½®ä¼šå½±å“å¤–æ¨çš„æ€§èƒ½å—ï¼Ÿ æ˜¯ä¼šçš„ï¼Œè¾ƒå°çš„å€¼ä¼šé€ æˆå¤–æ¨æ€§èƒ½ä¸¥é‡ä¸‹é™ã€‚å¯ä»¥æŠŠæ—‹è½¬è§’åº¦çš„å‡½æ•°å›¾ç”»å‡ºæ¥ï¼Œæˆ–è€…è®¾ç½®ä¸€ä¸ª$q,k$ç®—ä¸€ä¸‹å°±æ˜äº†äº†ã€‚\nä½¿ç”¨$\\text{base}=10000$ï¼Œè·‘å‡ºä¸‹å›¾çš„ç»“æœï¼š\nFig 1. $\\text{Base}=10000$ è€Œ$\\text{base}=50000$å’Œ$\\text{base}=10000$æ¯”ï¼Œè¿œç¨‹è¡°å‡çš„æ•ˆæœæœ‰é™ä½ï¼š\nFig 2. $\\text{Base}=50000$ ç›®å‰å¾ˆå¤šå¤§é•¿åº¦å¤–æ¨çš„æ¨¡å‹éƒ½æ˜¯é€šè¿‡è°ƒå¤§baseæ¥æå‡æ¨¡å‹çš„è¾“å…¥é•¿åº¦ã€‚\näºŒç»´çš„å­ç©ºé—´å¯ä»¥æ˜¯ä»»æ„çš„å— äºŒç»´çš„å­ç©ºé—´å¯ä»¥æ˜¯ä»»æ„çš„ï¼Œåªè¦æ˜¯æˆå¯¹çš„å°±å¯ä»¥äº†ï¼Œæ— éœ€æŒ‰ç…§æ–‡ç« ä¸­æ‰€è¯´çš„æ¥ã€‚åƒHF Llamaä¸­çš„é‚£æ ·ï¼Œå°±æ˜¯halfåˆ†å‰²çš„å½¢å¼ã€‚\n0x05 ä»£ç å®ç° å‚è€ƒçš„æ˜¯HFçš„Llama RoPEå®ç°ã€‚\nåœ¨å®ç°çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦é¿å¼€æ—‹è½¬çŸ©é˜µçš„ç›¸ä¹˜ï¼Œå› ä¸ºæ—‹è½¬çŸ©é˜µæ˜¯éå¸¸ç¨€ç–çš„ã€‚åœ¨è®ºæ–‡ä¸­ï¼Œä½œè€…ä½¿ç”¨çš„æ˜¯ï¼š\nFig 3. åŸæ–‡å­ç©ºé—´çš„é€‰æ‹©æ–¹æ³•${0, 1, 2, 3}$ -\u0026gt; { 0, 1 }, { 2, 3 }\nä½†æ˜¯å®é™…ä¸Šï¼Œå¦‚HF Llamaï¼Œå…¶ä½¿ç”¨çš„æ˜¯ï¼š\nFig 4. HF Llama å­ç©ºé—´çš„é€‰æ‹©æ–¹æ³•${0, 1, 2, 3}$ -\u0026gt; { 0, 2 }, { 1, 3 }\nä¸¤è€…éƒ½æ˜¯åˆç†çš„å®ç°ï¼Œåªæ˜¯å­ç©ºé—´çš„åˆ’åˆ†ä¸åŒã€‚å¯¹äºhalfåˆ’åˆ†ï¼Œåœ¨HF llamaçš„å®ç°ä¸­æ˜¯è¿™æ ·çš„ï¼š\ndef rotate_half(x): \u0026#34;\u0026#34;\u0026#34;Rotates half the hidden dims of the input.\u0026#34;\u0026#34;\u0026#34; x1 = x[..., : x.shape[-1] // 2] x2 = x[..., x.shape[-1] // 2 :] return torch.cat((-x2, x1), dim=-1) åœ¨ä¹˜ä¸Š$\\cos,\\sin$åæ˜¯ï¼š\ndef apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1): \u0026#34;\u0026#34;\u0026#34;Applies Rotary Position Embedding to the query and key tensors. Args: q (`torch.Tensor`): The query tensor. k (`torch.Tensor`): The key tensor. cos (`torch.Tensor`): The cosine part of the rotary embedding. sin (`torch.Tensor`): The sine part of the rotary embedding. position_ids (`torch.Tensor`, *optional*): Deprecated and unused. unsqueeze_dim (`int`, *optional*, defaults to 1): The \u0026#39;unsqueeze_dim\u0026#39; argument specifies the dimension along which to unsqueeze cos[position_ids] and sin[position_ids] so that they can be properly broadcasted to the dimensions of q and k. For example, note that cos[position_ids] and sin[position_ids] have the shape [batch_size, seq_len, head_dim]. Then, if q and k have the shape [batch_size, heads, seq_len, head_dim], then setting unsqueeze_dim=1 makes cos[position_ids] and sin[position_ids] broadcastable to the shapes of q and k. Similarly, if q and k have the shape [batch_size, seq_len, heads, head_dim], then set unsqueeze_dim=2. Returns: `tuple(torch.Tensor)` comprising of the query and key tensors rotated using the Rotary Position Embedding. \u0026#34;\u0026#34;\u0026#34; cos = cos.unsqueeze(unsqueeze_dim) sin = sin.unsqueeze(unsqueeze_dim) q_embed = (q * cos) + (rotate_half(q) * sin) k_embed = (k * cos) + (rotate_half(k) * sin) return q_embed, k_embed åœ¨$\\cos,\\sin$çš„ç”Ÿæˆä¸Šå°±ä¸ä½¿ç”¨Llamaçš„ä»£ç äº†ï¼Œå®ƒå°è£…çš„å¤ªå¤šäº†ï¼Œæˆ‘è‡ªå·±å†™äº†ä¸€ä¸ªï¼š\nbase = 1e5 d = D / 2 B = base ** (1/d) theta_beta = 1.0 / (B ** torch.arrange(0, d)) theta_0 = q.outer(theta_beta) theta = torch.concat([theta_0, theta_0], dim=-1) cos = theta.cos() sin = theta.sin() ","permalink":"https://chenghuawang.github.io/keep-moving-forward/tech/fundamental_rope/","summary":"RoPE from Fundamental Series","title":"[Fundamental] æ—‹è½¬ä½ç½®ç¼–ç (RoPE)"},{"content":"0x00 Materials æœ¬æ–‡æ˜¯å¯¹Flash Attentionçš„å­¦ä¹ ç¬”è®°ï¼Œå…¶ä¸­æœ‰ä¸å°‘å†…å®¹æ˜¯æ‘˜è‡ªä¸šå†…çš„å‰è¾ˆä»¬çš„æ–‡ç« ï¼Œåœ¨æ­¤ä¸€å¹¶æ„Ÿè°¢ã€‚æ‰€å‚è€ƒçš„èµ„æ–™ã€æ‘˜å½•çš„æ–‡ç« æ¥æºåœ¨ä¸‹é¢åˆ—å‡ºï¼š\nFrom Online Softmax to FlashAttention(CSE599m, ML for ML System) ,æœ¬æ–‡çš„è¡Œæ–‡é€»è¾‘ä¹Ÿæ˜¯æŒ‰ç…§è¿™ç¯‡æ–‡ç« æ¥çš„ã€‚å¼ºçƒˆå®‰åˆ©CSE599mç»™å…¥é—¨ML Systemçš„æ–°äººã€‚\nFlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\nFlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning\nã€BBufçš„CUDAç¬”è®°ã€‘åå››ï¼ŒOpenAI Tritonå…¥é—¨ç¬”è®°ä¸‰ FusedAttention\n[Attentionä¼˜åŒ–][2wå­—]ğŸ”¥åŸç†\u0026amp;å›¾è§£: ä»Online-Softmaxåˆ°FlashAttention V1/V2/V3\n0x01 é—®é¢˜å®šä¹‰ $$ \\text{Attention} = \\text{Softmax}(\\frac{QK^T}{\\sqrt{d_k}})V $$\n$$ Q,K,V \\in \\mathbb{R}^{N\\times D} $$\nå…¶ä¸­$N$è¡¨ç¤ºSequence Length,$D$è¡¨ç¤ºDimensionã€‚æˆ‘ä»¬å…ˆæ¥è€ƒè™‘æœ€ç®€å•çš„è®¡ç®—æ–¹å¼ï¼š\n$$ S = QK^T $$\n$$ P = \\text{Softmax}(S) $$\n$$ O = PV $$\nåœ¨è¿™ä¸ªNaiveçš„è®¡ç®—æ–¹å¼ä¸­ï¼Œ$P,S \\in \\mathbb R^{N\\times N}$ï¼Œè¿™æ„å‘³ç€ä¸ºäº†è®¡ç®—Pï¼Œæˆ‘ä»¬éœ€è¦å¤šä¿å­˜ä¸€ä¸ª$N\\times N$çš„çŸ©é˜µï¼Œè¿™ä¸ªæƒ…å†µä¸‹å†…å­˜çš„éœ€æ±‚æ˜¯$O(N^2)$çš„ï¼Œå¾ˆå®¹æ˜“çˆ†æ˜¾å­˜ï¼›ä¸”ä¸ºäº†è®¡ç®—$Så’ŒP$åŠ¿å¿…éœ€è¦ä»HBMä¸­è¿›è¡Œå¤§é‡çš„è¯»å†™æ“ä½œï¼ŒIOçš„è®¿é—®æ¬¡æ•°æ˜¯$O(N^2 + ND)$å¤æ‚åº¦çš„ã€‚éšç€ç°åœ¨çš„Context Lengthéœ€æ±‚è¶Šæ¥è¶Šå¤§ï¼Œåœ¨$N$å˜å¤§çš„æ—¶å€™ï¼Œæ˜¯å¾ˆå®¹æ˜“çˆ†æ˜¾å­˜çš„ã€‚æ€»ç»“é—®é¢˜ï¼Œä¸»è¦æœ‰ï¼š\nSequence Length($N$)è¶Šå¤§ï¼Œä¼ ç»Ÿçš„Attentionè®¡ç®—æ–¹æ³•å¾ˆå®¹æ˜“çˆ†æ˜¾å­˜ã€‚ ä¼ ç»Ÿçš„Attentionè®¡ç®—æ–¹å¼å¯¹HBMçš„è®¿é—®å¤æ‚åº¦æ˜¯å¹³æ–¹çº§åˆ«çš„ï¼Œè¶Šé•¿çš„$N$ï¼Œè€—æ—¶è¶Šé•¿ã€‚ HBM / Shared Mem IO BandwidthFrom FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\nè€ƒè™‘åˆ°HBMï¼ŒShared Memoryçš„é€Ÿåº¦å·®å¼‚ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå‡å°‘HBM Accessè€Œå°†æ›´å¤šçš„IO Accessæ“ä½œæ”¾åœ¨Shared Memoryä¸­ã€‚\n0x02 Online Softmax æˆ‘ä»¬å†æ¥çœ‹ä¸‹Safe Softmaxçš„é€»è¾‘:\n$$ S_i = \\frac{e^{x_i - M}}{\\sum_{i=0}^N e^{x_i - M}}, M = \\max{X},X \\in \\mathbb{R}^{N} $$ ã€‚æˆ‘ä»¬å…ˆç”¨ä¸€ä¸ªéå¸¸naiveçš„æ€è·¯æ¥å®ç°è¿™ä¸ªSoftmaxï¼Œè¿™é‡Œä½¿ç”¨From Online Softmax to FlashAttentionæ–‡ç« ä¸­çš„ä¼ªä»£ç æ¥è§£é‡Šï¼š\nOnline Softmax ä¼ªä»£ç From From Online Softmax to FlashAttention(CSE599m, ML for ML System)\nåœ¨è¿™ä¸ªç®€å•çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸‰ä¸ªå¾ªç¯æ¥è¿›è¡Œè®¡ç®—ï¼Œè¿™è¦æ±‚æˆ‘ä»¬å¯¹$[1; N]$è¿›è¡Œä¸‰æ¬¡è¿­ä»£ã€‚è€ŒSelf-Attentionä¸­ï¼Œå› ä¸ºSRAMæ”¾ä¸ä¸‹é‚£ä¹ˆå¤šçš„æ•°æ®ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸‰æ¬¡è®¿é—®$Q$å’Œ $K$ï¼ˆå¹¶ä¸”é‡æ–°è®¡ç®—ï¼‰ï¼Œè¿™åœ¨$I/O$æ•ˆç‡ä¸Šæ˜¯ä¸åˆ©çš„ã€‚\né‚£ä¹ˆï¼Œæœ‰æ²¡æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥åˆå¹¶ä¸€äº›Passï¼Œå°±åƒæ˜¯æˆ‘ä»¬ç»å¸¸åœ¨Kernel Fusionä¸­åšçš„é‚£æ ·å‘¢ï¼Ÿåˆçœ‹ä¼¼ä¹å›°éš¾ï¼Œå› ä¸ºå…¬å¼(8)ä¾èµ–äºå…¬å¼(7)æ‰€å¾—åˆ°çš„è®¡ç®—ç»“æœï¼Œä½†æ˜¯ï¼Œä½¿ç”¨ä¸€äº›å˜æ¢ï¼Œå¯ä»¥å…è®¸æˆ‘ä»¬ä»¥é‡è®¡ç®—ä¸€éƒ¨åˆ†æ•°æ®ä¸ºä»£ä»·æ¥åˆå¹¶å…¬å¼(7, 8)ã€‚\nç°åœ¨ï¼Œæˆ‘ä»¬æ¥æ¨å¯¼ä¸‹å…¬å¼ï¼Œ\n$$ \\begin{aligned} d_{i}^{\\prime}\u0026amp; =\\sum_{j=1}^ie^{x_j-m_i} \\\\ \u0026amp;= \\left(\\sum_{j=1}^{i-1} e^{x_j-m_i}\\right)+e^{x_i-m_i} \\\\ \u0026amp;= \\left(\\sum_{j=1}^{i-1} e^{x_j-m_{i-1}}\\right)e^{m_{i-1}-m_i}+e^{x_i-m_i} \\\\ \u0026amp;= d_{i-1}\u0026rsquo; e^{m_{i-1}-m_i}+e^{x_i-m_i} \\end{aligned} $$\næˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ä¸ªé€’æ¨çš„å…¬å¼ï¼Œå…¶ä¸­$d_N^{\\prime}$ä¸ºæœ€åæˆ‘ä»¬éœ€è¦çš„åŠ å’Œï¼Œå³$\\sum_{i=0}^{N}e^{x_i-m_N}$ã€‚åœ¨è¿™ä¸ªé€’æ¨å…¬å¼ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ–°çš„$m$æ¥ä¿®æ­£ä¹‹å‰çš„$d_i^{\\prime}$ï¼Œä¹‹å‰é”™è¯¯çš„$m$å¯ä»¥é€šè¿‡å¹‚ç›¸ä¹˜çš„è®¡ç®—è§„åˆ™æ¶ˆå»ã€‚æ€»çš„è®¡ç®—æµç¨‹è¢«ç¼©å‡ä¸º2ä¸ªPassï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\nOnline Softmax 2 passes ä¼ªä»£ç From From Online Softmax to FlashAttention(CSE599m, ML for ML System)\nä½†æ˜¯ï¼Œè¿™ä¸ªè®¡ç®—æ–¹å¼è¿˜æ˜¯æœ‰ä¸¤ä¸ªPassï¼Œæˆ‘ä»¬èƒ½ä¸èƒ½å°†æ‰€æœ‰çš„è®¡ç®—Fuseåˆ°ä¸€ä¸ªPassä¸­å»å‘¢ï¼Ÿ\nåœ¨Online Softmaxä¸­å¾ˆéš¾åšåˆ°è¿™ä¸€ç‚¹ï¼Œå› ä¸º$a_i$æ‰€éœ€è¦çš„$m_N,d_N^{\\prime}$ä¾èµ–äºå…¨å±€æ›´æ–°ã€‚è€Œ$a_i$æ˜¯ä¸€ä¸ªæ— æ³•å…¨å±€æ›´æ–°çš„å˜é‡ï¼Œé™¤éåœ¨ç¬¬ä¸€ä¸ªPassä¸­å†åµŒå¥—ä¸€ä¸ªå¾ªç¯ï¼Œè¿™æ ·è¿èƒŒäº†æˆ‘ä»¬ç®€åŒ–è®¡ç®—çš„åˆè¡·ã€‚ä½†æ˜¯ï¼Œå°†é—®é¢˜æ”¾åœ¨Self-Attentionçš„è®¡ç®—çš„æ—¶å€™ï¼Œå°±å˜å¾—ä¸ä¸€æ ·äº†ã€‚\næˆ‘ä»¬åœ¨è¿™é‡Œå†ç†è§£ä¸‹ï¼Œä¸ºä»€ä¹ˆ2Passçš„Online Safe Softmaxæ˜¯é‡è¦çš„ï¼Œåœ¨Self-Attentionçš„è®¡ç®—ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸‹é¢2ä¸ªä¸»è¦çš„é—®é¢˜ï¼š\néœ€è¦æå‰è®¡ç®—å¥½$QK^T$ï¼Œä¿å­˜åœ¨å…¨å±€æ˜¾å­˜ä¸­ï¼Œéœ€è¦$O(N^2)$çš„æ˜¾å­˜ï¼Œå®¹æ˜“çˆ†æ˜¾å­˜ã€‚ åœ¨ç®—æ³•ä¸­Onlineè®¡ç®—ï¼Œæ¯æ¬¡å¾ªç¯ä¸­å»åŠ è½½ä¸€éƒ¨åˆ†$Q,K$åˆ°ç‰‡ä¸Šå†…å­˜ï¼Œè®¡ç®—å¾—åˆ°éƒ¨åˆ†çš„$QK^T$ã€‚ æ€»çš„æ¥è¯´ï¼ŒOnline Softmaxè§£å†³çš„æ˜¯æ˜¾å­˜ä¸è¶³çš„é—®é¢˜ï¼Œä½†æ˜¯å› ä¸ºæœ‰ä¸¤ä¸ªPassï¼Œè¿˜æ˜¯å­˜åœ¨HBM R/Wæ¬¡æ•°è¾ƒå¤šï¼Œæœ‰Memory Boundï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ¶ˆé™¤è¿™ä¸ªç“¶é¢ˆã€‚è™½ç„¶ç°åœ¨æˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸€ä¸ª$d_i^{\\prime}$åšScaleï¼Œä½†æ˜¯è€ƒè™‘åˆ°ç›®å‰æ˜¾å¡å¹¶ä¸æ˜¯Compute Boundï¼Œè¿™å¤šä½™çš„è®¡ç®—æ˜¯å¯ä»¥æš‚æ—¶ä¸å»è€ƒè™‘çš„ã€‚\n0x03 FA1 è™½ç„¶åœ¨Online Softmaxä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰åŠæ³•å¾—åˆ°ä¸€ä¸ª1 Passçš„ç®—æ³•ï¼Œä½†æ˜¯åœ¨Self-Attentionä¸­ï¼Œæˆ‘ä»¬éœ€è¦çš„æ˜¯è®¡ç®—å‡º$O=A\\times V$ï¼Œè€Œä¸æ˜¯$A$ï¼Œè¿™æœ‰ä»€ä¹ˆä¸åŒå‘¢ï¼Ÿæˆ‘ä»¬æ¥æ¨å¯¼ä¸‹å…¬å¼ï¼Œä¸è¿‡é¦–å…ˆï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹åŸå§‹çš„Self-Attentionæ˜¯æ€ä¹ˆæ±‚è§£çš„ï¼š\nåŸå§‹çš„Self-Attention ä¼ªä»£ç From From Online Softmax to FlashAttention(CSE599m, ML for ML System)\nè¿™å¼ æœªæ‰“ç æµç¨‹å›¾ä»ç„¶æ˜¯ä»CSE 599mä¸­å€Ÿç”¨çš„ã€‚å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ç¬¬ä¸€ä¸ªPassä¸­ï¼Œå°±æ˜¯0x02ç« èŠ‚ä¸­æåŠçš„Online Softmaxï¼›åœ¨ç¬¬äºŒä¸ªPassä¸­ï¼Œ$o_i$çš„è®¡ç®—å¯èƒ½ç¨æœ‰ç‚¹éš¾ä»¥ç†è§£ï¼Œå¯ä»¥ç”»å¼ å›¾ã€‚å®é™…ä¸Šå°±æ˜¯éå†$a_i$å°±æ˜¯$\\text{Attention}$çŸ©é˜µçš„ä¸€è¡Œï¼Œæ‹¿æ¯ä¸€è¡Œçš„æ¯ä¸ªå€¼$a_i$å»ä¹˜$V$çŸ©é˜µçš„æ¯ä¸€è¡Œï¼Œå°±æ˜¯è¡Œä¹˜åˆ—æ“ä½œã€‚è¿™ä¸ªæ“ä½œå¯ä»¥åŒæ—¶æŠŠ$O$çŸ©é˜µçš„ä¸€è¡Œç»™ç®—å‡ºæ¥ã€‚\n$$o_i^{\\prime}:=\\left(\\sum_{j=1}^i\\frac{e^{x_j-m_i}}{d_i^{\\prime}}V[j,:]\\right)$$\nä¸Šé¢çš„å…¬å¼å°±æ˜¯æŠŠPass2å†…éƒ¨çš„è®¡ç®—æ•´åˆåœ¨äº†ä¸€èµ·ï¼Œå’Œ0x02ç« èŠ‚çš„æ¨å¯¼ä¸€æ ·ï¼Œæˆ‘ä»¬ä¹Ÿå»å°è¯•åšé€’æ¨ï¼š\n$$ \\begin{aligned} o_i^{\\prime}\u0026 =\\sum_{j=1}^i\\frac{e^{x_j-m_i}}{d_i'}V[j,:] \\\\ \u0026= \\left(\\sum_{j=1}^{i-1}\\frac{e^{x_j-m_i}}{d_i'}V[j,:] \\right)+\\frac{e^{x_i-m_i}}{d_i'}V[i,: ] \\\\ \u0026= \\left(\\sum_{j=1}^{i-1}\\frac{e^{x_j-m_{i-1}}}{d_{i-1}^{\\prime}}\\frac{e^{x_j-m_i}}{e^{x_j-m_{i-1}}}\\frac{d_{i-1}^{\\prime}}{d_i^{\\prime}}V[j,.]\\right)+\\frac{e^{x_i-m_i}}{d_i^{\\prime}}V[i,.] \\\\ \u0026= \\left(\\sum_{j=1}^{i-1}\\frac{e^{x_j-m_{i-1}}}{d_{i-1}^{\\prime}}V[j,:]\\right)\\frac{d_{i-1}^{\\prime}}{d_i^{\\prime}}e^{m_{i-1}-m_i}+\\frac{e^{x_i-m_i}}{d_i^{\\prime}}V[i,:] \\\\ \u0026=\\begin{array}{c}\\boldsymbol{o}_{i-1}^{\\prime}\\frac{d_{i-1}^{\\prime}e^{m_{i-1}-m_i}}{d_i^{\\prime}}+\\frac{e^{x_i-m_i}}{d_i^{\\prime}}V[i,:]\\end{array} \\end{aligned} $$ å¯ä»¥æ¨å¯¼å‡ºå’ŒOnline Softmaxç›¸ä¼¼çš„å½¢å¼ï¼Œè‡³æ­¤ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºäº†FAç®—æ³•ã€‚\nFA1 ä¼ªä»£ç From From Online Softmax to FlashAttention(CSE599m, ML for ML System)\nå¯ä»¥çœ‹å‡ºï¼Œåœ¨FAç®—æ³•ä¸­ï¼Œ$Q,K,V$éƒ½å¯ä»¥åˆ†å—è½½å…¥ï¼Œæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥å¾—åˆ°FAçš„Tilingæ–¹æ³•ï¼š\nFA1 TiledFrom From Online Softmax to FlashAttention(CSE599m, ML for ML System)\nåœ¨è¿™ç§æ”¹è¿›çš„TilingæŠ€æœ¯ä¸­ï¼ŒKçŸ©é˜µè¢«åˆ’åˆ†ä¸ºå¤šä¸ªè¾ƒå°çš„åŒºå—ï¼ŒåŒæ ·çš„æ–¹æ³•ä¹Ÿé€‚ç”¨äºQçŸ©é˜µã€‚è¿™äº›è¾ƒå°çš„åŒºå—å¯ä»¥è¢«åŠ è½½åˆ°SRAMä¸­ï¼Œä»¥ä¾¿äºè¿›è¡Œé«˜æ•ˆçš„è®¡ç®—ã€‚ä¸€æ—¦è¿™äº›åŒºå—è¢«åŠ è½½ï¼Œå°±å¯ä»¥åœ¨kernelå†…éƒ¨å®Œæˆæ•´ä¸ªæ³¨æ„åŠ›æœºåˆ¶çš„è®¡ç®—è¿‡ç¨‹ã€‚ä»ç®—æ³•çš„è§’åº¦æ¥çœ‹ï¼Œç°åœ¨åªéœ€è¦ä¸€æ¬¡æ€§åŠ è½½Qã€Kã€VçŸ©é˜µï¼Œå°±èƒ½åœ¨å†…æ ¸ä¸­å®Œæˆæ‰€æœ‰çš„æ³¨æ„åŠ›è®¡ç®—ã€‚è¿™ç§ä¼˜åŒ–æ–¹æ³•å°†åŸå§‹3-pass Self Attentionè½¬å˜ä¸º1-pass FlashAttentionï¼Œä¸ä»…èŠ‚çœäº†å­˜å‚¨ä¸­é—´çŸ©é˜µæ‰€éœ€çš„æ˜¾å­˜ï¼Œè¿˜å‡å°‘äº†å¯¹Qå’ŒKçŸ©é˜µçš„HBM R/Wçš„æ¬¡æ•°ã€‚\næœ€ç»ˆï¼ŒFAçš„ç®—æ³•å¯ä»¥è¢«ä¸‹é¢çš„ä¼ªä»£ç æ¥è¡¨ç¤ºï¼š\nFA1 tiled ä¼ªä»£ç From From Online Softmax to FlashAttention(CSE599m, ML for ML System)\næ­¤æ—¶ï¼Œæˆ‘ä»¬å†çœ‹FAçš„ç®—æ³•æµç¨‹å›¾ï¼Œå°±ä¸æ„Ÿè§‰é™Œç”Ÿäº†ã€‚å’Œä¸Šæ–‡ä¸­çš„æ¨å¯¼æ€è·¯ä¸€è‡´ï¼š\nFA1 åŸæ–‡ ä¼ªä»£ç From FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\nåœ¨ç¬¬6è¡Œï¼ŒFAè½½å…¥$K,V$åˆ†å—ï¼Œç„¶ååœ¨ç¬¬8è¡Œéå†å®Œæˆæ‰€æœ‰çš„$Q$ï¼ˆè¿™é‡Œæœ‰ä¸ªæ˜¾è€Œæ˜“è§çš„é—®é¢˜ï¼Œ$Q$çš„éå†æ”¾åœ¨æœ€å¤–é¢ä¼šå¥½å¾ˆå¤šï¼‰ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œå†æ¢è®¨ä¸‹ä¸ºä»€ä¹ˆåˆ†å—$B_c=\\lceil \\frac{M}{4d} \\rceil, B_r=\\min (\\lceil \\frac{M}{4d} \\rceil, d)$ã€‚\nè¿™æ ·è®¾ç½®çš„ç›®çš„æ˜¯ï¼Œä¸ºäº†ç¡®ä¿SRAMèƒ½å¤Ÿæ”¾ä¸‹æ‰€æœ‰$Q, K, V$çš„å°å—ï¼Œå…¶ä¸­$M$å°±æ˜¯ç³»ç»Ÿå¯ç”¨çš„SRAMä¸Šé™ã€‚é‚£ä¹ˆï¼Œå¯¹äºæ¯ä¸€ä¸ª$Q$çš„åˆ†å—$Q_i,O_i$ä»¥åŠ$K, V$çš„åˆ†å—$K_i, V_i$éœ€è¦çš„å…±äº«å†…å­˜ä¸ºï¼š\n$$ \\begin{gathered} SRAM(Q_{i})=B_{r}\\times d=\\min\\left(\\left\\lceil\\frac{M}{4d}\\right\\rceil,d\\right)\\times d\u0026lt;\\lceil\\frac{M}{4}\\rceil \\\\ SRAM(O_i)=B_r\\times d=\\min\\left(\\left\\lceil\\frac{M}{4d}\\right\\rceil,d\\right)\\times d\u0026lt;\\lceil\\frac{M}{4}\\rceil \\\\ SRAM(K_{j},V_{j})=2\\times B_{c}\\times d=2\\times\\left\\lceil\\frac{M}{4d}\\right\\rceil\\times d\u0026lt;\\lceil\\frac{M}{2}\\rceil \\end{gathered} $$\nåœ¨è¿™ä¸ªæƒ…å†µä¸‹ï¼ŒSRAMåŸºæœ¬ä¸Šå¯ä»¥è¢«å æ»¡ã€‚FA1åŸå§‹è®ºæ–‡ä¸­è¯´é“ï¼ŒBlock Size è¶Šå¤§ï¼ŒHBM Accesses è¶Šä½ï¼Œåœ¨256é™„è¿‘åŸºæœ¬å°±æ˜¯æ•ˆç‡æœ€ä¼˜çš„è½¬æŠ˜ç‚¹ã€‚\nFA1 Block Size å®éªŒFrom FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\næ–‡ä¸­çš„å®éªŒæ¡ä»¶æ˜¯A100GPUï¼ŒGPT-2 medium (seq. length 1024, head dim. 64, 16 heads, batch size 64)\n0x04 FA2 åœ¨0x03ç« èŠ‚ä¸­æˆ‘ä»¬æåˆ°ï¼šç„¶ååœ¨ç¬¬8è¡Œéå†å®Œæˆæ‰€æœ‰çš„$Q$ï¼ˆè¿™é‡Œæœ‰ä¸ªæ˜¾è€Œæ˜“è§çš„é—®é¢˜ï¼Œ$Q$çš„éå†æ”¾åœ¨æœ€å¤–é¢ä¼šå¥½å¾ˆå¤šï¼‰ï¼Œè¿™ç‚¹å°±æ˜¯FA2ä¼˜åŒ–çš„å¾ˆé‡è¦çš„ä¸€ç‚¹ã€‚\nFA2ä¸€å…±åšäº†ä¸»è¦çš„å‡ ç§ä¼˜åŒ–ï¼š\nä¼˜åŒ–äº†Scaleçš„æ—¶æœºï¼Œä½¿å¾—é™¤æ³•çš„æ¬¡æ•°è¢«å¤§å¤§å‡å°‘\nForwardä¼˜åŒ–äº†å¾ªç¯çš„é¡ºåºï¼Œä½¿å¾—HBM Accessæ›´åŠ çš„é«˜æ•ˆã€‚Backwardæ²¡æœ‰\nForward/Backwardå‡å¢åŠ äº†Seqç»´åº¦çš„å¹¶è¡Œ\nWarpçš„åˆ†é…æ›´åŠ çš„åˆç†ï¼Œé¿å…Split-K(ä¸æ˜¯å¾ˆç†è§£ï¼Ÿ)\nä¼˜åŒ–äº†Scaleçš„æ—¶æœºï¼Œä½¿å¾—é™¤æ³•çš„æ¬¡æ•°è¢«å¤§å¤§å‡å°‘ è™½ç„¶ä¸€èˆ¬æ¥è¯´ï¼Œématmulè¿ç®—FLOPsè¦æ¯”matmulä½ï¼Œä½†æ˜¯ématmulè®¡ç®—ä½¿ç”¨çš„æ˜¯CUDA Coresï¼Œè€ŒçŸ©é˜µè®¡ç®—å¯ä»¥åˆ©ç”¨Tensor CoresåŠ é€Ÿã€‚åŸºäºTensor Coresçš„matmulè¿ç®—ååæ˜¯ä¸ä½¿ç”¨Tensor Coresçš„ématmulè¿ç®—ååçš„16xã€‚\nä¸FA1ç›¸æ¯”ï¼ŒFA2çš„ä¸»è¦ä¸åŒç‚¹æ˜¯è®¡ç®—æ¯ä¸€æ¬¡çš„$\\boldsymbol{O}^{(n)}$çš„é€»è¾‘ï¼Œè¿™é‡Œä»¥$\\boldsymbol{O}^{(1)},\\boldsymbol{O}^{(2)}$ä¸ºä¾‹æ¥è¯´æ˜ï¼Œåœ¨FA2ä¸­ï¼š\n$$ \\begin{gathered} \\tilde{\\mathbf{o}}^{(1)} =e^{s^{(1)}-m^{(1)}}\\mathbf{V}^{(1)}\\in\\mathbb{R}^{B_{r}\\times d} \\\\ \\tilde{\\mathrm{o}}^{(2)} =e^{s^{(1)}-m}\\mathbf{V}^{(1)}+e^{s^{(2)}-m}\\mathbf{V}^{(2)} \\\\ \\mathrm{o}^{(2)} =\\mathrm{diag}\\left(\\ell^{(2)}\\right)^{-1}\\tilde{\\mathbf{O}}^{(2)}=\\mathbf{O} \\end{gathered} $$\nå…¶ä¸­ï¼Œ$\\tilde{\\mathrm{o}}^{(2)} =e^{s^{(1)}-m}\\mathbf{V}^{(1)}+e^{s^{(2)}-m}\\mathbf{V}^{(2)}$åœ¨è®¡ç®—çš„æ—¶å€™ï¼Œ$e^{s^{(1)}-m}\\mathbf{V}^{(1)}$è¿™ä¸€é¡¹æ˜¯å¯¹$\\tilde{\\mathbf{o}}^{(1)}$åšäº†ç¼©æ”¾ï¼Œç¼©æ”¾å› å­æ˜¯$e^{m^{(1)} - m}$ã€‚ä¹Ÿå°±æ˜¯ï¼š\n$$\\tilde{\\mathrm{o}}^{(2)} = e^{m^{(1)} - m} \\tilde{\\mathbf{o}}^{(1)} +e^{s^{(2)}-m}\\mathbf{V}^{(2)}$$\nç›¸æ¯”äºåŸæ¥çš„FA1ï¼Œæˆ‘ä»¬é¦–å…ˆè®¡ç®—Softmaxçš„åˆ†å­éƒ¨åˆ†ï¼Œåœ¨æœ€åæ‰ç®—ä¸Šåˆ†æ¯ã€‚è¿™æ ·å‡å°‘äº†æ¯æ¬¡è¿­ä»£è€Œå¿…é¡»çš„åˆ†æ¯ç¼©æ”¾ã€‚è€ŒåŸæœ¬çš„FA1çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹å¼æ‰€ç¤ºï¼š\n$$ \\mathbf{O}_{i}\\leftarrow\\mathrm{diag}\\left(\\ell_{i}^{\\mathrm{new}}\\right)^{-1}\\left(\\mathrm{diag}(\\ell_{i})e^{{m_{i}-m_{i}^{\\mathrm{new}}}}\\mathbf{O}_{i}+e^{{\\tilde{m}_{ij}-m_{i}^{\\mathrm{new}}}}\\mathbf{\\tilde{P}}_{ij}\\mathbf{V}_{j}\\right) $$ FA2çš„è®¡ç®—ä¸­ï¼Œå…ˆä¸åœ¨æ¯ä¸ªblockçš„æ¯æ¬¡è¿­ä»£è®¡ç®—ä¸­æ‰§è¡Œå…¨éƒ¨çš„rescaleæ“ä½œï¼Œè€Œæ˜¯æœ€åæ‰§è¡Œä¸€æ¬¡rescaleã€‚æ¯æ¬¡è®¡ç®—å¯ä»¥å‡å°‘ä¸€æ¬¡é™¤æ³•è¿ç®—ã€‚\nFA2 ä¼ªä»£ç From From Online Softmax to FlashAttention(CSE599m, ML for ML System)\nå¯ä»¥çœ‹åˆ°åœ¨åŸæ–‡çš„ä¼ªä»£ç ä¸­ï¼Œåœ¨$T_c$å¾ªç¯ç»“æŸåï¼Œæ‰å»åšäº†åˆ†æ¯ä¸Šçš„è®¡ç®—ã€‚\nç¬¬åè¡Œçš„$\\text{diag}^{-1}$æ˜¯é”™çš„ï¼ŒæŠŠ$^{-1}$å»æ‰ã€‚\nä¼˜åŒ–äº†å¾ªç¯çš„é¡ºåºï¼Œå¢åŠ äº†Seqç»´åº¦çš„å¹¶è¡Œ FA1çš„ä¸¤é‡å¾ªç¯ä¸­ï¼Œæ˜¯å…ˆå¤–å±‚å¾ªç¯load K, Vï¼Œç„¶åå†…å±‚å¾ªç¯å†load Qã€‚è¿™å°±ä¼šå¯¼è‡´å†…å±‚å¾ªç¯ï¼Œæ¯æ¬¡è®¡ç®—çš„åªæ˜¯Qiçš„ä¸€éƒ¨åˆ†ï¼Œæ¯æ¬¡å†…å¾ªç¯çš„è¿­ä»£éƒ½éœ€è¦å¯¹Oiè¿›è¡Œå…¨å±€å†…å­˜çš„è¯»å†™ã€‚è€Œä¸”ï¼Œä¸€ä¸ªæ˜¾è€Œæ˜“è§çš„äº‹å®å°±æ˜¯ï¼Œåœ¨Attentionçš„è®¡ç®—ä¸­ï¼Œä¸åŒqueryçš„Attentionè®¡ç®—æ˜¯å®Œå…¨ç‹¬ç«‹çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœå¤–éƒ¨å¾ªç¯æ˜¯å…ˆload Qï¼Œé‚£ä¹ˆå°±å¯ä»¥æŠŠä¸åŒçš„queryå—çš„Attentionåˆ†é…ä¸åŒthread blockè¿›è¡Œè®¡ç®—ï¼Œè¿™äº›thread blockä¹‹é—´æ˜¯ä¸éœ€è¦é€šä¿¡çš„ã€‚æ²¡é”™ï¼Œåœ¨FA2ä¸­ï¼Œæ­£æ˜¯è¿™æ ·åšçš„ï¼Œå¯¹äºforward passï¼Œç®—æ³•è°ƒæ¢äº†å¾ªç¯çš„é¡ºåºï¼Œå…ˆload Qï¼Œå†load K, Vã€‚\nFA2å¢åŠ seqlenå¹¶è¡Œï¼Œæé«˜äº†occupancyï¼Œå¹¶ä¸”å¯¹äºforward passï¼ŒQ*K^Tåœ¨ã€è¡Œã€‘æ–¹å‘çš„seqlenä¸Šå¤©ç„¶å¯ä»¥å¹¶è¡Œï¼Œthread blockä¹‹é—´ä¸éœ€è¦é¢å¤–çš„é€šä¿¡ã€‚\nWarpçš„åˆ†é…æ›´åŠ çš„åˆç†ï¼Œé¿å…Split-K æ‘˜è‡ª FlashAttentionæ ¸å¿ƒé€»è¾‘ä»¥åŠV1 V2å·®å¼‚æ€»ç»“\nWarp Split-KFrom From Online Softmax to FlashAttention(CSE599m, ML for ML System)\né¦–å…ˆçœ‹fwdï¼Œç›¸æ¯”V1ï¼ŒV2æ”¹è¿›äº†Warp Partitionï¼š4ä¸ªwarpä¼šä»smemçš„K/V tile loadåŒæ ·çš„æ•°æ®åšmmaè®¡ç®—ï¼Œä½†æ˜¯load ä¸åŒQï¼ŒæŠŠV1 sliced-K sliced-V æ”¹æˆäº†v2 sliced-Qï¼ŒV1çš„åšæ³•æ˜¯éœ€è¦warpä¹‹é—´äº§ç”ŸåŒæ­¥é€šä¿¡çš„ï¼Œå› ä¸ºåœ¨è®¡ç®—QKç»“æœä¹˜Vçš„æ—¶å€™ï¼Œå¦‚å›¾æ‰€ç¤ºéœ€è¦è·¨warp reductionå¾—åˆ°Oçš„ç»“æœï¼Œè€Œä¸”fwdçš„ç›®çš„æ˜¯æ²¿ç€è¡Œæ–¹å‘è®¡ç®—softmaxï¼Œè¡Œæ–¹å‘ä¿¡æ¯æœ€åè¦æ±‡æ€»çš„ï¼Œè¿™ä¹Ÿéœ€è¦è·¨warpä¸åŒã€‚V2å°±ä¸éœ€è¦äº†ï¼Œè¿™æ ·å¯ä»¥å‡å°‘åŒæ­¥å¼€é”€ã€‚\n0x05 Causal Maskæ€ä¹ˆç”¨ï¼Ÿ æ‘˜è‡ª [Attentionä¼˜åŒ–][2wå­—]ğŸ”¥åŸç†\u0026amp;å›¾è§£: ä»Online-Softmaxåˆ°FlashAttention V1/V2/V3\néå¸¸ç®€å•çš„Early Exité€»è¾‘ï¼š\næƒ…å†µ0: å…¨Early Exitã€‚å…¨0çš„maskå¯ä»¥ç›´æ¥è¿”å›0ï¼Œæ— éœ€$Q\\times K^T$ï¼Œæ— éœ€causal maskã€‚\næƒ…å†µ1: éƒ¨åˆ†Early Exitã€‚å…¨1çš„maskï¼Œåªéœ€$\\text{Softmax}(Q\\times K^T)$ï¼Œæ— éœ€causal maskã€‚\næƒ…å†µ3: æ— æ³•Early Exitã€‚0-1æ··åˆçš„causal maskï¼Œéœ€QxK^Tï¼Œéœ€è¦causal maskï¼Œç„¶å$\\text{Softmax}(\\text{Mask}(Q \\times K^T))$ã€‚\nMasked ç¤ºæ„å›¾[Attentionä¼˜åŒ–][2wå­—]ğŸ”¥åŸç†\u0026amp;å›¾è§£: ä»Online-Softmaxåˆ°FlashAttention V1/V2/V3\n0x06 MHA/GQA/MQA åœ¨FlashAttentionä¸­ï¼Œä¹Ÿæ”¯æŒMQAå’ŒGQAã€‚å¯¹äºMQAå’ŒGQAçš„æƒ…å½¢ï¼ŒFlashAttentioné‡‡ç”¨Indexingçš„æ–¹å¼ï¼Œè€Œä¸æ˜¯ç›´æ¥å¤åˆ¶å¤šä»½KV Headçš„å†…å®¹åˆ°æ˜¾å­˜ç„¶åå†è¿›è¡Œè®¡ç®—ã€‚Indexingï¼Œå³é€šè¿‡ä¼ å…¥KV/KV Headç´¢å¼•åˆ°Kernelä¸­ï¼Œç„¶åè®¡ç®—å†…å­˜åœ°å€ï¼Œç›´æ¥ä»å†…å­˜ä¸­è¯»å–KVã€‚\n0x07 IOå¤æ‚åº¦åˆ†æ å› ä¸ºFAä¸»è¦æ˜¯ä¼˜åŒ–IO Accesï¼Œæ‰€ä»¥æˆ‘ä»¬åˆ†æä¸‹FAçš„IOå¤æ‚åº¦ã€‚æˆ‘ä»¬å‡è®¾Sequenceçš„é•¿åº¦æ˜¯$N$ï¼Œæ¯ä¸ªå¤´çš„ç»´åº¦æ˜¯$d$ï¼ŒSRAMçš„å¤§å°æ˜¯$M,d \\le M \\le Nd$ã€‚\nä½¿ç”¨åŸå§‹çš„Self Attentionç®—æ³•çš„IOå¤æ‚åº¦æ˜¯$\\Theta(Nd + N^2)$ï¼ŒFA1çš„IOå¤æ‚åº¦æ˜¯$\\Theta(N^2d^2M^{-1})$ï¼Œè€ƒè™‘åˆ°$d$ä¸€èˆ¬æ˜¯64-128ï¼Œè€Œ$M$ä¸€èˆ¬æ˜¯100KBï¼Œæ‰€ä»¥FA1çš„è®¿å­˜æ¬¡æ•°å°äºåŸå§‹çš„åšæ³•ã€‚\nMemory Accesseså’Œdçš„å¹³æ–¹æˆæ­£æ¯”å…³ç³»ï¼Œå½“dè¶Šå¤§ï¼ŒFAçš„Memory Accessesä¼šå¢é•¿å‰§çƒˆã€‚æ¯”å¦‚å¯¹äºN=2K, M=192KB, å½“d=256æ—¶ï¼Œä¾ç„¶æ»¡è¶³ FA IO Acesses \u0026lt; Naive Attentionï¼Œä½†æ˜¯å½“d=512æ—¶ï¼Œè¿™ä¸ªç»“è®ºå°±ä¼šåè¿‡æ¥ï¼Œå˜æˆæ˜¯ FA IO Acesses \u0026gt; Naive Attention IO Acessesï¼Œå¹¶ä¸”ç”±äºFAæœ¬èº«çš„FLOPSå°±æ˜¯æ¯”Naive Attentioné«˜çš„ï¼Œäºæ˜¯ï¼Œæ­¤æ—¶æ— è®ºæ˜¯IOè¿˜æ˜¯FLOPSï¼ŒFAéƒ½ä¼šæ¯”Naive Attentioné«˜ï¼Œæ— è®ºæ˜¯è®¿å­˜è¿˜æ˜¯è®¡ç®—é‡éƒ½æ²¡æœ‰ä¼˜åŠ¿ï¼Œå”¯ä¸€å‰©ä¸‹çš„ä¼˜åŠ¿ï¼Œåº”è¯¥å°±åªå‰©èŠ‚çœæ˜¾å­˜äº†ï¼ˆä¸éœ€è¦ä¿å­˜ä¸­é—´çš„Så’ŒPçŸ©é˜µï¼ŒO(N^2)çš„å†…å­˜å¤æ‚åº¦ï¼‰\n0x08 Tritonä»£ç  å…ˆå†æ¥å¤ä¹ ä¸‹Blockæ˜¯æ€ä¹ˆåˆ‡å—çš„ï¼Œè¿™é‡Œçš„å›¾æ‘˜è‡ªBBufçš„ ç¬”è®°å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼šFlash Attention V2ï¼Œä»åŸç†åˆ°å¹¶è¡Œè®¡ç®—ã€‚\nBlockåˆ‡å—æ–¹å‘å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼šFlash Attention V2ï¼Œä»åŸç†åˆ°å¹¶è¡Œè®¡ç®—\nå¢åŠ äº†Seqç»´åº¦çš„å¹¶è¡Œä»¥åï¼š\nSeqç»´åº¦åˆ‡å—æ–¹å‘å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼šFlash Attention V2ï¼Œä»åŸç†åˆ°å¹¶è¡Œè®¡ç®—\nä¸V1ä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨Qçš„seq_lenç»´åº¦ä¸Šä¹Ÿåšäº†åˆ‡åˆ†ï¼Œå°†å…¶åˆ†æˆå››ä»½ï¼Œå³num_m_block = 4ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬å…±æœ‰1_2_4 = 8ä¸ªblockåœ¨è·‘ã€‚è¿™äº›blockä¹‹é—´çš„è¿ç®—ä¹Ÿæ˜¯ç‹¬ç«‹çš„ï¼Œ å› ä¸ºï¼š\nheadçš„è®¡ç®—æ˜¯ç‹¬ç«‹çš„ï¼Œæ‰€ä»¥çº¢è‰²blockå’Œè“è‰²blockäº’ä¸å¹²æ‰° é‡‡ç”¨Qåšå¤–å¾ªç¯ï¼ŒKVåšå†…å¾ªç¯æ—¶ï¼Œè¡Œä¸è¡Œä¹‹é—´çš„blockæ˜¯ç‹¬ç«‹çš„ï¼Œå› æ­¤ä¸åŒè¡Œçš„blockäº’ç›¸ä¸å¹²æ‰°ã€‚ æ¯ä¸ªblockä»Qä¸ŠåŠ è½½å¯¹åº”ä½ç½®çš„åˆ‡å—ï¼ŒåŒæ—¶ä»KVä¸ŠåŠ è½½head0çš„åˆ‡å—ï¼Œè®¡ç®—å‡ºè‡ªå·±æ‰€ç»´æŠ¤çš„é‚£éƒ¨åˆ†Oï¼Œç„¶åå†™å…¥Oçš„å¯¹åº”ä½ç½®ã€‚\næˆ‘ä»¬ä½¿ç”¨OpenAI Tritonçš„FA2 Tutorialä»£ç æ¥åˆ†æã€‚\nä¸‹é¢çš„ä»£ç æ˜¯æ¯ä¸€ä¸ªå­Blockä¸­çš„æœ€å†…å±‚çš„ä»£ç ï¼Œå…¶ä¸­qæ˜¯æœ€å¤–å±‚å¾ªç¯çš„å­å—ï¼›K_block_ptrã€V_block_ptræ˜¯$K$ã€$V$çš„å­å—ï¼Œéœ€è¦ä¸€æ¬¡forå¾ªç¯å®Œæ•´çš„éå†ã€‚\n@triton.jit def _attn_fwd_inner(acc, l_i, m_i, q, # K_block_ptr, V_block_ptr, # start_m, qk_scale, # BLOCK_M: tl.constexpr, HEAD_DIM: tl.constexpr, BLOCK_N: tl.constexpr, # STAGE: tl.constexpr, offs_m: tl.constexpr, offs_n: tl.constexpr, # N_CTX: tl.constexpr, fp8_v: tl.constexpr): # range of values handled by this stage # æ ¹æ®STAGEçš„å€¼ï¼Œå‡½æ•°å®šä¹‰äº†å¤„ç†çš„é”®ï¼ˆKï¼‰å’Œå€¼ï¼ˆVï¼‰çš„èŒƒå›´ã€‚ # ä¸åŒçš„STAGEå¯¹åº”ä¸åŒçš„å¤„ç†èŒƒå›´ï¼Œæ”¯æŒå› æœï¼ˆcausalï¼‰å’Œéå› æœï¼ˆnon-causalï¼‰çš„è‡ªæ³¨æ„åŠ›ã€‚ if STAGE == 1: # ä½¿ç”¨ Mask lo, hi = 0, start_m * BLOCK_M elif STAGE == 2: # ä½¿ç”¨ Mask lo, hi = start_m * BLOCK_M, (start_m + 1) * BLOCK_M lo = tl.multiple_of(lo, BLOCK_M) # causal = Falseï¼Œä¸ä½¿ç”¨ Mask else: lo, hi = 0, N_CTX # tl.advance æ ¹æ®æ­¥é•¿è°ƒæ•´K_block_ptrçš„æŒ‡å‘ K_block_ptr = tl.advance(K_block_ptr, (0, lo)) V_block_ptr = tl.advance(V_block_ptr, (lo, 0)) # å¯¹K,V Blockåšå®Œæ•´çš„éå† for start_n in range(lo, hi, BLOCK_N): start_n = tl.multiple_of(start_n, BLOCK_N) # -- compute qk ---- # åŠ è½½ K Block k = tl.load(K_block_ptr) # ä¼ªä»£ç  line8: q x k qk = tl.dot(q, k) if STAGE == 2: # Mask mask = offs_m[:, None] \u0026gt;= (start_n + offs_n[None, :]) # Mask åŒºåŸŸåŠ ä¸Š -INF qk = qk * qk_scale + tl.where(mask, 0, -1.0e6) # ä¼ªä»£ç  line 9: Safe online softmax çš„ max m_ij = tl.maximum(m_i, tl.max(qk, 1)) # ä¼ªä»£ç  line 9: s - m qk -= m_ij[:, None] else: # ä¼ªä»£ç  line 9: Safe online softmax çš„ maxï¼Œå’Œä¼ªä»£ç çš„åŒºåˆ«æ˜¯è¿™é‡Œæœ‰ qk_scaleï¼Œç¨åè§£é‡Š m_ij = tl.maximum(m_i, tl.max(qk, 1) * qk_scale) # ä¼ªä»£ç  line 9: s - m. å’Œä¼ªä»£ç çš„åŒºåˆ«æ˜¯è¿™é‡Œæœ‰ qk_scaleï¼Œç¨åè§£é‡Š qk = qk * qk_scale - m_ij[:, None] # ä¼ªä»£ç  line 9: p = exp(s-m) p = tl.math.exp2(qk) # ä¼ªä»£ç  line 9: rowsum(p) l_ij = tl.sum(p, 1) # -- update m_i and l_i # ä¼ªä»£ç  line 10 alpha = tl.math.exp2(m_i - m_ij) l_i = l_i * alpha + l_ij # -- update output accumulator -- # ä¼ªä»£ç  line 10: è¿™é‡Œçš„ acc æ˜¯ä¼ªä»£ç ä¸­çš„ O_i acc = acc * alpha[:, None] # update acc v = tl.load(V_block_ptr) if fp8_v: p = p.to(tl.float8e5) else: p = p.to(tl.float16) # ä¼ªä»£ç  line 10. acc = tl.dot(p, v, acc) # update m_i and l_i m_i = m_ij # æ›´æ–°ä¸‹ä¸€è½®çš„ K,V Blockçš„æŒ‡é’ˆ V_block_ptr = tl.advance(V_block_ptr, (BLOCK_N, 0)) K_block_ptr = tl.advance(K_block_ptr, (0, BLOCK_N)) return acc, l_i, m_i ä¸‹é¢æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹è°ƒç”¨è¿™ä¸ªå­å—å‡½æ•°çš„å‡½æ•°ã€‚\n@triton.autotune(list(filter(keep, configs)), key=[\u0026#34;N_CTX\u0026#34;, \u0026#34;HEAD_DIM\u0026#34;]) @triton.jit def _attn_fwd(Q, K, V, sm_scale, M, Out, # stride_qz, stride_qh, stride_qm, stride_qk, # stride_kz, stride_kh, stride_kn, stride_kk, # stride_vz, stride_vh, stride_vk, stride_vn, # stride_oz, stride_oh, stride_om, stride_on, # Z, H, N_CTX, # HEAD_DIM: tl.constexpr, # BLOCK_M: tl.constexpr, # BLOCK_N: tl.constexpr, # STAGE: tl.constexpr # ): tl.static_assert(BLOCK_N \u0026lt;= HEAD_DIM) # è¾“å…¥å‚æ•°é‡Œçš„Zå’ŒHåˆ†åˆ«è¡¨ç¤ºbatch sizeå’Œæ³¨æ„åŠ›å¤´æ•° # q.shape is [Batch, Head, Seq, Dim] # å¯åŠ¨çš„æ—¶å€™ [grid] æ˜¯ # grid = lambda args: (triton.cdiv(q.shape[2], args[\u0026#34;BLOCK_M\u0026#34;]), q.shape[0] * q.shape[1], 1) # start_mè¡¨ç¤ºå½“å‰kernel program å®ä¾‹å¯¹åº”çš„seqç»´åº¦çš„åç§»ï¼Œè€Œoff_hzè¡¨ç¤ºçš„æ˜¯batch*headsç»´åº¦çš„åç§»ã€‚ start_m = tl.program_id(0) # seq off_hz = tl.program_id(1) # batch * heads # è¿™ä¸¤è¡Œè®¡ç®—äº†ä¸¤ä¸ªåç§»é‡off_zå’Œoff_hï¼Œå®ƒä»¬åˆ†åˆ«ä»£è¡¨åœ¨batchï¼ˆæˆ–headsï¼‰ä¸­çš„ä½ç½®ã€‚ off_z = off_hz // H # è¡¨ç¤ºåœ¨å“ªä¸ª Batch off_h = off_hz % H # è¡¨ç¤ºåœ¨å“ªä¸ª Head # è®¡ç®—ç”¨äºå®šä½Qã€Kå’ŒVå¼ é‡ä¸­å½“å‰å¤„ç†å—çš„åç§»é‡ã€‚è¿™æ˜¯åŸºäºå…ˆå‰è®¡ç®—çš„åç§»é‡å’Œæä¾›çš„æ­¥é•¿å‚æ•°ã€‚ qvk_offset = off_z.to(tl.int64) * stride_qz + off_h.to(tl.int64) * stride_qh # block pointers # ä½¿ç”¨tl.make_block_ptråˆ›å»ºä¸€ä¸ªæŒ‡å‘Qå¼ é‡å½“å‰å¤„ç†å—çš„æŒ‡é’ˆã€‚è¿™ä¸ªå‡½æ•°è°ƒç”¨æŒ‡å®šäº†åŸºç¡€åœ°å€ã€å½¢çŠ¶ã€æ­¥é•¿ã€åç§»é‡å’Œå—å½¢çŠ¶ç­‰ï¼Œä»¥åŠå¦‚ä½•åœ¨å†…å­˜ä¸­è®¿é—®è¿™ä¸ªæ•°æ®å—ã€‚ # N_CTX æ˜¯q.shape[2]ï¼Œè¡¨ç¤ºçš„æ˜¯åºåˆ—é•¿åº¦ï¼ŒBLOCK_DMODELæ˜¯Lkï¼Œè¡¨ç¤ºçš„æ˜¯æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„éšè—å±‚ç»´åº¦å¤§å° # ä¸‹é¢å‡ ä¸ªmake_block_ptråˆ›å»ºçš„å¼ é‡ç±»ä¼¼ï¼Œåˆ†åˆ«æ˜¯å¯¹Kï¼ŒVä»¥åŠè¾“å‡ºOåˆ›å»ºæŒ‡å‘å½“å‰å¤„ç†å—çš„æŒ‡é’ˆ Q_block_ptr = tl.make_block_ptr( base=Q + qvk_offset, shape=(N_CTX, HEAD_DIM), strides=(stride_qm, stride_qk), offsets=(start_m * BLOCK_M, 0), block_shape=(BLOCK_M, HEAD_DIM), order=(1, 0), ) v_order: tl.constexpr = (0, 1) if V.dtype.element_ty == tl.float8e5 else (1, 0) V_block_ptr = tl.make_block_ptr( base=V + qvk_offset, shape=(N_CTX, HEAD_DIM), strides=(stride_vk, stride_vn), offsets=(0, 0), block_shape=(BLOCK_N, HEAD_DIM), order=v_order, ) K_block_ptr = tl.make_block_ptr( base=K + qvk_offset, shape=(HEAD_DIM, N_CTX), strides=(stride_kk, stride_kn), offsets=(0, 0), block_shape=(HEAD_DIM, BLOCK_N), order=(0, 1), ) O_block_ptr = tl.make_block_ptr( base=Out + qvk_offset, shape=(N_CTX, HEAD_DIM), strides=(stride_om, stride_on), offsets=(start_m * BLOCK_M, 0), block_shape=(BLOCK_M, HEAD_DIM), order=(1, 0), ) # initialize offsets # è®¡ç®—Mç»´åº¦ï¼ˆseqç»´åº¦ï¼‰ä¸Šæ¯ä¸ªçº¿ç¨‹åº”å¤„ç†çš„å…ƒç´ çš„èµ·å§‹åç§»é‡ã€‚ offs_m = start_m * BLOCK_M + tl.arange(0, BLOCK_M) # è®¡ç®—Nç»´åº¦ï¼ˆbatch*headsç»´åº¦ï¼‰ä¸Šæ¯ä¸ªçº¿ç¨‹åº”å¤„ç†çš„å…ƒç´ çš„åç§»é‡ã€‚ offs_n = tl.arange(0, BLOCK_N) # initialize pointer to m and l # åˆå§‹åŒ–må‘é‡ï¼Œmç”¨äºå­˜å‚¨æ¯ä¸ªmç»´åº¦ä¸Šçš„æœ€å¤§logitï¼Œåˆå§‹åŒ–ä¸ºè´Ÿæ— ç©·å¤§ã€‚ m_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\u0026#34;inf\u0026#34;) # åˆå§‹åŒ–lå‘é‡ï¼Œlç”¨äºç´¯è®¡softmaxçš„åˆ†æ¯ï¼Œåˆå§‹åŒ–ä¸º1ã€‚ l_i = tl.zeros([BLOCK_M], dtype=tl.float32) + 1.0 # åˆå§‹åŒ–ç´¯åŠ å™¨ï¼Œç”¨äºç´¯ç§¯æ³¨æ„åŠ›åŠ æƒå’Œã€‚æ³¨æ„è¿™é‡Œçš„shapeæ˜¯(BLOCK_M, BLOCK_DMODEL) acc = tl.zeros([BLOCK_M, HEAD_DIM], dtype=tl.float32) # load scales qk_scale = sm_scale qk_scale *= 1.44269504 # 1/log(2) # load q: it will stay in SRAM throughout # å°†QçŸ©é˜µçš„å½“å‰å—åŠ è½½åˆ°SRAMä¸­ï¼Œæ­¤æ•°æ®åœ¨æ•´ä¸ªè®¡ç®—è¿‡ç¨‹ä¸­ä¿æŒä¸å˜ã€‚ q = tl.load(Q_block_ptr) # stage 1: off-band # For causal = True, STAGE = 3 and _attn_fwd_inner gets 1 as its STAGE # For causal = False, STAGE = 1, and _attn_fwd_inner gets 3 as its STAGE if STAGE \u0026amp; 1: acc, l_i, m_i = _attn_fwd_inner(acc, l_i, m_i, q, K_block_ptr, V_block_ptr, # start_m, qk_scale, # BLOCK_M, HEAD_DIM, BLOCK_N, # 4 - STAGE, offs_m, offs_n, N_CTX, V.dtype.element_ty == tl.float8e5 # ) # stage 2: on-band if STAGE \u0026amp; 2: # barrier makes it easier for compielr to schedule the # two loops independently acc, l_i, m_i = _attn_fwd_inner(acc, l_i, m_i, q, K_block_ptr, V_block_ptr, # start_m, qk_scale, # BLOCK_M, HEAD_DIM, BLOCK_N, # 2, offs_m, offs_n, N_CTX, V.dtype.element_ty == tl.float8e5 # ) # epilogue m_i += tl.math.log2(l_i) acc = acc / l_i[:, None] m_ptrs = M + off_hz * N_CTX + offs_m tl.store(m_ptrs, m_i) tl.store(O_block_ptr, acc.to(Out.type.element_ty)) éœ€è¦ç‰¹åˆ«æ³¨æ„çš„æ˜¯è¿™æ®µä»£ç æœ€åçš„epilogueéƒ¨åˆ†å°±å¯¹åº”äº†FlashAttention V2ä¼ªä»£ç ä¸­çš„12è¡Œä»¥åçš„å†…å®¹ï¼Œæ ¹æ®softmaxçš„åˆ†æ¯éƒ¨åˆ†è¾ƒæ­£è¾“å‡ºã€‚æ­¤å¤–ï¼ŒTritonçš„å®ç°é‡Œé¢è€ƒè™‘äº†ä¸€äº›paperé‡Œé¢æ²¡æœ‰çš„ä¸œè¥¿æ¯”å¦‚qk_scaleï¼Œcausal maskï¼Œå¯¹Q*Kçš„ç»“æœSåº”ç”¨äº†å‡æ‰mï¼Œä½¿å¾—æ•´ä¸ªå®ç°çœ‹èµ·æ¥è¦å¤æ‚ä¸å°‘ï¼Œä½†æ•´ä½“çš„ç®—æ³•é€»è¾‘å’Œå¹¶è¡Œè®¾ç½®å’Œpaperè¿˜æ˜¯ä¸€è‡´çš„ã€‚\næœ€ååœ¨Attentionä¸­ä½¿ç”¨è¿™ä¸ªå‡½æ•°\nclass _attention(torch.autograd.Function): @staticmethod def forward(ctx, q, k, v, causal, sm_scale): # shape constraints HEAD_DIM_Q, HEAD_DIM_K = q.shape[-1], k.shape[-1] # when v is in float8_e5m2 it is transposed. HEAD_DIM_V = v.shape[-1] assert HEAD_DIM_Q == HEAD_DIM_K and HEAD_DIM_K == HEAD_DIM_V assert HEAD_DIM_K in {16, 32, 64, 128, 256} o = torch.empty_like(q) stage = 3 if causal else 1 extra_kern_args = {} # Tuning for AMD target if is_hip(): waves_per_eu = 3 if HEAD_DIM_K \u0026lt;= 64 else 2 extra_kern_args = {\u0026#34;waves_per_eu\u0026#34;: waves_per_eu, \u0026#34;allow_flush_denorm\u0026#34;: True} # q.shape is [Batch, Head, Seq, Dim] grid = lambda args: (triton.cdiv(q.shape[2], args[\u0026#34;BLOCK_M\u0026#34;]), q.shape[0] * q.shape[1], 1) M = torch.empty((q.shape[0], q.shape[1], q.shape[2]), device=q.device, dtype=torch.float32) # Launch Kernel. _attn_fwd[grid]( q, k, v, sm_scale, M, o, # q.stride(0), q.stride(1), q.stride(2), q.stride(3), # k.stride(0), k.stride(1), k.stride(2), k.stride(3), # v.stride(0), v.stride(1), v.stride(2), v.stride(3), # o.stride(0), o.stride(1), o.stride(2), o.stride(3), # q.shape[0], q.shape[1], # N_CTX=q.shape[2], # HEAD_DIM=HEAD_DIM_K, # STAGE=stage, # **extra_kern_args) ctx.save_for_backward(q, k, v, o, M) ctx.grid = grid ctx.sm_scale = sm_scale ctx.HEAD_DIM = HEAD_DIM_K ctx.causal = causal return o 0x09 CUDAä»£ç  0x0A FA 3 0x0B æ€è€ƒ CPUä¸Šä½¿ç”¨è¿™ä¸ªé è°±å—ï¼ŸCPUä¸Šå¹¶è¡Œåº¦è¾ƒä½ï¼Œç”¨è¿™ä¸ªæ²¡æœ‰å¿…è¦ï¼Œä½†æ˜¯å¯ä»¥è€ƒè™‘åˆ†å—å’ŒMaskæ··åˆçš„MatMulæ¥å‡å°‘è®¡ç®—é‡ï¼Œä¹Ÿå°±æ˜¯Early Exitã€‚ ","permalink":"https://chenghuawang.github.io/keep-moving-forward/tech/fundamental_from_online_softmax_to_flash_attentionv3/","summary":"Flash Attention from Fundamental Series","title":"[Fundamental] From Online Softmax to Flash Attention V3"},{"content":" ç¬”è€…æœ€è¿‘åœ¨åšä¸€äº›mllmç›¸å…³çš„å·¥ä½œï¼Œä¹¦å†™æ­¤æ–‡å¯¹mllmæ¡†æ¶è¿›è¡Œæ¢³ç†æ€»ç»“ï¼Œå®šæœ‰ä¸å°‘çº°æ¼ï¼Œè¯·è¯»è€…ç«‹å³æŒ‡å‡ºï¼Œè°¢è°¢ã€‚mllmç›®å‰åœ¨åšä¸€äº›å…¶ä»–å·¥ä½œï¼Œè¿™ç¯‡æ–‡ç« çš„ä¹¦å†™æ—¶é—´ä¸ºå‘å¸ƒæ—¶é—´ã€‚åœ¨mllmçš„å…¶ä»–å·¥ä½œåˆå¹¶è¿›ä¸»ä»“åº“åï¼Œæœ¬æ–‡è¿˜ä¼šè¿›ä¸€æ­¥çš„è·Ÿè¿›ã€‚è¯»è€…è¯·æ³¨æ„æœ¬æ–‡çš„æ—¶æ•ˆæ€§ã€‚\n1. ç®€ä»‹ mllmæ˜¯ä¸€æ¬¾é€‚ç”¨äºç§»åŠ¨è®¾å¤‡å’Œè¾¹ç¼˜è®¾å¤‡çš„å¿«é€Ÿã€è½»é‡çš„å¤šæ¨¡æ€LLMæ¨ç†å¼•æ“ã€‚\nå®Œå…¨çš„C/C++å®ç°ï¼Œæ— ç¬¬ä¸‰æ–¹ä¾èµ– é’ˆå¯¹fuyu-8Bç­‰å¤šæ¨¡æ€LLMè¿›è¡Œäº†ä¼˜åŒ– æ”¯æŒARM NEONå’ŒX86 AVX2å‘é‡æŒ‡ä»¤ æ”¯æŒ4 bitså’Œ6 bitsæ•´æ•°é‡åŒ– æœ¬æ–‡å°†æ›´å¤šçš„ä»¥å·¥ç¨‹çš„è§†è§’æ¥è§£æmllmæ¡†æ¶ï¼Œåœ¨è¡Œæ–‡è¿‡ç¨‹ä¸­ï¼Œæœ¬æ–‡ä¼šå°†mllmä¸å…¶ä»–æ¡†æ¶çš„è®¾è®¡æ–¹æ³•åšå¯¹æ¯”ã€‚æ¥ä¸‹æ¥ï¼Œæœ¬æ–‡å°†ä¼šç”¨é¡¹ç›®ç»„ç»‡ç»“æ„ã€æ¡†æ¶æ‰§è¡Œæµç¨‹ã€è‡ªå®šä¹‰Op/Layerã€Tokenizerå’Œå¦‚ä½•æ”¯æŒæ–°æ¨¡å‹äº”ä¸ªç« èŠ‚æ¥è¯¦ç»†æè¿°mllmæ¡†æ¶çš„å„é¡¹ç‰¹æ€§å’Œæ€»ä½“ç»“æ„ã€‚è¯»è€…å¯ä»¥æŠŠè¯¥æ–‡ç« åšmllmçš„ä½¿ç”¨æ–‡æ¡£ã€‚åœ¨æœ€åï¼Œæœ¬æ–‡å°†ä¼šæŒ‡å‡ºmllmçš„ä¸è¶³ä¹‹å¤„å’Œå¯ä»¥å°è¯•è·Ÿè¿›çš„å·¥ä½œã€‚\nåœ¨å¼€å§‹æ­£å¼è§£æmllmä¹‹å‰ï¼Œè¯»è€…å¯ä»¥å…ˆcloneä¸‹mllmçš„ä»£ç åº“ï¼Œä»¥ä¾¿äºè·Ÿè¿›åˆ†ææµç¨‹ã€‚mllmä¸ä¾èµ–äºgit submoduleï¼Œé¡¹ç›®é…ç½®èµ·æ¥å¾ˆæ–¹ä¾¿ï¼Œç›®å‰mllmå¯ä»¥åœ¨linuxä¸Šä½¿ç”¨Clang/GCCç¼–è¯‘å™¨è¿›è¡Œç¼–è¯‘ã€‚ç›®å‰mllmæ”¯æŒçš„ç›®æ ‡è®¾å¤‡ä½“ç³»ç»“æ„æ˜¯X86å’ŒArmã€‚\ngit clone https://github.com/UbiquitousLearning/mllm mllmå›¢é˜Ÿå°†æ‰€æœ‰LLMç›¸å…³çš„vocabæ–‡ä»¶éƒ½æ”¾åœ¨äº†gitä»“åº“ä¸­ï¼ˆè¿™ä¸ªå…¶å®å¯ä»¥ç§»åŠ¨åˆ°HuggingFaceçš„ä»“åº“ä¸Šï¼‰ï¼ŒLLMé‡åŒ–åçš„æ¨¡å‹æ–‡ä»¶éƒ½å­˜å‚¨åœ¨HuggingFaceä¸Šï¼Œè¯»è€…å¯ä»¥åœ¨https://huggingface.co/mllmTeamä¸Šæ‰¾åˆ°mllmæä¾›çš„æ¨¡å‹æ–‡ä»¶ã€‚\n2. æ¡†æ¶æ‰§è¡Œæµç¨‹ 2.1 ä»¥ä¸¤å±‚Linearå±‚è¿è¡Œä¸ºä¾‹ é¦–å…ˆï¼Œè€ƒè™‘ä¸‹é¢çš„ä»£ç ï¼Œå®šä¹‰äº†ä¸¤ä¸ªLinear Layersï¼Œå¹¶ä¸”è¾“å…¥$X$é€šè¿‡ä¸¤ä¸ªLinear Layersæ¥å¾—åˆ°è¾“å‡ºï¼š\nclass TwoLinear final : public Module { public: TwoLinear() = default; TwoLinear() { linear1 = Linear(in_f, out_f, /*bias*/true, \u0026#34;linear1\u0026#34;); linear2 = Linear(out_f, out_f, /*bias*/true, \u0026#34;linear2\u0026#34;); } std::vector\u0026lt;Tensor\u0026gt; Forward(std::vector\u0026lt;Tensor\u0026gt; inputs, std::vector\u0026lt;std::any\u0026gt; args) override { x = inputs[0]; x = linear1(x); x = linear2(x); return x; } private: Layer linear1; Layer linear2; } TwoLinear tl; 2.1.1 åŠ è½½å‚æ•° è¯»è€…å¯ä»¥ä½¿ç”¨ tl.load(path)æ¥åŠ è½½å‚æ•°ã€‚é‚£ä¹ˆmllmæ˜¯å¦‚ä½•å®ç°å‚æ•°åŠ è½½çš„å‘¢ï¼Ÿåœ¨loadå‡½æ•°ä¸­ï¼Œmllmä¼šåˆ›å»ºä¸€ä¸ªParamLoaderï¼Œè¿™ä¸ªParamLoaderæ˜¯Staticçš„ï¼Œåœ¨å…¨å±€å¯ä»¥è®¿é—®ã€‚ç„¶åmllmä¼šè®¾ç½®å¦ä¸€ä¸ªå…¨å±€å‚æ•°doLoadä¸ºTrueï¼Œè¿›è€Œè¿›å…¥æ¨ç†æµç¨‹operator()(tmps, tmpt);ã€‚åœ¨æ¨ç†æµç¨‹ä¸­ï¼Œè¦æ˜¯æ‰§è¡Œå±‚å‘ç°doLoadä¸ºTrueï¼Œé‚£ä¹ˆå°±æ‰§è¡Œæ¯ä¸ªç®—å­å†…å®šä¹‰å¥½çš„loadæŒ‡ä»¤ï¼Œè€Œä¸æ˜¯æ‰§è¡Œæ¯ä¸ªç®—å­çš„åŸæœ¬é€»è¾‘ã€‚ loadçš„æ‰§è¡Œåœ¨Layer.hppæ–‡ä»¶çš„INIT_OP()ä¸­ã€‚\n2.1.2Moduleçš„Operator()æ˜¯å¦‚ä½•è°ƒç”¨Forwardå‡½æ•°çš„ï¼Ÿ å¯¹äºå¸¸è§çš„INPUT_TENSORç±»å‹çš„Tensorï¼Œmllmé¦–å…ˆä¼šè®¾ç½®è¿™ä¸ªTensorçš„ç±»å‹ä¸ºTENSOR_STATIC_INITï¼Œè¿›è¡Œä¸€éForwardæ¨ç†ï¼›ç¬¬ä¸€éForwardæ¨ç†å®Œæ¯•ä»¥åå†æŠŠTensorçš„ç±»å‹è®¾ä¸ºTENSOR_STATIC_READYï¼Œç„¶åè¿›è¡Œç¬¬äºŒéForwardæ¨ç†ã€‚\nif (inputs[0].ttype() == TensorType::INPUT_TENSOR) { for (auto \u0026amp;input : inputs) { input.setTtype(TensorType::NORMAL_TENSOR); input.status() = TENSOR_STATIC_INIT; if(input.batch() == 0){ Tensor::gph_[input.name()] = input; } } tensor_status = TENSOR_STATIC_INIT; Forward(inputs, anyArgs); for (auto \u0026amp;input : inputs) { input.status() = TENSOR_STATIC_READY; } tensor_status = TENSOR_STATIC_READY; return Forward(inputs, anyArgs); } ç¬¬ä¸€æ¬¡Forwardæ¨ç†çš„ç›®çš„æ˜¯è°ƒç”¨Opå®šä¹‰çš„Reshapeå’ŒSetUpå‡½æ•°ï¼ŒReshapeå‡½æ•°ä¼šæ¨ç†å‡ºè¿™ä¸€æ¬¡æ¨¡å‹æ¨ç†çš„è¿‡ç¨‹ä¸­æ¯ä¸ªTensorçš„å½¢çŠ¶å¤§å°ã€‚SetUpå‡½æ•°ä¼šå¯¹Opéœ€è¦è¾“å‡ºçš„Tensoråšå†…å­˜çš„ç”³è¯·ã€‚ ç¬¬äºŒæ¬¡Forwardæ¨ç†æ‰æ˜¯çœŸæ­£çš„è®¡ç®—ã€‚\n2.1.3 Linearå±‚çš„æ‰§è¡Œ æ¯ä¸ªLayeråœ¨å®ç°çš„æ—¶å€™éƒ½ä¼šé‡è½½operator()ï¼Œæ¯”å¦‚linear layerçš„operator()å‡½æ•°å¦‚ä¸‹ï¼š\nTensor \u0026amp;operator()(Tensor \u0026amp;input) { return _1I1O_OP(input); } å…¶ä¸­ï¼Œ_1I1O_OPè¡¨ç¤ºçš„æ„æ€æ˜¯ï¼Œè¿™æ˜¯éœ€è¦ä½¿ç”¨1ä¸ªè¾“å…¥å’Œ1ä¸ªè¾“å‡ºçš„å‡½æ•°æ¥å¤„ç†è¿™ä¸ªç®—å­ã€‚mllmè¿˜æä¾›äº†è®¸å¤šç±»ä¼¼äº_1I1O_OPçš„å‡½æ•°æ¥å¤„ç†ä¸åŒçš„ç®—å­ã€‚\n2.2 æ€»ç»“ å¤§ä½“æ¥è¯´ï¼Œmllmä½¿ç”¨äº†ç±»ä¼¼äºçŠ¶æ€æœºçš„å‚æ•°æ¥è®¾ç½®äº†å½“å‰æ¨ç†è¿‡ç¨‹çš„è¿è¡ŒçŠ¶æ€ã€‚æ¯ä¸€æ¬¡éƒ½æ˜¯é€šè¿‡Forwardå‡½æ•°æ¥è¿›è¡Œå…¨æ¨¡å‹çš„éå†ï¼Œåœ¨Opçš„æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œç”¨è¿™äº›è®¾å®šçš„å‚æ•°æ¥åŒºåˆ†æ¯æ¬¡Opéœ€è¦è¡¨ç°çš„è¡Œä¸ºã€‚\n3. å¦‚ä½•ç¼–å†™Opä¸è‡ªå®šä¹‰Layer 3.1 æ–°å¢å¯¹åº”Backendçš„Opæ–‡ä»¶ mllmæä¾›äº†src/backends/new_op.pyå®ç”¨å·¥å…·æ¥å¸®åŠ©åˆ›å»ºOp Classã€‚è¯¥æ–‡ä»¶ä¼šå¸®åŠ©è¯»è€…åˆ›å»ºä¸‹è¿°åŸºæœ¬å‡½æ•°ï¼š\nErrorCode reshape(vector\u0026lt;shared_ptr\u0026lt;Tensor\u0026gt;\u0026gt; inputs, vector\u0026lt;shared_ptr\u0026lt;Tensor\u0026gt;\u0026gt; outputs) override; ErrorCode execute(vector\u0026lt;shared_ptr\u0026lt;Tensor\u0026gt;\u0026gt; inputs, vector\u0026lt;shared_ptr\u0026lt;Tensor\u0026gt;\u0026gt; outputs) override; ErrorCode load(AbstructLoader \u0026amp;loader) override; ErrorCode free(vector\u0026lt;shared_ptr\u0026lt;Tensor\u0026gt;\u0026gt; inputs, vector\u0026lt;shared_ptr\u0026lt;Tensor\u0026gt;\u0026gt; outputs) override; ErrorCode setUp(vector\u0026lt;shared_ptr\u0026lt;Tensor\u0026gt;\u0026gt; inputs, vector\u0026lt;shared_ptr\u0026lt;Tensor\u0026gt;\u0026gt; outputs) override; 3.2 Opå‚æ•°è‡ªå®šä¹‰ æ¯”å¦‚å¯¹äºCPUä¸Šçš„LinearOpï¼Œéœ€è¦in_featuresã€out_featureså’Œhas_biasä¸‰ä¸ªå‚æ•°ã€‚é‚£ä¹ˆå¯ä»¥åœ¨3.1è‡ªåŠ¨ç”Ÿæˆçš„classä¸­åŠ å…¥ï¼š\nclass CPULinear final : public Op { ... private: int in_features_; int out_features_; bool support_bias_; int thread_count = 4; Tensor weight_; Tensor bias_; }; åœ¨CPULinearCreatorä¸­åŠ å…¥ï¼š\nclass CPULinearCreator : public CPUBackend::Creator { public: virtual Op *create(OpParam op_param, Backend *bn, string name, int threadCount) const { int in_features = op_param[\u0026#34;in_features\u0026#34;]; int out_features = op_param[\u0026#34;out_features\u0026#34;]; int bias = op_param[\u0026#34;bias\u0026#34;]; return new CPULinear(bn, name, in_features, out_features, (bool)bias, threadCount); } }; è¯·æ³¨æ„ï¼ŒOpParamæ˜¯ä¸€ä¸ªstring-float mapã€‚\n3.3 é‡è½½å‡½æ•° è¯»è€…éœ€è¦è‡ªè¡Œå®ç°reshapeï¼Œexecuteï¼Œloadï¼Œfreeå‡½æ•°ï¼Œè§†æƒ…å†µé‡è½½setUpå‡½æ•°ã€‚ ä»¥Linear Opä¸ºä¾‹ï¼Œreshapeå‡½æ•°å°±ä¼šé€šè¿‡in_features_å˜é‡æ¥æ£€æŸ¥è¾“å…¥çš„Tensorçš„ç»´åº¦æ˜¯å¦æ­£ç¡®ï¼Œç„¶åå¯¹output Tensoråšoutputs[0]-\u0026gt;reshape(inputs[0]-\u0026gt;batch(), inputs[0]-\u0026gt;head(), inputs[0]-\u0026gt;sequence(), out_features_)\nåœ¨loadå‡½æ•°ä¸­ï¼Œå®ç°Weightå’ŒBiasçš„åŠ è½½ã€‚\nåœ¨executeå‡½æ•°ä¸­ï¼Œå…·ä½“å®ç°çŸ©é˜µä¹˜æ³•ç­‰è®¡ç®—æ“ä½œã€‚\nåœ¨freeå‡½æ•°ä¸­é‡Šæ”¾Weightå’ŒBiasã€‚\n3.4 Opæ˜¯å¦‚ä½•è¢«æ³¨å†Œå’Œåˆ›å»ºçš„ï¼Ÿ åœ¨å®šä¹‰å®ŒæˆOpåï¼Œè¯»è€…è¿˜éœ€è¦æŠŠè¯¥Opæ³¨å†Œåˆ°ç›¸åº”çš„Backendä¸­ï¼Œä»¥åŠå°†OpæŠ½è±¡æˆLayerã€‚\n3.4.1 åœ¨Backendä¸­æ³¨å†ŒOp ä»¥CPU Backendä¸ºä¾‹ï¼Œè¯»è€…éœ€è¦å†CPUBackendæ–‡ä»¶ä¸­åŠ å…¥addCreator(LINEAR, (CPUBackend::Creator *)(new CPULinearCreator()));\nå¦‚æœè¿™æ˜¯ä¸€ä¸ªæ–°çš„ç®—å­ï¼Œè¯»è€…è¿˜éœ€è¦åœ¨OpDefinedæ–‡ä»¶ä¸­åŠ å…¥æ–°Opçš„Enumé¡¹ã€‚\n3.4.2 åœ¨Layer.hppä¸­åŠ å…¥å¯¹åº”çš„Op Layer å¦‚Linear Layer:\nclass Linear final : public Layer { public: explicit Linear(int in_features, int out_features, bool bias, std::string name) { param_[\u0026#34;in_features\u0026#34;] = in_features; param_[\u0026#34;out_features\u0026#34;] = out_features; param_[\u0026#34;bias\u0026#34;] = (float)bias; init(std::move(name), OpType::LINEAR); } Tensor \u0026amp;operator()(Tensor \u0026amp;input) { return _1I1O_OP(input); } }; å…¶ä¸­ï¼Œåœ¨æ„é€ å‡½æ•°ä¸­çš„**init()**å‡½æ•°å¹¶æ²¡æœ‰åˆ›å»ºè¿™ä¸ªLinearç®—å­ã€‚å®ƒåªæ˜¯è´Ÿè´£ç»™è¿™ä¸ªLinearæŒ‡æ´¾äº†Backendã€‚ çœŸæ­£çš„ç®—å­åˆ›å»ºè¿˜æ˜¯åœ¨INIT_OP()å‡½æ•°ä¸­ã€‚åœ¨è¿™ä¸ªå‡½æ•°ä¸­ï¼Œå®ƒä¼šé€šè¿‡backend_-\u0026gt;opCreate(param_, name_);æ¥åˆ›å»ºç®—å­ã€‚\n4. Tokenizer mllmæä¾›äº†åŸºç¡€çš„Tokenizeræ”¯æŒï¼Œç›®å‰æ”¯æŒBPEå’ŒUnigramä¸¤ç§åˆ†è¯ç®—æ³•ã€‚\n5. å¦‚ä½•å¯¹æ–°æ¨¡å‹è¿›è¡Œæ”¯æŒ åœ¨mllmä¸­ï¼Œå¯¹æ¨¡å‹ç»„ä»¶ï¼ˆmodelã€Tokenizerã€Configurationï¼‰çš„å®šä¹‰å’ŒHuggingFace Transformeråº“ä¸­çš„å®šä¹‰æ–¹æ³•åŸºæœ¬ä¸€è‡´ã€‚ä»¥æ”¯æŒQWen0.5Bæ¨¡å‹ä¸ºä¾‹ï¼Œéœ€è¦ç¼–å†™ä¸‰ä¸ªæ–‡ä»¶ï¼š\nconfiguration_qwen.cpp modeling_qwen.cpp tokenization_qwen.cpp å…¶ä¸­configuration_qwen.cppå®šä¹‰äº†Qwen LLMçš„å„ç±»å‚æ•°ï¼Œå¦‚Headæ•°é‡ï¼Œhidden dimç­‰ã€‚modeling_qwen.cppå®šä¹‰äº†Qwen LLMç½‘ç»œã€‚tokenization_qwen.cppåŒ…å«äº†å°†å¥å­è½¬åŒ–ä¸ºTokençš„é¢„å¤„ç†è¡Œä¸ºã€‚\n5.1 ç”Ÿæˆmllmæ”¯æŒçš„vocabå’Œæ¨¡å‹å‚æ•° 5.1.1 æ¨¡å‹è½¬æ¢ ä½¿ç”¨mllmæä¾›çš„Converterå®ç”¨å·¥å…·æ¥è¿›è¡Œè½¬æ¢ï¼š\ncd tools/convertor pip install -r ./requirements.txt # for one file pytorch model python convert.py --input_model=model.pth --output_model=model.mllm --type=torch # for multi-file pytorch model python convert.py --input_model=pytorch_model.bin.index.json --output_model=model.mllm --type=torch # for one file safetensor model python convert.py --input_model=model.bin --output_model=model.mllm --type=safetensor # for multi-file safetensor model python convert.py --input_model=model.safetensors.index.json --output_model=model.mllm --type=safetensor 5.1.2 Vocabè½¬æ¢ ä½¿ç”¨mllmæä¾›çš„Converterå®ç”¨å·¥å…·æ¥è¿›è¡Œè½¬æ¢ï¼š\ncd tools/convertor python vocab.py --input_file=tokenizer.json --output_file=vocab.mllm --type=Unigram 5.1.3 é‡åŒ– mllmæä¾›äº†é‡åŒ–å·¥å…·ï¼Œè¯¥å·¥å…·æ”¯æŒ4 bitså’Œ6 bitsæ•´æ•°é‡åŒ–ï¼Œä½ å¯ä»¥ä½¿ç”¨ä¸‹è¿°æŒ‡ä»¤æ¥å¯¹æ¨¡å‹å‚æ•°è¿›è¡Œé‡åŒ–\ncd bin ./quantize model.mllm model_q4_0.mllm Q4_K 5.2 Configuration è®¾ç½®æ–‡ä»¶é‡Œé¢ä¸»è¦å®ç°ä¸¤ä¸ªç±»ï¼Œä¸€ä¸ªæ˜¯QWenNameConfigï¼Œä¸€ä¸ªæ˜¯QWenConfigï¼Œå…¶ä¸­QWenNameConfigåŒ…å«QWenConfigã€‚åœ¨ä¸€ä¸ªmllmæ¨¡å‹å‚æ•°æ–‡ä»¶ä¸­ï¼Œæ¨¡å‹å‚æ•°æ˜¯ä»¥key-valueå¯¹çš„å½¢å¼ç»Ÿä¸€èµ·æ¥çš„ã€‚QWenNameConfigçš„ç›®çš„å°±æ˜¯ç»™å‡ºæ¯ä¸ªå‚æ•°çš„åç§°ï¼Œä»¥ä¾¿äºmllmæ¡†æ¶ç´¢å¼•åˆ°æ­£ç¡®çš„æ¨¡å‹å‚æ•°ã€‚\nclass QWenNameConfig : public TransformerNameConfig { public: /** * @brief QWen2 following the hugging face naming method * * @param type RoPEType */ void init(RoPEType type = RoPEType::HFHUBROPE) { switch (type) { case RoPEType::HFHUBROPE: { blk_name = \u0026#34;model.layers.\u0026#34;; _attn_base_name = \u0026#34;self_attn.\u0026#34;; _ffn_base_name = \u0026#34;mlp.\u0026#34;; _q_proj_name = \u0026#34;q_proj\u0026#34;; _k_proj_name = \u0026#34;k_proj\u0026#34;; _v_proj_name = \u0026#34;v_proj\u0026#34;; _o_proj_name = \u0026#34;o_proj\u0026#34;; _gate_proj_name = \u0026#34;gate_proj\u0026#34;; _up_proj_name = \u0026#34;up_proj\u0026#34;; _down_proj_name = \u0026#34;down_proj\u0026#34;; _attn_norm_name = \u0026#34;input_layernorm\u0026#34;; _ffn_norm_name = \u0026#34;post_attention_layernorm\u0026#34;; token_embd_name = \u0026#34;model.embed_tokens\u0026#34;; post_norm_name = \u0026#34;model.norm\u0026#34;; lm_head_name = \u0026#34;lm_head\u0026#34;; break; } ... } } std::string blk_name; std::string token_embd_name; std::string post_norm_name; std::string lm_head_name; std::string _gate_proj_name; }; åœ¨QWenConfigä¸­åˆ™ä¸»è¦å®šä¹‰å„å±‚çš„è¶…å‚æ•°ï¼Œå¦‚ropeçš„thetaå€¼ã€ä¸­é—´å±‚ç»´åº¦å¤§å°ç­‰ï¼Œå¦‚ä¸‹é¢çš„ä»£ç æ‰€ç¤ºï¼š\nstruct QWenConfig { explicit QWenConfig(int token_limit, string billions = \u0026#34;0.5B\u0026#34;, RoPEType type = RoPEType::HFHUBROPE) : cache_limit(token_limit) { ... }; float attention_dropout = 0.0; int bos_token_id = 151643; int eos_token_id = 151643; std::string hidden_act = \u0026#34;silu\u0026#34;; int hidden_size = 1024; float initializer_range = 0.02; int intermediate_size = 2816; int max_position_embeddings = 32768; int max_window_layers = 21; std::string model_type = \u0026#34;qwen2\u0026#34;; int num_attention_heads = 16; int num_hidden_layers = 24; int num_key_value_heads = 16; double rms_norm_eps = 1e-6; float rope_theta = 1000000.0; int sliding_window = 32768; int vocab_size = 151936; bool tie_embedding_words = false; int cache_limit; RoPEType RoPE_type = RoPEType::HFHUBROPE; QWenNameConfig names_config; }; 5.3 Tokenization Tokenizationæ˜¯ä¸€ä¸ªéå¸¸å®¢åˆ¶åŒ–çš„æ­¥éª¤ï¼Œæ¯ä¸ªLLMçš„Tokenizationæ–¹æ³•éƒ½ä¸å°½ç›¸åŒã€‚ä»¥QWenä¸ºä¾‹å­ï¼ŒQWenä½¿ç”¨äº†BBPEæ–¹æ³•ï¼Œé‚£ä¹ˆè¯»è€…åœ¨æ”¯æŒQWenæ¨¡å‹çš„æ—¶å€™ï¼Œå°±è¦ç»™å‡ºå®ç°äº†BBPEçš„Tokenizerã€‚mllmå†…éƒ¨å·²ç»å®ç°ä¸€ä¸ªBPEç®—æ³•ï¼Œè¯»è€…å¯ä»¥å¤ç”¨è¯¥å®ç°æ¥å®ç°è‡ªå·±çš„Tokenizerã€‚\n5.4 Modeling ä½¿ç”¨mllmæ¡†æ¶æä¾›çš„ç®—å­æ¥å®ç°æ¨¡å‹æ˜¯éå¸¸ç®€å•å’Œä¾¿åˆ©çš„ï¼Œç†Ÿæ‚‰Pytorchçš„è¯»è€…å¯ä»¥å¿«é€Ÿçš„ä¸Šæ‰‹mllmã€‚æœ¬æ–‡åœ¨è¿™é‡Œé»˜è®¤è¯»è€…å¯¹llama/qwen/mistralç­‰å¸¸è§LLMçš„æ¨¡å‹æœ‰ç€åŸºæœ¬çš„äº†è§£ã€‚åœ¨ä¸‹æ–‡ä¸­ï¼Œæœ¬æ–‡ä»¥Attentionæ¨¡å—ä¸ºä¾‹æ¥æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨mllmæ¥æ­å»ºæ¨¡å‹ã€‚ é¦–å…ˆï¼Œæ‰€æœ‰çš„classéœ€è¦ç»§æ‰¿Moduleçˆ¶ç±»ã€‚Moduleçˆ¶ç±»æä¾›äº†Forwardå‡½æ•°ï¼Œè¯»è€…éœ€è¦é‡è½½è¯¥å‡½æ•°æ¥å®ç°ç›¸åº”çš„è®¡ç®—æµç¨‹ã€‚\nclass QWenAttention final : public Module ... 5.4.1 åˆ›å»ºè¯¥Moduleéœ€è¦ä½¿ç”¨çš„Layers class QWenAttention final : public Module { publicï¼š QWenAttention() = default; QWenAttention(const QWenConfig \u0026amp;config, const QWenNameConfig \u0026amp;names, const string \u0026amp;base_name) { hidden_size = config.hidden_size; num_heads = config.num_attention_heads; head_dim = config.hidden_size / num_heads; num_key_value_heads = config.num_key_value_heads; num_key_value_groups = num_heads / num_key_value_heads; // init layers q_proj = Linear(hidden_size, num_heads * head_dim, true, base_name + names._q_proj_name); k_proj = Linear(hidden_size, num_key_value_heads * head_dim, true, base_name + names._k_proj_name); v_proj = Linear(hidden_size, num_key_value_heads * head_dim, true, base_name + names._v_proj_name); o_proj = Linear(num_heads * head_dim, hidden_size, false, base_name + names._o_proj_name); q_rope = RoPE(config.RoPE_type, config.rope_theta, config.max_position_embeddings, base_name + \u0026#34;q_rope\u0026#34;); k_rope = RoPE(config.RoPE_type, config.rope_theta, config.max_position_embeddings, base_name + \u0026#34;k_rope\u0026#34;); k_cache = KVCache(num_key_value_groups, config.cache_limit, base_name + \u0026#34;k_cache\u0026#34;); v_cache = KVCache(num_key_value_groups, config.cache_limit, base_name + \u0026#34;v_cache\u0026#34;); mask = Causalmask(base_name + \u0026#34;mask\u0026#34;); softmax = Softmax(DIMENSION, base_name + \u0026#34;softmax\u0026#34;); } private: int hidden_size; int num_heads; int head_dim; int num_key_value_heads; int num_key_value_groups; Layer q_proj; Layer k_proj; Layer v_proj; Layer o_proj; Layer q_rope; Layer k_rope; Layer k_cache; Layer v_cache; Layer mask; Layer softmax; } ç»†å¿ƒçš„è¯»è€…å¯èƒ½å·²ç»å‘ç°äº†ï¼Œåœ¨QWenAttentionçš„æ„é€ å‡½æ•°ä¸­ï¼Œåˆ›å»ºæ¯ä¸ªLayerçš„æ—¶å€™éƒ½åœ¨æœ€åä¸€ä¸ªå‚æ•°ä¸Šä¼ é€’äº†Layeråç§°ï¼ˆstd::string typeï¼‰ï¼Œè¿™æ˜¯å› ä¸ºmllmä¾èµ–äºLayerçš„åç§°æ¥å¯»æ‰¾è¯¥Layeræ‰€éœ€è¦çš„å‚æ•°ã€‚\n5.4.2 é‡è½½Forwardå‰å‘æ¨ç†å‡½æ•° åˆ›å»ºå®Œäº†æ‰€æœ‰æˆ‘ä»¬éœ€è¦çš„Layersä»¥åï¼Œå°±å¯ä»¥ç¼–å†™Forwardå‡½æ•°æ¥å®šä¹‰Attentionæ¨¡å—çš„è®¡ç®—æµç¨‹ï¼ŒForwardå‡½æ•°æ¥æ”¶ä¸€ä¸ªTensor Arrayå’Œä¸€ä¸ªstd::any Arrayï¼Œè¿”å›Tensor Arrayï¼š\nstd::vector\u0026lt;Tensor\u0026gt; Forward(std::vector\u0026lt;Tensor\u0026gt; inputs, std::vector\u0026lt;std::any\u0026gt; args) override { auto query_states = q_proj(inputs[0]); auto key_states = k_proj(inputs[1]); auto value_states = v_proj(inputs[2]); // [batch, heads, sequence, dims] query_states = query_states.view(-1, num_heads, -1, head_dim); key_states = key_states.view(-1, num_key_value_heads, -1, head_dim); value_states = value_states.view(-1, num_key_value_heads, -1, head_dim); // embedding query_states = q_rope(query_states); key_states = k_rope(key_states); // kv cache key_states = k_cache(key_states); value_states = v_cache(value_states); // attention weight auto atten_weight = Tensor::mm(query_states, key_states.transpose(Chl::SEQUENCE, Chl::DIMENSION)) / std::sqrt(head_dim); atten_weight = mask(atten_weight); atten_weight = softmax(atten_weight); // attention output auto atten_output = Tensor::mm(atten_weight, value_states); atten_output = atten_output.view(-1, 1, -1, head_dim * num_heads); atten_output = o_proj(atten_output); return {atten_output}; } 5.5 è¿è¡Œ å®Œæ•´çš„Qwenæ¨¡å‹å®šä¹‰ä»£ç å¯ä»¥åœ¨é™„å½•1ä¸­æ‰¾åˆ°ã€‚è¯»è€…å¯ä»¥åƒTorchä¸€æ ·è°ƒç”¨å®šä¹‰å¥½çš„æ¨¡å‹ï¼šé¦–å…ˆï¼Œåˆ›å»ºæ¨¡å‹ï¼š\nQWenConfig config(tokens_limit, \u0026#34;0.5B\u0026#34;, RoPEType::HFHUBROPE); auto model = QWenForCausalLM(config); model.load(model_path); moduleclassé‡è½½äº†()operatorï¼Œè¯»è€…å¯ä»¥ä½¿ç”¨model({input_tensor})æ¥è¿›è¡Œæ¨ç†ã€‚\n6. mllmæ¡†æ¶çš„ä¸è¶³ è¿™é‡Œå†™çš„æœ‰ç‚¹meanï¼Œæœ¬äººä¸“ä¸šçŸ¥è¯†æµ…è–„ï¼Œåœ¨å­¦æœ¯ä¸Šæ˜¯ä¾æ‰˜ç­”è¾©ï¼Œå¯¹mllmçš„ç†è§£æ›´æ˜¯ä¸åˆ°ä½ï¼Œå¤§å®¶è½»å–·ã€‚\n6.1 Benchmark ç¼ºå°‘ç®—å­çš„Benchmark æœ¬æ–‡è®¤ä¸ºï¼Œmllmåœ¨å®ç°çš„æ—¶å€™æåŠ›çš„é¿å…ä½¿ç”¨ç¬¬ä¸‰æ–¹çš„åº“ï¼Œå› ä¸ºmllméœ€è¦è¿ç§»åˆ°ç§»åŠ¨è®¾å¤‡ä¸Šï¼Œä¸€äº›ä¸‰æ–¹åº“å¯èƒ½ä¸èƒ½æ­£å¸¸å·¥ä½œã€‚ä½†æ˜¯æ‰‹å·¥å®ç°çš„Kernelè¿˜æ˜¯éœ€è¦ä¸€ä¸ªBenchmarkæ¥å’Œç›®æ ‡å¹³å°ä¸Šæä¾›çš„ç®—å­åº“æ¥è¿›è¡Œæ€§èƒ½æ¯”è¾ƒçš„ã€‚å°±mllmç›®å‰æä¾›çš„MatMul Kernelæ¥çœ‹ï¼Œä¼¼ä¹ç¼ºå°‘Packä¼˜åŒ–å’Œ/micro Kernelçš„ä¼˜åŒ–ï¼Ÿ\nç¼ºå°‘prefill/decodeçš„Benchmark mllmçš„issuesä¸­ä¹Ÿæœ‰äººæåˆ°è¿‡è¿™ä¸ªé—®é¢˜ã€‚ä½œä¸ºå…·æœ‰LLMæ¨ç†èƒ½åŠ›çš„å¼•æ“ï¼Œåº”å½“æµ‹ä¸€ä¸‹è¿™ä¸¤ä¸ªåŸºæœ¬èƒ½åŠ›ã€‚\n6.2 å¯¹äºç§»åŠ¨ç«¯LLMæ¨ç†çš„ç‰¹å®šä¼˜åŒ– KV Cacheé‡åŒ– IIRCï¼Œåœ¨OPPOçš„Transformer-Lite[2]ä¸­ï¼Œç”¨åˆ°äº†KV Cacheé‡åŒ–çš„å°æŠ€å·§ã€‚è¿™å¯¹ç§»åŠ¨è®¾å¤‡æœ‰é™çš„å†…å­˜æ¥è¯´å¯èƒ½ä¼šæ›´åŠ å‹å¥½ï¼Œå½“ç„¶è¿˜éœ€è¦è€ƒé‡é‡åŒ–å¸¦æ¥çš„CPUè´Ÿè½½é—®é¢˜ã€‚\nåŠ¨æ€å½¢çŠ¶æ¨ç†/å†…å­˜å¤ç”¨/KV Cacheæ¬ç§»ä¼˜åŒ– ç›®å‰mllmæ˜¯æ²¡æœ‰åšå†…å­˜å¤ç”¨çš„ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨ç¬¦å·æ¨ç†æ–¹æ³•æ¥åšåŠ¨æ€å½¢çŠ¶çš„æ”¯æŒè¿›è€Œä¾¿äºæ±‚è§£ä¸‹ä¸€è½®çš„å†…å­˜ä½¿ç”¨æƒ…å†µã€‚æˆ–è®¸å¯ä»¥è€ƒè™‘ä¸€ä¸‹PageAttention[3]çš„Tensorç®¡ç†æ–¹æ³•æˆ–è€…[2]ä¸­çš„KV Cacheè§„åˆ’æ–¹æ³•æ¥è¿›ä¸€æ­¥å‡å°‘å†…å­˜çš„æ¬ç§»ã€‚\nå¼‚æ„ç®—åŠ› å¯ä»¥è€ƒè™‘æŠŠå½¢çŠ¶æ¨ç†ï¼ˆCPUï¼‰å’Œè®¡ç®—ï¼ˆGPU/NPUï¼‰å¹¶è¡Œæ‰§è¡Œèµ·æ¥ã€‚æˆ–è€…æ˜¯6.2.4ä¸­æåˆ°çš„å†…å®¹ä¸è®¡ç®—å¹¶è¡Œèµ·æ¥ã€‚\nå¯¹æ¨¡å‹å‚æ•°çš„Lazy Fetchå’ŒPre Fetch ç›®å‰ï¼Œmllmä¼šæŠŠå‚æ•°ä¸€æ¬¡æ€§çš„è¯»å…¥å†…å­˜ï¼Ÿè€ƒè™‘åˆ°ç§»åŠ¨è®¾å¤‡çš„å†…å­˜æœ‰é™ï¼Œå¯ä»¥åœ¨åˆé€‚çš„æ—¶æœºæå‰ä»å¤–å­˜ä¸Šé¢„å–è€Œä¸æ˜¯å…¨æ•°è½½å…¥ã€‚\n6.3 æ˜“ç”¨æ€§ æ¨¡å‹ç»“æ„éœ€è¦æ‰‹åŠ¨ç¼–å†™ä¸”æ— æ³•ä¿å­˜ ç›®å‰ï¼Œmllmçš„æ¨¡å‹ç»“æ„è¿˜æ˜¯éœ€è¦åœ¨C++æ–‡ä»¶ä¸­è¿›è¡Œæ˜¾ç¤ºçš„æ‰‹åŠ¨å®šä¹‰ã€‚æˆ–è®¸å¯ä»¥è€ƒè™‘åˆ›å»ºè‡ªå·±çš„è®¡ç®—å›¾å’Œç®—å­æè¿°æ–¹å¼ï¼Œä½¿ç”¨flatbuffersæ¥å­˜å‚¨è®¡ç®—å›¾ã€‚\nå¦‚æœè¦å¾ˆå¥½çš„ä½¿ç”¨æ‰€æœ‰çš„ç®—åŠ›ï¼Œå¯èƒ½è¿˜æ˜¯éœ€è¦å®Œå–„çš„è®¡ç®—å›¾æœºåˆ¶ï¼Œè¿™æ ·ä¾¿äºä¼˜åŒ–åˆ†æã€‚ å°è¯•å¼•å…¥ä¸‰æ–¹æ˜“ç”¨çš„åº“å¦‚icuç­‰æ¥å¼¥è¡¥C++ utf-8å¤„ç†èƒ½åŠ›çš„ä¸è¶³ã€‚ Refï¼š\n[1] mllm, https://github.com/UbiquitousLearning/mllm\n[2] transformer-lite, https://arxiv.org/abs/2403.20041\n[3] PageAttention, https://arxiv.org/abs/2309.06180\nA1. Qwenæ¨¡å‹å®šä¹‰ #ifndef MODELING_QWEN_HPP #define MODELING_QWEN_HPP #include \u0026#34;Backend.hpp\u0026#34; #include \u0026#34;Layer.hpp\u0026#34; #include \u0026#34;Module.hpp\u0026#34; #include \u0026#34;Tensor.hpp\u0026#34; #include \u0026#34;configuration_qwen.hpp\u0026#34; #include \u0026lt;cmath\u0026gt; using namespace mllm; // Copied from GemmaMLP with Gemma-\u0026gt;Qwen and using silu class QWenMLP final : public Module { public: QWenMLP() = default; QWenMLP(int hidden_size, int intermediate_size, const QWenNameConfig \u0026amp;names, const std::string \u0026amp;base_name) { gate_proj = Linear(hidden_size, intermediate_size, false, base_name + names._gate_proj_name); silu = SiLU(base_name + \u0026#34;act\u0026#34;); up_proj = Linear(hidden_size, intermediate_size, false, base_name + names._up_proj_name); down_proj = Linear(intermediate_size, hidden_size, false, base_name + names._down_proj_name); } std::vector\u0026lt;Tensor\u0026gt; Forward(std::vector\u0026lt;Tensor\u0026gt; inputs, std::vector\u0026lt;std::any\u0026gt; args) override { auto x = gate_proj(inputs[0]); x = silu(x); auto y = up_proj(inputs[0]); x = x * y; x = down_proj(x); return {x}; } private: Layer gate_proj; Layer up_proj; Layer down_proj; Layer silu; }; // Copied from GemmaAttention with Gemma-\u0026gt;Qwen and using SWA class QWenAttention final : public Module { public: QWenAttention() = default; QWenAttention(const QWenConfig \u0026amp;config, const QWenNameConfig \u0026amp;names, const string \u0026amp;base_name) { hidden_size = config.hidden_size; num_heads = config.num_attention_heads; head_dim = config.hidden_size / num_heads; num_key_value_heads = config.num_key_value_heads; num_key_value_groups = num_heads / num_key_value_heads; // init layers q_proj = Linear(hidden_size, num_heads * head_dim, true, base_name + names._q_proj_name); k_proj = Linear(hidden_size, num_key_value_heads * head_dim, true, base_name + names._k_proj_name); v_proj = Linear(hidden_size, num_key_value_heads * head_dim, true, base_name + names._v_proj_name); o_proj = Linear(num_heads * head_dim, hidden_size, false, base_name + names._o_proj_name); q_rope = RoPE(config.RoPE_type, config.rope_theta, config.max_position_embeddings, base_name + \u0026#34;q_rope\u0026#34;); k_rope = RoPE(config.RoPE_type, config.rope_theta, config.max_position_embeddings, base_name + \u0026#34;k_rope\u0026#34;); k_cache = KVCache(num_key_value_groups, config.cache_limit, base_name + \u0026#34;k_cache\u0026#34;); v_cache = KVCache(num_key_value_groups, config.cache_limit, base_name + \u0026#34;v_cache\u0026#34;); // mask = SlidingWindowMask(config.sliding_window, base_name + \u0026#34;mask\u0026#34;); mask = Causalmask(base_name + \u0026#34;mask\u0026#34;); softmax = Softmax(DIMENSION, base_name + \u0026#34;softmax\u0026#34;); } std::vector\u0026lt;Tensor\u0026gt; Forward(std::vector\u0026lt;Tensor\u0026gt; inputs, std::vector\u0026lt;std::any\u0026gt; args) override { auto query_states = q_proj(inputs[0]); auto key_states = k_proj(inputs[1]); auto value_states = v_proj(inputs[2]); // [batch, heads, sequence, dims] query_states = query_states.view(-1, num_heads, -1, head_dim); key_states = key_states.view(-1, num_key_value_heads, -1, head_dim); value_states = value_states.view(-1, num_key_value_heads, -1, head_dim); // embedding query_states = q_rope(query_states); key_states = k_rope(key_states); // kv cache key_states = k_cache(key_states); value_states = v_cache(value_states); // attention weight auto atten_weight = Tensor::mm(query_states, key_states.transpose(Chl::SEQUENCE, Chl::DIMENSION)) / std::sqrt(head_dim); atten_weight = mask(atten_weight); atten_weight = softmax(atten_weight); // attention output auto atten_output = Tensor::mm(atten_weight, value_states); atten_output = atten_output.view(-1, 1, -1, head_dim * num_heads); atten_output = o_proj(atten_output); return {atten_output}; } private: int hidden_size; int num_heads; int head_dim; int num_key_value_heads; int num_key_value_groups; Layer q_proj; Layer k_proj; Layer v_proj; Layer o_proj; Layer q_rope; Layer k_rope; Layer k_cache; Layer v_cache; Layer mask; Layer softmax; }; // Copied from GemmaDecoder with Gemma-\u0026gt;Qwen and set RmsNorm(without add_unit_offset) class QWenDecoder final : public Module { public: QWenDecoder() = default; QWenDecoder(const QWenConfig \u0026amp;config, const QWenNameConfig \u0026amp;names, const string \u0026amp;base_name) { self_atten = QWenAttention(config, names, base_name + names._attn_base_name); mlp = QWenMLP(config.hidden_size, config.intermediate_size, names, base_name + names._ffn_base_name); input_layernorm = RMSNorm(config.hidden_size, config.rms_norm_eps, base_name + names._attn_norm_name); post_attention_layernorm = RMSNorm(config.hidden_size, config.rms_norm_eps, base_name + names._ffn_norm_name); } std::vector\u0026lt;Tensor\u0026gt; Forward(std::vector\u0026lt;Tensor\u0026gt; inputs, std::vector\u0026lt;std::any\u0026gt; args) override { auto x = input_layernorm(inputs[0]); x = self_atten({x, x, x})[0]; auto tmp = x + inputs[0]; x = post_attention_layernorm(tmp); x = mlp({x})[0]; x = x + tmp; return {x}; } private: QWenAttention self_atten; QWenMLP mlp; Layer input_layernorm; Layer post_attention_layernorm; }; // Copied from GemmaModel with Gemma-\u0026gt;Qwen and set RmsNorm(without add_unit_offset) class QWenModel final : public Module { public: QWenModel() = default; QWenModel(const QWenConfig \u0026amp;config, const QWenNameConfig \u0026amp;names, const string \u0026amp;base_name) { blocks = List\u0026lt;QWenDecoder\u0026gt;(config.num_hidden_layers, config, names, base_name); norm = RMSNorm(config.hidden_size, config.rms_norm_eps, names.post_norm_name); } std::vector\u0026lt;Tensor\u0026gt; Forward(std::vector\u0026lt;Tensor\u0026gt; inputs, std::vector\u0026lt;std::any\u0026gt; args) override { auto x = inputs[0]; for (auto \u0026amp;block : blocks) { x = block({x})[0]; } x = norm(x); return {x}; } private: std::vector\u0026lt;QWenDecoder\u0026gt; blocks; Layer norm; }; class QWenForCausalLM final : public Module { public: QWenForCausalLM(QWenConfig \u0026amp;config) { auto names = config.names_config; hidden_size = config.hidden_size; tie_embedding_words = config.tie_embedding_words; embedding = Embedding(config.vocab_size, config.hidden_size, names.token_embd_name); model = QWenModel(config, names, names.blk_name); // FIXME Qwen-0.5 use tied embedding // Others use nn.Linear() if (tie_embedding_words) { lm_head = Parameter(1, config.vocab_size, 1, config.hidden_size, names.token_embd_name + \u0026#34;.weight\u0026#34;); } } std::vector\u0026lt;Tensor\u0026gt; Forward(std::vector\u0026lt;Tensor\u0026gt; inputs, std::vector\u0026lt;std::any\u0026gt; args) override { auto x = embedding(inputs[0]); // go through model auto outputs = model({x})[0]; if (tie_embedding_words) { outputs = Tensor::mm(outputs, lm_head().transpose(Chl::SEQUENCE, Chl::DIMENSION)); } return {outputs}; } private: int hidden_size; bool tie_embedding_words; Layer embedding; Parameter lm_head; QWenModel model; }; #endif //! MODELING_QWEN_HPP ","permalink":"https://chenghuawang.github.io/keep-moving-forward/tech/mllm-qwen/","summary":"ä»¥Qwen0.5Bä¸ºä¾‹è§£æmllmçš„åŸºæœ¬å®ç°ï¼ŒCPU Backend","title":"mllmæ¡†æ¶æµ…æ(ä¸€)-ä»¥QWen0.5Bä¸ºä¾‹"},{"content":"http://arxiv.org/abs/2310.16795\nMLSys 2024\n1.èƒŒæ™¯å’ŒåŠ¨æœº ä¸ºäº†è§£å†³å¤§å‹æ¨¡å‹çš„é«˜æ¨ç†æˆæœ¬é—®é¢˜ï¼ŒMoEæ¶æ„è¢«æå‡ºã€‚MoEé€šè¿‡ç¨€ç–è·¯ç”±çš„æ–¹å¼ï¼Œå°†è¾“å…¥åˆ†é…ç»™å¤šä¸ªä¸“å®¶ï¼ˆexpertsï¼‰ä¸­çš„ä¸€å°éƒ¨åˆ†ï¼Œä»¥å®ç°æ›´å¿«çš„æ¨ç†é€Ÿåº¦å’Œæ›´é«˜çš„æ¨¡å‹è´¨é‡ã€‚ä½†è¿™ç§æ¶æ„ä¹Ÿå¸¦æ¥äº†å·¨å¤§çš„å‚æ•°é‡ï¼Œä¾‹å¦‚SwitchTransformer-c2048æ¨¡å‹å°±æœ‰1.6ä¸‡äº¿å‚æ•°ã€‚MoEæ¨¡å‹çš„å‚æ•°é‡å·¨å¤§ï¼Œéœ€è¦æ•°TBçº§çš„å­˜å‚¨ç©ºé—´ï¼Œè¿™ä½¿å¾—å®ƒä»¬åœ¨å®é™…éƒ¨ç½²æ—¶é¢ä¸´å†…å­˜å’Œæˆæœ¬çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—çš„åœºåˆã€‚\nä¸ºäº†é™ä½MoEæ¨¡å‹çš„å†…å­˜å’Œå­˜å‚¨éœ€æ±‚ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ï¼Œæ¨¡å‹å‹ç¼©æˆä¸ºäº†ä¸€ä¸ªé‡è¦çš„ç ”ç©¶æ–¹å‘ã€‚ä¼ ç»Ÿçš„å‹ç¼©æŠ€æœ¯ï¼Œå¦‚é‡åŒ–å’Œç¨€ç–æ€§ï¼Œè™½ç„¶åœ¨ä¸€å®šç¨‹åº¦ä¸Šæœ‰æ•ˆï¼Œä½†å¯¹äºå‚æ•°é‡è¾¾åˆ°ä¸‡äº¿çº§åˆ«çš„æ¨¡å‹æ¥è¯´ï¼Œä»ç„¶ä¸è¶³ä»¥å®ç°é«˜æ•ˆçš„å‹ç¼©ã€‚\næœ¬æ–‡æå‡ºäº†QMoEï¼Œä¸€ç§æ–°çš„å‹ç¼©å’Œæ‰§è¡Œæ¡†æ¶ï¼Œæ—¨åœ¨å®ç°å¯¹ä¸‡äº¿å‚æ•°MoEæ¨¡å‹çš„é«˜æ•ˆå‹ç¼©å’Œæ¨ç†ã€‚QMoEé€šè¿‡è®¾è®¡ä¸€ç§å¯æ‰©å±•çš„ç®—æ³•ï¼Œå°†æ¨¡å‹å‹ç¼©åˆ°æ¯ä¸ªå‚æ•°ä¸åˆ°1æ¯”ç‰¹çš„å¤§å°ï¼Œå¹¶ä¸å®šåˆ¶çš„GPUè§£ç å†…æ ¸ååŒè®¾è®¡ï¼Œä»¥å®ç°ç«¯åˆ°ç«¯çš„é«˜æ•ˆå‹ç¼©æ¨ç†ï¼Œä¸”è¿è¡Œæ—¶å¼€é”€ç›¸å¯¹è¾ƒå°ã€‚\nFig 1. é‡åŒ–ç»“æœhttp://arxiv.org/abs/2310.16795\nä½œè€…é¦–å…ˆè€ƒè™‘äº†Huffmanå’ŒLZWä¸¤ç§å¸¸ç”¨äºæ–‡ä»¶å‹ç¼©çš„æ–¹æ³•ã€‚ä½†æ˜¯Huffmanæ–¹æ³•çš„è§£ç ä¾èµ–äºä¸Šæ–‡å·²ç»è¢«è§£æçš„å‚æ•°ï¼Œå¹¶è¡Œæ€§ä½ï¼›ä¸”å˜é•¿çš„ç¼–ç æ–¹å¼åœ¨å®ç°ä¸Šå’Œå­˜å‚¨çš„æ—¶å€™ä¹Ÿæ˜¯è¾ƒä¸ºå›°éš¾çš„ã€‚ä½œè€…æ€»ç»“å‡ºäº†MoEé‡åŒ–çš„4ä¸ªéš¾ç‚¹ï¼š\nç°æœ‰çš„å‹ç¼©æ–¹æ³•ï¼Œå¦‚é‡åŒ–å’Œç¨€ç–æ€§ï¼Œé€šå¸¸åªèƒ½åœ¨ä¸æ˜¾è‘—æŸå¤±ç²¾åº¦çš„æƒ…å†µä¸‹å°†æ¨¡å‹çš„ç²¾åº¦é™ä½åˆ°æ¯ä¸ªå‚æ•°3æˆ–4æ¯”ç‰¹ï¼Œæˆ–è€…è¾¾åˆ°å¤§çº¦50%çš„ç¨€ç–åº¦ã€‚ç„¶è€Œï¼Œè¦ä½¿ä¸‡äº¿å‚æ•°çš„MoEæ¨¡å‹å®ç”¨åŒ–ï¼Œéœ€è¦æ¯”16ä½ç²¾åº¦é«˜å‡º10åˆ°20å€çš„å‹ç¼©ç‡ï¼Œå³å¹³å‡æ¯ä¸ªå‚æ•°å°‘äº1æ¯”ç‰¹ã€‚ å°†ç°æœ‰çš„å‹ç¼©æ–¹æ³•åº”ç”¨äºæ¯”å¤§å‹denseæ¨¡å‹å¤§ä¸€ä¸ªæ•°é‡çº§çš„MoEæ¨¡å‹æ—¶ï¼Œä¼šé‡åˆ°å†…å­˜ã€æ€§èƒ½å’Œå¯é æ€§æ–¹é¢çš„éšœç¢ã€‚MoEæ¨¡å‹ç”±äºå…¶ç¨€ç–æ€§ï¼Œéœ€è¦å¤„ç†çš„å†…å­˜å’Œæ•°æ®é‡å·¨å¤§ã€‚å³é‡åŒ–è¿‡ç¨‹éœ€è¦çš„å†…å­˜å¤ªå¤§ï¼Œä¸”å¯èƒ½ä¼šå‡ºç°å› ä¸ºcorner caseå¯¼è‡´é‡åŒ–å¤±è´¥çš„é—®é¢˜ã€‚ å®ç°æ¯ä¸ªå‚æ•°å°‘äº1æ¯”ç‰¹çš„å‹ç¼©ç‡éœ€è¦ä¸€ä¸ªéå¹³å‡¡çš„è‡ªå®šä¹‰å‹ç¼©æ ¼å¼ï¼Œå¹¶ä¸”è¿™ç§æ ¼å¼éœ€è¦é…å¤‡åœ¨GPUç­‰åŠ é€Ÿå™¨ä¸Šé«˜æ•ˆçš„è§£ç ç®—æ³•ï¼Œä»¥é¿å…åœ¨å‹ç¼©æ¨¡å‹ä¸Šè¿›è¡Œæ¨ç†æ—¶å‡ºç°é‡å¤§çš„å¤„ç†å»¶è¿Ÿï¼ˆæ¯”å¦‚è¦é¿å…Huffmanæ–¹æ³•çš„åŒæ­¥ï¼‰ã€‚ ä¸ºäº†åº”å¯¹ä¸Šè¿°æŒ‘æˆ˜ï¼Œéœ€è¦åœ¨ç³»ç»Ÿçº§åˆ«è¿›è¡Œè®¾è®¡å’Œä¼˜åŒ–ï¼ŒåŒ…æ‹¬ä¼˜åŒ–æ¿€æ´»å¸è½½ã€ä½¿ç”¨åˆ—è¡¨ç¼“å†²åŒºæ¥æ”¯æŒæ ·æœ¬è®¿é—®ã€å»¶è¿Ÿæƒé‡è·å–ä»¥å‡å°‘å†…å­˜å ç”¨ã€ä¸“å®¶åˆ†ç»„ä»¥æé«˜GPUåˆ©ç”¨ç‡ï¼Œä»¥åŠè¿›è¡Œé²æ£’æ€§ä¿®æ”¹ä»¥å¤„ç†åœ¨å‹ç¼©å…·æœ‰æ•°ä¸‡ä¸ªå±‚çš„æ¨¡å‹æ—¶å¯èƒ½é‡åˆ°çš„ç½•è§corner caseã€‚ 2. ç®—æ³• 2.1 ä½¿ç”¨GPTQé‡åŒ– Fig 2. ä½¿ç”¨GPTQé‡åŒ–æµç¨‹http://arxiv.org/abs/2310.16795\nå…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç»´æŠ¤ä¸€ä¸ªå¤§å‹ç¼“å†²åŒº$B$ï¼Œå¹¶æŒ‰ä»¥ä¸‹æ–¹å¼æ›´æ–° Transformer å—çš„Denseéƒ¨åˆ†ï¼š\nä»CPUåˆ°GPUæŠ“å–ä¸€ä¸ª \u0026ldquo;æ ·æœ¬\u0026rdquo; $X$ï¼Œå…¶ä¸­åŒ…å«æ•°ç™¾ä¸ªToken é€šè¿‡ç›¸åº”çš„Dense Layerï¼Œå¾—åˆ°ç»“æœ$Y$ è®¡ç®—å¹¶å­˜å‚¨$Y$ä¸­æ ‡è®°çš„ä¸“å®¶åˆ†é… å°†$Y$é€å›CPUå¹¶è¦†ç›–$B$ä¸­çš„$X$ å¹¶ä¸”å¯¹äºç¨€ç–éƒ¨åˆ†ï¼Œåˆ†åˆ«å¯¹ä¸“å®¶è¿›è¡Œå¾ªç¯ï¼š\nä»CPUåˆ°GPUè·å–$B$ä¸­æ‰€æœ‰è¢«åˆ†é…ç»™ä¸“å®¶$E$çš„å•ç‹¬Tokenï¼Œè®°ä½œ$X_{E}$ ä½¿ç”¨å®ƒä»¬æ¥ç”Ÿæˆå‹ç¼©åçš„ä¸“å®¶$E^{\u0026rsquo;}$ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨GPTQç®—æ³•ï¼‰ é€šè¿‡$E^{\u0026rsquo;}$æ¨¡å—ä»¥è·å¾—$Y_{E^{\u0026rsquo;}}$ å°†$Y_{E^{\u0026rsquo;}}$å‘é€å›CPUï¼Œå¹¶åœ¨Bä¸­è¦†ç›–$X_{E}$ ä½œè€…åœ¨è¿™é‡Œè¿˜å¼•å…¥äº†List Bufferingã€Lazy Weight Fetchingå’ŒExpert GroupingæŠ€å·§\n2.1.1 List Buffering ä¸ºäº†æœ‰æ•ˆåœ°æ”¯æŒå¯¹Denseæ¨¡å‹çš„è®¿é—®ï¼Œä»¥åŠå¯¹ä¸“å®¶tokensçš„å®Œå…¨å‘é‡åŒ–æŸ¥è¯¢ï¼Œæˆ‘ä»¬å°†$B$å­˜å‚¨ä¸ºåˆ—è¡¨ç¼“å†²æ•°æ®ç»“æ„ã€‚è¿™å¯ä»¥è¢«çœ‹ä½œæ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰tokenséšè—çŠ¶æ€çš„å·¨å¤§è¿ç»­ç¼“å†²åŒºï¼Œä»¥åŠåˆ†éš”ç¬¦ç´¢å¼•ï¼Œè¿™äº›ç´¢å¼•æ ‡å¿—ç€å„ä¸ªæ ·æœ¬ä¹‹é—´çš„è¾¹ç•Œã€‚ä¸‹å›¾å±•ç¤ºäº†è¿™ç§å­˜å‚¨æ ¼å¼ã€‚è¿™ç§æ•°æ®ç»“æ„å¯¹æ•ˆç‡è‡³å…³é‡è¦ï¼›å¯¹äºå¤§é‡æ ·æœ¬è®¡æ•°ï¼Œé€šè¿‡æ©ç è¿­ä»£æ ·æœ¬å¹¶è·å–ç›¸å…³tokensçš„æ–¹æ³•æ˜¯å¾ˆæ…¢çš„ï¼Œè€Œä½œè€…æå‡ºçš„æ–¹æ³•åˆ™æœ‰å¤§å¹…åº¦æ”¹è¿›ã€‚\nFig 3. list bufferinghttp://arxiv.org/abs/2310.16795\n2.1.2 Lazy Weight Fetching ç”±äº1.6ä¸‡äº¿å‚æ•°æ¨¡å‹çš„æƒé‡å ç”¨äº†è¶…è¿‡3TBçš„å­˜å‚¨ç©ºé—´ï¼Œå®ƒä»¬ç”šè‡³æ— æ³•å­˜å‚¨åœ¨CPUçš„RAMä¸­ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æŒ‰éœ€ç›´æ¥ä»ç£ç›˜å­˜å‚¨ä¸­æ‡’åŠ è½½å®ƒä»¬ã€‚æŒ‰ç…§æ¨ç†çš„æµç¨‹ï¼Œæˆ‘ä»¬éœ€è¦å°†æ‰€æœ‰çš„å‚æ•°ä»ç£ç›˜æ¬ç§»åˆ°å†…å­˜ä¸­å®Œæ•´çš„ä¸€æ•´æ¬¡ã€‚\n2.1.3 Experts Grouping æ­¤å¤–ï¼Œä¸ºäº†é¿å…GPUçš„åˆ©ç”¨ç‡ä¸è¶³ï¼Œä½œè€…å°†å¤šä¸ªä¸“å®¶ç»„åˆåœ¨ä¸€èµ·ï¼Œå¹¶åº”ç”¨GPTQç®—æ³•çš„è”åˆæ‰¹å¤„ç†å˜ä½“ã€‚\n2.2 å­—å…¸ç”Ÿæˆ å¯¹äºé‡åŒ–åå¾—åˆ°çš„Ternary Pair ${w_{min}, 0, w_{max}}$ï¼Œåœ¨å¾ˆå¤šçš„æƒ…å†µä¸‹ï¼Œæ˜¯0å±…å¤šçš„ï¼Œä¹Ÿå°±æ˜¯è¯´æ˜¯ç¨€ç–çš„ï¼Œé‚£ä¹ˆå¯¹äºç¨€ç–çŸ©é˜µå¯ä»¥ç”¨CSRç­‰æ–¹æ³•æ¥å­˜å‚¨ã€‚ä½†æ˜¯ä½¿ç”¨ä¼ ç»Ÿçš„ç¨€ç–çŸ©é˜µå­˜å‚¨æ–¹æ³•å‹ç¼©æ¯”è¿˜æ˜¯ä¸å¤Ÿï¼Œä½œè€…å›¢é˜Ÿä½¿ç”¨äº†ä¸€ç§æ›´åŠ åå‘äºæ–‡ä»¶å‹ç¼©çš„æ€è·¯æ¥è¿›è¡Œé‡åŒ–åçš„å‚æ•°å‹ç¼©ï¼Œè¿™ä¸ªæ–¹æ³•å°±ä½¿ç”¨åˆ°äº†å­—å…¸æŸ¥æ‰¾çš„æ–¹æ³•ã€‚å­—å…¸æŸ¥æ‰¾çš„æ–¹æ³•è¿˜æ˜¯æ¯”è¾ƒé€šä¿—æ˜“æ‡‚çš„ï¼Œä»¥ä¸‹é¢çš„ä¾‹å­æ¥ä¸¾ä¾‹ï¼š\nå¯¹äºâ€œ001002003\u0026hellip;â€æˆ‘ä»¬å¯ä»¥ç»Ÿè®¡è¯¥ä¸²é‡Œé¢çš„å­ä¸²çš„å‡ºç°é¢‘ç‡ï¼Œæ¯”å¦‚001ï¼Œ002ï¼Œ003å‡ºç°çš„é¢‘ç‡é«˜ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å°†ä»–ä»¬ç¼–ç æˆ A,B,Cç„¶åä»…éœ€è¦ä¸‰ä¸ªcharçš„ç©ºé—´â€œABCâ€å°±å¯ä»¥è¡¨ç¤ºä¸€ä¸ªå‹ç¼©åçš„æ–‡ä»¶ã€‚\nä½¿ç”¨å­—å…¸æ¥å‹ç¼©å°±æ˜¯æœ¬æ–‡ä¸ºä»€ä¹ˆå¯ä»¥åšåˆ°å¹³å‡æ¯ä¸ªweightå°äº1bité‡åŒ–çš„æ¥æºã€‚\nä¸€èˆ¬æ¥è¯´ï¼Œå‡è®¾ä¸‰å…ƒæƒé‡çŸ©é˜µï¼ˆç”¨ 0ã€1ã€2 è¡¨ç¤ºï¼‰çš„å€¼æ¥è¿‘ç‹¬ç«‹åˆ†å¸ƒï¼Œå…¶åˆ†å¸ƒå¦‚ä¸‹:\n$$ P(0)=p_{0}, P(1)=P(2)=\\frac{1-p_{0}}{2} $$\nFig 4. å­—å…¸ç”Ÿæˆç®—æ³•http://arxiv.org/abs/2310.16795\nç„¶åï¼Œä½œè€…ç”¨ä¸Šå›¾ä¸­çš„ç®—æ³•æ¥ç”Ÿæˆå­—å…¸ã€‚å­—å…¸çš„Keyæ˜¯16bitçš„ç±»å‹ï¼Œå­—å…¸çš„Valueæ˜¯ä¸€ä¸ªé•¿åº¦åœ¨14ä»¥ä¸‹çš„éç©ºå¯¹æ•°ç»„(å³ï¼š[(t1, t2), (t0, t1), \u0026hellip;])ã€‚æœ¬æ–‡åœ¨ç”Ÿæˆå­—å…¸çš„æ—¶å€™åšäº†ä¸¤ä¸ªé™åˆ¶ï¼š1. å­—å…¸çš„Keyæ˜¯16ä½çš„ 2. å­—å…¸çš„Valueæœ€å¤šæ˜¯14ä¸ªPairã€‚\nè¯¥ç®—æ³•çš„æ¯æ¬¡å¾ªç¯ï¼Œä¼šæ‰¾å‡ºé˜Ÿåˆ—ä¸­å‡ºç°æ¦‚ç‡æœ€é«˜çš„Valueï¼Œç„¶åå¯¹å…¶Value Concatä¸Šä¸€ä¸ªæ–°çš„Pairï¼Œè¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼šå¯ä»¥è®©Cache Localityç‰¹æ€§å‘æŒ¥çš„å¾ˆå¥½ï¼Œæˆ‘ä»¬ä¼šåœ¨2.3å°èŠ‚ä¸­çœ‹åˆ°ã€‚ ä½œè€…ä¸€å…±ç”Ÿæˆäº†æœ‰$2^{16}$ä¸ªæ¡ç›®çš„å­—å…¸ã€‚\nå­—å…¸ä¸­çš„Valueæ˜¯åƒä¸‹å›¾æ‰€ç¤ºæ’å¸ƒçš„ï¼š\nFig 5. Valueçš„æ’å¸ƒhttp://arxiv.org/abs/2310.16795\nä¸€ä¸ªå­—å…¸ä¸­çš„ValueåŒ…å«2ä¸ªint32ç±»å‹ï¼Œä¹‹æ‰€ä»¥ä¸ç”¨int64æ˜¯å‡ºäºGPUè®¿å­˜å†²çªçš„è€ƒé‡ã€‚æ¯ä¸ªint32çš„4ä¸ªä½ä½è¡¨ç¤ºè¯¥Valueæœ‰å¤šå°‘ä¸ªæœ‰æ•ˆçš„pairsã€‚æ¯2ä¸ª2bitsè¡¨ç¤ºä¸€ä¸ªpairï¼Œæ¯ä¸ª2bitsè¡¨ç¤ºä¸€ä¸ªweightã€‚\n2.3 Decode åœ¨Decodeé˜¶æ®µï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“å½“å‰wrapå’Œthreadçš„IDï¼Œç„¶åç”¨shiftæ“ä½œç¬¦æå–åˆ°å¯¹åº”å­—å…¸ä¸­çš„å…ƒç´ ã€‚æ ¸å¿ƒä¼ªä»£ç å¦‚ä¸‹ï¼š\nint enc = w_comp_block[warp][j]; int wx14 = dec[2 * enc + (lane / 14)]; int ter = (wx14 \u0026gt;\u0026gt; (4 + 2 * (lane % 14))) \u0026amp; 0x3; float w = deq[ter][thread]; 31 res += w * x_shared[idx + lane]; idx += 2 * (wx14 \u0026amp; 0xf); å…¶ä¸­w_comp_blockæ˜¯å·²ç»å‹ç¼©è¿‡çš„weightï¼›decæ˜¯ä¸€ç»´å­—å…¸ï¼›deqæ˜¯é¢„å…ˆæå–å‡ºæ¥çš„ä¸‰å…ƒç»„ï¼›x_sharedæ˜¯è¾“å…¥Xã€‚ä½œè€…åœ¨è¿™é‡Œèåˆäº†è§£ç å’Œç‚¹ä¹˜çš„æ“ä½œã€‚\n3. æ€»ç»“ä¸æ€è€ƒ QMoEæœ‰ç€éå¸¸å¥½çš„æ•ˆæœï¼Œä½†æ˜¯ç°åœ¨çš„MoEæ¨¡å‹æ™®éä¸æ˜¯å¼€æºçš„ï¼Œå¹¶ä¸”æœ‰ç‰¹å®šçš„Infraè®¾æ–½ã€‚QMoEçš„è¿›ä¸€æ­¥éªŒè¯å’Œå®æ–½è¿˜éœ€è¦æ›´å¤šçš„ä¸šå†…å·¥ç¨‹è·Ÿè¿›ã€‚\nä¸ç†è§£çš„åœ°æ–¹ï¼šç”Ÿæˆå­—å…¸çš„Algorithm1ä¸ºä»€ä¹ˆå¯ä»¥ç”Ÿæˆæ‰€æœ‰æƒ…å†µçš„Valueå‘¢ï¼Ÿä¼šæœ‰ä¸åŒçš„ç»„åˆæƒ…å†µäº§ç”Ÿå—ï¼Ÿ\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/papers/mlsys2024-qmoe/","summary":"http://arxiv.org/abs/2310.16795\nMLSys 2024\n1.èƒŒæ™¯å’ŒåŠ¨æœº ä¸ºäº†è§£å†³å¤§å‹æ¨¡å‹çš„é«˜æ¨ç†æˆæœ¬é—®é¢˜ï¼ŒMoEæ¶æ„è¢«æå‡ºã€‚MoEé€šè¿‡ç¨€ç–è·¯ç”±çš„æ–¹å¼ï¼Œå°†è¾“å…¥åˆ†é…ç»™å¤šä¸ªä¸“å®¶ï¼ˆexpertsï¼‰ä¸­çš„ä¸€å°éƒ¨åˆ†ï¼Œä»¥å®ç°æ›´å¿«çš„æ¨ç†é€Ÿåº¦å’Œæ›´é«˜çš„æ¨¡å‹è´¨é‡ã€‚ä½†è¿™ç§æ¶æ„ä¹Ÿå¸¦æ¥äº†å·¨å¤§çš„å‚æ•°é‡ï¼Œä¾‹å¦‚SwitchTransformer-c2048æ¨¡å‹å°±æœ‰1.6ä¸‡äº¿å‚æ•°ã€‚MoEæ¨¡å‹çš„å‚æ•°é‡å·¨å¤§ï¼Œéœ€è¦æ•°TBçº§çš„å­˜å‚¨ç©ºé—´ï¼Œè¿™ä½¿å¾—å®ƒä»¬åœ¨å®é™…éƒ¨ç½²æ—¶é¢ä¸´å†…å­˜å’Œæˆæœ¬çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—çš„åœºåˆã€‚\nä¸ºäº†é™ä½MoEæ¨¡å‹çš„å†…å­˜å’Œå­˜å‚¨éœ€æ±‚ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ï¼Œæ¨¡å‹å‹ç¼©æˆä¸ºäº†ä¸€ä¸ªé‡è¦çš„ç ”ç©¶æ–¹å‘ã€‚ä¼ ç»Ÿçš„å‹ç¼©æŠ€æœ¯ï¼Œå¦‚é‡åŒ–å’Œç¨€ç–æ€§ï¼Œè™½ç„¶åœ¨ä¸€å®šç¨‹åº¦ä¸Šæœ‰æ•ˆï¼Œä½†å¯¹äºå‚æ•°é‡è¾¾åˆ°ä¸‡äº¿çº§åˆ«çš„æ¨¡å‹æ¥è¯´ï¼Œä»ç„¶ä¸è¶³ä»¥å®ç°é«˜æ•ˆçš„å‹ç¼©ã€‚\næœ¬æ–‡æå‡ºäº†QMoEï¼Œä¸€ç§æ–°çš„å‹ç¼©å’Œæ‰§è¡Œæ¡†æ¶ï¼Œæ—¨åœ¨å®ç°å¯¹ä¸‡äº¿å‚æ•°MoEæ¨¡å‹çš„é«˜æ•ˆå‹ç¼©å’Œæ¨ç†ã€‚QMoEé€šè¿‡è®¾è®¡ä¸€ç§å¯æ‰©å±•çš„ç®—æ³•ï¼Œå°†æ¨¡å‹å‹ç¼©åˆ°æ¯ä¸ªå‚æ•°ä¸åˆ°1æ¯”ç‰¹çš„å¤§å°ï¼Œå¹¶ä¸å®šåˆ¶çš„GPUè§£ç å†…æ ¸ååŒè®¾è®¡ï¼Œä»¥å®ç°ç«¯åˆ°ç«¯çš„é«˜æ•ˆå‹ç¼©æ¨ç†ï¼Œä¸”è¿è¡Œæ—¶å¼€é”€ç›¸å¯¹è¾ƒå°ã€‚\nFig 1. é‡åŒ–ç»“æœhttp://arxiv.org/abs/2310.16795\nä½œè€…é¦–å…ˆè€ƒè™‘äº†Huffmanå’ŒLZWä¸¤ç§å¸¸ç”¨äºæ–‡ä»¶å‹ç¼©çš„æ–¹æ³•ã€‚ä½†æ˜¯Huffmanæ–¹æ³•çš„è§£ç ä¾èµ–äºä¸Šæ–‡å·²ç»è¢«è§£æçš„å‚æ•°ï¼Œå¹¶è¡Œæ€§ä½ï¼›ä¸”å˜é•¿çš„ç¼–ç æ–¹å¼åœ¨å®ç°ä¸Šå’Œå­˜å‚¨çš„æ—¶å€™ä¹Ÿæ˜¯è¾ƒä¸ºå›°éš¾çš„ã€‚ä½œè€…æ€»ç»“å‡ºäº†MoEé‡åŒ–çš„4ä¸ªéš¾ç‚¹ï¼š\nç°æœ‰çš„å‹ç¼©æ–¹æ³•ï¼Œå¦‚é‡åŒ–å’Œç¨€ç–æ€§ï¼Œé€šå¸¸åªèƒ½åœ¨ä¸æ˜¾è‘—æŸå¤±ç²¾åº¦çš„æƒ…å†µä¸‹å°†æ¨¡å‹çš„ç²¾åº¦é™ä½åˆ°æ¯ä¸ªå‚æ•°3æˆ–4æ¯”ç‰¹ï¼Œæˆ–è€…è¾¾åˆ°å¤§çº¦50%çš„ç¨€ç–åº¦ã€‚ç„¶è€Œï¼Œè¦ä½¿ä¸‡äº¿å‚æ•°çš„MoEæ¨¡å‹å®ç”¨åŒ–ï¼Œéœ€è¦æ¯”16ä½ç²¾åº¦é«˜å‡º10åˆ°20å€çš„å‹ç¼©ç‡ï¼Œå³å¹³å‡æ¯ä¸ªå‚æ•°å°‘äº1æ¯”ç‰¹ã€‚ å°†ç°æœ‰çš„å‹ç¼©æ–¹æ³•åº”ç”¨äºæ¯”å¤§å‹denseæ¨¡å‹å¤§ä¸€ä¸ªæ•°é‡çº§çš„MoEæ¨¡å‹æ—¶ï¼Œä¼šé‡åˆ°å†…å­˜ã€æ€§èƒ½å’Œå¯é æ€§æ–¹é¢çš„éšœç¢ã€‚MoEæ¨¡å‹ç”±äºå…¶ç¨€ç–æ€§ï¼Œéœ€è¦å¤„ç†çš„å†…å­˜å’Œæ•°æ®é‡å·¨å¤§ã€‚å³é‡åŒ–è¿‡ç¨‹éœ€è¦çš„å†…å­˜å¤ªå¤§ï¼Œä¸”å¯èƒ½ä¼šå‡ºç°å› ä¸ºcorner caseå¯¼è‡´é‡åŒ–å¤±è´¥çš„é—®é¢˜ã€‚ å®ç°æ¯ä¸ªå‚æ•°å°‘äº1æ¯”ç‰¹çš„å‹ç¼©ç‡éœ€è¦ä¸€ä¸ªéå¹³å‡¡çš„è‡ªå®šä¹‰å‹ç¼©æ ¼å¼ï¼Œå¹¶ä¸”è¿™ç§æ ¼å¼éœ€è¦é…å¤‡åœ¨GPUç­‰åŠ é€Ÿå™¨ä¸Šé«˜æ•ˆçš„è§£ç ç®—æ³•ï¼Œä»¥é¿å…åœ¨å‹ç¼©æ¨¡å‹ä¸Šè¿›è¡Œæ¨ç†æ—¶å‡ºç°é‡å¤§çš„å¤„ç†å»¶è¿Ÿï¼ˆæ¯”å¦‚è¦é¿å…Huffmanæ–¹æ³•çš„åŒæ­¥ï¼‰ã€‚ ä¸ºäº†åº”å¯¹ä¸Šè¿°æŒ‘æˆ˜ï¼Œéœ€è¦åœ¨ç³»ç»Ÿçº§åˆ«è¿›è¡Œè®¾è®¡å’Œä¼˜åŒ–ï¼ŒåŒ…æ‹¬ä¼˜åŒ–æ¿€æ´»å¸è½½ã€ä½¿ç”¨åˆ—è¡¨ç¼“å†²åŒºæ¥æ”¯æŒæ ·æœ¬è®¿é—®ã€å»¶è¿Ÿæƒé‡è·å–ä»¥å‡å°‘å†…å­˜å ç”¨ã€ä¸“å®¶åˆ†ç»„ä»¥æé«˜GPUåˆ©ç”¨ç‡ï¼Œä»¥åŠè¿›è¡Œé²æ£’æ€§ä¿®æ”¹ä»¥å¤„ç†åœ¨å‹ç¼©å…·æœ‰æ•°ä¸‡ä¸ªå±‚çš„æ¨¡å‹æ—¶å¯èƒ½é‡åˆ°çš„ç½•è§corner caseã€‚ 2. ç®—æ³• 2.1 ä½¿ç”¨GPTQé‡åŒ– Fig 2. ä½¿ç”¨GPTQé‡åŒ–æµç¨‹http://arxiv.org/abs/2310.16795\nå…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç»´æŠ¤ä¸€ä¸ªå¤§å‹ç¼“å†²åŒº$B$ï¼Œå¹¶æŒ‰ä»¥ä¸‹æ–¹å¼æ›´æ–° Transformer å—çš„Denseéƒ¨åˆ†ï¼š\nä»CPUåˆ°GPUæŠ“å–ä¸€ä¸ª \u0026ldquo;æ ·æœ¬\u0026rdquo; $X$ï¼Œå…¶ä¸­åŒ…å«æ•°ç™¾ä¸ªToken é€šè¿‡ç›¸åº”çš„Dense Layerï¼Œå¾—åˆ°ç»“æœ$Y$ è®¡ç®—å¹¶å­˜å‚¨$Y$ä¸­æ ‡è®°çš„ä¸“å®¶åˆ†é… å°†$Y$é€å›CPUå¹¶è¦†ç›–$B$ä¸­çš„$X$ å¹¶ä¸”å¯¹äºç¨€ç–éƒ¨åˆ†ï¼Œåˆ†åˆ«å¯¹ä¸“å®¶è¿›è¡Œå¾ªç¯ï¼š\nä»CPUåˆ°GPUè·å–$B$ä¸­æ‰€æœ‰è¢«åˆ†é…ç»™ä¸“å®¶$E$çš„å•ç‹¬Tokenï¼Œè®°ä½œ$X_{E}$ ä½¿ç”¨å®ƒä»¬æ¥ç”Ÿæˆå‹ç¼©åçš„ä¸“å®¶$E^{\u0026rsquo;}$ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨GPTQç®—æ³•ï¼‰ é€šè¿‡$E^{\u0026rsquo;}$æ¨¡å—ä»¥è·å¾—$Y_{E^{\u0026rsquo;}}$ å°†$Y_{E^{\u0026rsquo;}}$å‘é€å›CPUï¼Œå¹¶åœ¨Bä¸­è¦†ç›–$X_{E}$ ä½œè€…åœ¨è¿™é‡Œè¿˜å¼•å…¥äº†List Bufferingã€Lazy Weight Fetchingå’ŒExpert GroupingæŠ€å·§\n2.1.1 List Buffering ä¸ºäº†æœ‰æ•ˆåœ°æ”¯æŒå¯¹Denseæ¨¡å‹çš„è®¿é—®ï¼Œä»¥åŠå¯¹ä¸“å®¶tokensçš„å®Œå…¨å‘é‡åŒ–æŸ¥è¯¢ï¼Œæˆ‘ä»¬å°†$B$å­˜å‚¨ä¸ºåˆ—è¡¨ç¼“å†²æ•°æ®ç»“æ„ã€‚è¿™å¯ä»¥è¢«çœ‹ä½œæ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰tokenséšè—çŠ¶æ€çš„å·¨å¤§è¿ç»­ç¼“å†²åŒºï¼Œä»¥åŠåˆ†éš”ç¬¦ç´¢å¼•ï¼Œè¿™äº›ç´¢å¼•æ ‡å¿—ç€å„ä¸ªæ ·æœ¬ä¹‹é—´çš„è¾¹ç•Œã€‚ä¸‹å›¾å±•ç¤ºäº†è¿™ç§å­˜å‚¨æ ¼å¼ã€‚è¿™ç§æ•°æ®ç»“æ„å¯¹æ•ˆç‡è‡³å…³é‡è¦ï¼›å¯¹äºå¤§é‡æ ·æœ¬è®¡æ•°ï¼Œé€šè¿‡æ©ç è¿­ä»£æ ·æœ¬å¹¶è·å–ç›¸å…³tokensçš„æ–¹æ³•æ˜¯å¾ˆæ…¢çš„ï¼Œè€Œä½œè€…æå‡ºçš„æ–¹æ³•åˆ™æœ‰å¤§å¹…åº¦æ”¹è¿›ã€‚\nFig 3. list bufferinghttp://arxiv.org/abs/2310.16795\n2.1.2 Lazy Weight Fetching ç”±äº1.6ä¸‡äº¿å‚æ•°æ¨¡å‹çš„æƒé‡å ç”¨äº†è¶…è¿‡3TBçš„å­˜å‚¨ç©ºé—´ï¼Œå®ƒä»¬ç”šè‡³æ— æ³•å­˜å‚¨åœ¨CPUçš„RAMä¸­ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æŒ‰éœ€ç›´æ¥ä»ç£ç›˜å­˜å‚¨ä¸­æ‡’åŠ è½½å®ƒä»¬ã€‚æŒ‰ç…§æ¨ç†çš„æµç¨‹ï¼Œæˆ‘ä»¬éœ€è¦å°†æ‰€æœ‰çš„å‚æ•°ä»ç£ç›˜æ¬ç§»åˆ°å†…å­˜ä¸­å®Œæ•´çš„ä¸€æ•´æ¬¡ã€‚\n2.1.3 Experts Grouping æ­¤å¤–ï¼Œä¸ºäº†é¿å…GPUçš„åˆ©ç”¨ç‡ä¸è¶³ï¼Œä½œè€…å°†å¤šä¸ªä¸“å®¶ç»„åˆåœ¨ä¸€èµ·ï¼Œå¹¶åº”ç”¨GPTQç®—æ³•çš„è”åˆæ‰¹å¤„ç†å˜ä½“ã€‚\n2.2 å­—å…¸ç”Ÿæˆ å¯¹äºé‡åŒ–åå¾—åˆ°çš„Ternary Pair ${w_{min}, 0, w_{max}}$ï¼Œåœ¨å¾ˆå¤šçš„æƒ…å†µä¸‹ï¼Œæ˜¯0å±…å¤šçš„ï¼Œä¹Ÿå°±æ˜¯è¯´æ˜¯ç¨€ç–çš„ï¼Œé‚£ä¹ˆå¯¹äºç¨€ç–çŸ©é˜µå¯ä»¥ç”¨CSRç­‰æ–¹æ³•æ¥å­˜å‚¨ã€‚ä½†æ˜¯ä½¿ç”¨ä¼ ç»Ÿçš„ç¨€ç–çŸ©é˜µå­˜å‚¨æ–¹æ³•å‹ç¼©æ¯”è¿˜æ˜¯ä¸å¤Ÿï¼Œä½œè€…å›¢é˜Ÿä½¿ç”¨äº†ä¸€ç§æ›´åŠ åå‘äºæ–‡ä»¶å‹ç¼©çš„æ€è·¯æ¥è¿›è¡Œé‡åŒ–åçš„å‚æ•°å‹ç¼©ï¼Œè¿™ä¸ªæ–¹æ³•å°±ä½¿ç”¨åˆ°äº†å­—å…¸æŸ¥æ‰¾çš„æ–¹æ³•ã€‚å­—å…¸æŸ¥æ‰¾çš„æ–¹æ³•è¿˜æ˜¯æ¯”è¾ƒé€šä¿—æ˜“æ‡‚çš„ï¼Œä»¥ä¸‹é¢çš„ä¾‹å­æ¥ä¸¾ä¾‹ï¼š\nå¯¹äºâ€œ001002003\u0026hellip;â€æˆ‘ä»¬å¯ä»¥ç»Ÿè®¡è¯¥ä¸²é‡Œé¢çš„å­ä¸²çš„å‡ºç°é¢‘ç‡ï¼Œæ¯”å¦‚001ï¼Œ002ï¼Œ003å‡ºç°çš„é¢‘ç‡é«˜ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å°†ä»–ä»¬ç¼–ç æˆ A,B,Cç„¶åä»…éœ€è¦ä¸‰ä¸ªcharçš„ç©ºé—´â€œABCâ€å°±å¯ä»¥è¡¨ç¤ºä¸€ä¸ªå‹ç¼©åçš„æ–‡ä»¶ã€‚","title":"âœ…[Oct 2023] QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models"},{"content":"èƒŒæ™¯å’ŒåŠ¨æœº ä»¥KV Cacheä¸ºå¯å‘ï¼Œæ¢ç´¢äº†å¯¹time-to-first-token (TTFT) Latencyçš„ä¼˜åŒ–ã€‚ç±»ä¼¼äºKV Cacheï¼ŒPrompt Cache(PC)æ¨ç†åŠ é€Ÿçš„æ ¸å¿ƒæ€æƒ³æ˜¯å¤ç”¨æ³¨æ„åŠ›çš„ä¸­é—´çŠ¶æ€(Attention States)ã€‚ç„¶è€Œä¸KV Cacheä¸åŒçš„æ˜¯ï¼ŒPCæ˜¯åœ¨ä¸åŒçš„promptä¹‹é—´è¿›è¡Œå¤ç”¨ã€‚\nåœ¨å¤§éƒ¨åˆ†çš„LLMä»»åŠ¡ä¸­ï¼Œpromptæœ‰é‡å (overlapping)çš„ç°è±¡ï¼Œè¿™äº›é‡å çš„promptå¯ä»¥è¢«å­˜å‚¨èµ·æ¥ï¼Œè¿›è€Œåœ¨æ¥ä¸‹æ¥çš„LLMå¤„ç†é˜¶æ®µå¯ä»¥åƒKV Cacheä¸€æ ·ï¼Œæå–å‡ºæ¥ç›´æ¥ä½¿ç”¨ã€‚åœ¨TTFTçš„æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå…å»è®¡ç®—ä¸åŒpromptä¸­é‡å éƒ¨åˆ†çš„æ³¨æ„åŠ›çŠ¶æ€ï¼Œä»è€Œç¼©çŸ­TTFTçš„ç”Ÿæˆæ—¶é—´ã€‚\nä¸KV Cacheä¸åŒçš„ç‚¹æ˜¯ï¼š\nç›¸åŒçš„æ–‡æœ¬æ®µå¯èƒ½å‡ºç°åœ¨ä¸åŒpromptçš„ä¸åŒä½ç½®ï¼Œå¦‚ä½•å¯¹å®ƒä»¬çš„Attention Statesè¿›è¡Œå¤ç”¨ã€‚å› ä¸ºä¸åŒä½ç½®çš„æ–‡æœ¬æ®µçš„Position Encodingè¿›å»çš„å€¼æ˜¯ä¸ä¸€æ ·çš„ã€‚åœ¨KV Cacheä¸­ä¸éœ€è¦è€ƒè™‘è¿™ä¸€ç‚¹ï¼Œå› ä¸ºcacheæ˜¯ä»å‰å¾€åçº¿æ€§å¢é•¿çš„ï¼Œä½†Promptæ‰€åœ¨çš„ä½ç½®æ˜¯ä¸ç¡®å®šçš„ã€‚ å¦‚ä½•ä»ä¸åŒçš„promptä¸­è¯†åˆ«å‡ºå·²ç»ç¼“å­˜è¿‡çš„æ–‡æœ¬ã€‚ ç®—æ³• å®éªŒç»éªŒ ä¸€æ®µpromptçš„Positionå€¼ä¸è¿ç»­æ²¡æœ‰å…³ç³»ã€‚åªè¦è¿™ä¸€æ®µpromptæœ¬èº«çš„Positionå€¼æ˜¯è¿ç»­çš„å°±è¡Œã€‚æ„æ€æ˜¯éƒ¨åˆ†è¿ç»­å¯¹äºLLMå°±å¤Ÿäº†ï¼Œä¸ä¸€å®šè¦å®Œå…¨è¿ç»­ã€‚è¯·æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§éªŒè¯çš„ç»“è®ºã€‚\nPrompt Schema Fig 1. Prompt Schema ä½œè€…å›¢é˜Ÿå®šä¹‰äº†ä¸€ä¸ªPrompt Markup Language(PML)ã€‚ä¸Šå›¾ä¸­çš„ä¾‹å­æœ‰ï¼šå¯ä»¥å¤ç”¨çš„moduleå’Œä¸èƒ½å¤ç”¨çš„å¡«å……éƒ¨åˆ†ï¼Œå¡«å……éƒ¨åˆ†éœ€è¦ç”¨ParamæŒ‡å‡ºï¼Œå¹¶ç»™å‡ºé•¿åº¦ã€‚Prompt Attention Statesä¸­çš„çº¢è‰²éƒ¨åˆ†æ˜¯å¯ä»¥è¢«å¤ç”¨çš„åŒºåŸŸã€‚\nFig 2. åŸå§‹LLM/KV Cache/Prompt Cache æˆ‘ä»¬æ¥å¯¹æ¯”ä¸‹æ™®é€šçš„è‡ªå›å½’LLMã€ä½¿ç”¨äº†KV Cacheçš„LLMå’Œä½¿ç”¨äº†Prompt Cacheçš„LLMã€‚æ™®é€šçš„LLMæ¯æ¬¡éƒ½è¦é€šè¿‡è¾“å…¥çš„Promptæ¥é¢„æµ‹å‡ºä¸‹ä¸€ä¸ªTokenï¼ŒPromptæ˜¯å…¨é‡çš„è®¡ç®—ã€‚ä½¿ç”¨äº†KV Cacheçš„LLMï¼Œæ¯æ¬¡Tokené¢„æµ‹ä¸ç”¨å…¨é‡è®¡ç®—äº†ï¼Œå¯ä»¥ä½¿ç”¨ä¸Šæ¬¡Attentionçš„ä¸­é—´ç»“æœã€‚è€Œä½¿ç”¨äº†Prompt Cacheçš„LLMï¼Œåœ¨åæœŸé¢„æµ‹Tokençš„è¿‡ç¨‹å’ŒåŸæ¥çš„KV Cacheæ²¡æœ‰ä»€ä¹ˆåŒºåˆ«ã€‚ä¸»è¦åŒºåˆ«æ˜¯åœ¨ä¸€å¼€å§‹çš„Promptè¾“å…¥çš„é˜¶æ®µï¼ŒPrompt Cacheä¸­å¸¸ç”¨çš„Prompt Attention Stateså¯ä»¥è¢«åˆ©ç”¨èµ·æ¥ï¼Œè¿™ä¼šæå¤§çš„ç¼©å‡ç¬¬ä¸€ä¸ªTokenè¾“å‡ºçš„æ—¶é—´ã€‚ Prompt Schemaæœ‰å¾ˆå¤šçš„ç»†èŠ‚ï¼Œè¿™é‡Œåªè®²å¤§è‡´çš„æ€è·¯ï¼Œå…·ä½“çš„è¯·çœ‹æ–‡ç« å’Œä»£ç ä»“åº“ã€‚\næˆ‘å¯¹moduleæ€ä¹ˆå¤ç”¨ä¸æ˜¯å¾ˆç†è§£ï¼Œåº”è¯¥æ˜¯é€šè¿‡å°†æ–‡æœ¬å†…å®¹è¿›è¡Œsha256ç¼–ç æ¥å¯¹å…¶è¿›è¡Œè¯†åˆ«ã€‚\næœ¬æ–‡ä¸»è¦æ˜¯å¯¹é¦–Tokenè¾“å‡ºæ—¶é—´çš„ä¼˜åŒ–ï¼Œå¯¹äºç”¨æˆ·æ¥è¯´å¯ä»¥æœ‰æ›´å¥½çš„ä½“éªŒã€‚è¦æ˜¯èƒ½åšä¸ªå…¨å±€çš„Prompt Cacheæ•°æ®åº“ï¼Œåº”è¯¥å¯ä»¥ç»™å¤§è§„æ¨¡çš„LLM Inferç³»ç»Ÿå¸¦æ¥ä¸å°‘çš„å¥½å¤„ã€‚\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/papers/prompt_cache/","summary":"èƒŒæ™¯å’ŒåŠ¨æœº ä»¥KV Cacheä¸ºå¯å‘ï¼Œæ¢ç´¢äº†å¯¹time-to-first-token (TTFT) Latencyçš„ä¼˜åŒ–ã€‚ç±»ä¼¼äºKV Cacheï¼ŒPrompt Cache(PC)æ¨ç†åŠ é€Ÿçš„æ ¸å¿ƒæ€æƒ³æ˜¯å¤ç”¨æ³¨æ„åŠ›çš„ä¸­é—´çŠ¶æ€(Attention States)ã€‚ç„¶è€Œä¸KV Cacheä¸åŒçš„æ˜¯ï¼ŒPCæ˜¯åœ¨ä¸åŒçš„promptä¹‹é—´è¿›è¡Œå¤ç”¨ã€‚\nåœ¨å¤§éƒ¨åˆ†çš„LLMä»»åŠ¡ä¸­ï¼Œpromptæœ‰é‡å (overlapping)çš„ç°è±¡ï¼Œè¿™äº›é‡å çš„promptå¯ä»¥è¢«å­˜å‚¨èµ·æ¥ï¼Œè¿›è€Œåœ¨æ¥ä¸‹æ¥çš„LLMå¤„ç†é˜¶æ®µå¯ä»¥åƒKV Cacheä¸€æ ·ï¼Œæå–å‡ºæ¥ç›´æ¥ä½¿ç”¨ã€‚åœ¨TTFTçš„æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå…å»è®¡ç®—ä¸åŒpromptä¸­é‡å éƒ¨åˆ†çš„æ³¨æ„åŠ›çŠ¶æ€ï¼Œä»è€Œç¼©çŸ­TTFTçš„ç”Ÿæˆæ—¶é—´ã€‚\nä¸KV Cacheä¸åŒçš„ç‚¹æ˜¯ï¼š\nç›¸åŒçš„æ–‡æœ¬æ®µå¯èƒ½å‡ºç°åœ¨ä¸åŒpromptçš„ä¸åŒä½ç½®ï¼Œå¦‚ä½•å¯¹å®ƒä»¬çš„Attention Statesè¿›è¡Œå¤ç”¨ã€‚å› ä¸ºä¸åŒä½ç½®çš„æ–‡æœ¬æ®µçš„Position Encodingè¿›å»çš„å€¼æ˜¯ä¸ä¸€æ ·çš„ã€‚åœ¨KV Cacheä¸­ä¸éœ€è¦è€ƒè™‘è¿™ä¸€ç‚¹ï¼Œå› ä¸ºcacheæ˜¯ä»å‰å¾€åçº¿æ€§å¢é•¿çš„ï¼Œä½†Promptæ‰€åœ¨çš„ä½ç½®æ˜¯ä¸ç¡®å®šçš„ã€‚ å¦‚ä½•ä»ä¸åŒçš„promptä¸­è¯†åˆ«å‡ºå·²ç»ç¼“å­˜è¿‡çš„æ–‡æœ¬ã€‚ ç®—æ³• å®éªŒç»éªŒ ä¸€æ®µpromptçš„Positionå€¼ä¸è¿ç»­æ²¡æœ‰å…³ç³»ã€‚åªè¦è¿™ä¸€æ®µpromptæœ¬èº«çš„Positionå€¼æ˜¯è¿ç»­çš„å°±è¡Œã€‚æ„æ€æ˜¯éƒ¨åˆ†è¿ç»­å¯¹äºLLMå°±å¤Ÿäº†ï¼Œä¸ä¸€å®šè¦å®Œå…¨è¿ç»­ã€‚è¯·æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§éªŒè¯çš„ç»“è®ºã€‚\nPrompt Schema Fig 1. Prompt Schema ä½œè€…å›¢é˜Ÿå®šä¹‰äº†ä¸€ä¸ªPrompt Markup Language(PML)ã€‚ä¸Šå›¾ä¸­çš„ä¾‹å­æœ‰ï¼šå¯ä»¥å¤ç”¨çš„moduleå’Œä¸èƒ½å¤ç”¨çš„å¡«å……éƒ¨åˆ†ï¼Œå¡«å……éƒ¨åˆ†éœ€è¦ç”¨ParamæŒ‡å‡ºï¼Œå¹¶ç»™å‡ºé•¿åº¦ã€‚Prompt Attention Statesä¸­çš„çº¢è‰²éƒ¨åˆ†æ˜¯å¯ä»¥è¢«å¤ç”¨çš„åŒºåŸŸã€‚\nFig 2. åŸå§‹LLM/KV Cache/Prompt Cache æˆ‘ä»¬æ¥å¯¹æ¯”ä¸‹æ™®é€šçš„è‡ªå›å½’LLMã€ä½¿ç”¨äº†KV Cacheçš„LLMå’Œä½¿ç”¨äº†Prompt Cacheçš„LLMã€‚æ™®é€šçš„LLMæ¯æ¬¡éƒ½è¦é€šè¿‡è¾“å…¥çš„Promptæ¥é¢„æµ‹å‡ºä¸‹ä¸€ä¸ªTokenï¼ŒPromptæ˜¯å…¨é‡çš„è®¡ç®—ã€‚ä½¿ç”¨äº†KV Cacheçš„LLMï¼Œæ¯æ¬¡Tokené¢„æµ‹ä¸ç”¨å…¨é‡è®¡ç®—äº†ï¼Œå¯ä»¥ä½¿ç”¨ä¸Šæ¬¡Attentionçš„ä¸­é—´ç»“æœã€‚è€Œä½¿ç”¨äº†Prompt Cacheçš„LLMï¼Œåœ¨åæœŸé¢„æµ‹Tokençš„è¿‡ç¨‹å’ŒåŸæ¥çš„KV Cacheæ²¡æœ‰ä»€ä¹ˆåŒºåˆ«ã€‚ä¸»è¦åŒºåˆ«æ˜¯åœ¨ä¸€å¼€å§‹çš„Promptè¾“å…¥çš„é˜¶æ®µï¼ŒPrompt Cacheä¸­å¸¸ç”¨çš„Prompt Attention Stateså¯ä»¥è¢«åˆ©ç”¨èµ·æ¥ï¼Œè¿™ä¼šæå¤§çš„ç¼©å‡ç¬¬ä¸€ä¸ªTokenè¾“å‡ºçš„æ—¶é—´ã€‚ Prompt Schemaæœ‰å¾ˆå¤šçš„ç»†èŠ‚ï¼Œè¿™é‡Œåªè®²å¤§è‡´çš„æ€è·¯ï¼Œå…·ä½“çš„è¯·çœ‹æ–‡ç« å’Œä»£ç ä»“åº“ã€‚\næˆ‘å¯¹moduleæ€ä¹ˆå¤ç”¨ä¸æ˜¯å¾ˆç†è§£ï¼Œåº”è¯¥æ˜¯é€šè¿‡å°†æ–‡æœ¬å†…å®¹è¿›è¡Œsha256ç¼–ç æ¥å¯¹å…¶è¿›è¡Œè¯†åˆ«ã€‚\næœ¬æ–‡ä¸»è¦æ˜¯å¯¹é¦–Tokenè¾“å‡ºæ—¶é—´çš„ä¼˜åŒ–ï¼Œå¯¹äºç”¨æˆ·æ¥è¯´å¯ä»¥æœ‰æ›´å¥½çš„ä½“éªŒã€‚è¦æ˜¯èƒ½åšä¸ªå…¨å±€çš„Prompt Cacheæ•°æ®åº“ï¼Œåº”è¯¥å¯ä»¥ç»™å¤§è§„æ¨¡çš„LLM Inferç³»ç»Ÿå¸¦æ¥ä¸å°‘çš„å¥½å¤„ã€‚","title":"âœ…[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference"},{"content":"Li L, Qian S, Lu J, et al. Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs. arxiv preprint arxiv:2403.20041, 2024.\næ— ä»£ç ï¼ŒæŠ€æœ¯æŠ¥å‘Š\nâ­ï¸â­ï¸â­ï¸\nhttp://arxiv.org/abs/2403.20041\n1. èƒŒæ™¯ \u0026amp; åŠ¨æœº è¿™ç¯‡è®ºæ–‡æ˜¯OPPO AI Centerå‘è¡¨çš„ï¼Œå…¶æå‡ºäº†Transformer-Liteæ¡†æ¶æ¥ç¼“è§£ç§»åŠ¨è®¾å¤‡GPUä¸Šéƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¶å­˜åœ¨çš„æ€§èƒ½é—®é¢˜ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ChatGLM2 6Bå’ŒGemma 2Bï¼‰è¢«å¹¿æ³›åº”ç”¨äºæ™ºèƒ½åŠ©æ‰‹ã€æ–‡æœ¬æ‘˜è¦ã€ç¿»è¯‘å’Œå¤šæ¨¡æ€ä»»åŠ¡ç­‰ï¼Œä½†å®ƒä»¬åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šçš„éƒ¨ç½²é¢ä¸´ç€å‡ ä¸ªå…³é”®é—®é¢˜ï¼š\nè®¡ç®—èƒ½åŠ›å’Œå†…å­˜å¸¦å®½çš„éœ€æ±‚ï¼šLLMséœ€è¦å¤§é‡çš„è®¡ç®—èƒ½åŠ›å’Œå†…å­˜å¸¦å®½ï¼Œè¿™äº›èµ„æºåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šæ˜¯æœ‰é™çš„ã€‚ ç”¨æˆ·ä½“éªŒï¼šå½“å‰çš„åœ¨ç«¯ä¾§è®¾å¤‡ä¸Šéƒ¨ç½²LLMçš„æ–¹æ³•é€šå¸¸æœ‰ç€è¾ƒæ…¢çš„æ¨ç†é€Ÿåº¦ï¼Œè¿™ä¼šä¸¥é‡å½±å“ç”¨æˆ·ä½“éªŒã€‚ æˆæœ¬ï¼šåœ¨äº‘ä¸Šå¤§è§„æ¨¡éƒ¨ç½²LLMæœ‰ç€å¯è§‚çš„æˆæœ¬ï¼Œè€Œä¸”éšç€ç§»åŠ¨è®¾å¤‡æ€§èƒ½çš„ä¸æ–­æå‡ï¼Œæœ¬åœ°éƒ¨ç½²LLMä¸ä»…å¯ä»¥å‡å°‘ä¸äº‘éƒ¨ç½²ç›¸å…³çš„é«˜æˆæœ¬ï¼Œè¿˜å¯ä»¥æ‰©å¤§LLMåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šçš„åº”ç”¨å‰æ™¯ä»¥åŠä¿æŠ¤ç”¨æˆ·éšç§ã€‚ ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ã€‚è¿™ç¯‡æ–‡ç« æ–‡ç« æå‡ºäº†ä»¥ä¸‹ä¼˜åŒ–æŠ€æœ¯ï¼š\nç¬¦å·è¡¨è¾¾å¼çš„æ–¹æ³•ï¼šæ”¯æŒåŠ¨æ€å½¢çŠ¶æ¨¡å‹æ¨ç†ï¼ŒåŒ…æ‹¬åŠ¨æ€å½¢çŠ¶æ¨å¯¼ã€å†…å­˜é‡ç”¨å’Œæ‰§è¡Œè°ƒåº¦ç­‰ã€‚ ç®—å­ä¼˜åŒ–å’Œæ‰§è¡Œä¼˜å…ˆçº§è®¾ç½®ï¼šåŠ å¿«æ¨ç†é€Ÿåº¦å¹¶å‡å°‘æ‰‹æœºå»¶è¿Ÿã€‚ FP4é‡åŒ–æ–¹æ³•ï¼šç§°ä¸ºM0E4ï¼Œå‡å°‘dequantizeå¼€é”€ï¼Œä½¿å¾—çŸ©é˜µä¹˜æ³•æ›´é«˜æ•ˆã€‚ åŸºäºå­å¼ é‡çš„æŠ€å·§ï¼šé¿å…äº†åœ¨LLMæ¨ç†åå¤åˆ¶KVç¼“å­˜çš„å†…å­˜å‹åŠ›ã€‚ ä½œè€…å›¢é˜Ÿè¿˜å®ç°äº†ä¸€ä¸ªåä¸ºTransformer-Liteçš„ç§»åŠ¨æ¨ç†å¼•æ“ï¼Œè¯¥å¼•æ“ä¸é«˜é€šå’Œè”å‘ç§‘å¤„ç†å™¨å…¼å®¹ï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—å®éªŒè¯„ä¼°äº†å…¶æ€§èƒ½ã€‚é€šè¿‡è¿™äº›æŠ€æœ¯ï¼ŒTransformer-Liteå¼•æ“åœ¨prefillå’Œdecodingæ–¹é¢ç›¸æ¯”åŸºäºCPUçš„FastLLMå’ŒåŸºäºGPUçš„MLC-LLMå–å¾—äº†æ˜¾è‘—çš„é€Ÿåº¦æå‡ã€‚\n2. æ–¹æ³• 2.1 å¯¹äºåŠ¨æ€å½¢çŠ¶æ¨ç†çš„ç¬¦å·è¡¨è¾¾æ–¹æ³• ä¸åŒäºå¤šæ•°é™æ€å°ºå¯¸çš„CVæ¨¡å‹ï¼ŒLLM æ˜¯ä¸€ç§åŠ¨æ€å½¢çŠ¶è¾“å…¥çš„åœºæ™¯ï¼Œæ¯æ¬¡è¿­ä»£çš„è¾“å…¥å½¢çŠ¶éƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚è¿™å¯¼è‡´æ¨¡å‹ä¸­ä¸€äº›æ¿€æ´»å¼ é‡çš„å½¢çŠ¶å‘ç”Ÿå˜åŒ–ï¼Œç»™å†…å­˜é‡ç”¨å’Œç®—å­æ€§èƒ½ä¼˜åŒ–å¸¦æ¥äº†å·¨å¤§æŒ‘æˆ˜ã€‚ ä¾‹å¦‚ï¼Œå°†å½¢çŠ¶[â€œsumN-Nâ€,1,2,128]ä¸axis 0ä¸Šçš„[â€œNâ€,1,2,128]è¿æ¥ï¼Œè¾“å‡ºå½¢çŠ¶ä¸º[â€œsumNâ€,1,2,128]ã€‚ä¸ºæ­¤ï¼Œä½œè€…å›¢é˜Ÿåˆ©ç”¨ç±»ä¼¼äº Nimble å’Œ DISC çš„æ–¹æ³•ï¼Œå°†æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­çš„ç®—å­åˆ†ä¸ºä¸¤ç±»ï¼šå¼ é‡è®¡ç®—ç®—å­å’Œå½¢çŠ¶è®¡ç®—ç®—å­ã€‚åä¸€ç±»ç®—å­åŒ…å«å½¢çŠ¶ç®—å­å’Œé‚£äº›å…¶è¾“å…¥å–å†³äºå½¢çŠ¶ç®—å­ç»“æœçš„ç®—å­ã€‚å½¢çŠ¶è®¡ç®—ç®—å­åœ¨ CPU ä¸Šæ‰§è¡Œï¼Œè®¡ç®—å½¢çŠ¶ä¿¡æ¯ã€‚ç›¸åï¼Œè´Ÿè´£è®¡ç®—æ¿€æ´»çš„å¼ é‡å’Œæƒé‡çš„å¼ é‡çš„è®¡ç®—ç®—å­åˆ™åœ¨ GPU ä¸Šæ‰§è¡Œã€‚\nFig 1. å½¢çŠ¶æ¨ç†from http://arxiv.org/abs/2403.20041\nä½œè€…å›¢é˜Ÿä½¿ç”¨äº†SymPyåŒ…ä¸”ç»“åˆäº†ONNXæ¥å®ç°äº†è¿™ä¸€èƒ½åŠ›ã€‚\nå¯¹äºå†…å­˜å¤ç”¨ï¼Œå®ç°å†…å­˜å¤ç”¨çš„å…ˆå†³æ¡ä»¶æ˜¯è·å¾—å¼ é‡ä¹‹é—´çš„å†…å­˜å¤§å°å…³ç³»ï¼Œè¿™åœ¨é™æ€å½¢çŠ¶æ¨ç†ä¸­å¾ˆç®€å•ã€‚ç¬¦å·è¡¨è¾¾å¼ä¾¿äºè½»æ¾ç¡®å®šè¿™ç§å…³ç³»ã€‚é¦–å…ˆï¼Œè®¡ç®—æ¯ä¸ªå¼ é‡çš„å†…å­˜å¤§å°ï¼Œå³å…ƒç´ æ•°ä¹˜ä»¥æ•°æ®ç±»å‹çš„å­—èŠ‚æ•°ï¼Œä»è€Œä¸ºæ¯ä¸ªå¼ é‡çš„å†…å­˜å¤§å°åˆ›å»ºä¸€ä¸ªç¬¦å·è¡¨è¾¾å¼ã€‚**ç„¶åç»“åˆå‡æ³•å’Œé™¤æ³•æ¥è¾¨åˆ«å¼ é‡ä¹‹é—´çš„å†…å­˜å¤§å°å…³ç³»ã€‚**ä¾‹å¦‚ï¼Œç”¨ â€œN â€*4096 é™¤ä»¥ â€œN â€32128ï¼Œå¾—åˆ°çš„æ•´æ•°ä¸º 1ï¼Œè¡¨ç¤ºå¤§å°ç›¸ç­‰ï¼Œå¯ä»¥é‡å¤ä½¿ç”¨å†…å­˜ã€‚å¦ä¸€æ–¹é¢ï¼Œå½“ â€œNâ€ * 4096 ä¸ â€œsumNâ€ * 2 * 128 ç›¸æ¯”è¾ƒæ—¶ï¼Œå‡æ³•å’Œé™¤æ³•éƒ½ä¼šäº§ç”Ÿå¦ä¸€ä¸ªç¬¦å·è¡¨è¾¾å¼ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªç¡®å®šçš„æ•´æ•°ã€‚å› æ­¤ï¼Œé™¤éæ¢ç´¢æ‰€æœ‰æ½œåœ¨çš„è¾“å…¥å½¢çŠ¶ï¼Œå¦åˆ™å®ƒä»¬ä¹‹é—´çš„å¤§å°å…³ç³»æ˜¯ä¸ç¡®å®šçš„ï¼Œè¿™æ„å‘³ç€æ— æ³•è¿›è¡Œå†…å­˜é‡ç”¨ã€‚ ä½œè€…å›¢é˜Ÿä½¿ç”¨äº†OpenCLå·¥å…·æ¥å®ç°äº†å†…å­˜å¤ç”¨ã€‚\né€šå¸¸ï¼ŒLLMçš„æ¯æ¬¡æ¨ç†è¿­ä»£éƒ½éœ€è¦æ›´æ–°è¾“å…¥å½¢çŠ¶ã€‚åœ¨å½¢çŠ¶æ›´æ–°è¿‡ç¨‹ä¸­ï¼Œéœ€è¦é‡æ–°è®¡ç®—åŠ¨æ€å¼ é‡çš„å½¢çŠ¶ï¼Œå¹¶æ›´æ–°å…·æœ‰åŠ¨æ€å½¢çŠ¶è¾“å…¥æˆ–è¾“å‡ºå¼ é‡çš„ç®—å­å‚æ•°ã€‚å› æ­¤ï¼Œé¢‘ç¹çš„è¾“å…¥å½¢çŠ¶æ›´æ–°é€šå¸¸ä¼šå¯¼è‡´ä¸å¯å¿½ç•¥çš„æ€§èƒ½å¼€é”€ã€‚ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…å›¢é˜Ÿé‡‡ç”¨äº†Maskæœºåˆ¶ï¼Œåœ¨è§£ç é˜¶æ®µå°†æ¨¡å‹è¾“å…¥åºåˆ—é•¿åº¦å¡«å……ä¸º64æˆ–128çš„å€æ•°ã€‚è¿™ç§æ–¹æ³•å¯ä»¥åœ¨å®é™…è®¡æ•°è¶…è¿‡å¡«å……é•¿åº¦æ—¶æ›´æ–°å½¢çŠ¶ï¼Œä»è€Œä½¿æ¯æ¬¡æ¨ç†è¿­ä»£çš„å½¢çŠ¶æ›´æ–°æ—¶é—´å¼€é”€å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚\n2.2 ç®—å­ä¼˜åŒ–å’Œæ‰§è¡Œä¼˜å…ˆçº§è®¾ç½® ä½œè€…å®ç°äº†åŠç²¾åº¦å’Œ4bité‡åŒ–çš„æ··åˆç²¾åº¦çŸ©é˜µä¹˜æ³•ã€‚æ­¤å¤–ï¼Œprefillå’Œdecodingé˜¶æ®µå¯¹çŸ©é˜µä¹˜æ³•çš„å½¢çŠ¶æ˜¯ä¸åŒçš„ã€‚åœ¨prefillé˜¶æ®µï¼ŒçŸ©é˜µä¹˜æ³•è¿›è¡ŒçŸ©é˜µ-çŸ©é˜µè®¡ç®—ï¼Œè€Œåœ¨decodingé˜¶æ®µï¼Œè¿™äº›è¿ç®—ç¬¦è¢«ç®€åŒ–ä¸ºå‘é‡-çŸ©é˜µè®¡ç®—ã€‚ä½œè€…å¯¹è¿™ä¸¤ç§æ–¹å¼çš„ä¹˜æ³•éƒ½åšäº†ä¼˜åŒ–ï¼Œæ–‡ä¸­æ²¡æœ‰æ¶‰åŠåˆ°ç®—å­ä¼˜åŒ–çš„ç»†èŠ‚ã€‚\nGPUåœ¨æ‰§è¡ŒLLMæ—¶è¿˜éœ€è¦è´Ÿè´£ç”¨æˆ·ç•Œé¢æ¸²æŸ“ï¼ŒLLMçš„æ‰§è¡Œå¯èƒ½ä¼šé€ æˆç•Œé¢æ¸²æŸ“å»¶è¿Ÿã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…åˆ©ç”¨é«˜é€šå’ŒARMæä¾›çš„OpenCLæ‰©å±•ï¼Œå°†æ·±åº¦å­¦ä¹ æ¨¡å‹ç®—å­çš„æ‰§è¡Œä¼˜å…ˆçº§è®¾ç½®ä¸ºæœ€ä½çº§åˆ«ã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆåœ°ç¼“è§£äº†ç§»åŠ¨è®¾å¤‡çš„æ¸²æŸ“å»¶è¿Ÿã€‚\n2.3 FP4é‡åŒ–æ–¹æ³•ï¼šM0E4 åœ¨ä¼ ç»Ÿçš„é‡åŒ–æ–¹æ³•ä¸­ï¼Œå¦‚GPTQå’ŒAWQï¼Œæ¨¡å‹æƒé‡ä»æµ®ç‚¹æ•°è¢«é‡åŒ–ä¸º4ä½æ•´æ•°ï¼Œä»¥å‡å°‘æ¨¡å‹å¤§å°å’Œå†…å­˜å¸¦å®½éœ€æ±‚ã€‚ç„¶è€Œï¼Œä¸ºäº†ä¿æŒé«˜ç²¾åº¦ï¼Œè®¡ç®—çš„æ—¶å€™é€šå¸¸ä½¿ç”¨åŠç²¾åº¦è¿›è¡Œã€‚åœ¨æ¨¡å‹æ¨ç†æ—¶ï¼Œéœ€è¦å°†é‡åŒ–çš„æƒé‡dequantizeä¸ºæµ®ç‚¹æ•°ä»¥æ‰§è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œè¿™ä¸ªè¿‡ç¨‹æ¶‰åŠåˆ°å°†æ•´æ•°è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œä¼šå¼•èµ·æ˜¾è‘—çš„æ€§èƒ½å¼€é”€ã€‚åœ¨å°†æ•´æ•°è½¬æ¢ä¸ºæµ®ç‚¹æ•°çš„è¿‡ç¨‹ä¸­éœ€è¦ä½¿ç”¨å¤æ‚çš„ç®—æ³•æˆ–æŒ‡ä»¤æ¥å®ç°ã€‚å› æ­¤ï¼Œdequantizeä¼šå¼•å‘ä¸å¯å¿½ç•¥çš„æ€§èƒ½å¼€é”€ã€‚\nM0E4ä¸­çš„\u0026quot;M0\u0026quot;è¡¨ç¤ºæŒ‡æ•°éƒ¨åˆ†ä½¿ç”¨0ä½ã€‚è¿™æ„å‘³ç€æŒ‡æ•°éƒ¨åˆ†è¢«è®¾ç½®ä¸ºä¸€ä¸ªå¸¸é‡å€¼ï¼Œé€šå¸¸æ˜¯ç”¨äºè¡¨ç¤ºåŠç²¾åº¦æµ®ç‚¹æ•°çš„æœ€å°æ­£æŒ‡æ•°ã€‚\u0026ldquo;E4\u0026quot;è¡¨ç¤ºå°¾æ•°éƒ¨åˆ†ä½¿ç”¨4ä½ã€‚è¿™äº›4ä½ç”¨äºå­˜å‚¨é‡åŒ–çš„å°¾æ•°ä¿¡æ¯ï¼Œè¿™ä¸æµ®ç‚¹æ•°è¡¨ç¤ºä¸­çš„å°¾æ•°ï¼ˆæˆ–ç§°ä¸ºå°æ•°éƒ¨åˆ†ï¼‰ç›¸å¯¹åº”ã€‚\nä½œè€…é‡‡ç”¨group-wiseé‡åŒ–ï¼Œå¹¶é€šè¿‡ç¼©æ”¾å’Œåç½®ç³»æ•°å°†æ¯ä¸ªgroupçš„å¼ é‡(è¡¨ç¤ºä¸ºw0)è½¬æ¢ä¸ºä¸€ä¸ªæ–°çš„æµ®ç‚¹å¼ é‡(è¡¨ç¤ºä¸ºw1)ã€‚å¹¶ä¸”ç¡®ä¿æ‰€æœ‰w1å…ƒç´ éƒ½åœ¨$[2^n, 2^{n+1} - eps]$çš„èŒƒå›´å†…ã€‚$n$çš„å–å€¼ä¸º1ï¼Œ2ã€‚åœ¨è¿™ä¸ªèŒƒå›´å†…ï¼Œå°±å¯ä»¥ä¿è¯è¿™äº›å…ƒç´ çš„æŒ‡æ•°éƒ¨åˆ†æ˜¯ä¸€è‡´çš„ã€‚\nä¸ºäº†æé«˜é‡åŒ–çš„å‡†ç¡®æ€§ï¼Œä½œè€…ä¸ºèˆå…¥åˆ†ç¦»äº†ä¸€ä¸ªé¢å¤–çš„ä½(è¡¨ç¤ºä¸ºy2ï¼Œå¦‚å›¾æ‰€ç¤º):y1 = min (y1+ y2,15)ã€‚è¿™é‡Œï¼Œ15æ˜¯ä¸€ä¸ª4ä½æ— ç¬¦å·æ•´æ•°æ‰€èƒ½è¡¨ç¤ºçš„æœ€å¤§å€¼ã€‚\nFig 2. M0E4 é‡åŒ–from http://arxiv.org/abs/2403.20041\nåœ¨dequantizeæ—¶å€™ï¼Œç”¨å¦‚ä¸‹å…¬å¼å³å¯\n$$ w1_{half} = as_{half} (\\text{ConstExpBinPart} | (w1_{fp4} \\ll \\text{ConstBitShiftNum})) $$\n2.4 åŸºäºsubtensoræ¥ç¼“è§£KV Cacheå‹åŠ› ä¸€å¼ å›¾å°±å¯ä»¥è¯´æ˜ï¼Œç»“åˆSWAåº”è¯¥å¯ä»¥å·¥ä½œçš„ä¸é”™ã€‚\nFig 3. KV Cache ä¼˜åŒ–from http://arxiv.org/abs/2403.20041\nå‘ç°è¿™ä¸ªåšæ³•ä¸å¦‚vLLMç§çš„Page Attentionæ¥çš„ç»Ÿä¸€ã€ç®€æ´ã€‚\n3. å®éªŒ 3.1 å„ä¸ªLLMä¸Šçš„æ€§èƒ½ Fig 4. å„ä¸ªLLMä¸Šçš„æ€§èƒ½from http://arxiv.org/abs/2403.20041\n3.2 å’ŒFastLLMå’ŒMLC-LLMæ¯”è¾ƒ Fig 5. å’ŒMLC-LLMæ¯”è¾ƒfrom http://arxiv.org/abs/2403.20041\nFig 6. å’ŒFastLLMæ¯”è¾ƒfrom http://arxiv.org/abs/2403.20041\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/papers/transformer-lite/","summary":"Transformer-Lite from OPPO","title":"âœ…[Mar 2024] Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs"},{"content":"Lin J, Tang J, Tang H, et al. Awq: Activation-aware weight quantization for llm compression and acceleration[j]. Machine Learning System. Best Paper. https://arxiv.org/abs/2306.00978\n1. èƒŒæ™¯å’ŒåŠ¨æœº ç›´æ¥åœ¨FP16ç²¾åº¦ä¸ŠRoundæˆINT3/INT4ä¼šé€ æˆæå¤§çš„æ€§èƒ½æŸå¤± åŸºäºactivation distributionå¯¹é‡è¦çš„weightåšç²¾åº¦ä¿ç•™åˆ™å¯ä»¥å¾ˆå¤§ç¨‹åº¦ä¸Šæé«˜æ¨¡å‹æ€§èƒ½ã€‚ ä½†æ˜¯æ··åˆå­˜å‚¨FP16å’ŒINT3/4ï¼Œåœ¨æ¨ç†ç³»ç»Ÿå®ç°çš„æ—¶å€™è¿‡äºå¤æ‚ä¸”å¯¹äºç¡¬ä»¶éå¸¸çš„ä¸å‹å¥½ã€‚ 2. ç®—æ³• 2.1 åŸç†å’Œå‡è®¾ Fig 1. AWQ åŸæœ‰çš„Roundæ–¹æ³•(å›¾a)ï¼š\n$$ Q(\\mathbf{w})=\\Delta\\cdot\\mathrm{Round}(\\frac{\\mathbf{w}}\\Delta),\\quad\\Delta=\\frac{\\max(|\\mathbf{w}|)}{2^{N-1}} $$\nå…¶ä¸­$\\mathbf{w}$è¡¨ç¤ºä¸€ç»„å‚æ•°ï¼Œ$Q(\\mathbf{w})$è¡¨ç¤ºé‡åŒ–å‡½æ•°ï¼Œ$N$è¡¨ç¤ºé‡åŒ–ä½æ•°ã€‚\næ”¹è¿›åçš„é‡åŒ–æ–¹æ³•(å›¾c)ï¼š\n$$ Q(w\\cdot s)\\cdot\\frac xs=\\Delta^{\u0026rsquo;}\\cdot\\mathrm{Round}(\\frac{ws}{\\Delta^{\u0026rsquo;}})\\cdot x\\cdot\\frac1s $$\nå…¶ä¸­$w \\in \\mathbf{W}$ã€‚å³å…ˆå¯¹ç‰¹å®šçš„$w$åšScalingç„¶åå†Scalingå›å»ã€‚è¿™æ ·åšçš„ç†ç”±æ˜¯ï¼Œè¯¯å·®å¯ä»¥æˆå€çš„å‡å°ï¼Œå¦‚ä¸‹é¢çš„å…¬å¼å’Œè§‚å¯Ÿå‡ºæ¥çš„ç°è±¡ï¼š\n$$ \\begin{aligned}\\operatorname{Err}(Q(w)x)\u0026amp;=\\Delta\\cdot\\operatorname{RoundErr}(\\frac w\\Delta)\\cdot x \\newline \\operatorname{Err}(Q(w\\cdot s)(\\frac xs))\u0026amp;=\\Delta^{\u0026rsquo;}\\cdot\\operatorname{RoundErr}(\\frac{ws}{\\Delta^{\u0026rsquo;}})\\cdot x\\cdot\\frac1s\\end{aligned} $$\nå…¶ä¸­ç”±äº$\\operatorname{Round}$å‡½æ•°æ˜¯å››èˆäº”å…¥ï¼Œæ‰€ä»¥è¯¯å·®$\\operatorname{RoundErr}\\in [0,0.5]$ä¸”æ˜¯ä¸€ä¸ªå‡åŒ€åˆ†å¸ƒã€‚å¹³å‡åœ¨0.25ã€‚ä¸ç®¡æ˜¯å¦è¢«ç¼©æ”¾äº†ï¼Œè¿™ä¸ªåˆ†å¸ƒæ˜¯ä¸å˜çš„ã€‚\nç”±äºä¸€ç»„æƒé‡$\\mathbf{w}$çš„æœ€å¤§å€¼åœ¨ç¼©æ”¾ä¸€ä¸ª$w$åæ˜¯åŸºæœ¬ä¸å˜çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è®¤ä¸º$\\Delta^{\u0026rsquo;} \\approx \\Delta$ã€‚ åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥çœ‹å‡ºä½¿ç”¨äº†Scalingä»¥åå¾—è¯¯å·®å˜å°äº†ï¼Œå°†ä¸Šè¿°æåˆ°çš„è¯¯å·®åšä¸ªæ¯”å€¼å¯ä»¥çœ‹å‡ºï¼Œ$k=\\frac{\\Delta^{\u0026rsquo;}}{\\Delta} \\times \\frac{1}{s}$ã€‚\n2.2 ä¼˜åŒ–ï¼šå¦‚ä½•æ‰¾åˆ°æœ€ä¼˜çš„Scalingå€¼å‘¢ï¼Ÿ $$ \\mathbf{s}^{*} = \\arg \\mathop{\\min}_{s}\\mathcal{L}(\\mathbf{s}) $$\n$$ \\mathcal{L}(s) = \\Vert Q(\\mathbf{W} \\cdot \\text{diag}(s))(\\text{diag}(s)^{-1}\\cdot \\mathbf{X}) - \\mathbf{WX} \\Vert $$\nå®é™…ä¸Šå°±æ˜¯ç”¨L2 Normæœç´¢å‡ºæ¥ä¸€ç»„æœ€ä¸ºåˆé€‚çš„Scalingå‚æ•°ï¼Œæ³¨æ„ï¼ŒScalingæ˜¯å¯¹äºæ¯ä¸ªæƒå€¼éƒ½åšçš„ã€‚ ä½œè€…å›¢é˜Ÿä¸ºäº†ç®€åŒ–æœç´¢çš„ç©ºé—´ï¼Œå¯¹$\\mathbf{s}$åšäº†ä¸€å®šçš„çº¦æŸï¼Œå¦‚ä¸‹ï¼š\n$$ \\mathbf{s} = \\mathbf{s_X}^{\\alpha}ï¼Œ\\alpha^{*}=\\arg \\mathop{\\min}_{\\alpha}\\mathcal{L}(\\mathbf{s_X}^{\\alpha}) $$\nå…¶ä¸­ï¼Œ$\\alpha \\in [0, 1]$ä¸ºç¼©æ”¾ç³»æ•°ï¼Œ$\\mathbf{s_{X}}$æ˜¯activation perchannel çš„å€¼ã€‚å½“$\\alpha = 0$æ—¶ï¼Œæ„å‘³ç€ä¸ç¼©æ”¾ï¼›åä¹‹ï¼Œæ„å‘³ç€å®Œå…¨ç¼©æ”¾ã€‚\n3. æ€»ç»“ éå¸¸æœ‰ç”¨ï¼Œç®€å•ç²—æš´ï¼ŒBest Paperå®è‡³åå½’ï¼Ÿæ˜¯ä¸€ä¸ªéå¸¸ç¬¦åˆç›´è§‰çš„å·¥ç¨‹æ€§è´¨çš„å·¥ä½œï¼Œä½†æ˜¯å·¥ç¨‹çš„å®ç°å¤æ‚æ€§æ¯”è¾ƒé«˜ï¼Œåœ¨å¤šæ•°åœºæ™¯ä¸Šæ²¡æœ‰è¢«ä½¿ç”¨ã€‚ é—®é¢˜ï¼šç”±äºä¸€ç»„æƒé‡$\\mathbf{w}$çš„æœ€å¤§å€¼åœ¨ç¼©æ”¾ä¸€ä¸ª$w$åæ˜¯åŸºæœ¬ä¸å˜çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è®¤ä¸º$\\Delta^{\u0026rsquo;} \\approx \\Delta$ã€‚è¿™ä¸ªå‡è®¾å¹¶ä¸æ˜¯å¾ˆæˆç«‹å•Šï¼Ÿ\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/papers/awq/","summary":"Lin J, Tang J, Tang H, et al. Awq: Activation-aware weight quantization for llm compression and acceleration[j]. Machine Learning System. Best Paper. https://arxiv.org/abs/2306.00978\n1. èƒŒæ™¯å’ŒåŠ¨æœº ç›´æ¥åœ¨FP16ç²¾åº¦ä¸ŠRoundæˆINT3/INT4ä¼šé€ æˆæå¤§çš„æ€§èƒ½æŸå¤± åŸºäºactivation distributionå¯¹é‡è¦çš„weightåšç²¾åº¦ä¿ç•™åˆ™å¯ä»¥å¾ˆå¤§ç¨‹åº¦ä¸Šæé«˜æ¨¡å‹æ€§èƒ½ã€‚ ä½†æ˜¯æ··åˆå­˜å‚¨FP16å’ŒINT3/4ï¼Œåœ¨æ¨ç†ç³»ç»Ÿå®ç°çš„æ—¶å€™è¿‡äºå¤æ‚ä¸”å¯¹äºç¡¬ä»¶éå¸¸çš„ä¸å‹å¥½ã€‚ 2. ç®—æ³• 2.1 åŸç†å’Œå‡è®¾ Fig 1. AWQ åŸæœ‰çš„Roundæ–¹æ³•(å›¾a)ï¼š\n$$ Q(\\mathbf{w})=\\Delta\\cdot\\mathrm{Round}(\\frac{\\mathbf{w}}\\Delta),\\quad\\Delta=\\frac{\\max(|\\mathbf{w}|)}{2^{N-1}} $$\nå…¶ä¸­$\\mathbf{w}$è¡¨ç¤ºä¸€ç»„å‚æ•°ï¼Œ$Q(\\mathbf{w})$è¡¨ç¤ºé‡åŒ–å‡½æ•°ï¼Œ$N$è¡¨ç¤ºé‡åŒ–ä½æ•°ã€‚\næ”¹è¿›åçš„é‡åŒ–æ–¹æ³•(å›¾c)ï¼š\n$$ Q(w\\cdot s)\\cdot\\frac xs=\\Delta^{\u0026rsquo;}\\cdot\\mathrm{Round}(\\frac{ws}{\\Delta^{\u0026rsquo;}})\\cdot x\\cdot\\frac1s $$\nå…¶ä¸­$w \\in \\mathbf{W}$ã€‚å³å…ˆå¯¹ç‰¹å®šçš„$w$åšScalingç„¶åå†Scalingå›å»ã€‚è¿™æ ·åšçš„ç†ç”±æ˜¯ï¼Œè¯¯å·®å¯ä»¥æˆå€çš„å‡å°ï¼Œå¦‚ä¸‹é¢çš„å…¬å¼å’Œè§‚å¯Ÿå‡ºæ¥çš„ç°è±¡ï¼š\n$$ \\begin{aligned}\\operatorname{Err}(Q(w)x)\u0026amp;=\\Delta\\cdot\\operatorname{RoundErr}(\\frac w\\Delta)\\cdot x \\newline \\operatorname{Err}(Q(w\\cdot s)(\\frac xs))\u0026amp;=\\Delta^{\u0026rsquo;}\\cdot\\operatorname{RoundErr}(\\frac{ws}{\\Delta^{\u0026rsquo;}})\\cdot x\\cdot\\frac1s\\end{aligned} $$\nå…¶ä¸­ç”±äº$\\operatorname{Round}$å‡½æ•°æ˜¯å››èˆäº”å…¥ï¼Œæ‰€ä»¥è¯¯å·®$\\operatorname{RoundErr}\\in [0,0.5]$ä¸”æ˜¯ä¸€ä¸ªå‡åŒ€åˆ†å¸ƒã€‚å¹³å‡åœ¨0.25ã€‚ä¸ç®¡æ˜¯å¦è¢«ç¼©æ”¾äº†ï¼Œè¿™ä¸ªåˆ†å¸ƒæ˜¯ä¸å˜çš„ã€‚\nç”±äºä¸€ç»„æƒé‡$\\mathbf{w}$çš„æœ€å¤§å€¼åœ¨ç¼©æ”¾ä¸€ä¸ª$w$åæ˜¯åŸºæœ¬ä¸å˜çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è®¤ä¸º$\\Delta^{\u0026rsquo;} \\approx \\Delta$ã€‚ åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥çœ‹å‡ºä½¿ç”¨äº†Scalingä»¥åå¾—è¯¯å·®å˜å°äº†ï¼Œå°†ä¸Šè¿°æåˆ°çš„è¯¯å·®åšä¸ªæ¯”å€¼å¯ä»¥çœ‹å‡ºï¼Œ$k=\\frac{\\Delta^{\u0026rsquo;}}{\\Delta} \\times \\frac{1}{s}$ã€‚\n2.2 ä¼˜åŒ–ï¼šå¦‚ä½•æ‰¾åˆ°æœ€ä¼˜çš„Scalingå€¼å‘¢ï¼Ÿ $$ \\mathbf{s}^{*} = \\arg \\mathop{\\min}_{s}\\mathcal{L}(\\mathbf{s}) $$","title":"âœ…[April 2024] AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration"},{"content":"1. Algorithm 2. Code void sgemm_micro_6x16_ac_br_cr(int m, int n, int k, float alpha, const float* A, const float* B, float beta, float* C, int ldc) { assert( m == 6 \u0026amp;\u0026amp; n == 16 \u0026amp;\u0026amp; \u0026#34;sgemm micro kernel expects A: 6xk(col major), B: kx16(row major) and C: 6x16(row major)\u0026#34;); uint64_t iters = k / 4; uint64_t remaining = k % 4; uint64_t ldc_ = ldc; #if defined(__AVX__) const float* a_ptr = A; const float* b_ptr = B; __m256 ymm4, ymm5, ymm6, ymm7, ymm8, ymm9, ymm10, ymm11, ymm12, ymm13, ymm14, ymm15; // set all outputs ymm register to zeros. ymm4 = _mm256_setzero_ps(); ymm5 = _mm256_setzero_ps(); ymm6 = _mm256_setzero_ps(); ymm7 = _mm256_setzero_ps(); ymm8 = _mm256_setzero_ps(); ymm9 = _mm256_setzero_ps(); ymm10 = _mm256_setzero_ps(); ymm11 = _mm256_setzero_ps(); ymm12 = _mm256_setzero_ps(); ymm13 = _mm256_setzero_ps(); ymm14 = _mm256_setzero_ps(); ymm15 = _mm256_setzero_ps(); // For C: 6 x 16 // // line0(16xfp32): ymm4, ymm5 // line1(16xfp32): ymm6, ymm7 // line2(16xfp32): ymm8, ymm9 // line3(16xfp32): ymm10, ymm11 // line4(16xfp32): ymm12, ymm13 // line5(16xfp32): ymm14, ymm15 for (uint64_t k_index = 0; k_index \u0026lt; iters; ++k_index) { __m256 ymm0, ymm1, ymm2, ymm3; // performance issues? __builtin_prefetch(b_ptr); __builtin_prefetch(a_ptr); __builtin_prefetch(b_ptr + 64); __builtin_prefetch(a_ptr + 24); // iteration 0 // get a line of matrix B -\u0026gt; 1 x 16 ymm0 = _mm256_load_ps(b_ptr); // -\u0026gt; 1 x 8 ymm1 = _mm256_load_ps(b_ptr + 8); // -\u0026gt; 1 x 8 ymm2 = _mm256_broadcast_ss(a_ptr); ymm3 = _mm256_broadcast_ss(a_ptr + 1); ymm4 = _mm256_fmadd_ps(ymm0, ymm2, ymm4); ymm5 = _mm256_fmadd_ps(ymm1, ymm2, ymm5); ymm6 = _mm256_fmadd_ps(ymm0, ymm3, ymm6); ymm7 = _mm256_fmadd_ps(ymm1, ymm3, ymm7); ymm2 = _mm256_broadcast_ss(a_ptr + 2); ymm3 = _mm256_broadcast_ss(a_ptr + 3); ymm8 = _mm256_fmadd_ps(ymm0, ymm2, ymm8); ymm9 = _mm256_fmadd_ps(ymm1, ymm2, ymm9); ymm10 = _mm256_fmadd_ps(ymm0, ymm3, ymm10); ymm11 = _mm256_fmadd_ps(ymm1, ymm3, ymm11); ymm2 = _mm256_broadcast_ss(a_ptr + 4); ymm3 = _mm256_broadcast_ss(a_ptr + 5); ymm12 = _mm256_fmadd_ps(ymm0, ymm2, ymm12); ymm13 = _mm256_fmadd_ps(ymm1, ymm2, ymm13); ymm14 = _mm256_fmadd_ps(ymm0, ymm3, ymm14); ymm15 = _mm256_fmadd_ps(ymm1, ymm3, ymm15); // iteration 1 // get a line of matrix B -\u0026gt; 1 x 16 ymm0 = _mm256_load_ps(b_ptr + 16); // -\u0026gt; 1 x 8 ymm1 = _mm256_load_ps(b_ptr + 24); // -\u0026gt; 1 x 8 ymm2 = _mm256_broadcast_ss(a_ptr + 6); ymm3 = _mm256_broadcast_ss(a_ptr + 7); ymm4 = _mm256_fmadd_ps(ymm0, ymm2, ymm4); ymm5 = _mm256_fmadd_ps(ymm1, ymm2, ymm5); ymm6 = _mm256_fmadd_ps(ymm0, ymm3, ymm6); ymm7 = _mm256_fmadd_ps(ymm1, ymm3, ymm7); ymm2 = _mm256_broadcast_ss(a_ptr + 8); ymm3 = _mm256_broadcast_ss(a_ptr + 9); ymm8 = _mm256_fmadd_ps(ymm0, ymm2, ymm8); ymm9 = _mm256_fmadd_ps(ymm1, ymm2, ymm9); ymm10 = _mm256_fmadd_ps(ymm0, ymm3, ymm10); ymm11 = _mm256_fmadd_ps(ymm1, ymm3, ymm11); ymm2 = _mm256_broadcast_ss(a_ptr + 10); ymm3 = _mm256_broadcast_ss(a_ptr + 11); ymm12 = _mm256_fmadd_ps(ymm0, ymm2, ymm12); ymm13 = _mm256_fmadd_ps(ymm1, ymm2, ymm13); ymm14 = _mm256_fmadd_ps(ymm0, ymm3, ymm14); ymm15 = _mm256_fmadd_ps(ymm1, ymm3, ymm15); // iteration 2 // get a line of matrix B -\u0026gt; 1 x 16 ymm0 = _mm256_load_ps(b_ptr + 32); // -\u0026gt; 1 x 8 ymm1 = _mm256_load_ps(b_ptr + 40); // -\u0026gt; 1 x 8 ymm2 = _mm256_broadcast_ss(a_ptr + 12); ymm3 = _mm256_broadcast_ss(a_ptr + 13); ymm4 = _mm256_fmadd_ps(ymm0, ymm2, ymm4); ymm5 = _mm256_fmadd_ps(ymm1, ymm2, ymm5); ymm6 = _mm256_fmadd_ps(ymm0, ymm3, ymm6); ymm7 = _mm256_fmadd_ps(ymm1, ymm3, ymm7); ymm2 = _mm256_broadcast_ss(a_ptr + 14); ymm3 = _mm256_broadcast_ss(a_ptr + 15); ymm8 = _mm256_fmadd_ps(ymm0, ymm2, ymm8); ymm9 = _mm256_fmadd_ps(ymm1, ymm2, ymm9); ymm10 = _mm256_fmadd_ps(ymm0, ymm3, ymm10); ymm11 = _mm256_fmadd_ps(ymm1, ymm3, ymm11); ymm2 = _mm256_broadcast_ss(a_ptr + 16); ymm3 = _mm256_broadcast_ss(a_ptr + 17); ymm12 = _mm256_fmadd_ps(ymm0, ymm2, ymm12); ymm13 = _mm256_fmadd_ps(ymm1, ymm2, ymm13); ymm14 = _mm256_fmadd_ps(ymm0, ymm3, ymm14); ymm15 = _mm256_fmadd_ps(ymm1, ymm3, ymm15); // iteration 3 // get a line of matrix B -\u0026gt; 1 x 16 ymm0 = _mm256_load_ps(b_ptr + 48); // -\u0026gt; 1 x 8 ymm1 = _mm256_load_ps(b_ptr + 56); // -\u0026gt; 1 x 8 ymm2 = _mm256_broadcast_ss(a_ptr + 18); ymm3 = _mm256_broadcast_ss(a_ptr + 19); ymm4 = _mm256_fmadd_ps(ymm0, ymm2, ymm4); ymm5 = _mm256_fmadd_ps(ymm1, ymm2, ymm5); ymm6 = _mm256_fmadd_ps(ymm0, ymm3, ymm6); ymm7 = _mm256_fmadd_ps(ymm1, ymm3, ymm7); ymm2 = _mm256_broadcast_ss(a_ptr + 20); ymm3 = _mm256_broadcast_ss(a_ptr + 21); ymm8 = _mm256_fmadd_ps(ymm0, ymm2, ymm8); ymm9 = _mm256_fmadd_ps(ymm1, ymm2, ymm9); ymm10 = _mm256_fmadd_ps(ymm0, ymm3, ymm10); ymm11 = _mm256_fmadd_ps(ymm1, ymm3, ymm11); ymm2 = _mm256_broadcast_ss(a_ptr + 22); ymm3 = _mm256_broadcast_ss(a_ptr + 23); ymm12 = _mm256_fmadd_ps(ymm0, ymm2, ymm12); ymm13 = _mm256_fmadd_ps(ymm1, ymm2, ymm13); ymm14 = _mm256_fmadd_ps(ymm0, ymm3, ymm14); ymm15 = _mm256_fmadd_ps(ymm1, ymm3, ymm15); a_ptr += 24; b_ptr += 64; } for (uint64_t k_index = 0; k \u0026lt; remaining; ++k_index) { __m256 ymm0, ymm1, ymm2, ymm3; // get a line of matrix B -\u0026gt; 1 x 16 ymm0 = _mm256_load_ps(b_ptr); // -\u0026gt; 1 x 8 ymm1 = _mm256_load_ps(b_ptr + 8); // -\u0026gt; 1 x 8 ymm2 = _mm256_broadcast_ss(a_ptr); ymm3 = _mm256_broadcast_ss(a_ptr + 1); ymm4 = _mm256_fmadd_ps(ymm0, ymm2, ymm4); ymm5 = _mm256_fmadd_ps(ymm1, ymm2, ymm5); ymm6 = _mm256_fmadd_ps(ymm0, ymm3, ymm6); ymm7 = _mm256_fmadd_ps(ymm1, ymm3, ymm7); ymm2 = _mm256_broadcast_ss(a_ptr + 2); ymm3 = _mm256_broadcast_ss(a_ptr + 3); ymm8 = _mm256_fmadd_ps(ymm0, ymm2, ymm8); ymm9 = _mm256_fmadd_ps(ymm1, ymm2, ymm9); ymm10 = _mm256_fmadd_ps(ymm0, ymm3, ymm10); ymm11 = _mm256_fmadd_ps(ymm1, ymm3, ymm11); ymm2 = _mm256_broadcast_ss(a_ptr + 4); ymm3 = _mm256_broadcast_ss(a_ptr + 5); ymm12 = _mm256_fmadd_ps(ymm0, ymm2, ymm12); ymm13 = _mm256_fmadd_ps(ymm1, ymm2, ymm13); ymm14 = _mm256_fmadd_ps(ymm0, ymm3, ymm14); ymm15 = _mm256_fmadd_ps(ymm1, ymm3, ymm15); a_ptr += 6; b_ptr += 16; } __m256 c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11; // For C: 6 x 16 // // line0(16xfp32): c0, c1 // line1(16xfp32): c2, c3 // line2(16xfp32): c4, c5 // line3(16xfp32): c6, c7 // line4(16xfp32): c8, c9 // line5(16xfp32): c10, c11 float* c_ptr0 = C; float* c_ptr1 = C + ldc_; float* c_ptr2 = c_ptr1 + ldc_; float* c_ptr3 = c_ptr2 + ldc_; float* c_ptr4 = c_ptr3 + ldc_; float* c_ptr5 = c_ptr4 + ldc_; c0 = _mm256_load_ps(c_ptr0); c1 = _mm256_load_ps(c_ptr0 + 8); c2 = _mm256_load_ps(c_ptr1); c3 = _mm256_load_ps(c_ptr1 + 8); c4 = _mm256_load_ps(c_ptr2); c5 = _mm256_load_ps(c_ptr2 + 8); c6 = _mm256_load_ps(c_ptr3); c7 = _mm256_load_ps(c_ptr3 + 8); c8 = _mm256_load_ps(c_ptr4); c9 = _mm256_load_ps(c_ptr4 + 8); c10 = _mm256_load_ps(c_ptr5); c11 = _mm256_load_ps(c_ptr5 + 8); c0 = _mm256_add_ps(c0, ymm4); c1 = _mm256_add_ps(c1, ymm5); c2 = _mm256_add_ps(c2, ymm6); c3 = _mm256_add_ps(c3, ymm7); c4 = _mm256_add_ps(c4, ymm8); c5 = _mm256_add_ps(c5, ymm9); c6 = _mm256_add_ps(c6, ymm10); c7 = _mm256_add_ps(c7, ymm11); c8 = _mm256_add_ps(c8, ymm12); c9 = _mm256_add_ps(c9, ymm13); c10 = _mm256_add_ps(c10, ymm14); c11 = _mm256_add_ps(c11, ymm15); _mm256_store_ps(c_ptr0, c0); _mm256_store_ps(c_ptr0 + 8, c1); _mm256_store_ps(c_ptr1, c2); _mm256_store_ps(c_ptr1 + 8, c3); _mm256_store_ps(c_ptr2, c4); _mm256_store_ps(c_ptr2 + 8, c5); _mm256_store_ps(c_ptr3, c6); _mm256_store_ps(c_ptr3 + 8, c7); _mm256_store_ps(c_ptr4, c8); _mm256_store_ps(c_ptr4 + 8, c9); _mm256_store_ps(c_ptr5, c10); _mm256_store_ps(c_ptr5 + 8, c11); #endif //! defined(__AVX__) } ","permalink":"https://chenghuawang.github.io/keep-moving-forward/tech/x86_avx_sgemm_6x16/","summary":"How to impl high performance 6xKx16 micro kernel","title":"ã€æ–½å·¥ä¸­ã€‘6xKx16 SGEMM Kernel on X86-AVX"},{"content":"äººå·¥æ™ºèƒ½é¢†åŸŸçš„è®¸å¤šæœ€æ–°è¿›å±•éƒ½å›´ç»•ç€å¤§è§„æ¨¡ç¥ç»ç½‘ç»œå±•å¼€ï¼Œä½†è®­ç»ƒå¤§è§„æ¨¡ç¥ç»ç½‘ç»œæ˜¯ä¸€é¡¹è‰°å·¨çš„å·¥ç¨‹å’Œç ”ç©¶æŒ‘æˆ˜ï¼Œéœ€è¦åè°ƒGPUé›†ç¾¤æ¥æ‰§è¡Œå•ä¸ªåŒæ­¥è®¡ç®—ã€‚éšç€é›†ç¾¤æ•°å’Œæ¨¡å‹è§„æ¨¡çš„å¢é•¿ï¼Œæœºå™¨å­¦ä¹ ä»ä¸šè€…å¼€å‘äº†å¤šé¡¹æŠ€æœ¯ï¼Œè®©æœºå™¨å­¦ä¹ æ¨¡å‹èƒ½åœ¨å¤šä¸ªGPUä¸Šè¿›è¡Œå¹¶è¡Œæ¨¡å‹è®­ç»ƒã€‚\nä¹ä¸€çœ‹ï¼Œè¿™äº›å¹¶è¡ŒæŠ€æœ¯ä»¤äººç”Ÿç•ï¼Œä½†åªéœ€å¯¹è®¡ç®—ç»“æ„è¿›è¡Œä¸€äº›å‡è®¾ï¼Œè¿™äº›æŠ€æœ¯å°±ä¼šå˜å¾—æ¸…æ™°ï¼šä»æŸäº›è§’åº¦æ¥çœ‹ï¼Œè¿™ä¹Ÿåªæ˜¯ä» A åˆ° B ä¼ é€’å¹¶ä¸é€æ˜çš„ä½ï¼Œå°±åƒæ•°æ®åŒ…åœ¨ç½‘ç»œäº¤æ¢æœºä¹‹é—´ä¼ é€’ä¸€æ ·ã€‚\nFig 1. å„ç§ Parallel æ¨¡å‹ ä¸åŒçš„å¹¶è¡ŒæŠ€æœ¯å°†è®­ç»ƒè¿‡ç¨‹åˆ’åˆ†ä¸ºä¸åŒçš„ç»´åº¦ï¼ŒåŒ…æ‹¬ï¼š\næ•°æ®å¹¶è¡Œï¼ˆData Parallelismï¼‰åœ¨ä¸åŒçš„GPUä¸Šè¿è¡ŒåŒä¸€æ‰¹æ•°æ®çš„ä¸åŒå­é›† DPï¼ˆData Parallelï¼‰ DDPï¼ˆDistributed Data Parallelï¼‰ FSDPï¼ˆFully Shared Data Parallelï¼‰ æµæ°´å¹¶è¡Œï¼ˆPipeline Parallelismï¼‰åœ¨ä¸åŒçš„GPUä¸Šè¿è¡Œæ¨¡å‹çš„ä¸åŒå±‚ æ¨¡å‹å¹¶è¡Œï¼ˆTensor Parallelismï¼‰å°†å•ä¸ªæ•°å­¦è¿ç®—ï¼ˆå¦‚çŸ©é˜µä¹˜æ³•ï¼‰æ‹†åˆ†åˆ°ä¸åŒçš„GPUä¸Šè¿è¡Œ ä¸“å®¶æ··åˆï¼ˆMixture-of-Expertsï¼‰åªç”¨æ¨¡å‹æ¯ä¸€å±‚ä¸­çš„ä¸€å°éƒ¨åˆ†æ¥å¤„ç†æ•°æ®ã€‚ Noteï¼šTensor Parallelism ç¿»è¯‘æˆæ¨¡å‹å¹¶è¡Œå¯èƒ½å¹¶ä¸æ˜¯éå¸¸çš„æ°å½“ğŸ¤£\n1. å¹¶è¡Œæ¨¡å‹ 1.1 æ•°æ®å¹¶è¡Œ ï¼ˆData Parallesimï¼‰ æ•°æ®å¹¶è¡Œæ˜¯æŒ‡å°†ç›¸åŒçš„å‚æ•°å¤åˆ¶åˆ°å¤šä¸ªå·¥ä½œèŠ‚ç‚¹ä¸Šï¼Œå¹¶ä¸ºæ¯ä¸ªå·¥ä½œèŠ‚ç‚¹åˆ†é…ä¸åŒçš„æ•°æ®å­é›†åŒæ—¶è¿›è¡Œå¤„ç†ã€‚æ¯ä¸ªå·¥ä½œèŠ‚ç‚¹æ‹¥æœ‰å®Œæ•´çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œæ¯æ¬¡è®­ç»ƒä»…å°†ä¸€æ‰¹æ•°æ®è¾“å…¥æ¨¡å‹ï¼Œè¿›è¡Œå‰å‘ä¼ æ’­ã€è®¡ç®—è¯¯å·®ã€åå‘ä¼ æ’­ï¼Œæœ€åè¿›è¡Œå‚æ•°çš„æ›´æ–°ã€‚å‚¨äº†å‚æ•°çš„æ›´æ–°ï¼Œå…¶ä½™çš„æ“ä½œéƒ½æ˜¯äº’ç›¸ç‹¬ç«‹çš„ï¼Œæ‰€ä»¥å¯ä»¥åœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šè¿›è¡Œå¹¶å‘çš„æ‰§è¡Œã€‚\næ¯ä¸ªå·¥ä½œèŠ‚ç‚¹éƒ½æœ‰è‡ªå·±çš„æ¨¡å‹å’Œè¾“å…¥ï¼Œå½“å±äºè‡ªå·±çš„æ¨¡å‹å‚æ•°æ¨ç†å®Œæˆåï¼ˆäº§ç”Ÿäº†æ¢¯åº¦å‚æ•°ï¼‰ï¼Œæ‰€æœ‰çš„å·¥ä½œèŠ‚ç‚¹ä¼šæŠŠå‚æ•°ï¼ˆæ¢¯åº¦å‚æ•°ï¼‰å‘ç»™ä¸€ä¸ª Masterï¼Œè¿™ä¸ª Master ä¼šæŠŠæ‰€æœ‰èŠ‚ç‚¹ä¼ è¿›æ¥çš„å‚æ•°åšèåˆï¼Œé€šè¿‡è¿™äº›æ¢¯åº¦å‚æ•°æ›´æ–°ç”Ÿæˆæ–°çš„æ¨¡å‹å‚æ•°ï¼Œç„¶åæŠŠè¿™ä¸ªæ¨¡å‹çš„å‚æ•°å†å‘é€ç»™æ¯ä¸ªå·¥ä½œèŠ‚ç‚¹ï¼Œæ‹±ä»–ä»¬è¿›è¡Œä¸‹ä¸€è½®çš„è®¡ç®—ã€‚\nåœ¨ Pytorch ä¸­æä¾›äº†DPï¼ˆData Parallelï¼‰ã€DDPï¼ˆDistributed Data Parallelï¼‰ã€FSDPï¼ˆFully Shared Data Parallelï¼‰ä¸‰ç§ä¸åŒçš„æ•°æ®å¹¶è¡Œæ–¹æ³•ã€‚\n1.1.1 DPï¼ˆData Parallelï¼‰Parameter Server DP ä½¿ç”¨äº† Parameter Serverï¼ˆPSï¼‰ ä½œä¸ºç†è®ºä¾æ®ã€‚PS ç»“æ„æ˜¯ææ²è€å¸ˆæå‡ºæ¥çš„æ–¹æ³•ï¼Œç”±serverèŠ‚ç‚¹å’ŒworkerèŠ‚ç‚¹ç»„æˆã€‚\n[ç‚¹å‡»æŠ˜å ] ææ²è€å¸ˆçš„ PS è®²è§£ Server èŠ‚ç‚¹çš„ä¸»è¦åŠŸèƒ½æ˜¯åˆå§‹åŒ–å’Œä¿å­˜æ¨¡å‹å‚æ•°ã€æ¥å—workerèŠ‚ç‚¹è®¡ç®—å‡ºçš„å±€éƒ¨æ¢¯åº¦ã€æ±‡æ€»è®¡ç®—å…¨å±€æ¢¯åº¦ï¼Œå¹¶æ›´æ–°æ¨¡å‹å‚æ•°ã€‚\nFig 2. Parameter Server Worker èŠ‚ç‚¹çš„ä¸»è¦åŠŸèƒ½æ˜¯å„è‡ªä¿å­˜éƒ¨åˆ†è®­ç»ƒæ•°æ®ï¼Œåˆå§‹åŒ–æ¨¡å‹ï¼Œä» Server èŠ‚ç‚¹æ‹‰å–ï¼ˆPullï¼‰æœ€æ–°çš„æ¨¡å‹å‚æ•°ï¼Œå†è¯»å–å‚æ•°ï¼Œæ ¹æ®è®­ç»ƒæ•°æ®è®¡ç®—å±€éƒ¨æ¢¯åº¦ï¼Œä¸Šä¼ ï¼ˆPushï¼‰ç»™ Server èŠ‚ç‚¹ã€‚psï¼šææ²è€å¸ˆè¯´è¿™ä¸ª Pull å’Œ Push å«æ³•æ¥æºäº Gitã€‚\nåœ¨è¿™ä¸ªæ¨¡å¼ä¸‹ï¼Œä¼šæœ‰è´Ÿè½½ä¸å‡è¡¡çš„æƒ…å†µå‡ºç°ã€‚å› ä¸ºåœ¨ Server éœ€è¦å¤§é‡çš„æ˜¾å­˜æ¥ä¿å­˜ä» Woker åˆ°æ¥çš„æ¢¯åº¦å‚æ•°ï¼Œè€Œ Server è¿˜éœ€è¦å°†æ›´æ–°åçš„å‚æ•°å¹¿æ’­åˆ°æ¯ä¸€ä¸ª Worker ä¸Šï¼Œé‚£ä¹ˆ Server çš„ç½‘ç»œå¸¦å®½å°±å˜å¾—æ˜¯éé‡è¦äº†ã€‚éšç€ Worker æ•°ç›®çš„å¢å¤šï¼Œç½‘ç»œçš„éœ€æ±‚ä¼šæ›´åŠ å¤§ã€‚å¹¶ä¸” Server ä½œä¸ºæœ€ç»ˆå¤„ç†æ‰€æœ‰ Worker ä¼ æ¥çš„æ¢¯åº¦å‚æ•°çš„æœºå™¨ï¼Œå…¶è®¡ç®—æ¶ˆè€—æ—¶é—´ä¹Ÿæ˜¯åˆ¶çº¦å…¶ä»– Worker ä¸é—´æ–­å·¥ä½œçš„ç“¶é¢ˆã€‚\n1.1.2 DDPï¼ˆDistributed Data Parallelï¼‰Ring-All-Reduce DDP ä¸»è¦åŸºäº Ring-All-Reduce ç®—æ³•ï¼Œè¯¥ç®—æ³•ä¸»è¦åˆ†ä¸¤æ­¥ï¼š\nshare-reduceï¼šä¼šé€æ­¥äº¤æ¢å½¼æ­¤çš„æ¢¯åº¦å¹¶èåˆï¼Œæœ€åæ¯ä¸ª GPU éƒ½ä¼šåŒ…å«å®Œæ•´èåˆæ¢¯åº¦çš„ä¸€éƒ¨åˆ†ã€‚ share-onlyï¼šGPU ä¼šé€æ­¥äº¤æ¢å½¼æ­¤ä¸å®Œæ•´çš„èåˆæ¢¯åº¦ï¼Œæœ€åæ‰€æœ‰ GPU éƒ½ä¼šå¾—åˆ°å®Œæ•´çš„èåˆæ¢¯åº¦ Fig 3. Ring-All-Reduce ç¤ºæ„å›¾ åœ¨ share-reduce é˜¶æ®µï¼Œæ¯ä¸ªè¿›ç¨‹ p å°†æ•°æ®å‘é€ç»™è¿›ç¨‹ (p+1) % pï¼Œå…¶ä¸­ % æ˜¯æ¨¡è¿ç®—ç¬¦ã€‚æ‰€ä»¥è¿›ç¨‹Aä¼šå‘è¿›ç¨‹ B å‘é€ã€‚è¿™å°±æ˜¯åˆ›å»ºç±»ä¼¼äºç¯å½¢é˜Ÿåˆ—çŠ¶æ€çš„çš„åŸå› ã€‚æ­¤å¤–ï¼Œé•¿åº¦ä¸º n çš„æ•°ç»„è¢«åˆ’åˆ†æˆ p å—ï¼Œè¿™äº›å—ä¸­çš„æ¯ä¸€ä¸ªéƒ½å°†ä»¥ i ä¸ºç´¢å¼•ã€‚å®ƒçœ‹èµ·æ¥ä¼šæ˜¯è¿™æ ·çš„ï¼š\nFig 4. Ring-All-Reduce 1 ç¬¬ä¸€ä¸ª share-reduce æ“ä½œè¿›ç¨‹ A å‘è¿›ç¨‹ B å‘é€ a0ï¼Œè¿›ç¨‹ B å°†å‘è¿›ç¨‹ C å‘é€ b1ï¼Œç­‰ç­‰ã€‚ç±»ä¼¼è¿™æ ·ï¼š\nFig 5. Ring-All-Reduce 2 ç„¶åï¼Œå½“æ¯ä¸ªè¿›ç¨‹æ”¶åˆ°å‰ä¸€ä¸ªè¿›ç¨‹çš„æ•°æ®æ—¶ï¼Œå®ƒå°±ä¼šåº”ç”¨ reduce operationï¼Œç„¶åç»§ç»­å°†å…¶å†æ¬¡å‘é€åˆ°ç¯ä¸­çš„ä¸‹ä¸€ä¸ªè¿›ç¨‹ã€‚å¦‚æœ reduce operation æ˜¯ sumã€‚å®ƒçœ‹èµ·æ¥å°±ä¼šåƒè¿™æ ·ï¼š\nFig 6. Ring-All-Reduce 3 ç„¶åï¼Œå†è¿›ä¸€æ­¥ï¼š\nFig 7. Ring-All-Reduce 4 ç¬¬äºŒæ­¥ï¼Œshared-onlyï¼Œè¿™ä¸ªæ“ä½œéå¸¸çš„ç®€å•ï¼Œåªæ˜¯ä»¥ç¯å½¢æ–¹å¼å…±äº«æ•°æ®ï¼Œè€Œä¸åº”ç”¨ reduce operationã€‚è¿™å°±æŠŠæ¯ä¸ªè¿›ç¨‹ä¸­çš„æ¯ä¸ªåˆ†å—çš„ç»“æœåˆå¹¶èµ·æ¥ã€‚\nFig 8. Ring-All-Reduce 5 Ring-All-Reduce æœ‰è¿™äº›ä¼˜ç‚¹ï¼š\nè´Ÿè½½åˆ†æ•£åœ¨æ¯ä¸ª Worker ä¸Šï¼Œé€šè®¯æ—¶é—´åŸºæœ¬æ˜¯ä¸€è‡´çš„ã€‚å¹¶ä¸”ä¸éœ€è¦é€šè¿‡ Server åˆ†å‘å…¨æ¨¡å‹çš„å‚æ•°åˆ°æ¯ä¸ª Worker ä¸Šã€‚ ä½¿ç”¨ ring-all-reduce çš„æ–¹å¼è¿›è¡Œé€šè®¯ï¼Œéšç€ Worker æ•°é‡ N å¢åŠ ï¼Œæ€»ä¼ è¾“é‡æ’å®šã€‚ä¹Ÿå°±æ˜¯ç†è®ºä¸Šï¼Œéšç€ Worker æ•°é‡çš„å¢åŠ ï¼Œring all-reduce æœ‰çº¿æ€§æ€§èƒ½æ‹“å±•èƒ½åŠ›ã€‚ DP å’Œ DDP ä¹‹é—´çš„åŒºåˆ«\nData Parallel Distributed Data Parallel æ›´å¤šçš„å¼€é”€ï¼›æ¨¡å‹åœ¨æ¯æ¬¡å‚æ•°èšåˆåéœ€è¦è¢«å¤åˆ¶ï¼Œå¹¶åœ¨æ¯æ¬¡å‰å‘ä¼ é€’åè¢«é”€æ¯ï¼ˆå› ä¸ºåªéœ€è¦æ¢¯åº¦å‚æ•°è¢«ä¼ å›å°±å¤Ÿäº†ï¼‰ã€‚ æ¨¡å‹åªä¼šè¢«å¤åˆ¶ä¸€æ¬¡ åªæ”¯æŒå•ä¸ªèŠ‚ç‚¹çš„ Master å¯ä»¥æ‹“å±•åˆ°å¤šå°æœºå™¨ä¸Š å•è¿›ç¨‹å¤šçº¿ç¨‹çš„å®ç°æ–¹å¼ é‡‡ç”¨å¤šè¿›ç¨‹çš„æ–¹å¼ 1.1.3 FSDPï¼ˆFully Shared Data Parallelï¼‰ DDP ç”¨èµ·æ¥ç®€å•æ–¹ä¾¿ï¼Œä½†æ˜¯è¦æ±‚æ•´ä¸ªæ¨¡å‹èƒ½åŠ è½½ä¸€ä¸ªGPUä¸Šï¼Œè¿™ä½¿å¾—å¤§æ¨¡å‹çš„è®­ç»ƒéœ€è¦ä½¿ç”¨é¢å¤–å¤æ‚çš„è®¾ç½®è¿›è¡Œæ¨¡å‹æ‹†åˆ†ã€‚Pytorch çš„ FSDP ä» DeepSpeed ZeRO [8] ä»¥åŠ FairScale çš„ FSDP ä¸­è·å–çµæ„Ÿï¼Œæ‰“ç ´æ¨¡å‹åˆ†ç‰‡çš„éšœç¢ï¼ˆåŒ…æ‹¬æ¨¡å‹å‚æ•°ï¼Œæ¢¯åº¦ï¼Œä¼˜åŒ–å™¨çŠ¶æ€ï¼‰ï¼ŒåŒæ—¶ä»ç„¶ä¿æŒäº†æ•°æ®å¹¶è¡Œçš„ç®€å•æ€§ã€‚\nFSDP æ˜¯å¯¹æ¨¡å‹å‚æ•°ã€ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦è¿›è¡Œåˆ†ç‰‡ï¼Œå¯ä»¥é€‰æ‹©å°†éƒ¨åˆ†æ¨¡å‹å‚æ•°å¸è½½åˆ° CPU ä¸­ã€‚FSDP æ˜¯åœ¨ DDP çš„åŸºç¡€ä¸Šï¼Œå°† All-Reduce æ“ä½œåˆ†è§£ä¸ºç‹¬ç«‹çš„ Reduce-Scatter å’Œ All-gather çš„æ“ä½œè¿™ç§æ–¹å¼èƒ½å¤Ÿä½¿å¾—æ¯ä¸ªå·¥ä½œèŠ‚ç‚¹ä»…éœ€å­˜å‚¨ä¸€ä¸ªå‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€çš„åˆ†ç‰‡ã€‚FSDP éå¸¸ç±»ä¼¼äº ZeRO-3ã€‚\nFig 9. FSDP workflow [3] å¦‚ FSDP å®Œå…¨æµç¨‹å›¾æ‰€ç¤ºï¼Œé€šè¿‡ All-gather æ“ä½œå¯ä»¥ä»å…¶ä»–å·¥ä½œèŠ‚ç‚¹è·å–æ¨¡å‹æƒé‡æ¥è¿›è¡Œå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ã€‚Reduce-Scatter æ“ä½œèšåˆå±€éƒ¨æ¢¯åº¦ï¼Œå¹¶åœ¨å„å·¥ä½œçš„èŠ‚ç‚¹ä¸Šåˆ†ç‰‡ï¼Œè¿˜å¯ä»¥é€‰æ‹©å°†æ¢¯åº¦å¸è½½åˆ°CPU ä¸­ï¼Œç­‰éœ€è¦æ—¶å†ä» CPU ä¸­åŠ è½½å›æ¥ã€‚\nFig 10. Reduce-Scatter and All-gather åŸæœ¬çš„ All-Reduce æ“ä½œå¯ä»¥æ‹†åˆ†æˆ Reduce-Scatter å’Œ All-gather æ“ä½œã€‚åœ¨è¿›è¡ŒReduce-Scatter æ—¶ï¼Œgradients åœ¨ç›¸åŒå—çš„å„ä¸ª ranks ä¸­è¢«åŠ èµ·æ¥ï¼Œåœ¨è¿›è¡Œ All-gather æ—¶ï¼Œæ¯ä¸ª Worker ä¸Šå¯ç”¨çš„èšåˆæ¢¯åº¦åˆ†ç‰‡çš„éƒ¨åˆ†å¯ä¾›æ‰€æœ‰ Worker ä½¿ç”¨ã€‚\n1.2 æµæ°´å¹¶è¡Œï¼ˆPipeline Parallesimï¼‰ é€šè¿‡æµæ°´çº¿æœºåˆ¶è¿›è¡Œå¹¶è¡Œè®­ç»ƒï¼Œæˆ‘ä»¬å°†æ¨¡å‹çš„å‚æ•°åˆ†é…åˆ°GPUä¸Šã€‚æ¯ä¸ªGPUåªæŒæœ‰ä¸€éƒ¨åˆ†å‚æ•°ï¼Œå› æ­¤ï¼ŒåŒä¸€ä¸ªæ¨¡å‹åœ¨æ¯ä¸ªGPUä¸Šæ¶ˆè€—çš„å†…å­˜æˆæ¯”ä¾‹å‡å°ã€‚\nå°†å¤§æ¨¡å‹åˆ†ä¸ºè‹¥å¹²ä»½è¿ç»­çš„layerå¾ˆç®€å•ã€‚ç„¶è€Œï¼Œå„å±‚çš„è¾“å…¥å’Œè¾“å‡ºä¹‹é—´å­˜åœ¨ç€é¡ºåºä¸Šçš„ä¾èµ–æ€§ï¼Œæ‰€ä»¥ä¸€ä¸ªç®€å•çš„å®ç°ä¼šå¯¼è‡´å¤§é‡çš„GPUç©ºé—²æ—¶é—´ï¼Œå› ä¸º Worker åœ¨ç­‰å¾…å‰ä¸€ä¸ª Worker çš„è¾“å‡ºæ¥ç”¨ä½œå…¶è¾“å…¥ã€‚è¿™äº›ç­‰å¾…æ—¶é—´å—è¢«ç§°ä¸º \u0026ldquo;æ°”æ³¡(bubble)\u0026rdquo;ï¼Œè€Œåœ¨è¿™äº›ç­‰å¾…çš„è¿‡ç¨‹ä¸­ï¼Œç©ºé—²çš„æœºå™¨æœ¬å¯ä»¥ç»§ç»­è¿›è¡Œè®¡ç®—ã€‚ã€‚\nFig 11. Naive way for Streaming [1] ä¸ºäº†å‡å°‘æ°”æ³¡çš„å¼€é”€ï¼Œæˆ‘ä»¬å¯ä»¥é‡ç”¨æ•°æ®å¹¶è¡Œçš„æ€æƒ³ï¼Œé€šè¿‡è®©æ¯ä¸ª Worker ä¸€æ¬¡åªå¤„ç†ä¸€ä¸ªæ•°æ®å…ƒç´ çš„å­é›†ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿå·§å¦™åœ°å°†æ–°çš„è®¡ç®—ä¸ç­‰å¾…æ—¶é—´é‡å (overlapping)èµ·æ¥ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯å°†ä¸€ä¸ªæ‰¹æ¬¡åˆ†æˆå¤šä¸ªå¾®æ‰¹(microbatches)ï¼›æ¯ä¸ªå¾®æ‰¹çš„å¤„ç†é€Ÿåº¦åº”è¯¥æ˜¯æˆæ¯”ä¾‹çš„ï¼Œæ¯ä¸ª Worker åœ¨ä¸‹ä¸€ä¸ªå¾®æ‰¹å¯ç”¨æ—¶å°±å¼€å§‹å·¥ä½œï¼Œä»è€ŒåŠ é€Ÿæµçš„æ‰§è¡Œã€‚æœ‰äº†è¶³å¤Ÿçš„å¾®æ‰¹ï¼ŒWorker å¯ä»¥åœ¨å¤§éƒ¨åˆ†æ—¶é—´å†…è¢«åˆ©ç”¨ï¼Œåœ¨è¿›ç¨‹çš„å¼€å§‹å’Œç»“æŸæ—¶ï¼Œæ°”æ³¡æœ€å°ã€‚æ¢¯åº¦æ˜¯è·¨å¾®æ‰¹çš„å¹³å‡æ•°ï¼Œåªæœ‰åœ¨æ‰€æœ‰å¾®æ‰¹å®Œæˆåæ‰ä¼šå¯¹å‚æ•°è¿›è¡Œæ›´æ–°ã€‚\næ¨¡å‹è¢«åˆ†å‰²çš„èŠ‚ç‚¹æ•°çš„æ•°é‡é€šå¸¸è¢«ç§°ä¸ºæµæ°´çº¿æ·±åº¦(Pipline depth)ã€‚\nåœ¨å‰å‘ä¼ é€’æœŸé—´ï¼ŒWorker åªéœ€è¦å°†å…¶ Layer çš„è¾“å‡ºï¼ˆç§°ä¸ºæ¿€æ´»ï¼‰å‘é€ç»™ä¸‹ä¸€ä¸ª Workerï¼›åœ¨åå‘ä¼ é€’æœŸé—´ï¼Œå®ƒåªå°†è¿™äº›æ¿€æ´»çš„æ¢¯åº¦å‘é€ç»™å‰ä¸€ä¸ª Worker ã€‚å¦‚ä½•å®‰æ’è¿™äº›ä¼ é€’ä»¥åŠå¦‚ä½•åœ¨å¾®æ‰¹ä¸­èšé›†æ¢¯åº¦ï¼Œæœ‰å¾ˆå¤§çš„è®¾è®¡ç©ºé—´ã€‚ GPipeè®©æ¯ä¸ªå·¥ä½œè€…è¿ç»­å¤„ç†å‰å‘å’Œåå‘çš„ä¼ é€’ï¼Œç„¶ååœ¨æœ€ååŒæ­¥èšåˆæ¥è‡ªå¤šä¸ªå¾®æ‰¹çš„æ¢¯åº¦ã€‚è€Œ PipeDream åˆ™å®‰æ’æ¯ä¸ª Worker äº¤æ›¿åœ°å¤„ç†å‰å‘å’Œåå‘ Streamã€‚\nFig 12. GPipe and PipeDream [1] 1.3 æ¨¡å‹å¹¶è¡Œï¼ˆTensor Parallesimï¼‰ æµæ°´å¹¶è¡Œå°†ä¸€ä¸ªæ¨¡å‹æŒ‰å±‚â€œå‚ç›´â€æ‹†åˆ†ã€‚ä¹Ÿå¯ä»¥åœ¨ä¸€ä¸ª layer å†… â€œæ°´å¹³â€ åˆ†å‰²æŸäº›æ“ä½œï¼Œè¿™é€šå¸¸è¢«ç§°ä¸ºæ¨¡å‹å¹¶è¡Œè®­ç»ƒã€‚å¯¹äºè®¸å¤šç°ä»£æ¨¡å‹ï¼ˆå¦‚Transformerï¼‰æ¥è¯´ï¼Œè®¡ç®—çš„ç“¶é¢ˆæ˜¯å°†æ¿€æ´»å€¼ä¸å¤§çš„æƒé‡çŸ©é˜µç›¸ä¹˜ã€‚çŸ©é˜µä¹˜æ³•å¯ä»¥è¢«è®¤ä¸ºæ˜¯æˆå¯¹çš„è¡Œå’Œåˆ—ä¹‹é—´çš„ç‚¹ç§¯ï¼šæœ‰å¯èƒ½åœ¨ä¸åŒçš„GPUä¸Šè®¡ç®—ç‹¬ç«‹çš„ç‚¹ç§¯ï¼Œæˆ–è€…åœ¨ä¸åŒçš„GPUä¸Šè®¡ç®—æ¯ä¸ªç‚¹ç§¯çš„ä¸€éƒ¨åˆ†ï¼Œç„¶åå°†ç»“æœç›¸åŠ ã€‚æ— è®ºé‡‡ç”¨å“ªç§ç­–ç•¥ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥å°†æƒé‡çŸ©é˜µåˆ‡æˆå¤§å°å‡åŒ€çš„ â€œå—(Shards)â€ï¼Œå°†æ¯ä¸ªå—æ”¾åœ¨ä¸åŒçš„GPUä¸Šã€‚è¦å¾—åˆ°å®Œæ•´çŸ©é˜µçš„ç»“æœï¼Œéœ€è¦è¿›è¡Œé€šä¿¡å°†ä¸åŒéƒ¨åˆ†çš„ç»“æœè¿›è¡Œæ•´åˆã€‚\nä¸€ä¸ªä¾‹å­æ˜¯ Megatron-LMï¼Œå®ƒåœ¨ Transformer çš„ è‡ªæ³¨æ„ å’Œ MLPå±‚å†…å¹¶è¡ŒåŒ–çŸ©é˜µä¹˜æ³•ã€‚ PTD-P åŒæ—¶ä½¿ç”¨å¼ é‡ã€æ•°æ®å’Œæµæ°´çº¿å¹¶è¡Œï¼›å®ƒçš„æµæ°´çº¿å¹¶è¡Œå°†å¤šä¸ªä¸è¿ç»­çš„ layer åˆ†é…åˆ°å•è®¾å¤‡ä¸Šè¿è¡Œï¼Œä»¥æ›´å¤šç½‘ç»œé€šä¿¡ä¸ºä»£ä»·æ¥å‡å°‘æ°”æ³¡å¼€é”€ã€‚\næœ‰æ—¶ï¼Œç½‘ç»œçš„è¾“å…¥å¯ä»¥åœ¨ä¸€ä¸ªç»´åº¦ä¸Šè¿›è¡Œå¹¶è¡ŒåŒ–ï¼Œç›¸å¯¹äºäº¤å‰é€šä¿¡æ¥è¯´ï¼Œå¹¶è¡Œè®¡ç®—çš„ç¨‹åº¦å¾ˆé«˜ã€‚ åºåˆ—å¹¶è¡Œå°±æ˜¯è¿™æ ·ä¸€ä¸ªæƒ³æ³•ï¼Œä¸€ä¸ªè¾“å…¥åºåˆ—åœ¨ä¸åŒæ—¶é—´è¢«åˆ†å‰²æˆå¤šä¸ªå­é›†ï¼Œé€šè¿‡åœ¨æ›´ç»†ç²’åº¦çš„å­é›†ä¸Šè¿›è¡Œè®¡ç®—ï¼Œå³°å€¼å†…å­˜æ¶ˆè€—å¯ä»¥æˆæ¯”ä¾‹åœ°å‡å°‘ã€‚\n1.4 æ··åˆå¹¶è¡Œï¼ˆMixture-of-Expertsï¼‰ æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ–¹æ³•ï¼Œå¯¹äºä»»ä½•ä¸€ä¸ªè¾“å…¥ï¼Œåªæœ‰ä¸€éƒ¨åˆ†ç½‘ç»œè¢«ç”¨æ¥è®¡ç®—è¾“å‡ºã€‚åœ¨æœ‰è®¸å¤šå¥—æƒé‡çš„æƒ…å†µä¸‹ï¼Œç½‘ç»œå¯ä»¥åœ¨æ¨ç†æ—¶é€šè¿‡é—¨æ§æœºåˆ¶é€‰æ‹©ä½¿ç”¨å“ªä¸€å¥—ã€‚è¿™æ ·å°±å¯ä»¥åœ¨ä¸å¢åŠ è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹å¢åŠ è®¸å¤šå‚æ•°ã€‚æ¯ç»„æƒé‡è¢«ç§°ä¸º \u0026ldquo;ä¸“å®¶(experts)\u0026quot;ï¼Œå¸Œæœ›ç½‘ç»œèƒ½å¤Ÿå­¦ä¼šå°†ä¸“é—¨çš„è®¡ç®—ä»»åŠ¡åˆ†é…ç»™æ¯ä¸ªä¸“å®¶ã€‚ä¸åŒçš„ä¸“å®¶å¯ä»¥æ‰˜ç®¡åœ¨ä¸åŒçš„GPUä¸Šï¼Œè¿™ä¹Ÿä¸ºæ‰©å¤§æ¨¡å‹ä½¿ç”¨çš„GPUæ•°é‡æä¾›äº†ä¸€ä¸ªæ˜ç¡®çš„æ–¹æ³•ã€‚\næ··åˆä¸“å®¶ï¼ˆMoEIllustration of a mixture-of-experts (MoE) layer. Only 2 out of the n experts are selected by the gating network. (Image adapted from: Shazeer et al., 2017)[1]\nGShardå°† MoE Transformer çš„è§„æ¨¡æ‰©å¤§åˆ°6000äº¿ä¸ªå‚æ•°ï¼Œå…¶ä¸­MoE layersè¢«æ‹†åˆ†åˆ°å¤šä¸ªTPUä¸Šï¼Œå…¶ä»–layersæ˜¯å®Œå…¨é‡å¤çš„ã€‚ Switch Transformer é€šè¿‡å°†ä¸€ä¸ªè¾“å…¥åªè·¯ç”±åˆ°ä¸€ä¸ªä¸“å®¶ï¼Œå°†æ¨¡å‹è§„æ¨¡æ‰©å±•åˆ°æ•°ä¸‡äº¿çš„å‚æ•°ï¼Œç”šè‡³æœ‰æ›´é«˜çš„ç¨€ç–åº¦ã€‚\néš¾ç‚¹ï¼š\nç°åœ¨çš„è®¾å¤‡ï¼Œæ¯”å¦‚GPUï¼Œæ¯”è¾ƒæ“…é•¿åšè¿ç®—ï¼Œä¸æ“…é•¿åšåˆ†æ”¯ã€‚ å¤§æ‰¹é‡æ˜¯è®­ç»ƒæ¨¡å‹çš„å¿…é¡»ï¼Œä½†æ˜¯è¿™ç§æ–¹å¼ä¸‹ä¼šå¯¼è‡´æ¯ä¸ªå°æ¨¡å‹çš„æ ·æœ¬æ•°è¾ƒå°‘ï¼Œæ— æ³•è®­ç»ƒå¾—åˆ°å¥½çš„æ¨¡å‹ã€‚ ä¸ºäº†æ§åˆ¶ç¨€ç–æ€§ï¼Œå¯èƒ½éœ€è¦åœ¨lossä¸Šå»åšäº›æ”¹è¿›ï¼Œæ¥ä¿éšœå°æ¨¡å‹ä¸Šçš„å‡è¡¡è´Ÿè½½ã€‚ Moe Github, code\n2. è‡ªåŠ¨å¹¶è¡Œæ–¹æ³• 2.1 Exploring Hidden Dimensions in Parallelizing Convolutional Neural Networks [9] Get This Paper\nè¿™ç¯‡æ–‡ç« å‹¾å‹’äº†è‡ªåŠ¨å¹¶è¡Œçš„åŸºæœ¬æ¡†æ¶ï¼Œå¾ˆå¤šè§£å†³è‡ªåŠ¨å¹¶è¡Œçš„å·¥ä½œéƒ½æ˜¯è¿™æ ·ä¸€ä¸ªæµç¨‹ã€‚\nReference:\n[1] Techniques for training large neural networks (openai.com)\n[2] å…ˆè¿›ç¼–è¯‘å®éªŒå®¤-è‡ªåŠ¨å¹¶è¡Œ-å¹¶è¡Œåˆ’åˆ† - çŸ¥ä¹ (zhihu.com)\n[3] Getting Started with Fully Sharded Data Parallel(FSDP)\n[4] chenzomi12/DeepLearningSystem: Deep Learning System core principles introduction. (github.com)\n[5] Deep Learning in a Nutshell: Core Concepts | NVIDIA Technical Blog\n[6] Visual intuition on ring-Allreduce for distributed Deep Learning | by Edir Garcia Lazo | Towards Data Science\n[7] æ•°æ®å¹¶è¡ŒDeep-dive: ä»DP åˆ° Fully Sharded Data Parallel ï¼ˆFSDPï¼‰å®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œ - çŸ¥ä¹ (zhihu.com)\n[8] DeepSpeed: Extreme-scale model training for everyone - Microsoft Research\n[9] Exploring Hidden Dimensions in Parallelizing Convolutional Neural Networks\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/tech/introduction_mldistri/","summary":"æ•°æ®å¹¶è¡Œã€æ¨¡å‹å¹¶è¡Œã€æµæ°´å¹¶è¡Œã€ä¸“å®¶æ··åˆ","title":"æµ…ææœºå™¨å­¦ä¹ ä¸­çš„å¹¶è¡Œæ¨¡å‹å’Œè‡ªåŠ¨å¹¶è¡Œæ–¹æ³•"},{"content":"NSight System Document\nWSL 2 çš„ cudaMallocHost() ä¸èƒ½æ­£å¸¸ç”³è¯·åˆ° VM çš„å†…å­˜ã€‚ä¹Ÿè®¸æ˜¯ WSL 2 ä¸Šçš„ cuda æ˜¯ ubuntu20.04 çš„ç‰ˆæœ¬ï¼Œä¸æ˜¯ WSL 2 ç‰¹ä¾›ç‰ˆã€‚WSL 2 çš„ cuda ä¹Ÿæœ‰ä¸€äº›é™åˆ¶ï¼Œè¯¦ç»†è§ WSL2 User guide ã€‚\n1. ä»€ä¹ˆæ˜¯ Nsight System æˆ‘ä»¬å…ˆçœ‹ä¸‹ Nsight System å®˜ç½‘å¯¹è¯¥å·¥å…·çš„æè¿°ï¼š\nNVIDIA Nsightâ„¢ Systems is a system-wide performance analysis tool designed to visualize an applicationâ€™s algorithms, help you identify the largest opportunities to optimize, and tune to scale efficiently across any quantity or size of CPUs and GPUs, from large servers to our smallest system on a chip (SoC).\nå¦‚ gperoftools ä¸€æ ·ï¼Œè¿™æ˜¯ä¸ªæ€§èƒ½è°ƒä¼˜å·¥å…·ï¼Œèšç„¦åœ¨ N å®¶çš„ GPU ä¸Šï¼Œå½“ç„¶ï¼ŒCPU ä¹Ÿæ˜¯åœ¨å…¶æ€§èƒ½åˆ†æçš„èŒƒå›´å†…ã€‚Nsight system æ›´å¤šçš„æ—¶å€™æ˜¯æŸ¥çœ‹ Memory Stream(Host2Device, Device2Host) å’Œ è®¡ç®— Kernel ä¹‹é—´çš„å…³ç³»ï¼ŒæŸ¥çœ‹æœ‰æ— åˆç†çš„å¡«å……æ»¡æµæ°´çº¿ï¼Œæ›´å¥½çš„åˆ©ç”¨ GPU çš„å¹¶è¡Œæ€§ã€‚\nNsight system ä¸»è¦æ˜¯é€šè¿‡é‡‡æ ·å’Œè¿½è¸ªæ¥åšæŠ“å–ç³»ç»Ÿä¿¡æ¯ï¼š\nsampling æ˜¯ç¡¬ä»¶å±‚é¢çš„å®ç° ï¼Œåˆ©ç”¨äº†Linux OS\u0026rsquo; perf subsystemï¼Œè·ŸLinux perfå·¥å…·ç”¨çš„ä¸€æ ·ï¼Œå‘¨æœŸæ€§åœ°åœæ­¢ç›®æ ‡ç¨‹åºï¼ˆæ¯”å¦‚æ¯100wä¸ªcycleï¼‰ï¼Œæ”¶é›†æ¯ä¸ªçº¿ç¨‹çš„ CPU Instruction Pointers(IP, æŒ‡ä»¤æŒ‡é’ˆ)ï¼Œä¾¿äºäº†è§£æŸä¸€æ—¶åˆ»ç³»ç»Ÿçš„æ‰§è¡ŒçŠ¶æ€ã€‚ tracing æ˜¯ç²¾ç¡®åœ°é‡‡é›†å„ä¸ªæ´»åŠ¨å¼€å§‹å’Œç»“æŸçš„æ—¶é—´ï¼Œä¾¿äºäº†è§£ç³»ç»Ÿå„ä¸ªç¯èŠ‚çš„æ—¶é—´å¼€é”€å’Œè¿è½¬æƒ…å†µã€‚ 2. å¦‚ä½•ä½¿ç”¨ Nsight System æˆ‘ä»¥ BGR 2 YUV çš„ä¾‹å­(ä»£ç æ¥è‡ªäº[1])æ¥å±•ç¤ºäº† Nsight system çš„ä¿¡æ¯ã€‚è¯¥ç¤ºä¾‹ä½¿ç”¨äº†ä¸¤ç§æ–¹å¼ï¼š1. å• Stream æ‰§è¡Œï¼›2. 16 Stream æ‰§è¡Œ(Stream çš„æ•°é‡æ²¡æœ‰æ˜ç¡®çš„é™åˆ¶ï¼Œä½†æ˜¯è²Œä¼¼åœ¨æˆ‘çš„æœºå™¨ä¸Šï¼Œæ€§èƒ½æœ€ä¼˜çš„ç»“æœå°±æ˜¯ 16ï¼Œåº”è¯¥ stream å¤šäº†ä»¥åå°±åä¼šè¢«åŠ å…¥è°ƒåº¦é˜Ÿåˆ—äº†)ã€‚\nä¸€èˆ¬åœ¨è°ƒä¼˜çš„æ—¶å€™å…ˆä½¿ç”¨ Nsight system æ¥å¤§ä½“çš„çœ‹ä¸€ä¸‹åŒæ­¥ï¼Œoverlap æ•°æ®æ¬è¿å’Œè®¡ç®—ç­‰æ˜¯ä¸æ˜¯åˆç†ã€‚å¯¹äº Kernel çš„è°ƒä¼˜ä¸€èˆ¬æ˜¯åœ¨ Nsight compute ä¸­ã€‚å½“ç„¶ï¼Œè¯¥å·¥å…·å®é™…ä¸Šä¹Ÿå¯ä»¥æ¥ç›‘æµ‹ Graphic ç›¸å…³çš„ä¸œè¥¿ï¼Œä¸ä»…ä»…æ˜¯åªæœ‰ CUDAã€‚\nä¸ºäº†ä¾¿åˆ©ï¼Œç›´æ¥ä½¿ç”¨ GUI ç•Œé¢æ¥æ“ä½œï¼Œä¸ªäººä¹Ÿæ¨è GUI å¯åŠ¨ï¼Œæ¯•ç«Ÿæœ€ç»ˆè¿˜æ˜¯è¦çœ‹æ—¶é—´è½´å›¾æ¥çš„ç›´è§‚ã€‚å¯¹äºæ²¡è£… GUI çš„æœºå™¨ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ SSH è¿œç¨‹è¿æ¥å®ƒï¼Œä¾¿äºæ“ä½œã€‚\nå¯¹äº BGR 2 YUV çš„ä¾‹å­ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨ GUI ä¸­è®¾ç½®ç¨‹åºçš„ä½ç½®å’Œç¨‹åºçš„å¯åŠ¨å‘½ä»¤å³å¯é…ç½®å®Œæˆä¸€ä¸ª Nsight system Projectã€‚(å¯ä»¥çœ‹åˆ°ï¼Œè¿™ä¸ªperfå·¥å…·è¿˜æ”¯æŒå¾ˆå¤šçš„ä¿¡æ¯ç»Ÿè®¡ï¼Œå¦‚ Vulkan å’Œ OpenGL)\nFig 1. NSight System Project Settings. åœ¨é…ç½®å®Œé‡‡æ ·ä¿¡æ¯ï¼Œéœ€è¦è¿½è¸ªçš„ä¿¡æ¯åï¼Œç‚¹å‡» Start å°±æ„‰å¿«çš„å¼€å§‹ç¨‹åºçš„åˆ†æäº†ã€‚åœ¨åˆ†æåçš„ Timeline View ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥æ¸…æ™°çš„çœ‹åˆ°æ¯ä¸ªé˜¶æ®µçš„æ—¶é—´æ¶ˆè€—ã€‚\nFig 2. 1 Stream. æ¯”å¦‚åœ¨ BGR 2 YUV çš„ç¬¬ä¸€ä¸ªä¾‹å­ä¸­(ä¸Šå›¾ï¼Œåªä½¿ç”¨å•ä¸ªStream)ï¼Œä»æ—¶é—´è½´ä¸Šå¯ä»¥çœ‹åˆ°å¹¶è¡Œæ€§å¹¶æ²¡æœ‰èµ·æ¥ï¼Œæˆ‘ä»¬å¯ä»¥å¤šå¼€å‡ ä¸ª Stream è®©æ•°æ®ä¼ è¾“å’Œè®¡ç®—å¹¶è¡Œèµ·æ¥ã€‚é€šè®©æ¯ä¸ª Stream åšä¸åŒçš„å·¥ä½œ(æ•°æ®æ¬è¿ï¼Œè®¡ç®—)ï¼Œæ¥æœ€å¤§åŒ–å¹¶è¡Œã€‚å¦‚ä¸‹å›¾æ‰€ç¤º:\nFig 3. 16 streams. code:\n[Click to expand] ä¸»é¡¹ç›® CMake è®¾ç½®\ncmake_minimum_required(VERSION 3.18) project( cmake_learn LANGUAGES CXX CUDA ) if(CUDA_ENABLE) enable_language(CUDA) endif() set(CMAKE_EXPORT_COMPILE_COMMANDS ON CACHE BOOL \u0026#34;\u0026#34;) message(STATUS \u0026#34;cuda version: \u0026#34; ${CUDA_VERSION_STRING}) include_directories(${CUDA_INCLUDE_DIRS}) add_subdirectory(\u0026#34;./stream\u0026#34;) å­é¡¹ç›® CMake è®¾ç½®\nproject(cuda_stream) add_executable(cuda_stream main.cu) add_compile_options(--cuda-gpu-arch=sm_20) main.cu\n#include \u0026lt;vector\u0026gt; #include \u0026lt;random\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;cuda.h\u0026gt; #include \u0026lt;cuda_runtime.h\u0026gt; #ifdef DEBUG #define CUDA_CALL(F) if( (F) != cudaSuccess ) \\ {printf(\u0026#34;Error %s at %s:%d\\n\u0026#34;, cudaGetErrorString(cudaGetLastError()), \\ __FILE__,__LINE__); exit(-1);} #define CUDA_CHECK() if( (cudaPeekAtLastError()) != cudaSuccess ) \\ {printf(\u0026#34;Error %s at %s:%d\\n\u0026#34;, cudaGetErrorString(cudaGetLastError()), \\ __FILE__,__LINE__-1); exit(-1);} #else #define CUDA_CALL(F) (F) #define CUDA_CHECK() #endif void PrintDeviceInfo(); void GenerateBgra8K(uint8_t* buffer, int dataSize); void convertPixelFormatCpu(uint8_t* inputBgra, uint8_t* outputYuv, int numPixels); __global__ void convertPixelFormat(uint8_t* inputBgra, uint8_t* outputYuv, int numPixels); int main() { PrintDeviceInfo(); uint8_t* bgraBuffer; uint8_t* yuvBuffer; uint8_t* deviceBgraBuffer; uint8_t* deviceYuvBuffer; const int dataSizeBgra = 7680 * 4320 * 4; const int dataSizeYuv = 7680 * 4320 * 3; CUDA_CALL(cudaMallocHost(\u0026amp;bgraBuffer, dataSizeBgra)); CUDA_CALL(cudaMallocHost(\u0026amp;yuvBuffer, dataSizeYuv)); CUDA_CALL(cudaMalloc(\u0026amp;deviceBgraBuffer, dataSizeBgra)); CUDA_CALL(cudaMalloc(\u0026amp;deviceYuvBuffer, dataSizeYuv)); std::vector\u0026lt;uint8_t\u0026gt; yuvCpuBuffer(dataSizeYuv); cudaEvent_t start, stop; float elapsedTime; float elapsedTimeTotal; float dataRate; CUDA_CALL(cudaEventCreate(\u0026amp;start)); CUDA_CALL(cudaEventCreate(\u0026amp;stop)); std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Generating 7680 x 4320 BRGA8888 image, data size: \u0026#34; \u0026lt;\u0026lt; dataSizeBgra \u0026lt;\u0026lt; std::endl; GenerateBgra8K(bgraBuffer, dataSizeBgra); std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Computing results using CPU.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::endl; CUDA_CALL(cudaEventRecord(start, 0)); convertPixelFormatCpu(bgraBuffer, yuvCpuBuffer.data(), 7680*4320); CUDA_CALL(cudaEventRecord(stop, 0)); CUDA_CALL(cudaEventSynchronize(stop)); CUDA_CALL(cudaEventElapsedTime(\u0026amp;elapsedTime, start, stop)); std::cout \u0026lt;\u0026lt; \u0026#34; Whole process took \u0026#34; \u0026lt;\u0026lt; elapsedTime \u0026lt;\u0026lt; \u0026#34;ms.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Computing results using GPU, default stream.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Move data to GPU.\u0026#34; \u0026lt;\u0026lt; std::endl; CUDA_CALL(cudaEventRecord(start, 0)); CUDA_CALL(cudaMemcpy(deviceBgraBuffer, bgraBuffer, dataSizeBgra, cudaMemcpyHostToDevice)); CUDA_CALL(cudaEventRecord(stop, 0)); CUDA_CALL(cudaEventSynchronize(stop)); CUDA_CALL(cudaEventElapsedTime(\u0026amp;elapsedTime, start, stop)); dataRate = dataSizeBgra/(elapsedTime/1000.0)/1.0e9; elapsedTimeTotal = elapsedTime; std::cout \u0026lt;\u0026lt; \u0026#34; Data transfer took \u0026#34; \u0026lt;\u0026lt; elapsedTime \u0026lt;\u0026lt; \u0026#34;ms.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Performance is \u0026#34; \u0026lt;\u0026lt; dataRate \u0026lt;\u0026lt; \u0026#34;GB/s.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Convert 8-bit BGRA to 8-bit YUV.\u0026#34; \u0026lt;\u0026lt; std::endl; CUDA_CALL(cudaEventRecord(start, 0)); convertPixelFormat\u0026lt;\u0026lt;\u0026lt;32400, 1024\u0026gt;\u0026gt;\u0026gt;(deviceBgraBuffer, deviceYuvBuffer, 7680*4320); CUDA_CHECK(); CUDA_CALL(cudaDeviceSynchronize()); CUDA_CALL(cudaEventRecord(stop, 0)); CUDA_CALL(cudaEventSynchronize(stop)); CUDA_CALL(cudaEventElapsedTime(\u0026amp;elapsedTime, start, stop)); dataRate = dataSizeBgra/(elapsedTime/1000.0)/1.0e9; elapsedTimeTotal += elapsedTime; std::cout \u0026lt;\u0026lt; \u0026#34; Processing of 8K image took \u0026#34; \u0026lt;\u0026lt; elapsedTime \u0026lt;\u0026lt; \u0026#34;ms.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Performance is \u0026#34; \u0026lt;\u0026lt; dataRate \u0026lt;\u0026lt; \u0026#34;GB/s.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Move data to CPU.\u0026#34; \u0026lt;\u0026lt; std::endl; CUDA_CALL(cudaEventRecord(start, 0)); CUDA_CALL(cudaMemcpy(yuvBuffer, deviceYuvBuffer, dataSizeYuv, cudaMemcpyDeviceToHost)); CUDA_CALL(cudaEventRecord(stop, 0)); CUDA_CALL(cudaEventSynchronize(stop)); CUDA_CALL(cudaEventElapsedTime(\u0026amp;elapsedTime, start, stop)); dataRate = dataSizeYuv/(elapsedTime/1000.0)/1.0e9; elapsedTimeTotal += elapsedTime; std::cout \u0026lt;\u0026lt; \u0026#34; Data transfer took \u0026#34; \u0026lt;\u0026lt; elapsedTime \u0026lt;\u0026lt; \u0026#34;ms.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Performance is \u0026#34; \u0026lt;\u0026lt; dataRate \u0026lt;\u0026lt; \u0026#34;GB/s.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Whole process took \u0026#34; \u0026lt;\u0026lt; elapsedTimeTotal \u0026lt;\u0026lt; \u0026#34;ms.\u0026#34; \u0026lt;\u0026lt;std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Compare CPU and GPU results ...\u0026#34; \u0026lt;\u0026lt; std::endl; bool foundMistake = false; for(int i=0; i\u0026lt;dataSizeYuv; i++){ if(yuvCpuBuffer[i]!=yuvBuffer[i]){ foundMistake = true; break; } } if(foundMistake){ std::cout \u0026lt;\u0026lt; \u0026#34; Results are NOT the same.\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34; Results are the same.\u0026#34; \u0026lt;\u0026lt; std::endl; } const int nStreams = 16; std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Computing results using GPU, using \u0026#34;\u0026lt;\u0026lt; nStreams \u0026lt;\u0026lt;\u0026#34; streams.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::endl; cudaStream_t streams[nStreams]; std::cout \u0026lt;\u0026lt; \u0026#34; Creating \u0026#34; \u0026lt;\u0026lt; nStreams \u0026lt;\u0026lt; \u0026#34; CUDA streams.\u0026#34; \u0026lt;\u0026lt; std::endl; for (int i = 0; i \u0026lt; nStreams; i++) { CUDA_CALL(cudaStreamCreate(\u0026amp;streams[i])); } int brgaOffset = 0; int yuvOffset = 0; const int brgaChunkSize = dataSizeBgra / nStreams; const int yuvChunkSize = dataSizeYuv / nStreams; CUDA_CALL(cudaEventRecord(start, 0)); for(int i=0; i\u0026lt;nStreams; i++) { std::cout \u0026lt;\u0026lt; \u0026#34; Launching stream \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34;.\u0026#34; \u0026lt;\u0026lt; std::endl; brgaOffset = brgaChunkSize*i; yuvOffset = yuvChunkSize*i; CUDA_CALL(cudaMemcpyAsync( deviceBgraBuffer+brgaOffset, bgraBuffer+brgaOffset, brgaChunkSize, cudaMemcpyHostToDevice, streams[i] )); convertPixelFormat\u0026lt;\u0026lt;\u0026lt;4096, 1024, 0, streams[i]\u0026gt;\u0026gt;\u0026gt;(deviceBgraBuffer+brgaOffset, deviceYuvBuffer+yuvOffset, brgaChunkSize/4); CUDA_CALL(cudaMemcpyAsync( yuvBuffer+yuvOffset, deviceYuvBuffer+yuvOffset, yuvChunkSize, cudaMemcpyDeviceToHost, streams[i] )); } CUDA_CHECK(); CUDA_CALL(cudaDeviceSynchronize()); CUDA_CALL(cudaEventRecord(stop, 0)); CUDA_CALL(cudaEventSynchronize(stop)); CUDA_CALL(cudaEventElapsedTime(\u0026amp;elapsedTime, start, stop)); std::cout \u0026lt;\u0026lt; \u0026#34; Whole process took \u0026#34; \u0026lt;\u0026lt; elapsedTime \u0026lt;\u0026lt; \u0026#34;ms.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Compare CPU and GPU results ...\u0026#34; \u0026lt;\u0026lt; std::endl; for(int i=0; i\u0026lt;dataSizeYuv; i++){ if(yuvCpuBuffer[i]!=yuvBuffer[i]){ foundMistake = true; break; } } if(foundMistake){ std::cout \u0026lt;\u0026lt; \u0026#34; Results are NOT the same.\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34; Results are the same.\u0026#34; \u0026lt;\u0026lt; std::endl; } CUDA_CALL(cudaFreeHost(bgraBuffer)); CUDA_CALL(cudaFreeHost(yuvBuffer)); CUDA_CALL(cudaFree(deviceBgraBuffer)); CUDA_CALL(cudaFree(deviceYuvBuffer)); return 0; } void PrintDeviceInfo(){ int deviceCount = 0; cudaGetDeviceCount(\u0026amp;deviceCount); std::cout \u0026lt;\u0026lt; \u0026#34;Number of device(s): \u0026#34; \u0026lt;\u0026lt; deviceCount \u0026lt;\u0026lt; std::endl; if (deviceCount == 0) { std::cout \u0026lt;\u0026lt; \u0026#34;There is no device supporting CUDA\u0026#34; \u0026lt;\u0026lt; std::endl; return; } cudaDeviceProp info; for(int i=0; i\u0026lt;deviceCount; i++){ cudaGetDeviceProperties(\u0026amp;info, i); std::cout \u0026lt;\u0026lt; \u0026#34;Device \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Name: \u0026#34; \u0026lt;\u0026lt; std::string(info.name) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Glocbal memory: \u0026#34; \u0026lt;\u0026lt; info.totalGlobalMem/1024.0/1024.0 \u0026lt;\u0026lt; \u0026#34; MB\u0026#34;\u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Shared memory per block: \u0026#34; \u0026lt;\u0026lt; info.sharedMemPerBlock/1024.0 \u0026lt;\u0026lt; \u0026#34; KB\u0026#34;\u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Warp size: \u0026#34; \u0026lt;\u0026lt; info.warpSize\u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Max thread per block: \u0026#34; \u0026lt;\u0026lt; info.maxThreadsPerBlock\u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Thread dimension limits: \u0026#34; \u0026lt;\u0026lt; info.maxThreadsDim[0]\u0026lt;\u0026lt; \u0026#34; x \u0026#34; \u0026lt;\u0026lt; info.maxThreadsDim[1]\u0026lt;\u0026lt; \u0026#34; x \u0026#34; \u0026lt;\u0026lt; info.maxThreadsDim[2]\u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Max grid size: \u0026#34; \u0026lt;\u0026lt; info.maxGridSize[0]\u0026lt;\u0026lt; \u0026#34; x \u0026#34; \u0026lt;\u0026lt; info.maxGridSize[1]\u0026lt;\u0026lt; \u0026#34; x \u0026#34; \u0026lt;\u0026lt; info.maxGridSize[2]\u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Compute capability: \u0026#34; \u0026lt;\u0026lt; info.major \u0026lt;\u0026lt; \u0026#34;.\u0026#34; \u0026lt;\u0026lt; info.minor \u0026lt;\u0026lt; std::endl; } } void GenerateBgra8K(uint8_t* buffer, int dataSize){ std::random_device rd; std::mt19937 gen(rd()); std::uniform_int_distribution\u0026lt;\u0026gt; sampler(0, 255); for(int i=0; i\u0026lt;dataSize/4; i++){ buffer[i*4] = sampler(gen); buffer[i*4+1] = sampler(gen); buffer[i*4+2] = sampler(gen); buffer[i*4+3] = 255; } } void convertPixelFormatCpu(uint8_t* inputBgra, uint8_t* outputYuv, int numPixels){ short3 yuv16; char3 yuv8; for(int idx=0; idx\u0026lt;numPixels; idx++){ yuv16.x = 66*inputBgra[idx*4+2] + 129*inputBgra[idx*4+1] + 25*inputBgra[idx*4]; yuv16.y = -38*inputBgra[idx*4+2] + -74*inputBgra[idx*4+1] + 112*inputBgra[idx*4]; yuv16.z = 112*inputBgra[idx*4+2] + -94*inputBgra[idx*4+1] + -18*inputBgra[idx*4]; yuv8.x = (yuv16.x\u0026gt;\u0026gt;8)+16; yuv8.y = (yuv16.y\u0026gt;\u0026gt;8)+128; yuv8.z = (yuv16.z\u0026gt;\u0026gt;8)+128; *(reinterpret_cast\u0026lt;char3*\u0026gt;(\u0026amp;outputYuv[idx*3])) = yuv8; } } __global__ void convertPixelFormat(uint8_t* inputBgra, uint8_t* outputYuv, int numPixels){ int stride = gridDim.x * blockDim.x; int idx = threadIdx.x + blockIdx.x * blockDim.x; short3 yuv16; char3 yuv8; while(idx\u0026lt;=numPixels){ if(idx\u0026lt;numPixels){ yuv16.x = 66*inputBgra[idx*4+2] + 129*inputBgra[idx*4+1] + 25*inputBgra[idx*4]; yuv16.y = -38*inputBgra[idx*4+2] + -74*inputBgra[idx*4+1] + 112*inputBgra[idx*4]; yuv16.z = 112*inputBgra[idx*4+2] + -94*inputBgra[idx*4+1] + -18*inputBgra[idx*4]; yuv8.x = (yuv16.x\u0026gt;\u0026gt;8)+16; yuv8.y = (yuv16.y\u0026gt;\u0026gt;8)+128; yuv8.z = (yuv16.z\u0026gt;\u0026gt;8)+128; *(reinterpret_cast\u0026lt;char3*\u0026gt;(\u0026amp;outputYuv[idx*3])) = yuv8; } idx += stride; } } Reference:\n[1] CUDAéšç¬”ä¹‹Streamçš„ä½¿ç”¨\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/tech/cuda_nsight_system/","summary":"Usage of Nsight System","title":"CUDA: NSight System"},{"content":"xv6 ä¸­çš„ fork() ç³»ç»Ÿè°ƒç”¨å°†çˆ¶è¿›ç¨‹çš„æ‰€æœ‰ç”¨æˆ·ç©ºé—´å†…å­˜å¤åˆ¶åˆ°å­è¿›ç¨‹ä¸­ã€‚å¦‚æœçˆ¶è¿›ç¨‹å¾ˆå¤§ï¼Œå¤åˆ¶å¯èƒ½éœ€è¦å¾ˆé•¿çš„æ—¶é—´ã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œè¿™é¡¹å·¥ä½œé€šå¸¸æ˜¯æ— ç”¨çš„ï¼šfork() ä¹‹åé€šå¸¸æ˜¯å­è¿›ç¨‹çš„ exec()ï¼Œå®ƒæ”¾å¼ƒäº†å¤åˆ¶çš„å†…å­˜ï¼Œæ²¡æœ‰ä½¿ç”¨å¤åˆ¶è¿‡æ¥çš„å¤§éƒ¨åˆ†å†…å­˜ã€‚å¦‚æœçˆ¶ä»£å’Œå­ä»£éƒ½ä½¿ç”¨äº†å¤åˆ¶çš„é¡µé¢ï¼Œå¹¶ä¸”å…¶ä¸­ä¸€ä¸ªæˆ–ä¸¤ä¸ªéƒ½å†™äº†å®ƒï¼Œé‚£ä¹ˆè¿™ä¸ªå¤åˆ¶æ‰æ˜¯çœŸæ­£éœ€è¦çš„ã€‚\næ‰€ä»¥å†™æ—¶å¤åˆ¶(copy on write, cow) è¿™ä¸ªæŠ€æœ¯å˜å¾—ååˆ†çš„é‡è¦ã€‚åœ¨è¿™ä¸ª lab ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å®ç°ä¸€ä¸ªå†™æ—¶å¤åˆ¶çš„ fork()ã€‚æˆ‘ä»¬éœ€è¦ä¿®æ”¹åŸæœ¬çš„ fork() ç¨‹åºä¸­åšå†…å­˜ç”³è¯·çš„æ¨¡å—ï¼ŒåŒæ—¶æˆ‘ä»¬è¿˜éœ€è¦å®ç° usertrap æ¥åœ¨å†™æ—¶(åœ¨å®é™…å†™çš„æ—¶å€™ç¢°åˆ° cow flagï¼ŒæŠ›å‡ºåˆ†é¡µé”™è¯¯)çš„æ—¶å€™å¤„ç†è¿™ä¸ª trapã€‚\nå› ä¸ºä¸€ä¸ªç¨‹åºå¾ˆå¯èƒ½è¢« fork() äº†å¾ˆå¤šçš„åˆ†æ”¯ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸€ä¸ªè®¡æ•°å™¨æ¥ç¡®å®šè¿™ä¸ª page æ˜¯è¦è¢«é‡Šæ”¾è¿˜æ˜¯ä¿ç•™ã€‚\nä¸€èˆ¬æ¥è¯´ï¼Œä¸€ä¸ªæ­£å¸¸è¿è¡Œçš„ç¨‹åºåœ¨å†™æ—¶å¤åˆ¶çš„æ—¶å€™ä¼šæœ‰ä¸‹é¢å‡ ä¸ªæµç¨‹:\nfork() å‡ºä¸€ä¸ªå­è¿›ç¨‹ childã€‚ child æ‹¥æœ‰çˆ¶è¿›ç¨‹çš„é¡µçš„å¼•ç”¨ï¼Œå¹¶ä¸”é¡µçš„ flag æœ‰ cow æ ‡è¯†ã€‚ å¹¶ä¸”è¦æŠŠ é¡µ å¼•ç”¨ ++ child éœ€è¦å‘è‡ªå·±çš„é¡µä¸­å†™å…¥æ–°çš„æ•°æ®. æ­¤æ—¶éœ€è¦é‡æ–°åˆ†é…å†…å­˜ï¼Œé¡µå¼•ç”¨ \u0026ndash;ã€‚ å½“ child è¿”å›çš„æ—¶å€™ï¼Œå¯èƒ½æœ‰å†…å­˜éœ€è¦ç”± kernel è½¬æ¢åˆ° userã€‚ å½“çˆ¶è¿›ç¨‹é”€æ¯çš„æ—¶å€™ï¼Œå¦‚æœè®¡æ•°å™¨ä¸º 0ï¼Œåˆ™é”€æ¯ï¼Œåä¹‹ï¼Œä¸å˜ã€‚ æ¯ä¸€é¡µéƒ½éœ€è¦ä¸€ä¸ªè®¡æ•°å™¨æ¥è¿›è¡Œè®¡æ•°ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦åœ¨ kernel ä¸­åŠ å…¥ä¸€ä¸ªæ•°ç»„æ¥è®°å½•ï¼ŒæŸ¥é˜… xv6 bookï¼Œæˆ‘ä»¬å‘ç°æœ‰å¦‚ä¸‹çš„å›¾:\nFig 1. memlayoutXV6 æ‰‹å†Œ\næˆ‘ä»¬éœ€è¦åœ¨ kernel data ä¹‹åçš„åŒºåŸŸå†…ç”³è¯·ä¸€å—å†…å­˜æ¥ä½œä¸ºè®¡æ•°å™¨å­˜å‚¨çš„æ•°ç»„ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ kalloc.c ä¸­å®ç°ã€‚\n// ./kernel/kalloc.c struct { struct spinlock lock; struct run *freelist; // lab 5 uint* ref_cnt; struct spinlock ref_cnt_lock; char * pa_start; } kmem; åœ¨è¿™ä¸ª kmem ç»“æ„ä½“ä¸­åŠ å…¥äº†ä¸€ä¸ª ref_cnt_lock æ¥ä¿è¯è®¡æ•°å™¨çš„æ­£ç¡®å¼•ç”¨ã€‚ä¸€ä¸ª ref_cnt pointer æ¥æŒ‡ç¤º ref array çš„èµ·å§‹ä½ç½®ï¼Œä½¿ç”¨ pa_start æ¥è¡¨ç¤ºå®é™…çš„ free memory çš„èµ·å§‹ä½ç½®ã€‚æˆ‘ä»¬è¿˜éœ€è¦ä¿®æ”¹åˆå§‹åŒ–ç¨‹åºæ¥æ­£ç¡®çš„ç”³è¯·è®¡æ•°å™¨æ•°ç»„ï¼Œå¹¶ä¸”å¯¹ free memory å¡«å……ä¸Šä¸€ä¸ªåˆå§‹å€¼ã€‚\n// ./kernel/kalloc.c void kinit() { initlock(\u0026amp;kmem.lock, \u0026#34;kmem\u0026#34;); // lab 5 initlock(\u0026amp;kmem.ref_cnt_lock, \u0026#34;kmemrefcnt\u0026#34;); uint64 pg_size = (((PHYSTOP - (uint64)end)) \u0026gt;\u0026gt; PGSHIFT) + 1; // get the page size uint64 ref_array_size = ((pg_size * sizeof(uint)) \u0026gt;\u0026gt; PGSHIFT) + 1; // caculate how many page wes need to store ref cnt. kmem.ref_cnt = (uint*)end; // the start of ref cnt array kmem.pa_start = end + (ref_array_size \u0026lt;\u0026lt; PGSHIFT); // the start of user memory space. char *p; p = (char*)PGROUNDUP((uint64)kmem.pa_start); for (; p + PGSIZE \u0026lt;= (char*)PHYSTOP; p+= PGSIZE) { acquire(\u0026amp;kmem.ref_cnt_lock); uint64 idx = (uint64)((PGROUNDDOWN((uint64)p) - PGROUNDUP((uint64)kmem.pa_start)) / PGSIZE); kmem.ref_cnt[idx] = 1; // set to 1, force freerange(.., ...) function to remove all mem in start-\u0026gt;end scope. release(\u0026amp;kmem.ref_cnt_lock); } freerange((void*)kmem.pa_start, (void*)PHYSTOP); // free memory in those scope. } PGSHIFT, PHYSTOP æ˜¯å®šä¹‰åœ¨ riscv.h ä¸­ä¾¿äºä½¿ç”¨çš„ macroã€‚ä¸‹é¢æ˜¯ kfree çš„ä»£ç ï¼Œéœ€è¦åœ¨ ref \u0026gt; 1 çš„æ—¶å€™å‡å°‘å¼•ç”¨ï¼Œåœ¨ ref == 1 çš„æ—¶å€™é‡Šæ”¾è¿™å—å†…å­˜ï¼Œå¹¶ä¸”æŠŠè®¡æ•°å™¨çš„å¼•ç”¨æ¬¡æ•°ç½®æˆ 0ã€‚\nvoid kfree(void *pa) { struct run *r; // lab 5 // If ref is not 0 acquire(\u0026amp;kmem.ref_cnt_lock); // get the ref cnt location of pa in ref cnt array uint64 idx = (uint64)((PGROUNDDOWN((uint64)pa) - PGROUNDUP((uint64)kmem.pa_start)) / PGSIZE); if (kmem.ref_cnt[idx] \u0026gt; 1) { kmem.ref_cnt[idx] --; release(\u0026amp;kmem.ref_cnt_lock); return; } // If ref is 1; if(((uint64)pa % PGSIZE) != 0 || (char*)pa \u0026lt; end || (uint64)pa \u0026gt;= PHYSTOP) panic(\u0026#34;kfree\u0026#34;); // Fill with junk to catch dangling refs. memset(pa, 1, PGSIZE); // lab 5 kmem.ref_cnt[idx] = 0; release(\u0026amp;kmem.ref_cnt_lock); r = (struct run*)pa; acquire(\u0026amp;kmem.lock); r-\u0026gt;next = kmem.freelist; kmem.freelist = r; release(\u0026amp;kmem.lock); } åœ¨ç”³è¯·å†…å­˜çš„åŒæ—¶ï¼Œä¹Ÿè¦åŠ ä¸Šè®¡æ•°å™¨:\nvoid * kalloc(void) { struct run *r; acquire(\u0026amp;kmem.lock); r = kmem.freelist; if(r) kmem.freelist = r-\u0026gt;next; release(\u0026amp;kmem.lock); // lab 5 if (r) { acquire(\u0026amp;kmem.ref_cnt_lock); uint64 idx = (uint64)((PGROUNDDOWN((uint64)r) - PGROUNDUP((uint64)kmem.pa_start)) / PGSIZE); kmem.ref_cnt[idx] = 1; release(\u0026amp;kmem.ref_cnt_lock); } if(r) memset((char*)r, 5, PGSIZE); // fill with junk return (void*)r; } åœ¨ vm.c ä¸­æˆ‘ä»¬éœ€è¦ä¿®æ”¹ uvmcopy å‡½æ•°ï¼Œåœ¨è¿™ä¸ªå‡½æ•°ä¸­ï¼Œæˆ‘ä»¬è¦æ³¨é‡Šæ‰åŸæ¥çš„å†…å­˜ç”³è¯·çš„ä»£ç ï¼Œç„¶åä½¿ç”¨ cow ç­–ç•¥æ¥â€œç”³è¯·â€å†…å­˜\nfor (i = 0; i \u0026lt; sz; i += PGSIZE) { if ((pte = walk(old, i, 0)) == 0) { panic(\u0026#34;uvmcopy: pte should exist\u0026#34;); } if ((*pte \u0026amp; PTE_V) == 0) { panic(\u0026#34;uvmcopy: page not present\u0026#34;); } pa = PTE2PA(*pte); // clear write flag and add read flag. *pte = ((*pte) \u0026amp; (~PTE_W)) | PTE_COW; flags = PTE_FLAGS(*pte); // Map to child process\u0026#39;s pagetable directly. Make both read-only. if (mappages(new, i, PGSIZE, pa, flags) != 0) { goto err; } // increase ref of page old. kincre_ref(pa); } return 0; åœ¨ä¸Šé¢çš„è¿™æ®µä»£ç ä¸­ï¼Œæˆ‘å°† flag ç”±åŸæ¥çš„å¯å†™è½¬å˜æˆäº† cow(PTE_COW éœ€è¦åœ¨ reiscv.h ä¸­å®šä¹‰)ï¼Œç„¶åå°†é¡µå…±äº«ï¼Œå¦‚æœå…±äº«æˆåŠŸï¼Œåˆ™å°† reference ++ã€‚\nå½“ç”¨æˆ·éœ€è¦å†™å†…å­˜çš„æ—¶å€™ï¼Œä¼šè§¦å‘ä¸€ä¸ª trapï¼ŒåŒä¸Šä¸€ä¸ªå®éªŒï¼Œæˆ‘ä»¬éœ€è¦åœ¨ usertrap ä¸­åŠ å…¥ä»£ç æ¥å¤„ç†è¿™ä¸ª trapã€‚\nelse if (r_scause() == 15) { uint64 va = r_stval(); if (va \u0026gt; p-\u0026gt;sz) p-\u0026gt;killed = 1; else if (kalloc_cow(p-\u0026gt;pagetable, va) != 0) p-\u0026gt;killed = 1; } int kalloc_cow(pagetable_t pagetable, uint64 va) { va = PGROUNDDOWN(va); if (va \u0026gt;= MAXVA) return -1; pte_t *pte = walk(pagetable, va, 0); if (!pte) return -1; uint64 pa = PTE2PA(*pte); if (!pa) return -1; uint64 flags = PTE_FLAGS(*pte); if (flags \u0026amp; PTE_COW) { uint64 mem = (uint64)kalloc(); if (!mem) return -1; memmove((char*)mem, (char*)pa, PGSIZE); uvmunmap(pagetable, va, 1, 1); flags = (flags | PTE_W) \u0026amp; (~PTE_COW); if (mappages(pagetable, va, PGSIZE, mem, flags) != 0) { kfree((void*)mem); return -1; } } return 0; } å½“ç”¨æˆ·æ‰€è®¿é—®çš„å†…å­˜éœ€è¦å†™æ—¶å¤åˆ¶çš„æ—¶å€™ï¼Œç”± trap å¤„ç†ç¨‹åºæ¥è¿›è¡Œå¤„ç†ï¼Œkalloc_cow ç¨‹åºè´Ÿè´£ç”³è¯·å‡ºä¸åŸæ¥çš„å†…å­˜åŒºå—ç›¸åŒå¤§å°çš„åŒºé—´ï¼Œç„¶åæŠŠå†…å­˜ copy è¿‡å»ï¼Œå¹¶ä¸”æŠŠ flag æ”¹ä¸ºå¯å†™è€Œä¸æ˜¯ cowã€‚\nå½“ kernel éœ€è¦æŠŠå†…å­˜äº¤æ¢åˆ° user åŒºæ—¶ï¼Œä¹Ÿéœ€è¦å¯¹ cow ç‰¹æ®Šå¯¹å¾…ã€‚åœ¨ copyout å‡½æ•°ä¸­ï¼Œéœ€è¦åŠ å…¥ä¸‹è¿°ä»£ç :\nif (kalloc_cow(pagetable, va0) != 0) return -1; ","permalink":"https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab5_cow/","summary":"xv6 ä¸­çš„ fork() ç³»ç»Ÿè°ƒç”¨å°†çˆ¶è¿›ç¨‹çš„æ‰€æœ‰ç”¨æˆ·ç©ºé—´å†…å­˜å¤åˆ¶åˆ°å­è¿›ç¨‹ä¸­ã€‚å¦‚æœçˆ¶è¿›ç¨‹å¾ˆå¤§ï¼Œå¤åˆ¶å¯èƒ½éœ€è¦å¾ˆé•¿çš„æ—¶é—´ã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œè¿™é¡¹å·¥ä½œé€šå¸¸æ˜¯æ— ç”¨çš„ï¼šfork() ä¹‹åé€šå¸¸æ˜¯å­è¿›ç¨‹çš„ exec()ï¼Œå®ƒæ”¾å¼ƒäº†å¤åˆ¶çš„å†…å­˜ï¼Œæ²¡æœ‰ä½¿ç”¨å¤åˆ¶è¿‡æ¥çš„å¤§éƒ¨åˆ†å†…å­˜ã€‚å¦‚æœçˆ¶ä»£å’Œå­ä»£éƒ½ä½¿ç”¨äº†å¤åˆ¶çš„é¡µé¢ï¼Œå¹¶ä¸”å…¶ä¸­ä¸€ä¸ªæˆ–ä¸¤ä¸ªéƒ½å†™äº†å®ƒï¼Œé‚£ä¹ˆè¿™ä¸ªå¤åˆ¶æ‰æ˜¯çœŸæ­£éœ€è¦çš„ã€‚\næ‰€ä»¥å†™æ—¶å¤åˆ¶(copy on write, cow) è¿™ä¸ªæŠ€æœ¯å˜å¾—ååˆ†çš„é‡è¦ã€‚åœ¨è¿™ä¸ª lab ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å®ç°ä¸€ä¸ªå†™æ—¶å¤åˆ¶çš„ fork()ã€‚æˆ‘ä»¬éœ€è¦ä¿®æ”¹åŸæœ¬çš„ fork() ç¨‹åºä¸­åšå†…å­˜ç”³è¯·çš„æ¨¡å—ï¼ŒåŒæ—¶æˆ‘ä»¬è¿˜éœ€è¦å®ç° usertrap æ¥åœ¨å†™æ—¶(åœ¨å®é™…å†™çš„æ—¶å€™ç¢°åˆ° cow flagï¼ŒæŠ›å‡ºåˆ†é¡µé”™è¯¯)çš„æ—¶å€™å¤„ç†è¿™ä¸ª trapã€‚\nå› ä¸ºä¸€ä¸ªç¨‹åºå¾ˆå¯èƒ½è¢« fork() äº†å¾ˆå¤šçš„åˆ†æ”¯ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸€ä¸ªè®¡æ•°å™¨æ¥ç¡®å®šè¿™ä¸ª page æ˜¯è¦è¢«é‡Šæ”¾è¿˜æ˜¯ä¿ç•™ã€‚\nä¸€èˆ¬æ¥è¯´ï¼Œä¸€ä¸ªæ­£å¸¸è¿è¡Œçš„ç¨‹åºåœ¨å†™æ—¶å¤åˆ¶çš„æ—¶å€™ä¼šæœ‰ä¸‹é¢å‡ ä¸ªæµç¨‹:\nfork() å‡ºä¸€ä¸ªå­è¿›ç¨‹ childã€‚ child æ‹¥æœ‰çˆ¶è¿›ç¨‹çš„é¡µçš„å¼•ç”¨ï¼Œå¹¶ä¸”é¡µçš„ flag æœ‰ cow æ ‡è¯†ã€‚ å¹¶ä¸”è¦æŠŠ é¡µ å¼•ç”¨ ++ child éœ€è¦å‘è‡ªå·±çš„é¡µä¸­å†™å…¥æ–°çš„æ•°æ®. æ­¤æ—¶éœ€è¦é‡æ–°åˆ†é…å†…å­˜ï¼Œé¡µå¼•ç”¨ \u0026ndash;ã€‚ å½“ child è¿”å›çš„æ—¶å€™ï¼Œå¯èƒ½æœ‰å†…å­˜éœ€è¦ç”± kernel è½¬æ¢åˆ° userã€‚ å½“çˆ¶è¿›ç¨‹é”€æ¯çš„æ—¶å€™ï¼Œå¦‚æœè®¡æ•°å™¨ä¸º 0ï¼Œåˆ™é”€æ¯ï¼Œåä¹‹ï¼Œä¸å˜ã€‚ æ¯ä¸€é¡µéƒ½éœ€è¦ä¸€ä¸ªè®¡æ•°å™¨æ¥è¿›è¡Œè®¡æ•°ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦åœ¨ kernel ä¸­åŠ å…¥ä¸€ä¸ªæ•°ç»„æ¥è®°å½•ï¼ŒæŸ¥é˜… xv6 bookï¼Œæˆ‘ä»¬å‘ç°æœ‰å¦‚ä¸‹çš„å›¾:\nFig 1. memlayoutXV6 æ‰‹å†Œ\næˆ‘ä»¬éœ€è¦åœ¨ kernel data ä¹‹åçš„åŒºåŸŸå†…ç”³è¯·ä¸€å—å†…å­˜æ¥ä½œä¸ºè®¡æ•°å™¨å­˜å‚¨çš„æ•°ç»„ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ kalloc.c ä¸­å®ç°ã€‚\n// ./kernel/kalloc.c struct { struct spinlock lock; struct run *freelist; // lab 5 uint* ref_cnt; struct spinlock ref_cnt_lock; char * pa_start; } kmem; åœ¨è¿™ä¸ª kmem ç»“æ„ä½“ä¸­åŠ å…¥äº†ä¸€ä¸ª ref_cnt_lock æ¥ä¿è¯è®¡æ•°å™¨çš„æ­£ç¡®å¼•ç”¨ã€‚ä¸€ä¸ª ref_cnt pointer æ¥æŒ‡ç¤º ref array çš„èµ·å§‹ä½ç½®ï¼Œä½¿ç”¨ pa_start æ¥è¡¨ç¤ºå®é™…çš„ free memory çš„èµ·å§‹ä½ç½®ã€‚æˆ‘ä»¬è¿˜éœ€è¦ä¿®æ”¹åˆå§‹åŒ–ç¨‹åºæ¥æ­£ç¡®çš„ç”³è¯·è®¡æ•°å™¨æ•°ç»„ï¼Œå¹¶ä¸”å¯¹ free memory å¡«å……ä¸Šä¸€ä¸ªåˆå§‹å€¼ã€‚","title":"XV6 Lab 5: Copy On Write"},{"content":"RISC-V assembly Which registers contain arguments to functions? For example, which register holds 13 in main\u0026rsquo;s call to printf?\nRegister: a0, a1, a2\u0026hellip;, a7 for integer arguments. Register fa0, fa1, fa2\u0026hellip;, fa7 for float arguments.\nRegister a2 holds 13 when we call printf().\nWhere is the call to function f in the assembly code for main? Where is the call to g? (Hint: the compiler may inline functions.)\nCompiler inlined f(8) and g() in printf() function. And in assembly code it just pass a immediate 12 to register a1.\nHowerver, we can set -O0 to disable advanced optimization and get the call address of function f and g.\nAt what address is the function printf located?\nThe auipc instruction get the PC address and load it to register ra. jalr instruction will combine 1562(0x61A) to 0x30 to get the final result.\n0x30 is 0011 0000 0000 0000 0000\n0x61A is 0110 0001 1010\nAnd the final result is 0x64A\nWhat value is in the register ra just after the jalr to printf in main?\nThe PC will reset to the main function(the address called printf() + 1) after printf returned. ra = 0x38.\nOutput is He110 World, there is no need to change var i when risc-v processors set to big-endian.\nThe x=3, and y depends on the register setting. (Mostly like a random number).\nBacktrace As mentioned in the question, the compiler will set the frame pointer to register s0. We need to add a piece of code in kernel/riscv.h to get the value of s0.\nstatic inline uint64 r_fp() { uint64 x; asm volatile(\u0026#34;mv %0, s0\u0026#34; : \u0026#34;=r\u0026#34;(x)); return x; } Form hints, we knows that:\nThe return address lives at a fixed offset (-8) from the frame pointer of a stackframe, and that the saved frame pointer lives at fixed offset (-16) from the frame pointer.\nThese lecture nots have a picture of layouts of stack frames.\nStack . . +-\u0026gt; . | +-----------------+ | | | return address | | | | previous fp ------+ | | saved registers | | | local variables | | | ... | \u0026lt;-+ | +-----------------+ | | | return address | | +------ previous fp | | | saved registers | | | local variables | | +-\u0026gt; | ... | | | +-----------------+ | | | return address | | | | previous fp ------+ | | saved registers | | | local variables | | | ... | \u0026lt;-+ | +-----------------+ | | | return address | | +------ previous fp | | | saved registers | | | local variables | | $fp --\u0026gt; | ... | | +-----------------+ | | return address | | | previous fp ------+ | saved registers | $sp --\u0026gt; | local variables | +-----------------+ In that case, if we want to get the live address, we need to add -8 to s0. To get the previous fp, add -16 to s0;\nThe fp is the top of one frame.\nYou can use PGROUNDDOWN(fp) (see kernel/riscv.h) to identify the page that a frame pointer refers to. But what we need to use is PGROUNDUP(fp) here.\nIn ./kernel/printf.c, we neded to impl backtrace function:\nvoid backtrace() { uint64 fp = r_fp(); uint64 bound_high = PGROUNDUP(fp); // the page frame pointer ref to. while(fp \u0026lt; bound_high) { uint64 tmp = *(uint64*)(fp - 8); fp = *(uint64*)(fp - 16); printf(\u0026#34;%p\\n\u0026#34;, tmp); } return; } Alarm In this exercise we need to add a feature to xv6 that periodically alerts a process as it uses CPU time. This might be useful for compute-bound processes that want to limit how much CPU time they chew up, or for processes that want to compute but also want to take some periodic action.\nWe should add a new sigalarm(interval, handler) system call. If an application calls sigalarm(n, fn), then after every n \u0026ldquo;ticks\u0026rdquo; of CPU time that the program consumes, the kernel should cause application function fn to be called. When fn returns, the application should resume where it left off. A tick is a fairly arbitrary unit of time in xv6, determined by how often a hardware timer generates interrupts. If an application calls sigalarm(0, 0), the kernel should stop generating periodic alarm calls.\ntest 0 In oerder to let system knows what function need to execute when a process\u0026rsquo;s alarm interval expires, we need to add some structs to proc. First, we need to store the alarm interval and functions pointer. Second, we need to backup the trapframe for user/kernel switch.\nThe figure shown below illuminate the workflow of sigalarm and sigreturn:\nFig 1. workflowÂ© chenghua.wang\nIn ./kernel/proc.h, we need to add some infomation to let process know the state of current sigalarm/sigreturn.\nstruct proc { ... int alarm_interval; // n ticks per action int alarm_ticks_left; // how many times has timer intrupt void (*alarm_handler)(); // the function pointer for exec struct trapframe *trapframe_bk; // backup, for user/trap switch ... } Also, we need to modified alloc and free functions for process. In ./kernel/proc.c:\nstatic void allocproc(void) { ... if ((p-\u0026gt;trapframe_bk = (struct trapframe *)kalloc()) == 0) { freeproc(p); release(\u0026amp;p-\u0026gt;lock); return 0; } ... p-\u0026gt;alarm_interval = 0; p-\u0026gt;alarm_handler = 0; p-\u0026gt;alarm_ticks_left = 0; ... } static void freeproc(struct proc* p) { ... if(p-\u0026gt;trapframe_bk) kfree((void*)p-\u0026gt;trapframe_bk); ... p-\u0026gt;alarm_interval = 0; p-\u0026gt;alarm_handler = 0; p-\u0026gt;alarm_ticks_left = 0; } And we need to register this two system-call\u0026rsquo;s definitions in the ./user/usys.pl to let it generate the trap entries(it\u0026rsquo;s exactly same as previous lab).\nThen we need to handle the timer interupt. In ./kernel/trap.c, we need to impl the logic when which_dev==2. First, we need to judge if alarm_interval is zero or not. Then, increase the alarm_ticks_left and compare it with alarm_interval. If timer interupts times equles to n tick, execute the alarm_handler user passed in.\nNote that, if we want to execute the alarm_handler, the pc should point to code section in user process. So, we need to figure the epc register manually. When executing alarm_handler, registers may changed. So we need to back up current trapframe before calling alarm_handler. After alarm_handler returned, we can use this backuped trapframe to restore the register state.\nIn ./kernel/trap.c:\nvoid usertrap(void) { ... // give up the CPU if this is a timer interrupt. if(which_dev == 2) { if (p-\u0026gt;alarm_interval) { if (++p-\u0026gt;alarm_ticks_left == p-\u0026gt;alarm_interval) { *p-\u0026gt;trapframe_bk = *p-\u0026gt;trapframe; p-\u0026gt;trapframe-\u0026gt;epc = (uint64)p-\u0026gt;alarm_handler; } } yield(); } ... } Then, let us impl the sigalarm and sigreturn functions in ./kernel/sysproc.c:\nint sigalarm(int ticks, void (* handler)()) { struct proc *p = myproc(); p-\u0026gt;alarm_interval = ticks; p-\u0026gt;alarm_handler = handler; p-\u0026gt;alarm_ticks_left = 0; return 0; } uint64 sys_sigalarm(void) { int ticks; uint64 func_ptr; if (argint(0, \u0026amp;ticks), ticks \u0026lt; 0) return -1; if (argaddr(1, \u0026amp;func_ptr), func_ptr \u0026lt; 0) return -1; return sigalarm(ticks, (void(*)())func_ptr); } int sigreturn() { struct proc *p = myproc(); *p-\u0026gt;trapframe = *p-\u0026gt;trapframe_bk; p-\u0026gt;alarm_ticks_left = 0; return p-\u0026gt;trapframe-\u0026gt;a0; } uint64 sys_sigreturn(void) { return sigreturn(); } test 1/2/3 The code is shown in previous section.\nIf alarm_handler is still running while timer interupt n ticks. We need to make sure there is only one alarm_handler running in the system emitted by sigalarm.\nIn order to impl this, we can add a lock-like flag to record the state(alarm_handler is running or not)\nHowever, we can reset the alarm_ticks_left to zero in the sigreturn instead of in the function usertrap. The alarm_handler will not be called util user calls sigreturn.\nThe return value of sigreturn is stored in the a0 register, which is not the behavior we expected. This value may cover the original a0 register. So, just return p-\u0026gt;trapfraame-\u0026gt;a0 is ok. It will set the a0 register to previous value. It\u0026rsquo;s tricky but useful.\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab4_trap/","summary":"RISC-V assembly Which registers contain arguments to functions? For example, which register holds 13 in main\u0026rsquo;s call to printf?\nRegister: a0, a1, a2\u0026hellip;, a7 for integer arguments. Register fa0, fa1, fa2\u0026hellip;, fa7 for float arguments.\nRegister a2 holds 13 when we call printf().\nWhere is the call to function f in the assembly code for main? Where is the call to g? (Hint: the compiler may inline functions.)\nCompiler inlined f(8) and g() in printf() function.","title":"XV6 Lab 4: Traps"},{"content":"MIT 6.S081 Lab3 website\nåš Lab 3 éœ€è¦æå‰é˜…è¯» XV6 bookï¼Œäº†è§£ RISC-V SR39 çš„åœ°å€æ ¼å¼ï¼Œå¹¶ä¸”å®éªŒä¸­å¤§é‡ç”¨åˆ°äº†é¡µè¡¨çš„å‡†æ¢å‡½æ•°ï¼Œéœ€è¦æŸ¥é˜… XV6 æ‰‹å†Œã€‚ä¸è¿‡ï¼Œç†Ÿè®° RISC-V çš„åœ°å€è¯´å®åœ¨çš„æ²¡æœ‰ä»€ä¹ˆç”¨å¤„ï¼Œé€šè¿‡è¿™ä¸ªå®éªŒç†è§£é¡µè¡¨çš„å·¥ä½œæ–¹å¼å¹¶ä¸” hands on æ‰æ˜¯çœŸçš„ã€‚\nSpeed up system calls ç›®å‰æœ‰å¾ˆå¤šçš„æ“ä½œç³»ç»Ÿ(Linux)åœ¨ç”¨æˆ·åŒºå’Œå†…æ ¸åŒºä¹‹é—´å…±äº«ä¸€å—æ•°æ®(Read-Only for user)ï¼Œè¿™æ ·ç”¨æˆ·åœ¨è¿›è¡Œç³»ç»Ÿè°ƒç”¨çš„æ—¶å€™å°±ä¸éœ€è¦é™·å…¥å†…æ ¸æ€åï¼Œç”±å†…æ ¸æ€æ‹·è´æ•°æ®è¿›ç”¨æˆ·æ€ï¼Œè€Œæ˜¯å°†æ•°æ®å†™åœ¨è¿™ä¸ªå…±äº«çš„åŒºå—å†…ã€‚è¿™æ ·å¯ä»¥åŠ å¿«æ“ä½œç³»ç»Ÿçš„è¿è¡Œé€Ÿåº¦(æ¯•ç«Ÿå¤§éƒ¨åˆ†ç³»ç»Ÿè°ƒç”¨éœ€è¦çš„å†…å­˜æ¶ˆè€—æ˜¯å¾ˆå°çš„ï¼Œå†…å­˜çš„æ¶ˆè€—åœ¨å½“ä»Šå·²ç»ä¸æ˜¯é—®é¢˜)ã€‚\nåœ¨æœ¬å®éªŒä¸­æˆ‘ä»¬éœ€è¦ä½¿ç”¨ ugetpid() æ¥è¿›è¡ŒåŠ é€Ÿè·å¾—è¿›ç¨‹çš„ pidã€‚\né¦–å…ˆå°±æ˜¯ä¸ºæ¯ä¸€ä¸ªè¿›ç¨‹åˆ›å»ºä¸€ä¸ªé¡µè¡¨ä½œä¸ºå…±äº«å†…å­˜åŒºå—ã€‚æˆ‘ä»¬å‘ç°åœ¨ kernel\\memlayout.h ä¸­å·²ç»ä¸ºæˆ‘ä»¬å®šä¹‰å¥½äº†éœ€è¦çš„æ•°æ®ç»“æ„:\nstruct usyscall { int pid; // Process ID }; é‚£ä¹ˆæˆ‘ä»¬åªéœ€è¦åœ¨ kernel/proc.c /proc.h ä¸­åŠ å…¥ä»£ç ï¼Œæ¥å®ç°è¿›ç¨‹åˆ›å»ºæ—¶åˆ›å»ºé¡µè¡¨ï¼Œé”€æ¯æ—¶é”€æ¯é¡µè¡¨çš„åŠ¨ä½œå°±è¡Œäº†ã€‚\nåœ¨ proc.h ä¸­ï¼Œæˆ‘ä»¬éœ€è¦åœ¨è¿›ç¨‹çš„ PCB ä¸­åŠ å…¥æ–°çš„æ•°æ®ç»“æ„:\nstruct proc { ... struct usyscall *usyscall; // using read only shared data to accelerate. ... } ä¸ºäº†è®©è¿›ç¨‹çš„æ­£å¸¸åˆ›å»ºå’Œé‡Šæ”¾ï¼Œæˆ‘ä»¬éœ€è¦å‘è¿›ç¨‹åˆ›å»ºå’Œé”€æ¯å‡½æ•°ä¸­åŠ å…¥å¯¹åº”çš„é¡µè¡¨æ“ä½œä»£ç ã€‚\nstatic struct proc * allocproc(void) { ... found: ... // -- Modified -- // To alloc a mem for usyscall_page p-\u0026gt;usyscall_page = (struct usyscall *)kalloc(); if (p-\u0026gt;usyscall_page == 0) { freeproc(p); release(\u0026amp;p-\u0026gt;lock); return 0; } ... // -- Modified -- // Init the syscall pid p-\u0026gt;usyscall_page-\u0026gt;pid = p-\u0026gt;pid; return p; } static void freeproc(struct proc *p) { ... // -- Modified -- // free usyscall page if (p-\u0026gt;usyscall_page) { kfree((void*)p-\u0026gt;usyscall_page); } p-\u0026gt;usyscall_page = 0; ... } å› ä¸ºç”¨æˆ·æ€å¯»å€çš„æ—¶å€™éƒ½è¦ç»è¿‡é¡µè¡¨ç¡¬ä»¶çš„ç¿»è¯‘ï¼Œæ‰€ä»¥ usyscall ä¹Ÿè¦æ˜ å°„åœ¨è¿›ç¨‹çš„ pagetable ä¸Šã€‚æˆ‘ä»¬éœ€è¦ä¿®æ”¹æ˜ å°„å‡½æ•°å’Œé‡Šæ”¾æ˜ å°„çš„å‡½æ•°ã€‚\npagetable_t proc_pagetable(struct proc *p) { ... if (mappages(pagetable, USYSCALL, PGSIZE, (uint64)(p-\u0026gt;usyscall_page), PTE_R | PTE_U) \u0026lt; 0) { uvmunmap(pagetable, TRAMPOLINE, 1, 0); uvmunmap(pagetable, TRAPFRAME, 1, 0); uvmfree(pagetable, 0); return 0; } ... } void proc_freepagetable(pagetable_t pagetable, uint64 sz) { uvmunmap(pagetable, TRAMPOLINE, 1, 0); uvmunmap(pagetable, TRAPFRAME, 1, 0); // -- Modified -- // free mapping of usyscall page uvmunmap(pagetable, USYSCALL, 1, 0); uvmfree(pagetable, sz); } æ€»ç»“ï¼š\nå…ˆä½¿ç”¨ kalloc(kernel malloc) åœ¨ç³»ç»Ÿçš„é¡µè¡¨ä¸­ç”³è¯·åˆ°ä¸€å—ç©ºé—´ï¼Œåˆå§‹åŒ–ã€‚\nç„¶åæŠŠè¿™å—ç©ºé—´çš„åœ°å€ç¿»è¯‘åˆ°ç”¨æˆ·ç©ºé—´å¯¹åº”çš„é¡µè¡¨ä¸­å»ï¼Œé¡µè¡¨ä¸­å¯¹åº”ç€ USYSCALLï¼Œåœ¨ kernel\\memlayout.h ä¸­æ˜¯è¿™æ ·å®šä¹‰çš„\n#define USYSCALL (TRAPFRAME - PGSIZE) å¯ä»¥çœ‹åˆ°è¿™æ˜¯ç´§æŒ¨ç€ TRAPFRAME çš„ã€‚\nå½“åº”ç”¨ç¨‹åºè°ƒç”¨äº† ugetpid() æŒ‡ä»¤çš„æ—¶å€™ï¼Œåªéœ€è¦å» USYSCALL é¡µè¡¨æ‰¾åˆ°å¯¹åº”çš„å†…å®¹å°±å¯ä»¥äº†ã€‚è€Œ USYCALL é¡µè¡¨çš„å†…å®¹å®é™…ä¸Šæ˜¯ proc.c ä¸­è°ƒç”¨ kalloc() åè·å¾—çš„å®é™…ç‰©ç†åœ°å€çš„å¼•ç”¨ã€‚\nPrint a page table æŒ‰ç…§ä¸€å®šæ ¼å¼æ‰“å°å‡ºé¡µè¡¨çš„ä¿¡æ¯ï¼Œè¿™ä¸ªéå¸¸çš„ç®€å•ï¼Œåªè¦é€’å½’çš„è°ƒç”¨å°±è¡Œäº†ã€‚\n// Lab 3. Not visiable to user. void k_vmprint_recur(pagetable_t pgt, int blank) { for(int i = 0; i \u0026lt; 512; i++) { pte_t pte = pgt[i]; if (pte \u0026amp; PTE_V) { uint64 child = PTE2PA(pte); for (int j = 0; j \u0026lt; blank; j++) { printf(\u0026#34; ..\u0026#34;); } printf(\u0026#34;%d: pte %p pa %p\\n\u0026#34;, i, pte, child); if ((pte \u0026amp; (PTE_R|PTE_W|PTE_X)) == 0) { k_vmprint_recur((pagetable_t)child, blank+1); } } } } // Lab 3 void vmprint(pagetable_t pgt) { // recursively print the three level page. printf(\u0026#34;page table %p\\n\u0026#34;, pgt); k_vmprint_recur(pgt, 1); } Detecting which pages have been accessed ä¸€äº› GC(garbage cllector) å¯ä»¥ä»æœ‰å…³å“ªäº›é¡µé¢å·²è¢«è®¿é—®ï¼ˆè¯»å–æˆ–å†™å…¥ï¼‰çš„ä¿¡æ¯ä¸­è·ç›Šã€‚ åœ¨å®éªŒçš„è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†å‘ xv6 æ·»åŠ ä¸€é¡¹æ–°åŠŸèƒ½ï¼Œé€šè¿‡æ£€æŸ¥ RISC-V é¡µè¡¨ä¸­çš„è®¿é—®ä½æ¥æ£€æµ‹æ­¤ä¿¡æ¯å¹¶å°†å…¶æŠ¥å‘Šç»™ç”¨æˆ·ç©ºé—´ã€‚æ¯å½“è§£å†³ TLB æœªå‘½ä¸­æ—¶ï¼ŒRISC-V ç¡¬ä»¶é¡µé¢éå†å™¨éƒ½ä¼šåœ¨ PTE ä¸­æ ‡è®°è¿™äº›ä½ã€‚\né¦–å…ˆè¦åœ¨ kernel/sysproc.c ä¸­åŠ å…¥ç³»ç»Ÿè°ƒç”¨çš„å®ç°\n#ifdef LAB_PGTBL int sys_pgaccess(void) { // lab pgtbl: your code here. uint64 buffer, ans; int number; if (argaddr(0, \u0026amp;buffer), buffer \u0026lt; 0) return -1; if (argint(1, \u0026amp;number), number \u0026lt; 0) return -1; if (argaddr(2, \u0026amp;ans), ans \u0026lt; 0) return -1; return pgaccess((void*)buffer, number, (void*)ans); } #endif ç„¶åç€æ‰‹å®ç° pgacess çš„å®ç°ï¼Œè¿™ä¸ªå®ç°éœ€è¦æ·»åŠ å¤´æ–‡ä»¶å®šä¹‰ï¼Œå¹¶ä¸”åœ¨ kernel/proc.c ä¸­æ·»åŠ å®ç°:\nuint64 pgaccess(void *pg, int number, void *store) { struct proc *p = myproc(); if (p == 0) return 1; int ans = 0; pagetable_t pagetable = p-\u0026gt;pagetable; for (int i = 0; i \u0026lt; number \u0026amp;\u0026amp; i \u0026lt; 32; i++) { pte_t *pte; pte = walk(pagetable, (uint64)pg + (uint64)PGSIZE * i, 0); if (pte != 0 \u0026amp;\u0026amp; ((*pte) \u0026amp; PTE_A)) { ans |= 1 \u0026lt;\u0026lt; i; *pte ^= PTE_A; //clear PTE_A } } // copy the value to user page. return copyout(pagetable, (uint64)store, (char *)\u0026amp;ans, sizeof(int)); } è¿™ä¸ªå®ç°æ˜¯è¿™æ ·çš„ï¼Œé€šè¿‡éå†æŒ‡å®šçš„é¡µè¡¨ä¹‹åçš„ n ä¸ª pageï¼Œè®¿é—®æ¯ä¸ª page çš„ PTE_A bitï¼Œå¦‚æœè¿™ä¸ª bit æ˜¯ 1ï¼Œå°±ä½¿ç”¨ bit map æ¥è®°å½•ä»–ã€‚æœ€ç»ˆåˆ«å¿˜äº†æŠŠè¿™ä¸ª int ç±»å‹çš„ ans è¿”å›ç»™ç”¨æˆ·æ€ã€‚\nå¯¹äº PTE_Aï¼Œéœ€è¦åœ¨ kernel\\risc.h ä¸­è¿›è¡Œæ·»åŠ ï¼ŒæŸ¥é˜… XV6 æ‰‹å†Œå¾—çŸ¥ï¼Œæ”¹ PTE_A ä½äºç¬¬ 6 ä½ï¼Œæ•…ä¸º 1 \u0026lt;\u0026lt; 6ã€‚\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab3_pagetable/","summary":"MIT 6.S081 Lab3 website\nåš Lab 3 éœ€è¦æå‰é˜…è¯» XV6 bookï¼Œäº†è§£ RISC-V SR39 çš„åœ°å€æ ¼å¼ï¼Œå¹¶ä¸”å®éªŒä¸­å¤§é‡ç”¨åˆ°äº†é¡µè¡¨çš„å‡†æ¢å‡½æ•°ï¼Œéœ€è¦æŸ¥é˜… XV6 æ‰‹å†Œã€‚ä¸è¿‡ï¼Œç†Ÿè®° RISC-V çš„åœ°å€è¯´å®åœ¨çš„æ²¡æœ‰ä»€ä¹ˆç”¨å¤„ï¼Œé€šè¿‡è¿™ä¸ªå®éªŒç†è§£é¡µè¡¨çš„å·¥ä½œæ–¹å¼å¹¶ä¸” hands on æ‰æ˜¯çœŸçš„ã€‚\nSpeed up system calls ç›®å‰æœ‰å¾ˆå¤šçš„æ“ä½œç³»ç»Ÿ(Linux)åœ¨ç”¨æˆ·åŒºå’Œå†…æ ¸åŒºä¹‹é—´å…±äº«ä¸€å—æ•°æ®(Read-Only for user)ï¼Œè¿™æ ·ç”¨æˆ·åœ¨è¿›è¡Œç³»ç»Ÿè°ƒç”¨çš„æ—¶å€™å°±ä¸éœ€è¦é™·å…¥å†…æ ¸æ€åï¼Œç”±å†…æ ¸æ€æ‹·è´æ•°æ®è¿›ç”¨æˆ·æ€ï¼Œè€Œæ˜¯å°†æ•°æ®å†™åœ¨è¿™ä¸ªå…±äº«çš„åŒºå—å†…ã€‚è¿™æ ·å¯ä»¥åŠ å¿«æ“ä½œç³»ç»Ÿçš„è¿è¡Œé€Ÿåº¦(æ¯•ç«Ÿå¤§éƒ¨åˆ†ç³»ç»Ÿè°ƒç”¨éœ€è¦çš„å†…å­˜æ¶ˆè€—æ˜¯å¾ˆå°çš„ï¼Œå†…å­˜çš„æ¶ˆè€—åœ¨å½“ä»Šå·²ç»ä¸æ˜¯é—®é¢˜)ã€‚\nåœ¨æœ¬å®éªŒä¸­æˆ‘ä»¬éœ€è¦ä½¿ç”¨ ugetpid() æ¥è¿›è¡ŒåŠ é€Ÿè·å¾—è¿›ç¨‹çš„ pidã€‚\né¦–å…ˆå°±æ˜¯ä¸ºæ¯ä¸€ä¸ªè¿›ç¨‹åˆ›å»ºä¸€ä¸ªé¡µè¡¨ä½œä¸ºå…±äº«å†…å­˜åŒºå—ã€‚æˆ‘ä»¬å‘ç°åœ¨ kernel\\memlayout.h ä¸­å·²ç»ä¸ºæˆ‘ä»¬å®šä¹‰å¥½äº†éœ€è¦çš„æ•°æ®ç»“æ„:\nstruct usyscall { int pid; // Process ID }; é‚£ä¹ˆæˆ‘ä»¬åªéœ€è¦åœ¨ kernel/proc.c /proc.h ä¸­åŠ å…¥ä»£ç ï¼Œæ¥å®ç°è¿›ç¨‹åˆ›å»ºæ—¶åˆ›å»ºé¡µè¡¨ï¼Œé”€æ¯æ—¶é”€æ¯é¡µè¡¨çš„åŠ¨ä½œå°±è¡Œäº†ã€‚\nåœ¨ proc.h ä¸­ï¼Œæˆ‘ä»¬éœ€è¦åœ¨è¿›ç¨‹çš„ PCB ä¸­åŠ å…¥æ–°çš„æ•°æ®ç»“æ„:\nstruct proc { ... struct usyscall *usyscall; // using read only shared data to accelerate. ... } ä¸ºäº†è®©è¿›ç¨‹çš„æ­£å¸¸åˆ›å»ºå’Œé‡Šæ”¾ï¼Œæˆ‘ä»¬éœ€è¦å‘è¿›ç¨‹åˆ›å»ºå’Œé”€æ¯å‡½æ•°ä¸­åŠ å…¥å¯¹åº”çš„é¡µè¡¨æ“ä½œä»£ç ã€‚","title":"XV6 Lab 3: Page Table"},{"content":"MIT 6.S081 Lab2 website\nä¸ºäº†å®Œæˆ Syscall ä½œä¸šï¼Œéœ€è¦é˜…è¯»:\nXV6-book, Chapter 2, Sections 4.3 and 4.4\nfiles: user/user.h, kernel/proc.c kernel/proc.h, kernel/syscall.c kernel/syscall.h\nsystem call tracing system call tracing éœ€è¦æˆ‘ä»¬è¡¥å…… kernel ä¸­çš„ä¸€äº›ç¨‹åºï¼Œå°†æŸç¨‹åºä¸­æŒ‡å®šçš„ system call æ‰“å°å‡ºæ¥ã€‚å½“ç„¶ï¼Œè¿™éœ€è¦æˆ‘ä»¬æ–°å¢ä¸€ä¸ª system_trace ç³»ç»Ÿè°ƒç”¨å‡½æ•°ã€‚é¢˜ä¸­ï¼Œç»™å®šçš„ tracing ç¨‹åºä»¥ trace [system-call-number] [cmd] çš„æ–¹å¼è¿è¡Œã€‚æˆ‘ä»¬é¦–å…ˆå»çœ‹ user/trace.c ä¸­çš„å†…å®¹ï¼Œçœ‹çœ‹ system call number æ˜¯æ€ä¹ˆä¼ å…¥ç³»ç»Ÿè°ƒç”¨çš„ã€‚\nuser/trace.c çš„ç¨‹åºå¦‚ä¸‹æ‰€ç¤º:\nint main(int argc, char *argv[]) { int i; char *nargv[MAXARG]; if(argc \u0026lt; 3 || (argv[1][0] \u0026lt; \u0026#39;0\u0026#39; || argv[1][0] \u0026gt; \u0026#39;9\u0026#39;)){ fprintf(2, \u0026#34;Usage: %s mask command\\n\u0026#34;, argv[0]); exit(1); } if (trace(atoi(argv[1])) \u0026lt; 0) { fprintf(2, \u0026#34;%s: trace failed\\n\u0026#34;, argv[0]); exit(1); } for(i = 2; i \u0026lt; argc \u0026amp;\u0026amp; i \u0026lt; MAXARG; i++){ nargv[i-2] = argv[i]; } exec(nargv[0], nargv); exit(0); } æˆ‘ä»¬å‘ç°è¿™ä¸ªç¨‹åºç›´æ¥ä½¿ç”¨äº† trace ç³»ç»Ÿè°ƒç”¨æ¥å®ç°ã€‚æ‰€ä»¥æ¥ä¸‹æ¥çš„ä»»åŠ¡æ˜¯è¿›è¡Œ trace ç³»ç»Ÿè°ƒç”¨çš„å®ç°ã€‚å†æ¬¡å›é¡¾ Lab 1 ä¸­çš„å†…å®¹ï¼Œåœ¨ Lab 1 ä¸­æˆ‘ä»¬åˆ†æç³»ç»Ÿè°ƒç”¨æ˜¯é€šè¿‡åœ¨ usys.S çš„æ±‡ç¼–ç¨‹åºä¸­è¿›å…¥çš„ï¼Œç„¶å ecall åˆ° kernel/syscall.c ä¸­æ˜ å°„åˆ°çš„å‡½æ•°ï¼Œæœ€ç»ˆæ‰§è¡Œã€‚é‚£ä¹ˆ trace ç³»ç»Ÿè°ƒç”¨ä¹Ÿæ˜¯è¿™ä¸ªé€»è¾‘ã€‚\nåœ¨æ±‡ç¼–ä¸­ï¼Œæ˜¯è¿™æ ·å®ç°çš„:\nli a7, SYS_trace\recall\rret è¿™ä¸ª lab ä½¿ç”¨çš„æ˜¯ risc-v æ±‡ç¼–ã€‚li a7, SYS_trace è¡¨ç¤ºæŠŠ 32 ä½çš„æ•°æ® SYS_trace åŠ è½½åˆ°æŒ‡å®šçš„å¯„å­˜å™¨ a7 ä¸­ã€‚\necall å°†å¼‚å¸¸çš„ç±»å‹å†™åœ¨ a7 å¯„å­˜å™¨ä¸­ï¼Œå‚æ•°å†™åœ¨ a0-a5 å¯„å­˜å™¨ä¸­ã€‚syscall åœºæ™¯ä¸‹ï¼Œä½¿ç”¨ ecall ä¼šæŠŠå¤„ç†å™¨çš„ç‰¹æƒçº§åˆ«ç”± User-Mode è½¬åˆ° Supervisor-Modeã€‚é‚£ ecall è·³è½¬çš„åœ°å€åœ¨å“ªé‡Œå‘¢ï¼Ÿåœ¨æ“ä½œç³»ç»Ÿå¯åŠ¨çš„æ—¶å€™ï¼Œä¼šæŠŠå¼‚å¸¸è¡¨åœ°å€ç»‘å®šåˆ° stevc å¯„å­˜å™¨ä¸­ã€‚\nä¸ºäº†èƒ½å¤Ÿè®©æ¯ä¸ªè¿›ç¨‹çŸ¥é“éœ€è¦æ‰“å°å‡ºä»€ä¹ˆæ ·çš„ syscall è°ƒç”¨ï¼Œæˆ‘ä»¬éœ€è¦å°† trace è°ƒç”¨ä¼ å…¥çš„å€¼ä¼ ç»™è¿›ç¨‹ï¼Ÿé‚£å¦‚ä½•å°†ä¸€ä¸ªå€¼ä¼ ç»™è¿›ç¨‹ï¼Œè¿›ç¨‹åˆè¯¥å¦‚ä½•ä¿å­˜è¿™ä¸ªå€¼å‘¢ï¼Ÿ\næ˜¾ç„¶ï¼Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹è¿›ç¨‹çš„å®šä¹‰ï¼Œåœ¨ kernel/proc.h ä¸­ä¿®æ”¹è¿›ç¨‹çš„æ•°æ®ç»“æ„ï¼ŒåŠ ä¸Šä¸€ä¸ª mask é¡¹æ¥å­˜å‚¨éœ€è¦è·Ÿè¸ªçš„ç³»ç»Ÿè°ƒç”¨çš„æ•°å€¼ã€‚\nstruct proc { struct spinlock lock; ... char name[16]; // Process name (debugging) int mask; // -- Modified -- Lab2, system call. }; æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘åœ¨å“ªä¸ªåœ°æ–¹æ’å…¥æ‰“å°æŒ‡ä»¤æ¥æ‰“å°å‡º trace ç¨‹åºè¿½è¸ªçš„ç³»ç»Ÿè°ƒç”¨ï¼Ÿæ˜¯åœ¨ process ä¸­åŠ å…¥å—ï¼Ÿæ˜¾ç„¶ä¸èƒ½åœ¨è¿›ç¨‹ä¸­åšåˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬åªèƒ½åœ¨ syscall è¿™ä¸ªé€šç”¨çš„ç³»ç»Ÿè°ƒç”¨å‡½æ•°é‡Œé¢åŠ å…¥å¤„ç†ä»£ç ã€‚åœ¨æ–‡ä»¶ kernel/syscall.c çš„å‡½æ•° syscall ä¸­åŠ å…¥æ‰“å°ä»£ç :\nvoid syscall(void) { ... if(num \u0026gt; 0 \u0026amp;\u0026amp; num \u0026lt; NELEM(syscalls) \u0026amp;\u0026amp; syscalls[num]) { ... // -- modified -- if ((1 \u0026lt;\u0026lt; num) \u0026amp; p-\u0026gt;mask) { printf(\u0026#34;%d: syscall %s -\u0026gt; %d\\n\u0026#34;, p-\u0026gt;pid, sysname[num], p-\u0026gt;trapframe-\u0026gt;a0); } } else { ... } } åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œsyscall æŒ‡ä»¤ä¼šå°†è°ƒç”¨å·(a7 å¯„å­˜å™¨)è¯»å–åˆ° num ä¸­ï¼Œç„¶åæŸ¥æ‰¾ç³»ç»Ÿè°ƒç”¨è¡¨å¹¶æ‰§è¡Œã€‚æˆ‘åœ¨è¿™é‡Œå®šä¹‰äº†ä¸€ä¸ªæ–°çš„æ•°ç»„ sysname æ¥å­˜æ”¾æ¯ä¸ªç³»ç»Ÿè°ƒç”¨çš„åç§°ã€‚\nå¯¹äºç³»ç»Ÿè°ƒç”¨ï¼Œa0 å¯„å­˜å™¨ä¸­ä¿å­˜çš„æ˜¯è¿”å›å€¼\nä¸ºäº†ä¾¿åˆ©çš„å¢åŠ æ–°çš„ç³»ç»Ÿè°ƒç”¨ï¼Œxv6 lab å®ç°äº†ç”¨ perl è„šæœ¬æ¥ç”Ÿæˆ asm çš„ä¸€æ®µå°ç¨‹åºã€‚æˆ‘ä»¬éœ€è¦åœ¨ user/usys.pl ä¸­åŠ å…¥:\nentry(\u0026#34;trace\u0026#34;); åœ¨ make qemu çš„è¿‡ç¨‹ä¸­ï¼Œå®ƒä¼šè‡ªåŠ¨ç”Ÿæˆå¯¹åº”çš„é™·å…¥ç³»ç»Ÿè°ƒç”¨çš„æ±‡ç¼–å¦‚ä¸‹:\n.global trace\rtrace:\rli a7, SYS_trace\recall\rret æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ç»™ sys_trace å‡½æ•°åœ¨å†…æ ¸ä¸­æ–°åŠ ä¸€æ®µå£°æ˜ï¼Œä¿®æ”¹ kernel/syscall.c æ–‡ä»¶ï¼ŒåŠ å…¥\nextern uint64 sys_trace(); ç„¶ååœ¨ kernel/sysproc.c ä¸­å®ç°ç³»ç»Ÿè°ƒç”¨:\nuint64 sys_trace() { int mask; argint(0, \u0026amp;mask); if(mask \u0026lt; 0) return -1; myproc()-\u0026gt;mask = mask; return 0; } è¿™é‡Œçš„ argint å‡½æ•°ä¼šå»è°ƒç”¨ argraw å‡½æ•°å¦‚ä¸‹:\nstatic uint64 argraw(int n) { struct proc *p = myproc(); switch (n) { case 0: return p-\u0026gt;trapframe-\u0026gt;a0; case 1: return p-\u0026gt;trapframe-\u0026gt;a1; case 2: return p-\u0026gt;trapframe-\u0026gt;a2; case 3: return p-\u0026gt;trapframe-\u0026gt;a3; case 4: return p-\u0026gt;trapframe-\u0026gt;a4; case 5: return p-\u0026gt;trapframe-\u0026gt;a5; } panic(\u0026#34;argraw\u0026#34;); return -1; } å› ä¸ºæˆ‘ä»¬éœ€è¦è·å¾— mask å€¼ï¼Œè€Œ mask å€¼åœ¨ trace() å‡½æ•°ä¸­æ˜¯ç¬¬ä¸€ä¸ªï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´æ¥æ–¹ä½ a0 å¯„å­˜å™¨æ¥å¾—åˆ° mask çš„å€¼ã€‚\næ€»ç»“:\nåœ¨ xv6 ä¸­å®ç°ç³»ç»Ÿè°ƒç”¨æœ‰å¦‚ä¸‹çš„å‡ æ­¥:\nuser-mode è°ƒç”¨ trace()ï¼Œ trace() çš„å®ç°åœ¨ usys.S çš„æ±‡ç¼–ä¸­ usys.S å°† user-mode ä¸­è°ƒç”¨çš„ç³»ç»Ÿè°ƒç”¨ä»£å·å¡«å……åˆ° a7 å¯„å­˜å™¨ä¸­ ecall è°ƒç”¨äº† kernel/syscall.c ä¸­çš„ syscall() å‡½æ•°æ¥æ‰§è¡Œç³»ç»Ÿè°ƒç”¨ï¼Œå¹¶åˆ‡æ¢åˆ° supervisor-mode syscall() å‡½æ•°æœ¬èº«æ²¡æœ‰å®šä¹‰è¾“å…¥ï¼Œå…¶ä» a7 å¯„å­˜å™¨ä¸­æ‰¾åˆ°ç³»ç»Ÿè°ƒç”¨å‡½æ•°çš„ä»£å·ï¼Œç„¶åå†åœ¨å‡½æ•°è¡¨ä¸­æŸ¥æ‰¾ã€‚ Notes:\nä¸ºäº†è¿‡ fork() æµ‹è¯•æ ·ä¾‹ï¼Œéœ€è¦ä¿®æ”¹ fork() å‡½æ•°ï¼ŒåŠ å…¥ np-\u0026gt;mask = p-\u0026gt;mask; æ¥ç»§æ‰¿ maskã€‚\nsysinfo æœ‰äº†ä¸Šé¢çš„ä¾‹å­ï¼Œå®ç° sysinfo() å°±éå¸¸çš„ç®€å•äº†ã€‚sysinfo è¦æ±‚æˆ‘ä»¬ç»Ÿè®¡ç©ºé—²è¿›ç¨‹çš„æ•°é‡å’Œç©ºé—²å†…å­˜çš„æ•°é‡ã€‚\nå¯¹äºè¿›ç¨‹ï¼Œxv6 ä½¿ç”¨äº†ä¸€ä¸ªæ•°ç»„æ¥å­˜å‚¨äº†æ‰€æœ‰çš„è¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹çš„çŠ¶æ€éƒ½ä¿å­˜åœ¨ä¸€ä¸ªç»“æ„ä½“(PCB)ä¸­ã€‚å¦‚æœè¦æŸ¥è¯¢æ¯ä¸ªè¿›ç¨‹çš„çŠ¶æ€ï¼Œæˆ‘ä»¬åªéœ€è¦éå†æ‰€æœ‰çš„è¿›ç¨‹ï¼Œç„¶å check æ˜¯å¦æ˜¯ UNUSED çŠ¶æ€å°±è¡Œäº†ã€‚\næ¯ä¸ªè¿›ç¨‹çš„çŠ¶æ€åªèƒ½æ˜¯ä¸‹é¢çš„å‡ ç§ä¹‹ä¸€:\nenum procstate { UNUSED, SLEEPING, RUNNABLE, RUNNING, ZOMBIE }; æˆ‘ä»¬éœ€è¦åœ¨ kernel/proc.c ä¸­åŠ å…¥ä»£ç :\n// -- modified -- // To get the number of free processes. uint64 free_process_num() { uint64 res = 0; struct proc* tmp; for (tmp = proc; tmp \u0026lt; \u0026amp;proc[NPROC]; tmp++) { acquire(\u0026amp;tmp-\u0026gt;lock); if (tmp-\u0026gt;state != UNUSED) res++; release(\u0026amp;tmp-\u0026gt;lock); } return res; } éœ€è¦æ³¨æ„çš„æ˜¯: åœ¨ç»Ÿè®¡çŠ¶æ€çš„æ—¶å€™ï¼Œå¿…é¡»å¯¹å½“å‰çš„ PCB åŠ é”ï¼Œé˜²æ­¢å‡ºç°å†²çª(free_process_num)è¿è¡Œè¿‡ç¨‹ä¸­å˜æˆäº† UNUSED æˆ–è€…å…¶ä»–\nè€Œå¯ç”¨ç©ºé—´åˆ¤æ–­åˆ™æ˜¯åœ¨ kernel/kalloc.c æ–‡ä»¶ä¸­å®šä¹‰äº†ä¸€ä¸ªé“¾è¡¨ï¼Œæ¯ä¸ªé“¾è¡¨éƒ½æŒ‡å‘ä¸Šä¸€ä¸ªå¯ç”¨ç©ºé—´ï¼Œè¿™ä¸ªkmemå°±æ˜¯ä¸€ä¸ªä¿å­˜æœ€åé“¾è¡¨çš„å˜é‡ã€‚\nstruct run { struct run *next; }; struct { struct spinlock lock; struct run *freelist; } kmem; kmem.freelist æ°¸è¿œæŒ‡å‘æœ€åä¸€ä¸ªå¯ç”¨é¡µï¼Œé‚£æˆ‘ä»¬åªè¦é¡ºç€è¿™ä¸ªé“¾è¡¨å¾€å‰èµ°ï¼Œç›´åˆ° NULL ä¸ºæ­¢ã€‚\nåœ¨ kernel/kalloc.c ä¸­åŠ å…¥ä»£ç :\nuint64 free_mem_num() { uint64 res = 0; struct run *page = kmem.freelist; while(page != 0) { res ++; page = page-\u0026gt;next; } return res * PGSIZE; } å¯¹äºç»Ÿè®¡ç©ºé—²å†…å­˜å’Œè¿›ç¨‹çš„ä»£ç ï¼Œkernel/def.h ä¸­å£°æ˜ã€‚ ä¹‹åï¼Œæˆ‘ä»¬åœ¨ kernel/sysproc.c ä¸­å®ç° sysinfo() å‡½æ•°å¦‚ä¸‹:\nuint64 sys_sysinfo() { uint64 address; struct sysinfo info; struct proc *p = myproc(); argaddr(0, \u0026amp;address); if (address \u0026lt; 0) return -1; info.freemem = free_mem_num(); info.nproc = free_process_num(); if (copyout(p-\u0026gt;pagetable, address, (char*)\u0026amp;info, sizeof(info)) \u0026lt; 0) return -1; return 0; } è¿™é‡Œ copyout æ˜¯å§é¡µè¡¨ä¸­çš„å†…å®¹ copy åˆ° user-mode çš„è¿›ç¨‹ä¿¡æ¯ä¸­å»ã€‚æˆ‘ä»¬é€šè¿‡ argaddr(0, \u0026amp;address); æ‹¿åˆ° info çš„åœ°å€ï¼ŒæŠŠå†…æ ¸æ€çš„å†…å­˜ copy åˆ°ç”¨æˆ·æ€å»ã€‚\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab2_syscall/","summary":"MIT 6.S081 Lab2 website\nä¸ºäº†å®Œæˆ Syscall ä½œä¸šï¼Œéœ€è¦é˜…è¯»:\nXV6-book, Chapter 2, Sections 4.3 and 4.4\nfiles: user/user.h, kernel/proc.c kernel/proc.h, kernel/syscall.c kernel/syscall.h\nsystem call tracing system call tracing éœ€è¦æˆ‘ä»¬è¡¥å…… kernel ä¸­çš„ä¸€äº›ç¨‹åºï¼Œå°†æŸç¨‹åºä¸­æŒ‡å®šçš„ system call æ‰“å°å‡ºæ¥ã€‚å½“ç„¶ï¼Œè¿™éœ€è¦æˆ‘ä»¬æ–°å¢ä¸€ä¸ª system_trace ç³»ç»Ÿè°ƒç”¨å‡½æ•°ã€‚é¢˜ä¸­ï¼Œç»™å®šçš„ tracing ç¨‹åºä»¥ trace [system-call-number] [cmd] çš„æ–¹å¼è¿è¡Œã€‚æˆ‘ä»¬é¦–å…ˆå»çœ‹ user/trace.c ä¸­çš„å†…å®¹ï¼Œçœ‹çœ‹ system call number æ˜¯æ€ä¹ˆä¼ å…¥ç³»ç»Ÿè°ƒç”¨çš„ã€‚\nuser/trace.c çš„ç¨‹åºå¦‚ä¸‹æ‰€ç¤º:\nint main(int argc, char *argv[]) { int i; char *nargv[MAXARG]; if(argc \u0026lt; 3 || (argv[1][0] \u0026lt; \u0026#39;0\u0026#39; || argv[1][0] \u0026gt; \u0026#39;9\u0026#39;)){ fprintf(2, \u0026#34;Usage: %s mask command\\n\u0026#34;, argv[0]); exit(1); } if (trace(atoi(argv[1])) \u0026lt; 0) { fprintf(2, \u0026#34;%s: trace failed\\n\u0026#34;, argv[0]); exit(1); } for(i = 2; i \u0026lt; argc \u0026amp;\u0026amp; i \u0026lt; MAXARG; i++){ nargv[i-2] = argv[i]; } exec(nargv[0], nargv); exit(0); } æˆ‘ä»¬å‘ç°è¿™ä¸ªç¨‹åºç›´æ¥ä½¿ç”¨äº† trace ç³»ç»Ÿè°ƒç”¨æ¥å®ç°ã€‚æ‰€ä»¥æ¥ä¸‹æ¥çš„ä»»åŠ¡æ˜¯è¿›è¡Œ trace ç³»ç»Ÿè°ƒç”¨çš„å®ç°ã€‚å†æ¬¡å›é¡¾ Lab 1 ä¸­çš„å†…å®¹ï¼Œåœ¨ Lab 1 ä¸­æˆ‘ä»¬åˆ†æç³»ç»Ÿè°ƒç”¨æ˜¯é€šè¿‡åœ¨ usys.","title":"XV6 Lab 2: syscall"},{"content":"MIT 6.S081 Lab1 website\næœ¬ç« èŠ‚çš„å®éªŒæ˜¯ä¸ºäº†ç†Ÿæ‚‰ XV6 ç¯å¢ƒå’Œ interface è€Œå‡†å¤‡çš„ã€‚åŒ…å«äº† interface è°ƒç”¨ã€å¤šè¿›ç¨‹ç¼–ç¨‹ã€Pipelineã€‚\né˜…è¯» book-riscv-ref3 ç†Ÿæ‚‰ XV6 çš„ç³»ç»Ÿç»„ç»‡å½¢å¼\nsleep é€šè¿‡è°ƒç”¨ user.h ä¸­çš„ç³»ç»Ÿè°ƒç”¨å‡½æ•°æ¥å®Œæˆ sleep ç¨‹åºã€‚ä¸»è¦æ˜¯ä¸ºäº†ä»‹ç» ç³»ç»Ÿè°ƒç”¨ çš„å·¥ä½œæ–¹å¼ã€‚\n/** * @author chenghua.wang * @brief Lab1-utilities. sleep prog using syscall. * @time Feb 23, 2023 * */ #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;kernel/stat.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; int main(int argc, char *argv[]){ if (argc != 2){ printf(\u0026#34;[ error ] you should follow anw integer with sleep prog to indicate ticks times!\\n\u0026#34;); exit(1); // failure } sleep(atoi(argv[1])); // sys call provided by user.h exit(0); // success } ä¸‹é¢ä»¥ sleep(int) ç³»ç»Ÿè°ƒç”¨æ¥é˜è¿° XV6 ä¸­è°ƒç”¨çš„æµç¨‹ã€‚sleep å‡½æ•°åœ¨ user/user.h ä¸­å£°æ˜ï¼Œå…·ä½“çš„å‡½æ•°å®šä¹‰åˆ™é€šè¿‡å…¶ä»–æ¨¡å—çš„åŠ¨æ€è¿æ¥æœ€ç»ˆåˆæˆå¯æ‰§è¡Œæ–‡ä»¶ _sleep.\nåœ¨ user/usys.S ä¸­ sleep è°ƒç”¨çš„æ±‡ç¼–ä»£ç æ˜¯è¿™æ ·çš„:\n.global sleep\rsleep:\rli a7, SYS_sleep\recall\rret è¿™é‡Œçš„ sleep å°±æ˜¯ä¸Šé¢é‚£ä¸ª sleep å‡½æ•°çš„å®šä¹‰ï¼Œå°±æ˜¯è¯´æ‰§è¡Œ sleep æ—¶ï¼Œå°±æ˜¯æ‰§è¡Œè¿™æ®µæ±‡ç¼–ä»£ç ã€‚å¯ä»¥çœ‹åˆ°åœ¨ç”¨æˆ·ç©ºé—´ sleep å‡½æ•°çš„ä»»åŠ¡å°±æ˜¯å°† SYS_sleep æ”¾å…¥ a7 ä¸­ï¼Œç„¶åä¸­æ–­ã€‚SYS_sleep åœ¨ kernel/syscall.h ä¸­å®å®šä¹‰ä¸ºä¸€ä¸ªç³»ç»Ÿè°ƒç”¨å·ã€‚å¯ä»¥çœ‹åˆ°è¿™ä¸ª usys.S æ–‡ä»¶ä¹ŸåŒ…å«äº†è¿™ä¸ªå¤´æ–‡ä»¶ã€‚\n// kernel/syscall.h #define SYS_sleep 13 æ¥ä¸‹æ¥åœ¨ kernel/syscall.c ä¸­ï¼Œå¯ä»¥çœ‹åˆ° SYS_sleep è½¬æ¢ä¸ºäº†å¯¹åº”çš„ sys_sleep:\n// kernel/syscall.c // An array mapping syscall numbers from syscall.h // to the function that handles the system call. static uint64 (*syscalls[])(void) = { [SYS_fork] sys_fork, [SYS_exit] sys_exit, [SYS_wait] sys_wait, [SYS_pipe] sys_pipe, [SYS_read] sys_read, [SYS_kill] sys_kill, [SYS_exec] sys_exec, [SYS_fstat] sys_fstat, [SYS_chdir] sys_chdir, [SYS_dup] sys_dup, [SYS_getpid] sys_getpid, [SYS_sbrk] sys_sbrk, [SYS_sleep] sys_sleep, [SYS_uptime] sys_uptime, [SYS_open] sys_open, [SYS_write] sys_write, [SYS_mknod] sys_mknod, [SYS_unlink] sys_unlink, [SYS_link] sys_link, [SYS_mkdir] sys_mkdir, [SYS_close] sys_close, }; pingpong ä½¿ç”¨ pipe è¿›è¡Œçˆ¶è¿›ç¨‹å’Œå­è¿›ç¨‹ä¹‹é—´çš„è°ƒç”¨ã€‚æ³¨æ„ç®¡é“ 0, 1 çš„å…³é—­ã€‚\n/** * @author chenghua.wang * @brief Lab-1-utilities pingpong. Using the pipe syscall. * */ #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;kernel/stat.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; char* buf[8]; int main() { int p[2]; pipe(p); // using syscall to create pipe. // 1. child if (fork() == 0){ int id = getpid(); read(p[0], buf, 1); close(p[0]); printf(\u0026#34;%d: received ping\\n\u0026#34;, id); write(p[1], \u0026#34;c\u0026#34;, 1); close(p[1]); } else { // 2. parent int id = getpid(); write(p[1], \u0026#34;p\u0026#34;, 1); close(p[1]); wait(0); read(p[0], buf, 1); close(p[0]); printf(\u0026#34;%d: received pong\\n\u0026#34;, id); } exit(0); } prime é€šè¿‡ç®¡é“ä½œä¸ºä¸åŒè¿›ç¨‹ä¹‹é—´é€šä¿¡çš„æ¸ é“æ¥è¿›è¡Œå¤šè¿›ç¨‹æ±‚è§£ç´ æ•°ï¼Œå®ç°ç´ æ•°ç­›ã€‚è¿™é‡Œå› ä¸º XV6 çš„é™åˆ¶åªèƒ½å¼€ 34 ä¸ªè¿›ç¨‹ã€‚\nç®—æ³•çš„å…·ä½“æµç¨‹éå¸¸çš„ç®€å•:\næœ‰ç®¡é“ p_{0} æŠŠæ•°æ®(2-\u0026gt;35)å…¨éƒ½å¡«å…¥\np_{0} å³ç«¯è¿æ¥ä¸€ä¸ªè¿›ç¨‹ï¼Œè¿™ä¸ªè¿›ç¨‹ç­›å» p_{0} ä¸­ %2==0çš„ï¼Œå°†å‰©ä¸‹çš„æ•°ä¼ é€’ç»™ p_{1} ç®¡é“ã€‚\nä»¥æ­¤ç±»æ¨ã€‚\nåªéœ€è¦æ³¨æ„ä¸¤æ¬¡ç®¡é“çš„å…³é—­å°±å¥½äº†ã€‚\n/** * @author chenghua.wang * @brief using concurrency to get primes. * @time Feb 23, 2023 * */ #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;kernel/stat.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; int child(int previous_pipe[2]) { int child_pipe[2]; int prime; close(previous_pipe[1]); // child do not need write data to previous pipe. int len = read(previous_pipe[0], \u0026amp;prime, 1); if (!len) { close(previous_pipe[0]); // no data need to read anymore. exit(0); // success. } pipe(child_pipe); printf(\u0026#34;prime %d\\n\u0026#34;, prime); int num; if (fork() == 0) { close(previous_pipe[0]); child(child_pipe); } else { close(child_pipe[0]); while(1) { int len = read(previous_pipe[0], \u0026amp;num, 1); if (len == 0) break; if (num % prime != 0) { write(child_pipe[1], \u0026amp;num, 1); } } close(child_pipe[1]); close(previous_pipe[0]); wait(0); } exit(0); // success } int main() { int parent_pipe[2]; pipe(parent_pipe); if (fork() == 0) { child(parent_pipe); } else { close(parent_pipe[0]); // parent do not need to read data. for (int i = 2; i \u0026lt; 36; ++i) { write(parent_pipe[1], \u0026amp;i, sizeof(int)); } close(parent_pipe[1]); // parent do not need to write anymore. wait(0); // wait for child process done. } exit(0); } find åŸºæœ¬ä¸Šå°±æ˜¯ XV6 ä¸­ ls ç¨‹åºçš„æ”¹ç‰ˆã€‚åªä¸è¿‡åˆ¤æ–­æ˜¯æ–‡ä»¶å¤¹çš„è¯è¦é€’å½’ã€‚\n/** * @author chenghua.wang * @brief Lab1-utilities find * @time Feb 23, 2023 * */ #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;kernel/stat.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; #include \u0026#34;kernel/fs.h\u0026#34; // for file system. DIRSIZ, etc. char* fmtname(char *path) { char *p; for (p = path + strlen(path); p \u0026gt;= path \u0026amp;\u0026amp; *p != \u0026#39;/\u0026#39;; --p); p++; return p; } void find(char *directory, char *file_name) { char buf[512], *p; int fd; struct dirent de; struct stat st; // open file. if ((fd = open(directory, 0)) \u0026lt; 0) { fprintf(2, \u0026#34;find: cannot open %s\\n\u0026#34;, directory); return; } // get the state of this file if (fstat(fd, \u0026amp;st) \u0026lt; 0) { fprintf(2, \u0026#34;find: cannot get stat of %s\\n\u0026#34;, directory); close(fd); return; } // find the correct type need to check. // 1. path-\u0026gt; find if file_name is same. // 2. directory-\u0026gt; run find func again. // 3. others(\u0026#39;.\u0026#39;, \u0026#39;..\u0026#39;)-\u0026gt; skip. switch(st.type) { case T_DEVICE: case T_FILE: if (strcmp(file_name, fmtname(directory)) == 0) { printf(\u0026#34;%s\\n\u0026#34;, directory); } break; case T_DIR: strcpy(buf, directory); p = buf + strlen(buf); *p++ = \u0026#39;/\u0026#39;; while(read(fd, \u0026amp;de, sizeof(de)) == sizeof(de)) { if (de.inum == 0 || strcmp(de.name, \u0026#34;..\u0026#34;) == 0 || strcmp(de.name, \u0026#34;.\u0026#34;) == 0) continue; memmove(p, de.name, DIRSIZ); p[DIRSIZ] = 0; find(buf, file_name); } break; } close(fd); } int main(int argc, char *argv[]) { if (argc != 3) { printf(\u0026#34;[ error ] find [directory] [\u0026#39;name\u0026#39;]\\n\u0026#34;); exit(1); // failure } find(argv[1], argv[2]); exit(0); // success } xargs æˆ‘æƒ³ XV6 è¿™ä¸ªå®éªŒä¸»è¦æ˜¯æƒ³è€ƒå¯Ÿ exec çš„ä½œç”¨ã€‚xargs ä»æ ‡å‡†è¾“å…¥å¾—åˆ°æ•°æ®ï¼Œç„¶åå¯¹æ¯ä¸€è¡Œæ•°æ®é‡æ–°å¡«å…¥ argv å†æ‰§è¡Œã€‚\n/** * @author chenghua.wang * @brief Lab1-utilities xargs. * @time Feb 23, 2023 * */ #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;kernel/stat.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; char buf[512]; int main(int argc, char *argv[]) { char *pass_argv[64]; for (int i = 0; i \u0026lt; argc; ++i) { pass_argv[i] = argv[i + 1]; // the terminate 0 is also moved. } for (;;) { // to read a line int i = 0; for(;;++i) { int len = read(0, \u0026amp;buf[i], 1); // read from stdin. if (len == 0 || buf[i] == \u0026#39;\\n\u0026#39;) break; } if (i == 0) break; // exec a line buf[i] = 0; pass_argv[argc - 1] = buf; if (fork() == 0) { exec(pass_argv[0], pass_argv); exit(0); // success } else { wait(0); } } exit(0); // success } ","permalink":"https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab1_utility/","summary":"MIT 6.S081 Lab1 website\næœ¬ç« èŠ‚çš„å®éªŒæ˜¯ä¸ºäº†ç†Ÿæ‚‰ XV6 ç¯å¢ƒå’Œ interface è€Œå‡†å¤‡çš„ã€‚åŒ…å«äº† interface è°ƒç”¨ã€å¤šè¿›ç¨‹ç¼–ç¨‹ã€Pipelineã€‚\né˜…è¯» book-riscv-ref3 ç†Ÿæ‚‰ XV6 çš„ç³»ç»Ÿç»„ç»‡å½¢å¼\nsleep é€šè¿‡è°ƒç”¨ user.h ä¸­çš„ç³»ç»Ÿè°ƒç”¨å‡½æ•°æ¥å®Œæˆ sleep ç¨‹åºã€‚ä¸»è¦æ˜¯ä¸ºäº†ä»‹ç» ç³»ç»Ÿè°ƒç”¨ çš„å·¥ä½œæ–¹å¼ã€‚\n/** * @author chenghua.wang * @brief Lab1-utilities. sleep prog using syscall. * @time Feb 23, 2023 * */ #include \u0026#34;kernel/types.h\u0026#34; #include \u0026#34;kernel/stat.h\u0026#34; #include \u0026#34;user/user.h\u0026#34; int main(int argc, char *argv[]){ if (argc != 2){ printf(\u0026#34;[ error ] you should follow anw integer with sleep prog to indicate ticks times!","title":"XV6 Lab 1: Xv6 and Unix utilities"},{"content":"go back to home\nPaper link\nACM SIGOPS Operating Systems Review, 2010, 44(4): 30-39.\nLast Edit: Jan 19, 2023\nIntroduction æ˜¯çš„ï¼Œè¿™èŠ‚å†…å®¹è¿˜æ˜¯ FT(fault-tolerance)ã€‚ç°åœ¨åš FT ä¸»è¦æœ‰ä¸¤ç§æ‰‹æ®µ[2]ï¼š\nState transfer Primaryç”¨æ¥æ‰§è¡Œæ‰€æœ‰çš„ä»»åŠ¡ï¼ŒPrimaryå‘é€è¯¥æœºå™¨çš„æ‰€æœ‰çŠ¶æ€(æ‰€æœ‰çš„å†…å­˜å˜åŠ¨ï¼Œæ‰€æœ‰çš„ç£ç›˜å˜åŠ¨ï¼Œç­‰)ç»™Replicaã€‚State Transfer è™½ç„¶å¬èµ·æ¥éå¸¸çš„ç®€å•(å®é™…ä¸Šåšèµ·æ¥ä¹Ÿæ˜¯çš„ï¼Œç›¸å¯¹äºReplicated state machine)ï¼Œä½†æ˜¯éœ€è¦å ç”¨éå¸¸å¤§é‡çš„ç½‘ç»œå¸¦å®½æ¥å®ç°ã€‚\nå°½ç®¡å¦‚æ­¤(å ç”¨å¤§é‡çš„ç½‘ç»œèµ„æºï¼Œå¯¼è‡´ä¼ è¾“ç¼“æ…¢)ï¼ŒState Transferæ˜¯å¯¹å¤šå¤„ç†å™¨å‹å¥½çš„ä¸€ç§æ–¹å¼ï¼Œè€ŒReplicated state machineåˆ™ä¸æ˜¯ã€‚\nReplicated state machine Client å‘ Primary å‘é€æ“ä½œå’Œæ•°æ®(inputs)ã€‚PrimaryæŠŠè¿™äº›æ“ä½œå’Œæ•°æ®å‘é€ç»™Replicasï¼ŒReplicaså’ŒPrimaryéƒ½ä¼šæ‰§è¡Œè¿™äº›æŒ‡ä»¤ï¼Œéƒ½ä¼šå—åˆ°è¿™äº›æ•°æ®(inputs)ï¼Œæ‰€æœ‰çš„æŒ‡ä»¤éƒ½ä»¥åŒæ ·çš„é¡ºåºæ‰§è¡Œï¼Œåªè¦Primaryå’ŒReplicasåˆå§‹çš„çŠ¶æ€æ˜¯ä¸€è‡´çš„ï¼Œé‚£ä¹ˆäºŒè€…å°±ä¸€ç›´ä¿æŒç€åŒæ­¥(ä¹Ÿæ„å‘³ç€deterministic)ã€‚\nåœ¨å¹¶è¡ŒåŒ–çš„åº”ç”¨ä¸­ï¼ŒState transfer æ˜¯é¦–é€‰ï¼Œæ¯•ç«Ÿåœ¨å¹¶è¡Œçš„æ—¶å€™ï¼Œå¹¶è¡Œé¡ºåºå¯¹äºReplicated state machineæ¥è¯´æ˜¯å¼‚å¸¸éš¾åŒæ­¥çš„ã€‚\nä¸»ä»å¤åˆ¶æ—¶çš„æŒ‘æˆ˜[2]ï¼š\nè¦å¤åˆ¶ä»€ä¹ˆçŠ¶æ€ primaryéœ€è¦ç­‰å¾…backupå— ä»€ä¹ˆæ—¶å€™éœ€è¦åˆ‡æ¢åˆ°backup åˆ‡æ¢çš„æ—¶å€™å¼‚å¸¸æƒ…å†µæ˜¯å¦èƒ½çœ‹åˆ° å¦‚ä½•æé«˜åˆ›å»ºæ–°backupçš„é€Ÿåº¦ VM-FTä½¿ç”¨çš„å°±æ˜¯Replicated state machineçš„æ–¹æ³•ã€‚ä¸ºäº†èƒ½å¤Ÿæ•è·æ•°æ®ï¼Œå¹¶ä¸”åšå‡ºä¸€äº›è½¯ä»¶ä¸­æ–­ï¼ŒPrimaryå’ŒBackupéƒ½æ˜¯åœ¨VMä¸Šè¿è¡Œçš„ï¼Œç”±hypervisoræ¥ç®¡ç†ä»–ä»¬ã€‚\nArch VM-FT æ€»ä½“çš„ç»“æ„è¾ƒä¸ºç®€å•ï¼Œè®ºæ–‡ä¸­æ˜¯ä¸€ä¸»ä¸€ä»çš„ç»“æ„ã€‚VM-FTä¸»è¦ä¾èµ–äº Deterministic replay(ç¡®å®šæ€§é‡æ”¾)ã€‚VM-FT é€šè¿‡ç¡®å®šæ€§é‡æ”¾æ¥äº§ç”Ÿç›¸å…³çš„æ—¥å¿—æ¡ç›®ï¼Œä½†ä¸å°†æ—¥å¿—å†™å…¥ç£ç›˜ï¼Œè€Œæ˜¯é€šè¿‡ logging channel å‘é€ç»™backup(è¿™é‡ŒæŒ‡å¤‡ç”¨æœº)ã€‚backupå®æ—¶é‡æ”¾æ—¥å¿—é¡¹ã€‚\nå› ä¸ºä¸€åˆ‡éƒ½æ˜¯åœ¨ logging channel ä¸ŠåšåŒæ­¥çš„ã€‚ä¸ºäº†å®¹é”™ï¼Œå¿…é¡»åœ¨ logging channel ä¸Šå®ç°ä¸¥æ ¼çš„å®¹é”™åè®®ï¼Œæœ‰ä»¥ä¸‹è¦æ±‚ï¼š\nPrimaryç›´åˆ°backupæ¥æ”¶å¹¶ç¡®è®¤äº†å’Œè¾“å‡ºç›¸å…³çš„æ—¥å¿—çš„æ—¶å€™ï¼Œæ‰å‘é€è¾“å‡ºç»™å¤–ç•Œã€‚(è¿™æ ·åšçš„ç›®çš„æ˜¯ï¼Œåªè¦backupæ”¶åˆ°äº†æ‰€æœ‰çš„æ—¥å¿—æ¡ç›®ï¼Œå³ä½¿primaryå®•æœºäº†ï¼Œbackupä»èƒ½å¤Ÿé‡æ”¾åˆ°å®¢æˆ·ç«¯æœ€åçœ‹åˆ°çš„çŠ¶æ€ã€‚) Primaryå’Œbackupçš„æ•°æ®éƒ½æ˜¯10ã€‚ç°åœ¨å®¢æˆ·ç«¯å‘é€increaseè¯·æ±‚ï¼ŒPrimary+1å¹¶å›å¤ç»™client 11ï¼Œä¹‹åé©¬ä¸Šå®•æœºäº†ï¼Œæ›´ç³Ÿç³•çš„æ˜¯Primaryå‘ç»™backupçš„+1æ“ä½œä¹Ÿä¸¢åŒ…äº†ã€‚è¿™æ—¶å€™backupè¿˜æ˜¯10ï¼Œå¹¶æ¥ç®¡äº†primaryçš„å·¥ä½œï¼Œclientå†æ¬¡è¯·æ±‚+1ï¼Œåˆä¼šæ”¶åˆ°11çš„å›å¤ã€‚è¿™å°±äº§ç”Ÿäº†çŸ›ç›¾ã€‚\nå¦‚æœå¤‡æœºåœ¨ä¸»æœºæ•…éšœåæ¥ç®¡ï¼Œå¤‡æœºå°†ä»¥å’Œä¸»æœºå·²ç»å‘å¤–ç•Œå‘é€çš„è¾“å‡ºå®Œå…¨ä¸€è‡´çš„æ–¹å¼ç»§ç»­è¿è¡Œã€‚ ä¸ºäº†ç¡®ä¿ä¸€æ¬¡åªæœ‰ä¸€ä¸ªè™šæ‹Ÿæœºæˆä¸ºä¸»æœºï¼Œé¿å…å‡ºç°brain splitï¼ŒVMware åœ¨å…±äº«å­˜å‚¨ä¸Šæ‰§è¡Œtest and setæŒ‡ä»¤(\u0026ldquo;OSTEP\u0026quot;ä¸­æåˆ°è¿‡)ã€‚\nä¸ºäº†ä¿è¯ä¸€å®šçš„æ€§èƒ½ï¼ŒVM-FTå†³å®šåœ¨Primaryæ²¡æ”¶åˆ°Ackä»¥å‰ï¼Œå¯ä»¥ç»§ç»­å¾€ä¸‹æ‰§è¡Œï¼Œä½†æ˜¯è¿™æ ·ä¼šæ‹‰å¤§å’Œbackupä¹‹é—´çš„è·ç¦»ã€‚æ‰€ä»¥æ–‡ä¸­ç”¨ä¸€å®šçš„æ–¹æ³•æ¥é™åˆ¶è¿™ä¸ªgapï¼šå¦‚æœbackupåœ¨éœ€è¦è¯»å–ä¸‹ä¸€ä¸ªæ—¥å¿—æ¡ç›®æ—¶é‡åˆ°ç©ºæ—¥å¿—æ¡ç›®ï¼Œåˆ™åœæ­¢æ‰§è¡Œï¼Œç›´åˆ°æœ‰æ–°çš„æ—¥å¿—æ¡ç›®å¯ç”¨ã€‚å› ä¸ºbackupæ²¡æœ‰ä¸å¤–éƒ¨é€šä¿¡ï¼Œå› æ­¤æ­¤æš‚åœä¸ä¼šå½±å“clientsã€‚ç›¸åŒçš„ï¼ŒPrimaryå¦‚æœåœ¨éœ€è¦å†™å…¥æ—¥å¿—æ¡ç›®æ—¶é‡åˆ°ä¸€ä¸ªæ»¡çš„buffer(è™šæ‹Ÿæœºç®¡ç†ç¨‹åºç»´æŠ¤äº†ä¸€ä¸ªå¤§çš„æ—¥å¿—ç¼“å†²(log buffer)ï¼Œä¿å­˜ä¸»æœºå’Œå¤‡æœºçš„æ—¥å¿—ã€‚ä¸»æœºä¼šäº§ç”Ÿæ—¥å¿—é¡¹åˆ°æ—¥å¿—ç¼“å†²ï¼Œå¤‡æœºä»æ—¥å¿—ç¼“å†²æ¶ˆè´¹æ—¥å¿—ã€‚)ï¼Œåˆ™åœæ­¢æ‰§è¡Œï¼Œç›´åˆ°æ—¥å¿—æ¡ç›®è¢«æ¸…é™¤ä¸ºæ­¢ï¼Œæ˜¾ç„¶æˆ‘ä»¬ä¸å¸Œæœ›Primaryä¸backupä¹‹é—´çŠ¶æ€å·®è·å¤ªå¤§ï¼Œä¸€èˆ¬æ¥è¯´Primaryé€Ÿåº¦æ›´å¿«ã€‚\nç¼ºé™· ä»…æ”¯æŒå•å¤„ç†å™¨ï¼Œå¤šæ ¸å¯¹äºReplicated state machineæ˜¯æå…¶ä¸ç¡®å®šçš„ã€‚\nReference [1] Scales D J, Nelson M, Venkitachalam G. The design of a practical system for fault-tolerant virtual machines[J]. ACM SIGOPS Operating Systems Review, 2010, 44(4): 30-39.\n[2] MIT6.824 Notes. l-vm-tf.txt\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/papers/ft-vm/","summary":"notes of paper, ACM SIGOPS Operating Systems Review, 2010, 44(4): 30-39.","title":"The Design of a Practical System for Fault-Tolerant Virtual Machines"},{"content":"go back to home\nPaper link\nProceedings of the 19th ACM Symposium on Operating Systems Principles, ACM, Bolton Landing, NY (2003), pp. 20-43\nLast Edit: Jan 18, 2023\nGFS æœ‰éå¸¸å¤šçš„ä¸œè¥¿ï¼Œè¿™é‡Œåªå†™äº†ä¸€äº›é‡è¦çš„éƒ¨åˆ†ã€‚åƒæ˜¯snapshotï¼Œæ–‡ä»¶åˆ é™¤ï¼Œé«˜å¯ç”¨æœºåˆ¶ï¼ŒReplicaç®¡ç†ç­‰æ²¡æœ‰å…·ä½“æåŠã€‚\nIntroduction GFSæ˜¯googleæå‡ºçš„ä¸€ä¸ªå¯æ‰©å±•åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼Œä¸ºå¤§å‹åˆ†å¸ƒå¼æ•°æ®å¯†é›†å‹åº”ç”¨æä¾›æœåŠ¡ã€‚å¯ä»¥åœ¨å¤§è§„æ¨¡çš„æ¶ˆè´¹çº§æœºå™¨é›†ç¾¤ä¸Šæä¾›ä¸é”™çš„å®¹é”™èƒ½åŠ›ã€‚GFSåœ¨è®¾è®¡çš„æ—¶å€™ä¸»è¦ä¾æ®6ä¸ªå‡è®¾(è§‚å¯Ÿå¾—å‡ºçš„):\nèŠ‚ç‚¹å¤±æ•ˆç»å¸¸å‘ç”Ÿã€‚ç³»ç»Ÿç”±éå¸¸å¤šçš„æ¶ˆè´¹çº§æœºå™¨ç»„æˆï¼Œå¤§é‡ç”¨æˆ·åŒæ—¶è¿›è¡Œè®¿é—®ï¼Œè¿™ä½¿å¾—èŠ‚ç‚¹å¾ˆå®¹æ˜“å› ä¸ºç¨‹åºbugã€ç£ç›˜æ•…éšœã€å†…å­˜æ•…éšœç­‰åŸå› å¤±æ•ˆã€‚ å­˜å‚¨ä»¥å¤§æ–‡ä»¶ä¸ºä¸»ã€‚æ¯ä¸ªæ–‡ä»¶é€šå¸¸100MBæˆ–å‡ GBã€‚ç³»ç»Ÿéœ€è¦æ”¯æŒå°æ–‡ä»¶ï¼Œä½†ä¸éœ€è¦å¯¹å…¶è¿›è¡Œç‰¹æ®Šçš„ä¼˜åŒ–ã€‚ å¤§å®¹é‡è¿ç»­è¯»ï¼Œå°å®¹é‡éšæœºè¯»å–æ˜¯æ–‡ä»¶ç³»ç»Ÿä¸­çš„å¸¸æ€ã€‚ å†™å…¥ä¹Ÿå·²å¤§å®¹é‡ä¸ºä¸»ï¼Œå°å®¹é‡æ— éœ€ç‰¹æ®Šä¼˜åŒ–ã€‚ æ”¯æŒåŸå­çš„æ–‡ä»¶è¿½åŠ æ“ä½œã€‚ä½¿å¾—å¤§é‡ç”¨æˆ·å¯ä»¥å¹¶è¡Œè¿½åŠ æ–‡ä»¶ï¼Œè€Œä¸éœ€è¦é¢å¤–çš„åŠ é”æœºåˆ¶ã€‚ é«˜ååé‡æ¯”ä½å»¶æ—¶æ›´é‡è¦ ä¸ºä»€ä¹ˆè®¾è®¡ä¸€ä¸ªä¼˜ç§€çš„åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿéå¸¸çš„å›°éš¾:\nPerformance. å½“æ•°æ®é‡éå¸¸å¤§çš„æ—¶å€™ï¼Œæ•°æ®åˆ†ç‰‡(Sharding)æ˜¯éå¸¸é‡è¦çš„ã€‚ Fault Tolerance. ä½†æ˜¯ç”±äºæ•°æ®åœ¨å¤šå°æœåŠ¡å™¨ä¸Šåˆ†ç‰‡ã€‚ç”±äºå¤šå°æœåŠ¡å™¨ï¼Œæ•´ä¸ªç³»ç»Ÿå‡ºç°æ•…éšœçš„æ¦‚ç‡ä¼šå¤§å¾ˆå¤šã€‚å› æ­¤éœ€è¦å®¹é”™æœºåˆ¶ Replication. å¤åˆ¶æ•°æ®å‰¯æœ¬åˆ°å¤šå°æœåŠ¡å™¨ä¸Šï¼Œä½†æ˜¯ä¸ºäº†ç”¨æˆ·èƒ½å¤Ÿæ‹¿åˆ°ä¸€è‡´çš„æ•°æ®ï¼Œéœ€è¦è€ƒè™‘ä¸€è‡´æ€§ Consistency. ä¸ºäº†ä¸€è‡´æ€§ï¼Œä¸å¾—ä¸ä½¿ç”¨ç½‘ç»œ(ææ…¢çš„æ•°æ®äº¤äº’æ–¹å¼)è¿›è¡Œç¡®è®¤å’ŒåŒæ­¥ã€‚è¿™åˆä¼šå½±å“æ€§èƒ½(Performance)!!! ä¸–ç•Œå› æ­¤å˜æˆäº†ä¸€ä¸ªç¾å¦™çš„ç¯ã€‚:-)ã€‚è¿™ä¹Ÿæ˜¯åˆ†å¸ƒå¼çš„æŒ‘æˆ˜ä¹‹å¤„ã€‚\nGFSè®¨è®ºäº†ä¸Šè¿°çš„è¿™äº›ä¸»é¢˜å’Œåœ¨å®é™…ç”Ÿäº§åœºæ™¯ä¸­çš„åº”ç”¨ã€‚\nArchitecture Fig 1. GFS ArchGoole File System. Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. Proceedings of the 19th ACM Symposium on Operating Systems Principles, ACM, Bolton Landing, NY (2003), pp. 20-43\nä¸€ä¸ªGFSé›†ç¾¤ç”±ä¸€ä¸ªMasterèŠ‚ç‚¹å’Œè‹¥å¹²ä¸ªChunk ServerèŠ‚ç‚¹ç»„æˆã€‚æ¯ä¸ªChunk Serverå¯ä»¥è¢«è®¸å¤šä¸ªClientè®¿é—®ã€‚GFS Chunk Serverä½œä¸ºç”¨æˆ·çº§è¿›ç¨‹åœ¨LinuxæœåŠ¡å™¨ä¸­è¿è¡Œï¼Œå¹¶ä¸”æ–‡ä»¶ç³»ç»Ÿæœ¬èº«ä½¿ç”¨çš„å°±æ˜¯Linuxç³»ç»Ÿçš„é‚£å¥—ã€‚(æ‰€ä»¥æ–‡ä¸­è¯´ï¼Œæ²¡æœ‰ç‰¹åœ°çš„ä¸ºGFS Chunk ServeråŠ å…¥cacheåŠŸèƒ½ï¼Œå› ä¸ºLinuxæ–‡ä»¶ç³»ç»Ÿå·²ç»å¹²äº†è¿™ä»¶äº‹)\nChunk: GFSä¸­çš„æ–‡ä»¶åœ¨å­˜å‚¨çš„æ—¶å€™ä¼šè¢«åˆ†å‰²æˆå¤šä¸ªChunkï¼Œæ¯ä¸ªChunkçš„å¤§å°ä¸º64MBã€‚åœ¨Chunkåˆ†é…çš„æ—¶å€™ï¼ŒMasterä¼šåˆ†é…ä¸€ä¸ªHandleç»™Chunkï¼Œç±»ä¼¼äºæŒ‡é’ˆã€‚Chunkåœ¨googleçš„å®ç°ä¸­ï¼Œä½¿ç”¨3ä»½å‰¯æœ¬ã€‚\nMaster: ç»´æŠ¤å…ƒæ•°æ®ï¼Œè®°å½•æ–‡ä»¶è¢«åˆ†å‰²ä¸ºå“ªäº›Chunkã€ä»¥åŠè¿™äº›Chunkçš„å­˜å‚¨ä½ç½®ï¼›å®ƒè¿˜è´Ÿè´£Chunkçš„è¿ç§»ã€é‡æ–°å¹³è¡¡(rebalancing)å’Œåƒåœ¾å›æ”¶ï¼›æ­¤å¤–ï¼ŒMasteré€šè¿‡å¿ƒè·³æœºåˆ¶ä¸ChunkServeré€šä¿¡ï¼Œå‘å…¶ä¼ é€’æŒ‡ä»¤(æ˜¯çš„ï¼Œä¹Ÿæ˜¯é€šè¿‡å¿ƒè·³æœºåˆ¶)ï¼Œå¹¶æ”¶é›†çŠ¶æ€ï¼›\nClient: é¦–å…ˆå‘Masterè¯¢é—®è¯¥æ–‡ä»¶çš„Chunkåœ¨å“ªé‡Œï¼ŒChunk Serverä½ç½®ï¼Œå†ä» Chunk Serverè·å–æ•°æ®ã€‚Clientå¹¶ä¸ä¼šæ¯æ¬¡éƒ½å‘Masterå‘é€æ•°æ®è¿›è¡Œè¯¢é—®ï¼Œå®ƒä¼šcacheä¸€éƒ¨åˆ†çš„æ•°æ®(ä¸æ˜¯Chunkçš„ï¼Œæ˜¯æŸä¸ªæ–‡ä»¶å¯¹åº”çš„Chunk Serverçš„ä½ç½®ï¼Œå³Chunkçš„åœ°å€)ï¼Œå¹¶ä¸”ä¿æŒä¸€å®šçš„æ—¶é—´ã€‚\nChunkServer: å­˜å‚¨Chunkï¼ŒClientå’ŒChunk Serverä¸ä¼šç¼“å­˜Chunkæ•°æ®ï¼Œé˜²æ­¢æ•°æ®å‡ºç°ä¸ä¸€è‡´\nChunk and Chunk Size Chunkå¤§å°çš„é€‰æ‹©æ˜¯éå¸¸é‡è¦çš„ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼ŒChunkå¤§å°ä¸º64MBï¼Œè¿™æ¯”å…¸å‹çš„æ–‡ä»¶ç³»ç»Ÿçš„blockå¤§å¾—å¤šï¼Œå¯ä»¥é€šè¿‡æƒ°æ€§ç©ºé—´åˆ†é…ç­–ç•¥ï¼Œæ¥é¿å…å› å†…éƒ¨ç¢ç‰‡é€ æˆçš„ç©ºé—´æµªè´¹ã€‚\nä¸è¿‡ï¼Œè¾ƒå¤§çš„Chunkä¼šä½¿å¾—å°æ–‡ä»¶å æ®é¢å¤–çš„å­˜å‚¨ç©ºé—´ã€‚æ­¤å¤–ï¼Œå°æ–‡ä»¶é€šå¸¸åªä¼šå æ®ä¸€ä¸ªChunkï¼Œå½“å¤§é‡å®¢æˆ·ç«¯è®¿é—®è¿™ä¸ªå°æ–‡ä»¶æ—¶ï¼Œè¿™ä¸ªChunkå®¹æ˜“æˆä¸ºç³»ç»Ÿçš„è´Ÿè½½çƒ­ç‚¹ã€‚\nChunkçš„å¤§å°è®¾ç½®ä¸»è¦è€ƒè™‘è¿™äº›å› ç´ ï¼š\nå‡å°‘Masterä¿å­˜çš„å…ƒæ•°æ®å¤§å°(æ¯ä¸ªchunckéƒ½å¯¹åº”ç€ä¸€ä»½å…ƒæ•°æ®ï¼Œåˆ†å‰²çš„Chunkå¤ªå¤šä¼šå¯¼è‡´å…ƒæ•°æ®éå¸¸çš„å¤§ã€‚ç±»ä¼¼çš„ï¼Œå¯ä»¥æ¯”ä½œå†…å­˜åˆ†é¡µä¸­çš„é¡µè¡¨)ï¼Œä½¿å¾—å¯ä»¥æŠŠå…ƒæ•°æ®å…¨éƒ¨æ”¾åœ¨å†…å­˜ä¸­ã€‚ å‡å°‘Clientä¸Masterçš„é€šä¿¡æ¬¡æ•°ï¼Œå› ä¸ºå¯¹åŒä¸€ä¸ªChunkçš„å¤šæ¬¡è¯»å†™åªéœ€è¦è¯·æ±‚ä¸€æ¬¡Chunkä¿¡æ¯(Clientä¼šæš‚æ—¶çš„å­˜å‚¨è¿™äº›å…ƒä¿¡æ¯ï¼Œç±»æ¯”äºå†…å­˜çš„Spacial localityç‰¹æ€§)ã€‚ å¢å¤§Clientæ“ä½œè½åˆ°åŒä¸€ä¸ªChunkä¸Šçš„æ¦‚ç‡ã€‚é€šè¿‡ä¿æŒæŒä¹…çš„TCPè¿æ¥æ¥å‡å°‘ç½‘ç»œä¸Šçš„è´Ÿè½½ã€‚(ç±»ä¼¼çš„ï¼Œå¯ä»¥ç±»æ¯”äºå†…å­˜çš„Temporal localityç‰¹æ€§) Master ä¸ºäº†ç®€åŒ–è®¾è®¡ï¼Œåªæœ‰ä¸€å°æœºå™¨ä¼šä½œä¸ºMasterå­˜åœ¨ã€‚Masteråœ¨å†…å­˜ä¸­å­˜å‚¨3ç§metadatã€‚æ ‡è®° nv(non-volatile, éæ˜“å¤±) çš„æ•°æ®éœ€è¦åœ¨å†™å…¥çš„åŒæ—¶å­˜åˆ°ç£ç›˜(ä¸ºäº†æ•ˆç‡ï¼Œä¹Ÿæœ‰æ‰¹å†™å…¥çš„)ï¼Œæ ‡è®°vçš„æ•°æ®ï¼ŒMasterä¼šåœ¨å¯åŠ¨åæŸ¥è¯¢Chunk Server é›†ç¾¤ã€‚\nnamespace(ç›®å½•å±‚æ¬¡ç»“æ„)å’Œæ–‡ä»¶å(nv)\næ–‡ä»¶å -\u0026gt; array of Chunk Handles çš„æ˜ å°„(nv)\nChunk Handles -\u0026gt; ç‰ˆæœ¬å·(nv)ã€list of Chunk Servers(v)ã€primary(v)ã€lease(v)\nMaster ä½¿ç”¨Logå’ŒCheckPointsæ¥è¿›è¡Œè®°å½•è€Œä¸æ˜¯ä½¿ç”¨æ•°æ®åº“çš„å½¢å¼ã€‚Logå½¢å¼å¯ä»¥åœ¨å°¾éƒ¨å¿«é€Ÿæ·»åŠ ï¼Œç›¸æ¯”äºæ•°æ®åº“çš„å¤æ‚æ•°æ®ç»“æ„ï¼ŒLogçš„é€Ÿåº¦ä¼šæ›´å¿«ã€‚å¹¶ä¸”Logæ˜¯ä¸€ç§é¡ºåºçš„ç»“æ„ï¼Œå¯ä»¥å¾ˆå¥½çš„ä½“ç°å‡ºæ—¶é—´çº¿ã€‚\nå…ƒæ•°æ®ç®¡ç†[2] å…ƒæ•°æ®ä¿å­˜åœ¨Masterå†…å­˜ä¸­ä½¿å¾—Masterè¦å¯¹å…ƒæ•°æ®ä½œå‡ºå˜æ›´å˜å¾—æä¸ºå®¹æ˜“ï¼›åŒæ—¶ï¼Œè¿™ä¹Ÿä½¿å¾—Masterå¯ä»¥ç®€å•é«˜æ•ˆåœ°å‘¨æœŸæ€§æ‰«ææ•´ä¸ªé›†ç¾¤çš„çŠ¶æ€ï¼Œä»¥å®ç°Chunkå›æ”¶ã€è¿ç§»ã€å‡è¡¡ç­‰æ“ä½œã€‚ä¸€ä¸ª64MBçš„chunckéœ€è¦ä½¿ç”¨æ‰64KBçš„ç©ºé—´æ¥å­˜å‚¨å…ƒæ•°æ®ã€‚\nMasterä¼šæŠŠå‰ä¸¤ç±»ä¿¡æ¯(namespace+æ–‡ä»¶åï¼Œæ–‡ä»¶ååˆ°chunck Handlesçš„æ˜ å°„)ä»¥æ—¥å¿—å½¢å¼æŒä¹…åŒ–å­˜å‚¨åœ¨Masterçš„æœ¬åœ°ç£ç›˜ä¸Šï¼Œå¹¶åœ¨åœ¨å…¶ä»–æœºå™¨ä¸Šå¤‡ä»½ï¼Œä½†æ˜¯ä¸ä¼šæŒä¹…åŒ–ä¿å­˜Chunk Replicaçš„ä½ç½®ä¿¡æ¯ï¼Œè€Œæ˜¯åœ¨é›†ç¾¤å¯åŠ¨æ—¶ç”±Masterè¯¢é—®å„ä¸ªChunk Serverå…¶å½“å‰æ‰€æœ‰çš„Repicaã€‚è¿™æ ·åšå¯ä»¥çœå»ç”±äºChunk Serverç¦»å¼€é›†ç¾¤ã€æ›´æ”¹åå­—ã€é‡å¯ç­‰åŸå› çš„Masterä¸Chunk Serverçš„åŒæ­¥é—®é¢˜ã€‚æ­¤åï¼ŒMasteré€šè¿‡å¿ƒè·³åŒ…æ¥ç›‘æ§Chunk Serverçš„çŠ¶æ€å¹¶æ›´æ–°å†…å­˜ä¸­çš„ä¿¡æ¯ã€‚\nä¸ºäº†ä¿è¯å…ƒæ•°æ®çš„å¯ç”¨æ€§ï¼ŒMasteråœ¨å¯¹å…ƒæ•°æ®åšä»»ä½•æ“ä½œå‰å¯¹ä¼šç”¨å…ˆå†™æ—¥å¿—çš„å½¢å¼å°†æ“ä½œè¿›è¡Œè®°å½•ï¼Œåªæœ‰å½“æ—¥å¿—å†™å…¥å®Œæˆåæ‰ä¼šå“åº”å®¢æˆ·ç«¯çš„è¯·æ±‚ï¼Œè€Œè¿™äº›æ—¥å¿—ä¹Ÿä¼šå¤‡ä»½åˆ°å¤šä¸ªæœºå™¨ä¸Šã€‚æ—¥å¿—ä¸ä»…æ˜¯å…ƒæ•°æ®çš„å”¯ä¸€æŒä¹…åŒ–è®°å½•ï¼Œä¹Ÿæ˜¯å®šä¹‰æ“ä½œæ‰§è¡Œé¡ºåºçš„æ—¶é—´çº¿ã€‚æ–‡ä»¶ã€Chunkå’Œä»–ä»¬çš„ç‰ˆæœ¬ä¿¡æ¯éƒ½ç”±ä»–ä»¬çš„åˆ›å»ºæ—¶é—´å”¯ä¸€çš„æ°¸ä¹…çš„æ ‡è¯†ã€‚\nNamespaceç®¡ç†[2] åœ¨é€»è¾‘ä¸Šï¼ŒMasterå¹¶ä¸ä¼šæ ¹æ®æ–‡ä»¶ä¸ç›®å½•çš„å…³ç³»ä»¥åˆ†å±‚çš„ç»“æ„æ¥ç®¡ç†è¿™éƒ¨åˆ†æ•°æ®ï¼Œè€Œæ˜¯å•çº¯åœ°å°†å…¶è¡¨ç¤ºä¸ºä»å®Œæ•´è·¯å¾„ååˆ°å¯¹åº”æ–‡ä»¶å…ƒæ•°æ®çš„æ˜ å°„è¡¨ï¼Œå¹¶åœ¨è·¯å¾„åä¸Šåº”ç”¨å‰ç¼€å‹ç¼©ä»¥å‡å°‘å†…å­˜å ç”¨ã€‚\nä¸ºäº†ç®¡ç†æ¥è‡ªä¸åŒå®¢æˆ·ç«¯çš„å¹¶å‘è¯·æ±‚å¯¹Namespaceçš„ä¿®æ”¹ï¼ŒMasterä¼šä¸ºNamespaceä¸­çš„æ¯ä¸ªæ–‡ä»¶å’Œç›®å½•éƒ½åˆ†é…ä¸€ä¸ªè¯»å†™é”ï¼ˆRead-Write Lockï¼‰ã€‚ç”±æ­¤ï¼Œå¯¹ä¸åŒNamespaceåŒºåŸŸçš„å¹¶å‘è¯·æ±‚ä¾¿å¯ä»¥åŒæ—¶è¿›è¡Œã€‚\næ‰€æœ‰Masteræ“ä½œåœ¨æ‰§è¡Œå‰éƒ½ä¼šéœ€è¦å…ˆè·å–ä¸€ç³»åˆ—çš„é”ï¼šé€šå¸¸ï¼Œå½“æ“ä½œæ¶‰åŠæŸä¸ªè·¯å¾„ /d1/d2/\u0026hellip;/dn/leafæ—¶ï¼ŒMasterä¼šéœ€è¦å…ˆè·å–ä»/d1ã€/d1/d2åˆ°/d1/d2/\u0026hellip;/dnçš„è¯»é”ï¼Œç„¶åå†æ ¹æ®æ“ä½œçš„ç±»å‹è·å– /d1/d2/\u0026hellip;/dn/leadçš„è¯»é”æˆ–å†™é”ã€‚è·å–çˆ¶ç›®å½•çš„è¯»é”æ˜¯ä¸ºäº†é¿å…çˆ¶ç›®å½•åœ¨æ­¤æ¬¡æ“ä½œæ‰§è¡Œçš„è¿‡ç¨‹ä¸­è¢«é‡å‘½åæˆ–åˆ é™¤ã€‚\nç”±äºå¤§é‡çš„è¯»å†™é”å¯èƒ½ä¼šé€ æˆè¾ƒé«˜çš„å†…å­˜å ç”¨ï¼Œè¿™äº›é”ä¼šåœ¨å®é™…éœ€è¦æ—¶æ‰è¿›è¡Œåˆ›å»ºï¼Œå¹¶åœ¨ä¸å†éœ€è¦æ—¶è¢«é”€æ¯ã€‚æ­¤å¤–ï¼Œæ‰€æœ‰çš„é”è·å–æ“ä½œä¹Ÿä¼šæŒ‰ç…§ä¸€ä¸ªç›¸åŒçš„é¡ºåºè¿›è¡Œï¼Œä»¥é¿å…å‘ç”Ÿæ­»é”ï¼šé”é¦–å…ˆæŒ‰Namespaceæ ‘çš„å±‚çº§æ’åˆ—ï¼ŒåŒä¸€å±‚çº§å†…åˆ™ä»¥è·¯å¾„åå­—å…¸åºæ’åˆ—(\u0026ldquo;OSTEP\u0026quot;ä¸­chapter32è®²è¿°çš„ï¼Œä½¿ç”¨ä¸€å®šçš„é”çš„é¡ºåºæ¥é¿å…æ­»é”)ã€‚\nLeaseç®¡ç†[2] GFSä½¿ç”¨ç§Ÿçº¦ï¼ˆleaseï¼‰æœºåˆ¶æ¥ä¿æŒå¤šä¸ªå‰¯æœ¬é—´å˜æ›´é¡ºåºçš„ä¸€è‡´æ€§ã€‚åœ¨å®¢æˆ·ç«¯å¯¹æŸä¸ªChunkåšå‡ºå˜æ›´æ—¶ï¼Œä¼šæŠŠè¯¥Chunkçš„Leaseäº¤ç»™æŸä¸ªReplicaï¼Œä½¿å…¶æˆä¸ºPrimaryï¼šPrimary ä¼šè´Ÿè´£ä¸ºè¿™äº›å˜æ›´å®‰æ’ä¸€ä¸ªæ‰§è¡Œé¡ºåºï¼Œç„¶åå…¶ä»–Replicaä¾¿æŒ‰ç…§ç›¸åŒçš„é¡ºåºæ‰§è¡Œè¿™äº›ä¿®æ”¹ã€‚\nè®¾è®¡ç§Ÿçº¦æœºåˆ¶çš„ç›®çš„æ˜¯ä¸ºäº†æœ€å°åŒ–MasterèŠ‚ç‚¹çš„ç®¡ç†è´Ÿæ‹…ã€‚Chunk Leaseåœ¨åˆå§‹æ—¶ä¼šæœ‰60ç§’çš„è¶…æ—¶æ—¶é—´ã€‚åœ¨æœªè¶…æ—¶å‰ï¼ŒPrimaryå¯ä»¥å‘Masterç”³è¯·å»¶é•¿Chunk Leaseçš„æ—¶é—´ï¼›å¿…è¦æ—¶Masterä¹Ÿå¯ä»¥ç›´æ¥æ’¤å›å·²åˆ†é…çš„Chunk Leaseã€‚\nRead and Write åœ¨å†™æ–‡ä»¶çš„æ—¶å€™ä¼šæ¶‰åŠåˆ°Leaseå’ŒVersionçš„é—®é¢˜ã€‚\nRead Clientå°†æ–‡ä»¶å + Offsetè½¬ä¸ºæ–‡ä»¶å + Chunk Indexï¼Œå‘Masterå‘èµ·è¯·æ±‚\nMasteråœ¨å…ƒæ•°æ®ä¸­æŸ¥è¯¢å¯¹åº”Chunkæ‰€åœ¨çš„Chunk Handle + Chunk Locationså¹¶è¿”å›ç»™Client\nClientå°†Masterè¿”å›ç»™å®ƒçš„ä¿¡æ¯ç¼“å­˜èµ·æ¥ï¼Œç”¨æ–‡ä»¶å + Chunk Indexä½œä¸º key\nClientä¼šé€‰æ‹©ç½‘ç»œä¸Šæœ€è¿‘çš„Chunk Serveré€šä¿¡ï¼Œå¹¶é€šè¿‡ Chunk Handle + Chunk Locations æ¥è¯»å–æ•°æ®\nWrite Fig 2. Write Control and Data FlowGoole File System. Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. Proceedings of the 19th ACM Symposium on Operating Systems Principles, ACM, Bolton Landing, NY (2003), pp. 20-43\nå†™æ–‡ä»¶å¯åˆ†ä¸º 7 æ­¥ï¼š\nClientå‘Masterè¯¢é—®å“ªä¸ªChunk ServeræŒæœ‰è¯¥Chunkçš„å½“å‰ç§Ÿçº¦ï¼Œä»¥åŠå…¶ä»–å‰¯æœ¬çš„ä½ç½®ã€‚å¦‚æœæ²¡æœ‰äººæœ‰ç§Ÿçº¦ï¼Œåˆ™Masterå°†ç§Ÿçº¦æˆäºˆå®ƒé€‰æ‹©çš„Replicaã€‚\nMasterå›å¤è°æ˜¯Primaryå’ŒSecondary Replicaçš„ä½ç½®ã€‚Clientç¼“å­˜æ­¤æ•°æ®ä»¥å¤‡å°†æ¥æ›´æ”¹ã€‚ä»…å½“Primaryå˜å¾—ä¸å¯è®¿é—®æˆ–å®ƒä¸å†æŒæœ‰ç§Ÿçº¦æ—¶ï¼ŒClientæ‰éœ€è¦å†æ¬¡è”ç³»Masterã€‚\nClientå°†æ•°æ®æ¨é€åˆ°æ‰€æœ‰Replicaã€‚Clientå¯ä»¥æŒ‰ä»»ä½•é¡ºåºæ‰§è¡Œæ­¤æ“ä½œã€‚æ¯ä¸ª Chunk Serveréƒ½ä¼šå°†æ•°æ®å­˜å‚¨åœ¨å†…éƒ¨LRUç¼“å†²åŒºç¼“å­˜ä¸­ï¼Œç›´åˆ°æ•°æ®è¢«ä½¿ç”¨æˆ–è€åŒ–ã€‚é€šè¿‡å°†æ•°æ®æµä¸æ§åˆ¶æµåˆ†ç¦»ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡åŸºäºç½‘ç»œæ‹“æ‰‘è°ƒåº¦ä¸åŒæ•°æ®æµæ¥æé«˜æ€§èƒ½ï¼Œè€Œä¸ç®¡å“ªä¸ªChunk Serveræ˜¯Primaryã€‚\nä¸€æ—¦Clientç¡®è®¤æ¯ä¸ªChunk Serveréƒ½æ”¶åˆ°æ•°æ®ï¼ŒClientå‘Primaryå‘é€å†™è¯·æ±‚ï¼ŒPrimaryå¯èƒ½ä¼šæ”¶åˆ°å¤šä¸ªè¿ç»­çš„å†™è¯·æ±‚ï¼Œä¼šå…ˆå°†è¿™äº›æ“ä½œçš„é¡ºåºå†™å…¥æœ¬åœ°(ä»¥æ­¤æ¥é¿å…å¹¶å‘é—®é¢˜ï¼Œé¡ºåºå¯¹äºå…¶ä»–Replicaæ¥è¯´æ˜¯ä¸€è‡´çš„)ã€‚\nPrimaryåšå®Œå†™è¯·æ±‚åï¼Œå°†å†™è¯·æ±‚å’Œé¡ºåºè½¬å‘ç»™æ‰€æœ‰çš„Secondaryï¼Œè®©ä»–ä»¬ä»¥åŒæ ·çš„é¡ºåºå†™æ•°æ®ã€‚\nSecondaryå®Œæˆååº”ç­”Primaryå†™è¯·æ±‚æ˜¯å¦æˆåŠŸã€‚\nPrimaryåº”ç­”Clientæ‰€æœ‰çš„æµç¨‹æ˜¯æˆåŠŸè¿˜æ˜¯å¤±è´¥ã€‚å¦‚æœå‡ºç°å¤±è´¥ï¼ŒClientä¼šé‡è¯•ï¼Œä½†åœ¨é‡è¯•æ•´ä¸ªå†™ä¹‹å‰ï¼Œä¼šå…ˆé‡å¤æ­¥éª¤ 3-7\nAtomic Record Appends æ–‡ä»¶è¿½åŠ çš„æ“ä½œä¸å†™æ–‡ä»¶çš„æ“ä½œéå¸¸åƒã€‚\nClientå°†æ•°æ®æ¨é€åˆ°æ¯ä¸ªReplicaï¼Œç„¶åå°†å†™è¯·æ±‚å‘å¾€Primaryã€‚ Primaryé¦–å…ˆåˆ¤æ–­å°†æ•°æ®è¿½åŠ åˆ°Chunkåæ˜¯å¦ä¼šä»¤CHunkçš„å¤§å°è¶…è¿‡ä¸Šé™ã€‚å¦‚æœæ˜¯ï¼Œé‚£ä¹ˆPrimaryä¼šå°†å½“å‰Chunkå¡«å……è‡³å…¶å¤§å°è¾¾åˆ°ä¸Šé™ï¼Œå¹¶é€šçŸ¥å…¶ä»–Replicaæ‰§è¡Œç›¸åŒçš„æ“ä½œï¼Œå†å“åº”å®¢æˆ·ç«¯ï¼Œé€šçŸ¥å…¶åº”åœ¨ä¸‹ä¸€ä¸ªChunkä¸Šé‡è¯•è¯¥æ“ä½œã€‚ å¦‚æœæ•°æ®èƒ½å¤Ÿè¢«æ”¾å…¥åˆ°å½“å‰Chunkä¸­ï¼Œé‚£ä¹ˆPrimaryä¼šæŠŠæ•°æ®è¿½åŠ åˆ°Chunkä¸­ï¼Œæ‹¿åˆ°è¿½åŠ æˆåŠŸè¿”å›çš„åç§»é‡ï¼Œç„¶åé€šçŸ¥å…¶ä»–Replicaå°†æ•°æ®å†™å…¥åˆ°ç›¸åŒä½ç½®ä¸­ã€‚ æœ€åPrimaryæŠŠåç§»é‡è¿”å›ç»™Clientã€‚ NOTEï¼ï¼ï¼\nGFSåªç¡®ä¿æ•°æ®ä¼šä»¥ä¸€ä¸ªåŸå­çš„æ•´ä½“è¢«è¿½åŠ åˆ°æ–‡ä»¶ä¸­è‡³å°‘ä¸€æ¬¡ã€‚å¦‚æœä¸€ä¸ªReplicaè¿½åŠ ä¸æˆåŠŸï¼Œé‚£ä¹ˆä¼šé‡è¯•ï¼Œæ­¤æ—¶å¯èƒ½ä¼šå‘ç”Ÿåœ¨ä¸€ä¸ªReplicaä¸­å‡ºç°ä¸¤æ¬¡è¯¥æ–‡ä»¶ï¼Œä½†æ˜¯ä¸è®ºå¦‚ä½•ï¼Œä»–ä»¬çš„åç§»é‡éƒ½æ˜¯ä¸€æ ·çš„ã€‚\nç±»ä¼¼äºè¿™æ ·çš„(ä»ä¸Šåˆ°ä¸‹çœ‹)ï¼š\nReplica 1(primary) Replica 2(secondary) Replica 3(secondary) state A A A - B Failed B write B C C C write C B B B try write B again Consistency Fig 3. File Region State After MutationGoole File System. Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. Proceedings of the 19th ACM Symposium on Operating Systems Principles, ACM, Bolton Landing, NY (2003), pp. 20-43\nGFSæ˜¯å¼±ä¸€è‡´æ€§çš„æ¨¡å‹ã€‚å®ƒå¹¶ä¸ä¿è¯ä¸€ä¸ª chunk çš„æ‰€æœ‰å‰¯æœ¬æ˜¯ç›¸åŒçš„ã€‚ä»æ–‡ä»¶è¿½åŠ ä¸­å°±å¯ä»¥çœ‹å‡ºæ¥ã€‚\nInconsistentï¼šå®¢æˆ·ç«¯è¯»å–ä¸åŒçš„Replicaæ—¶å¯èƒ½ä¼šè¯»å–åˆ°ä¸åŒçš„å†…å®¹ï¼Œé‚£è¿™éƒ¨åˆ†æ–‡ä»¶æ˜¯ä¸ä¸€è‡´çš„ã€‚\nConsistentï¼šæ‰€æœ‰å®¢æˆ·ç«¯æ— è®ºè¯»å–å“ªä¸ªReplicaéƒ½ä¼šè¯»å–åˆ°ç›¸åŒçš„å†…å®¹ï¼Œé‚£è¿™éƒ¨åˆ†æ–‡ä»¶å°±æ˜¯ä¸€è‡´çš„ã€‚\nDefinedï¼šæ‰€æœ‰å®¢æˆ·ç«¯éƒ½èƒ½çœ‹åˆ°ä¸Šä¸€æ¬¡ä¿®æ”¹çš„å®Œæ•´å†…å®¹ï¼Œä¸”è¿™éƒ¨åˆ†æ–‡ä»¶æ˜¯ä¸€è‡´çš„ï¼Œé‚£ä¹ˆæˆ‘ä»¬è¯´è¿™éƒ¨åˆ†æ–‡ä»¶æ˜¯ç¡®å®šçš„ã€‚\nmaterials check FAQ of MIT6.824 2022 Lecture 3[3]\nä¸ºä»€ä¹ˆéœ€è¦Lease å¦‚æœæ²¡æœ‰Leaseï¼Œé‚£ä¹ˆåŠ å…¥Masterå…ˆæŒ‡å®šä¸€ä¸ªchunkserverä¸ºPrimaryï¼Œä½†æ˜¯å®ƒå®•æœºæˆ–è€…ç½‘ç»œå»¶è¿Ÿäº†ï¼Œç„¶åMasteré‡æ–°æŒ‡å®šäº†ä¸€ä¸ªchunk serverï¼Œå½“å‰ä¸€ä¸ªchunk serveræ¢å¤åï¼Œä»¥ä¸ºè‡ªå·±è¿˜æ˜¯Primaryï¼Œè¿™æ ·å°±æœ‰ä¸¤ä¸ªPrimaryï¼Œä¼šæŒ‡å®šä¸åŒçš„æ¬¡åºè¿›è¡Œå†™ï¼Œé‚£ä¹ˆå°±è¿åäº†ä¸€è‡´æ€§ã€‚æœ‰Leaseï¼Œé‚£ä¹ˆåœ¨ç¬¬ä¸€ä¸ªchunk serverçš„Leaseæ— æ•ˆå‰ï¼Œä¸ä¼šåˆ†é…ç¬¬äºŒä¸ªLeaseã€‚\nmasterå¦‚ä½•é€‰æ‹©Primaryï¼Œä¸ºä»€ä¹ˆéœ€è¦ç‰ˆæœ¬å· å¯¹äºæ¯ä¸ªchunk handleï¼ŒMasteråœ¨å†…å­˜ä¸­æœ‰å®ƒçš„æœ€æ–°ç‰ˆæœ¬å·ï¼Œå› æ­¤é€šè¿‡å®šæœŸå’Œchunk serveräº¤æµåçŸ¥é“æœ€æ–°çš„chunkåœ¨å“ªä¸ªchunk serverä¸Šï¼Œé€‰æ‹©å®ƒä¸ºPrimaryï¼›å› æ­¤ï¼Œç‰ˆæœ¬å·å¯ä»¥å¸®åŠ©è¯†åˆ«æœ€æ–°çš„Replicaæ•°æ®ï¼›æ­¤å¤–ï¼Œæœ‰å¯èƒ½Masterä¼šçœ‹åˆ°chunk serveræœ‰æ›´å¤§çš„ç‰ˆæœ¬å·ï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºå¯èƒ½å‘å®Œç§Ÿçº¦å’Œæœ€æ–°çš„ç‰ˆæœ¬å·åï¼ŒMasterå®•æœºäº†ï¼Œæ²¡æœ‰æ›´æ–°æœ¬åœ°çš„ç‰ˆæœ¬å·ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼ŒMasterä¼šé‡‡ç”¨æ›´å¤§çš„ç‰ˆæœ¬å·ã€‚\nReference [1] Goole File System. Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. Proceedings of the 19th ACM Symposium on Operating Systems Principles, ACM, Bolton Landing, NY (2003), pp. 20-43\n[2] SOSP'03 The Google File System, from zhihu\n[3] MIT 6.824 2022, distributed system\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/papers/gfs/","summary":"go back to home\nPaper link\nProceedings of the 19th ACM Symposium on Operating Systems Principles, ACM, Bolton Landing, NY (2003), pp. 20-43\nLast Edit: Jan 18, 2023\nGFS æœ‰éå¸¸å¤šçš„ä¸œè¥¿ï¼Œè¿™é‡Œåªå†™äº†ä¸€äº›é‡è¦çš„éƒ¨åˆ†ã€‚åƒæ˜¯snapshotï¼Œæ–‡ä»¶åˆ é™¤ï¼Œé«˜å¯ç”¨æœºåˆ¶ï¼ŒReplicaç®¡ç†ç­‰æ²¡æœ‰å…·ä½“æåŠã€‚\nIntroduction GFSæ˜¯googleæå‡ºçš„ä¸€ä¸ªå¯æ‰©å±•åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼Œä¸ºå¤§å‹åˆ†å¸ƒå¼æ•°æ®å¯†é›†å‹åº”ç”¨æä¾›æœåŠ¡ã€‚å¯ä»¥åœ¨å¤§è§„æ¨¡çš„æ¶ˆè´¹çº§æœºå™¨é›†ç¾¤ä¸Šæä¾›ä¸é”™çš„å®¹é”™èƒ½åŠ›ã€‚GFSåœ¨è®¾è®¡çš„æ—¶å€™ä¸»è¦ä¾æ®6ä¸ªå‡è®¾(è§‚å¯Ÿå¾—å‡ºçš„):\nèŠ‚ç‚¹å¤±æ•ˆç»å¸¸å‘ç”Ÿã€‚ç³»ç»Ÿç”±éå¸¸å¤šçš„æ¶ˆè´¹çº§æœºå™¨ç»„æˆï¼Œå¤§é‡ç”¨æˆ·åŒæ—¶è¿›è¡Œè®¿é—®ï¼Œè¿™ä½¿å¾—èŠ‚ç‚¹å¾ˆå®¹æ˜“å› ä¸ºç¨‹åºbugã€ç£ç›˜æ•…éšœã€å†…å­˜æ•…éšœç­‰åŸå› å¤±æ•ˆã€‚ å­˜å‚¨ä»¥å¤§æ–‡ä»¶ä¸ºä¸»ã€‚æ¯ä¸ªæ–‡ä»¶é€šå¸¸100MBæˆ–å‡ GBã€‚ç³»ç»Ÿéœ€è¦æ”¯æŒå°æ–‡ä»¶ï¼Œä½†ä¸éœ€è¦å¯¹å…¶è¿›è¡Œç‰¹æ®Šçš„ä¼˜åŒ–ã€‚ å¤§å®¹é‡è¿ç»­è¯»ï¼Œå°å®¹é‡éšæœºè¯»å–æ˜¯æ–‡ä»¶ç³»ç»Ÿä¸­çš„å¸¸æ€ã€‚ å†™å…¥ä¹Ÿå·²å¤§å®¹é‡ä¸ºä¸»ï¼Œå°å®¹é‡æ— éœ€ç‰¹æ®Šä¼˜åŒ–ã€‚ æ”¯æŒåŸå­çš„æ–‡ä»¶è¿½åŠ æ“ä½œã€‚ä½¿å¾—å¤§é‡ç”¨æˆ·å¯ä»¥å¹¶è¡Œè¿½åŠ æ–‡ä»¶ï¼Œè€Œä¸éœ€è¦é¢å¤–çš„åŠ é”æœºåˆ¶ã€‚ é«˜ååé‡æ¯”ä½å»¶æ—¶æ›´é‡è¦ ä¸ºä»€ä¹ˆè®¾è®¡ä¸€ä¸ªä¼˜ç§€çš„åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿéå¸¸çš„å›°éš¾:\nPerformance. å½“æ•°æ®é‡éå¸¸å¤§çš„æ—¶å€™ï¼Œæ•°æ®åˆ†ç‰‡(Sharding)æ˜¯éå¸¸é‡è¦çš„ã€‚ Fault Tolerance. ä½†æ˜¯ç”±äºæ•°æ®åœ¨å¤šå°æœåŠ¡å™¨ä¸Šåˆ†ç‰‡ã€‚ç”±äºå¤šå°æœåŠ¡å™¨ï¼Œæ•´ä¸ªç³»ç»Ÿå‡ºç°æ•…éšœçš„æ¦‚ç‡ä¼šå¤§å¾ˆå¤šã€‚å› æ­¤éœ€è¦å®¹é”™æœºåˆ¶ Replication. å¤åˆ¶æ•°æ®å‰¯æœ¬åˆ°å¤šå°æœåŠ¡å™¨ä¸Šï¼Œä½†æ˜¯ä¸ºäº†ç”¨æˆ·èƒ½å¤Ÿæ‹¿åˆ°ä¸€è‡´çš„æ•°æ®ï¼Œéœ€è¦è€ƒè™‘ä¸€è‡´æ€§ Consistency. ä¸ºäº†ä¸€è‡´æ€§ï¼Œä¸å¾—ä¸ä½¿ç”¨ç½‘ç»œ(ææ…¢çš„æ•°æ®äº¤äº’æ–¹å¼)è¿›è¡Œç¡®è®¤å’ŒåŒæ­¥ã€‚è¿™åˆä¼šå½±å“æ€§èƒ½(Performance)!!! ä¸–ç•Œå› æ­¤å˜æˆäº†ä¸€ä¸ªç¾å¦™çš„ç¯ã€‚:-)ã€‚è¿™ä¹Ÿæ˜¯åˆ†å¸ƒå¼çš„æŒ‘æˆ˜ä¹‹å¤„ã€‚\nGFSè®¨è®ºäº†ä¸Šè¿°çš„è¿™äº›ä¸»é¢˜å’Œåœ¨å®é™…ç”Ÿäº§åœºæ™¯ä¸­çš„åº”ç”¨ã€‚\nArchitecture Fig 1. GFS ArchGoole File System. Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. Proceedings of the 19th ACM Symposium on Operating Systems Principles, ACM, Bolton Landing, NY (2003), pp.","title":"Google File System(GFS)"},{"content":"OSDI'04: 6th Symposium on Operating Systems Design and Implementation\ngo back to home\nPaper link\nä»€ä¹ˆæ˜¯ MapReduce åœ¨MapReduceåŸæ–‡ä¸­æ˜¯è¿™ä¹ˆè¯´çš„\nMapReduce is a programming model and an associated implementation for processing and generating large data sets. [1]\nè¿™æ˜¯ä¸€ä¸ªè¾ƒä¸ºç®€å•çš„å¤„ç†å¤§å‹é—®é¢˜çš„åˆ†å¸ƒå¼ç¼–ç¨‹æ¨¡å‹ã€‚å…¶äº§ç”Ÿçš„åŸå› æ˜¯å› ä¸º google æƒ³è¦è®©æ™®é€šçš„ç¨‹åºå‘˜ä¹Ÿèƒ½å¤Ÿé€šè¿‡ä¸€å¥—ç®€å•çš„ç¼–ç¨‹æ¨¡å‹æ¥ç¼–å†™åˆ†å¸ƒå¼åº”ç”¨ç¨‹åºï¼Œä»¥æ­¤æ¥å¤„ç† google å†…éƒ¨çš„å¤§æ•°æ®ã€‚ç„¶åè‘—åçš„ Jeff Dean å’Œ Sanjay Ghemawat å‡ºé©¬æå®šäº†è¿™ä¸ªé—®é¢˜(åœ¨çŸ¥ä¹ä¸Šå…³äºJeff Deançš„è½¶äº‹:-))ã€‚MapReduce åœ¨ google å†…éƒ¨è¿è¡Œå¾ˆé•¿çš„æ—¶é—´å¹¶ä¸”å¤„ç†äº†å¾ˆå¤šä¸šåŠ¡ï¼Œä½†æ˜¯ç›®å‰ä¹Ÿè´¥ä¸‹é˜µæ¥ï¼Œå…·ä½“åŸå› å‚è§ MapReduce ç¼ºé™·ç« èŠ‚(MRæ—©åœ¨2004å¹´å°±å‡ºæ¥äº†ï¼Œå…¶å®æ˜¯å¤æ—©çš„æŠ€æœ¯äº†ï¼Œå…¶æ²¡æœ‰åœ¨æ€§èƒ½ä¸Šåšæ–‡ç« ï¼Œä¸»è¦åœ¨å¯æ‰©å±•æ€§ä¸Š)ã€‚\nMapReduce çš„è®¾è®¡æ¡†æ¶å’ŒåŸºæœ¬æµç¨‹ MRå®é™…ä¸Šæ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„æ¡†æ¶ï¼Œæ€è·¯ä¹Ÿéå¸¸çš„ç›´ç™½ã€‚MapReduce èƒŒåçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ•°æ®é›†æ˜ å°„åˆ°ä¸€ä¸ª \u0026lt;key, value\u0026gt; pairçš„é›†åˆä¸­ï¼Œç„¶åä½¿ç”¨ç›¸åŒçš„é”®å¯¹æ‰€æœ‰pairè¿›è¡Œæ•´åˆã€‚ æ•´ä½“æ¦‚å¿µå¾ˆç®€å•ï¼Œä½†æ˜¯å¦‚æœä½ è®¾æƒ³ä¸‹ä¸‹é¢çš„æƒ…å†µï¼ŒMRå®é™…ä¸Šéå¸¸æœ‰ç”¨: åŸºæœ¬ä¸Šæ‰€æœ‰çš„æ•°æ®éƒ½èƒ½è¢«æ˜ å°„åˆ°ä¸€ä¸ª \u0026lt;key, value\u0026gt; å¯¹ä¸­ï¼Œå¹¶ä¸”keyå’Œvalueå¯ä»¥æ˜¯ä»»æ„ç±»å‹ã€‚\nåœ¨è®ºæ–‡ä¸­MRä½¿ç”¨çš„æ ·ä¾‹æ˜¯åœ¨è¶…å¤§çš„æ–‡ä»¶é‡Œåšå•è¯ç»Ÿè®¡ã€‚è¿™ä¸ªæ¡†æ¶è¿˜å¯ä»¥ç”¨æ¥åšï¼š\nåˆ†å¸ƒå¼çš„æ’åº åˆ†å¸ƒå¼çš„æœç´¢ Webé“¾æ¥å›¾éå† \u0026hellip; Fig 1. MapReduce Archfrom \u0026ldquo;MapReduce: Simplified Data Processing on Large Clusters\u0026rdquo; googleusercontent.com.\nMR ä¸­çš„Mapå’ŒReduceæ˜¯ä»å‡½æ•°å¼ç¼–ç¨‹è¯­è¨€(LISP)ä¸­å€Ÿé‰´è¿‡æ¥çš„ä¸€ä¸ªæ¦‚å¿µã€‚ç¨‹åºå‘˜åªéœ€è¦ç¼–å†™Mapå’ŒReduceä¸¤ä¸ªå‡½æ•°å°±èƒ½å¤Ÿå¯¹æŸä¸ªä»»åŠ¡å¹¶å‘å¤„ç†ã€‚åœ¨ Fig 1 ä¸­ï¼ŒMRä¸»è¦çš„æµç¨‹åˆ†ä¸º6ä¸ªéƒ¨åˆ†\nç”¨æˆ·ç¨‹åºçš„MRé¦–å…ˆå°†è¾“å…¥æ–‡ä»¶åˆ†æˆ M å—ï¼Œæ¯å—é€šå¸¸ä¸º 16 MBåˆ° 64 MB(å¯ç”±ç”¨æˆ·é€šè¿‡å‚æ•°æ§åˆ¶)ã€‚ ç„¶åï¼Œå®ƒä¼šåœ¨ä¸€ç»„æœºå™¨ä¸Šå¯åŠ¨è¯¥ç¨‹åºçš„å¤šä¸ªå‰¯æœ¬ã€‚\nè¿™äº›å‰¯æœ¬ä¸­æœ‰ä¸€ä¸ªæ§åˆ¶ç¨‹åº(Master)ã€‚å…¶ä½™çš„ç¨‹åº(Worker)ç”±æ§åˆ¶ç¨‹åº(Master)æ¥åˆ†é…ã€‚æœ‰ M ä¸ª Map ä»»åŠ¡å’Œ R ä¸ª Reduce ä»»åŠ¡è¦åˆ†é…ã€‚Master æŒ‘é€‰ç©ºé—²çš„ Worker å¹¶ä¸ºæ¯ä¸ªæœºå™¨åˆ†é…ä¸€ä¸ª Map ä»»åŠ¡æˆ– Reduce ä»»åŠ¡ã€‚\nåˆ†é…äº† map ä»»åŠ¡çš„ worker è¯»å–ç›¸åº”çš„å†…å®¹(æ‹†åˆ†åçš„æ–‡ä»¶å—)(è®¾æƒ³ä¸‹ï¼Œå¦‚æœè¿™é‡Œçš„æ–‡ä»¶è¯»å–éœ€è¦ä»æ•°æ®ä»“åº“ä¸­æ‹¿å‡ºï¼Œé‚£ä¹ˆæ•´ä¸ªæ¡†æ¶çš„è®¡ç®—èƒ½åŠ›æå¤§çš„è¢«ç½‘ç»œæ‰€é™åˆ¶äº†)ã€‚å®ƒä»è¾“å…¥æ•°æ®ä¸­è§£æå‡º\u0026lt;key, value\u0026gt;å¯¹ï¼Œå¹¶å°†æ¯ä¸€å¯¹ä¼ é€’ç»™ç”¨æˆ·å®šä¹‰çš„ Map å‡½æ•°ã€‚ Map å‡½æ•°äº§ç”Ÿçš„ä¸­é—´\u0026lt;key, value\u0026gt;å¯¹è¢«ç¼“å­˜åœ¨å†…å­˜ä¸­ã€‚\nç¼“å­˜åœ¨æœºå™¨ä¸­çš„ä¸­é—´\u0026lt;key, value\u0026gt;å¯¹å‘¨æœŸæ€§åœ°è¢«å†™å…¥æœ¬åœ°ç£ç›˜ï¼Œç”±åˆ†åŒºå‡½æ•°åˆ’åˆ†ä¸º R ä¸ªåŒºåŸŸã€‚è¿™äº›ç¼“å†²å¯¹åœ¨æœ¬åœ°ç£ç›˜ä¸Šçš„ä½ç½®è¢«ä¼ å› Masterï¼ŒMaster è´Ÿè´£å°†è¿™äº›ä½ç½®è½¬å‘ç»™ Reduce Workerã€‚\nå½“ Master é€šçŸ¥ Reduce Worker æœ‰å…³è¿™äº›ä½ç½®æ—¶ï¼Œå®ƒä¼šä½¿ç”¨RPCä» Map Worker çš„æœ¬åœ°ç£ç›˜è¯»å–ç¼“å†²æ•°æ®ã€‚å½“ Reduce Worker è¯»å–æ‰€æœ‰ä¸­é—´æ•°æ®æ—¶ï¼Œå®ƒä¼šæŒ‰ä¸­é—´é”®å¯¹å…¶è¿›è¡Œæ’åºï¼Œä»¥ä¾¿å°†æ‰€æœ‰å‡ºç°çš„ç›¸åŒé”®ç»„åˆåœ¨ä¸€èµ·ã€‚æ’åºæ˜¯å› ä¸ºé€šå¸¸è®¸å¤šä¸åŒçš„é”®æ˜ å°„åˆ°åŒä¸€ä¸ª Reduce ä»»åŠ¡ã€‚å¦‚æœä¸­é—´æ•°æ®é‡å¤ªå¤§è€Œæ— æ³•æ”¾å…¥å†…å­˜ï¼Œåˆ™ä½¿ç”¨å¤–éƒ¨æ’åºã€‚\nReduce Worker è¿­ä»£æ’åºçš„ä¸­é—´æ•°æ®ï¼Œå¯¹äºé‡åˆ°çš„æ¯ä¸ªå”¯ä¸€ä¸­é—´é”®ï¼Œå®ƒå°†é”®å’Œç›¸åº”çš„ä¸­é—´å€¼é›†ä¼ é€’ç»™ç”¨æˆ·çš„ Reduce å‡½æ•°ã€‚Reduce å‡½æ•°çš„è¾“å‡ºåˆ°æ­¤ Reduce åˆ†åŒºçš„æœ€ç»ˆè¾“å‡ºæ–‡ä»¶ã€‚\nå½“æ‰€æœ‰çš„ Map ä»»åŠ¡å’Œ Reduce ä»»åŠ¡éƒ½å®Œæˆåï¼ŒMasterå”¤é†’ç”¨æˆ·ç¨‹åºã€‚æ­¤æ—¶ç”¨æˆ·ç¨‹åºä¸­çš„ MR è°ƒç”¨è¿”å›ç»™ç”¨æˆ·ä»£ç \nå› ä¸ºç½‘ç»œä¸Šçš„æ•°æ®äº¤æ¢æ˜¯éå¸¸ç¼“æ…¢çš„ï¼Œä½œè€…åœ¨åˆ†å‘æ•°æ®çš„æ—¶å€™å°½é‡ä¿è¯æ•°æ®å°±åœ¨è¿™å°è®¡ç®—æœåŠ¡å™¨ä¸Šï¼Œè€Œä¸éœ€è¦ä¼ è¾“æ•°æ®ã€‚åœ¨åŸæ–‡ä¸­æ˜¯è¿™æ ·è¯´çš„ï¼š\nWe conserve network bandwidth by taking advantage of the fact that the input data (managed by GFS) is stored on the local disks of the machines that make up our cluster.\nMapReduce çš„ä½¿ç”¨èŒƒä¾‹ è®ºæ–‡ä¸­ï¼Œä»¥è¯é¢‘ç»Ÿè®¡ä¸ºä¾‹å­ï¼Œå¦‚è®ºæ–‡ä¸­çš„ä¼ªä»£ç ï¼š\nmap(String key, String value):\r// key: document name\r// value: document contents\rfor each word w in value:\rEmitIntermediate(w, \u0026#34;1\u0026#34;); reduce(String key, Iterator values):\r// key: a word\r// values: a list of counts\rint result = 0;\rfor each v in values:\rresult += ParseInt(v);\rEmit(AsString(result)); MR Fault Tolerance Fault Tolerance åœ¨åˆ†å¸ƒå¼ç¨‹åºä¸­æ˜¯éå¸¸é‡è¦çš„ã€‚MR ä¸»è¦çš„è´¡çŒ®ç‚¹å…¶å®å°±åœ¨ scalability å’Œ fault toleranceã€‚\nWorker Failure Master ä¼šå®šæœŸçš„ ping Worker æœåŠ¡å™¨ï¼Œå¦‚æœä¸é€šï¼Œé‚£ä¹ˆè¿™ä¸ª Worker è¢«è®¾ç½®æˆ idleï¼Œåˆ†é…ç»™è¿™å°æœºå™¨çš„ä»»åŠ¡ä¼šè¢«åˆ†å‘ç»™å…¶ä»–çš„æœºå™¨ã€‚\nMaster Failure Master å› ä¸ºåªæœ‰å°‘é‡çš„æœºå™¨ï¼Œæ‰€ä»¥å‘ç”Ÿé”™è¯¯çš„å¯èƒ½æ€§éå¸¸çš„å°ã€‚å¯ä»¥é€šè¿‡å­˜å‚¨ Master çš„çŠ¶æ€ä¸º checkpoints æ¥è¿›è¡Œé”™è¯¯æ—¶å›é€€å’Œæ¢å¤ã€‚\nMR ç¼ºé™· MR çš„ç¼ºé™·å®é™…ä¸Šåœ¨ Google I/O ä¸Šå·²ç»è¯´æ˜äº†ï¼Œå¦‚ä¸‹:\nToday at Google I/O, we are demonstrating Google Cloud Dataflow for the first time. Cloud Dataflow is a fully managed service for creating data pipelines that ingest, transform and analyze data in both batch and streaming modes. Cloud Dataflow is a successor to MapReduce, and is based on our internal technologies like Flume and MillWheel.[2]\nMRæ˜¯ä¸€ä¸ªåŸºäº batch mode çš„æ¡†æ¶ã€‚ ç”¨ MR å†™å¤æ‚çš„åˆ†æ pipeline å¤ªéº»çƒ¦ã€‚ åœ¨å¾ˆå¤šæƒ…å†µä¸‹ï¼Œä¸€æ¬¡ MR æ‰§è¡Œæ˜¯æ²¡æ³•æŠŠäº‹æƒ…åšå®Œçš„ï¼Œéœ€è¦å¾ˆå¤šä¸ª MR ä»»åŠ¡äº’ç›¸ç»„åˆï¼Œè¿™å°±æ˜¯ MR pipeline. åœ¨æ•°æ®æµå¤æ‚çš„åˆ†æä»»åŠ¡ä¸­ï¼Œè®¾è®¡å¥½çš„ pipeline è¾¾åˆ°æœ€é«˜è¿è¡Œæ•ˆç‡å¾ˆå›°éš¾ã€‚\nMR æœ€å¤§çš„è´¡çŒ®æˆ‘è®¤ä¸ºå°±æ˜¯ scalability å’Œ fault toleranceã€‚åœ¨ MillWheel é‡Œï¼Œç»“æœå¯ä»¥éšç€æ•°æ®æµçš„è¾“å…¥å®æ—¶çš„æ˜¾ç¤ºå‡ºæ¥ï¼Œè€Œä¸æ˜¯åˆ°æ•°æ®æµç»“æŸæ—¶æ‰è¾“å‡ºä¸€ä¸ªç»“æœï¼Œè€Œä¸”è¿™æ ·ä¸­é—´ç»“æœä¸éœ€è¦ä¿å­˜ä¸‹æ¥ã€‚\nMR Lab in MIT6.824 Check the lab-mr page here\nåœ¨æœ¬å®éªŒä¸­ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ª MapReduce ç³»ç»Ÿã€‚ æˆ‘ä»¬å°†å®ç°ä¸€ä¸ªè°ƒç”¨åº”ç”¨ç¨‹åº Map å’Œ Reduce å‡½æ•°å¹¶å¤„ç†è¯»å†™æ–‡ä»¶çš„ç¨‹åºï¼Œä»¥åŠä¸€ä¸ªå°†ä»»åŠ¡åˆ†å‘ç»™ Worker å¹¶å¤„ç†å¤±è´¥çš„ Worker çš„è¿›ç¨‹(Master)ã€‚åœ¨ MR å®éªŒä¸­ï¼Œä½¿ç”¨ Golang æ¥ç¼–ç å®ç°ã€‚\næˆ‘çš„å®ç°åœ¨ WSL Ubuntu20.04 ä¸Š goç‰ˆæœ¬ 1.18ã€‚\nè¿™æ¬¡çš„è¦æ±‚è²Œä¼¼æ¯”ä»¥å‰æ›´éš¾äº†ï¼Œè¿™æ¬¡éœ€è¦ Worker ä¸»åŠ¨å‘ Master è¯·æ±‚ä»»åŠ¡ï¼Œå½“ä»»åŠ¡è¶…æ—¶åï¼Œéœ€è¦ Master æ¥é‡æ–°åˆ†é…è¿™ä¸ªä»»åŠ¡ã€‚\næ€»ä½“æ€è·¯å…¶å®ä¹Ÿéå¸¸çš„ç®€å•ï¼Œworker å’Œ coordinator çš„äº¤äº’éƒ½å›´ç»•ç€ RPC å±•å¼€ï¼Œæ•…å…ˆä» RPC çš„å®šä¹‰å¼€å§‹ã€‚å› ä¸ºæ·±å—äº‹ä»¶è½®è¯¢ç¼–ç¨‹æ¨¡å¼çš„\u0026rsquo;è¼æ¯’\u0026rsquo;ï¼Œæˆ‘æŠŠ worker å’Œ coordinator ä¹‹é—´çš„äº¤äº’è¿‡ç¨‹ä»¥äº‹ä»¶çš„å½¢å¼æ¥è¿›è¡Œå¤„ç†ã€‚é¦–å…ˆå®šä¹‰äº‹ä»¶çš„ç±»å‹ã€‚\n// src/mr/rpc.go type TaskTp = int const ( TpRequireTask = iota TpMapTaskDone TpReduceTaskDone TpSendMapTask TpSendReduceTask TpTaskAllDone TpWait ) å†æ¥è€ƒè™‘ RPC éœ€è¦åœ¨ worker å’Œ coordinator ä¸­ä¼ é€’ä»€ä¹ˆä¿¡æ¯ï¼Ÿä¸è®ºä½•ç§ä¿¡æ¯ï¼Œé¦–å…ˆéƒ½éœ€è¦ä¸€ä¸ªæ—¶é—´æˆ³æ¥è®°å½• require å’Œ reply å¯¹ã€‚å…¶æ¬¡æ¯ä¸ª worker éƒ½éœ€è¦çŸ¥é“ä¸€å…±æœ‰å¤šå°‘ä¸ª Map å’Œ Reduce ä»»åŠ¡ã€‚æ¯ä¸ª require éœ€è¦è·Ÿä¸Šå½“å‰ worker çš„ä»»åŠ¡ç¼–å·ã€‚å½“ç„¶ï¼Œå› ä¸ºæ˜¯äº‹ä»¶é©±åŠ¨çš„è§’åº¦ç¼–å†™çš„ï¼Œæ‰€ä»¥æ¯æ¡ require å’Œ reply éƒ½éœ€è¦æœ‰ä¸€ä¸ªäº‹ä»¶ç±»å‹è®°å½•ã€‚\n// src/mr/rpc.go type RequireMsg struct { Stamp int64 MsgFlag TaskTp TaskID int } type ReplyMsg struct { Stamp int64 MsgFlag TaskTp TaskID int NumReduceWorkers int NumMapWorkers int Content string } å¯¹äº coordinatorï¼Œå…¶ä½œç”¨åƒæ˜¯ä¸€ä¸ªçŠ¶æ€æœºï¼Œéœ€è¦ç»´æŠ¤æ‰€æœ‰çš„ worker çš„çŠ¶æ€ï¼Œå¹¶èƒ½åšåˆ°å›é€€(Fault Tolerance)ã€‚Coordinator çš„å®šä¹‰å¦‚ä¸‹\n// src/mr/coordinator.go type Coordinator struct { nMapWorkers int nReduceWorkers int nMapWorking int nReduceWorking int MapWorkerState []int64 ReduceWorkerState []int64 FilesContent []string MapWorkerPool chan int ReduceWorkerPool chan int IsDone bool GlobalLock *sync.Cond // to make sure the rpc visit is atomic. } coordinator éœ€è¦å¤„ç† RPC çš„è¯·æ±‚ï¼Œå¯¹äºä¸åŒçš„äº‹ä»¶è¿›è¡Œååº”ã€‚å› ä¸ºéœ€è¦è¶…æ—¶å¤„ç†ï¼Œæ‰€ä»¥åœ¨è¿™é‡Œï¼Œæ¯ä¸€ä¸ª worker éƒ½ä¼šæœ‰ä¸€ä¸ªåç¨‹æ¥è¿›è¡Œç›¸åº”çš„è®¡æ—¶å’Œ id å›æ”¶ã€‚\n// src/mr/coordinator.go func (c *Coordinator) ProcessEvents(args *RequireMsg, reply *ReplyMsg) error { c.GlobalLock.L.Lock() tmpBool := c.IsDone c.GlobalLock.L.Unlock() if tmpBool { reply.MsgFlag = TpTaskAllDone reply.Stamp = args.Stamp return nil } switch args.MsgFlag { case TpMapTaskDone: c.GlobalLock.L.Lock() if c.MapWorkerState[args.TaskID] == args.Stamp { c.MapWorkerState[args.TaskID] = 1 c.nMapWorking-- } c.GlobalLock.L.Unlock() case TpReduceTaskDone: c.GlobalLock.L.Lock() if c.ReduceWorkerState[args.TaskID] == args.Stamp { c.ReduceWorkerState[args.TaskID] = 1 c.nReduceWorking-- } if c.nReduceWorking == 0 { c.IsDone = true } c.GlobalLock.L.Unlock() case TpRequireTask: if len(c.MapWorkerPool) \u0026gt; 0 { // State 1. Send Map Task to worker. reply.Stamp = args.Stamp reply.TaskID = \u0026lt;-c.MapWorkerPool reply.MsgFlag = TpSendMapTask reply.NumMapWorkers = c.nMapWorkers reply.NumReduceWorkers = c.nReduceWorkers reply.Content = c.FilesContent[reply.TaskID] c.GlobalLock.L.Lock() c.MapWorkerState[reply.TaskID] = args.Stamp c.GlobalLock.L.Unlock() go func(id int) { time.Sleep(10 * time.Second) c.GlobalLock.L.Lock() if c.MapWorkerState[id] != 1 { // run out of 10 secs. recycle this id to id pool. c.MapWorkerPool \u0026lt;- id } c.GlobalLock.L.Unlock() }(reply.TaskID) return nil } else { c.GlobalLock.L.Lock() nMapOnWorking := c.nMapWorking nReduceOnWorking := c.nReduceWorking c.GlobalLock.L.Unlock() // State 2. All map worker is on working. wait. if nMapOnWorking != 0 { reply.Stamp = args.Stamp reply.TaskID = -1 reply.MsgFlag = TpWait reply.Content = \u0026#34;Just Wait !!! Map Worker !!!\u0026#34; reply.NumMapWorkers = c.nMapWorkers reply.NumReduceWorkers = c.nReduceWorkers } else { // State 3. Map is Done. Send Reduce task to works. if len(c.ReduceWorkerPool) \u0026gt; 0 { reply.Stamp = args.Stamp reply.TaskID = \u0026lt;-c.ReduceWorkerPool reply.MsgFlag = TpSendReduceTask reply.Content = \u0026#34;Reduce no need to handle this\u0026#34; reply.NumMapWorkers = c.nMapWorkers reply.NumReduceWorkers = c.nReduceWorkers c.GlobalLock.L.Lock() c.ReduceWorkerState[reply.TaskID] = args.Stamp c.GlobalLock.L.Unlock() go func(id int) { time.Sleep(10 * time.Second) c.GlobalLock.L.Lock() if c.ReduceWorkerState[id] != 1 { // run out of 10 secs. resolved this id to id pool. c.ReduceWorkerPool \u0026lt;- id } c.GlobalLock.L.Unlock() }(reply.TaskID) } else { // State 4. All reduce worker is on working. wait. if nReduceOnWorking != 0 { reply.Stamp = args.Stamp reply.TaskID = -1 reply.MsgFlag = TpWait reply.Content = \u0026#34;Just Wait !!! Reduce Worker !!!\u0026#34; reply.NumMapWorkers = c.nMapWorkers reply.NumReduceWorkers = c.nReduceWorkers } } } } default: return nil } return nil } åŒæ ·çš„ï¼Œåœ¨ worker ä¸­çš„æµç¨‹ä¹Ÿæ˜¯ä¸æ–­çš„å¾ªç¯äº§ç”Ÿäº‹ä»¶ï¼Œå¤„ç†äº‹ä»¶\n// src/mr/worker.go func Worker(mapf func(string, string) []KeyValue, reducef func(string, []string) string) { for true { ThisStamp := time.Now().Unix() Req := RequireMsg{} Req.Stamp = ThisStamp Req.MsgFlag = TpRequireTask Req.TaskID = -1 Rep := ReplyMsg{} ok := call(\u0026#34;Coordinator.ProcessEvents\u0026#34;, \u0026amp;Req, \u0026amp;Rep) if ok \u0026amp;\u0026amp; Rep.Stamp == Req.Stamp { switch Rep.MsgFlag { case TpSendMapTask: doMap(mapf, \u0026amp;Rep) case TpSendReduceTask: doReduce(reducef, \u0026amp;Rep) case TpWait: time.Sleep(time.Second) case TpTaskAllDone: return default: return } } } return } doMap(mapf, \u0026amp;Rep) å’Œ doReduce(reducef, \u0026amp;Rep) å°±æ˜¯éå¸¸ç®€å•çš„é€»è¾‘ç¼–å†™äº†ã€‚Mapéœ€è¦æŠŠæ–‡ä»¶åˆ†æ‹†åˆ°N=numReduceå—ä¸­ï¼Œæ€»å…±äº§ç”ŸN * M(reduce num, map num)å—æ–‡ä»¶ã€‚Reduce workerä»è‡ªå·±å¯¹åº”çš„ç¼–å·ä¸­å–å‡ºMå—è¿›è¡Œæ’åºå’Œåˆå¹¶ã€‚\nç»“æœé¡ºåˆ©é€šè¿‡ï¼Œæ²¡æœ‰è¿‡å¤šçš„å»¶è¿Ÿ(å› ä¸º10sçš„åˆ¤æ–­)äº§ç”Ÿã€‚\nFig 2. test mr Reference [1] \u0026ldquo;MapReduce: Simplified Data Processing on Large Clusters\u0026rdquo; googleusercontent.com.\n[2] Google cloud blog about MapReduce\u0026rsquo;s successor\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/papers/mapreduce/","summary":"OSDI'04: 6th Symposium on Operating Systems Design and Implementation\ngo back to home\nPaper link\nä»€ä¹ˆæ˜¯ MapReduce åœ¨MapReduceåŸæ–‡ä¸­æ˜¯è¿™ä¹ˆè¯´çš„\nMapReduce is a programming model and an associated implementation for processing and generating large data sets. [1]\nè¿™æ˜¯ä¸€ä¸ªè¾ƒä¸ºç®€å•çš„å¤„ç†å¤§å‹é—®é¢˜çš„åˆ†å¸ƒå¼ç¼–ç¨‹æ¨¡å‹ã€‚å…¶äº§ç”Ÿçš„åŸå› æ˜¯å› ä¸º google æƒ³è¦è®©æ™®é€šçš„ç¨‹åºå‘˜ä¹Ÿèƒ½å¤Ÿé€šè¿‡ä¸€å¥—ç®€å•çš„ç¼–ç¨‹æ¨¡å‹æ¥ç¼–å†™åˆ†å¸ƒå¼åº”ç”¨ç¨‹åºï¼Œä»¥æ­¤æ¥å¤„ç† google å†…éƒ¨çš„å¤§æ•°æ®ã€‚ç„¶åè‘—åçš„ Jeff Dean å’Œ Sanjay Ghemawat å‡ºé©¬æå®šäº†è¿™ä¸ªé—®é¢˜(åœ¨çŸ¥ä¹ä¸Šå…³äºJeff Deançš„è½¶äº‹:-))ã€‚MapReduce åœ¨ google å†…éƒ¨è¿è¡Œå¾ˆé•¿çš„æ—¶é—´å¹¶ä¸”å¤„ç†äº†å¾ˆå¤šä¸šåŠ¡ï¼Œä½†æ˜¯ç›®å‰ä¹Ÿè´¥ä¸‹é˜µæ¥ï¼Œå…·ä½“åŸå› å‚è§ MapReduce ç¼ºé™·ç« èŠ‚(MRæ—©åœ¨2004å¹´å°±å‡ºæ¥äº†ï¼Œå…¶å®æ˜¯å¤æ—©çš„æŠ€æœ¯äº†ï¼Œå…¶æ²¡æœ‰åœ¨æ€§èƒ½ä¸Šåšæ–‡ç« ï¼Œä¸»è¦åœ¨å¯æ‰©å±•æ€§ä¸Š)ã€‚\nMapReduce çš„è®¾è®¡æ¡†æ¶å’ŒåŸºæœ¬æµç¨‹ MRå®é™…ä¸Šæ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„æ¡†æ¶ï¼Œæ€è·¯ä¹Ÿéå¸¸çš„ç›´ç™½ã€‚MapReduce èƒŒåçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ•°æ®é›†æ˜ å°„åˆ°ä¸€ä¸ª \u0026lt;key, value\u0026gt; pairçš„é›†åˆä¸­ï¼Œç„¶åä½¿ç”¨ç›¸åŒçš„é”®å¯¹æ‰€æœ‰pairè¿›è¡Œæ•´åˆã€‚ æ•´ä½“æ¦‚å¿µå¾ˆç®€å•ï¼Œä½†æ˜¯å¦‚æœä½ è®¾æƒ³ä¸‹ä¸‹é¢çš„æƒ…å†µï¼ŒMRå®é™…ä¸Šéå¸¸æœ‰ç”¨: åŸºæœ¬ä¸Šæ‰€æœ‰çš„æ•°æ®éƒ½èƒ½è¢«æ˜ å°„åˆ°ä¸€ä¸ª \u0026lt;key, value\u0026gt; å¯¹ä¸­ï¼Œå¹¶ä¸”keyå’Œvalueå¯ä»¥æ˜¯ä»»æ„ç±»å‹ã€‚\nåœ¨è®ºæ–‡ä¸­MRä½¿ç”¨çš„æ ·ä¾‹æ˜¯åœ¨è¶…å¤§çš„æ–‡ä»¶é‡Œåšå•è¯ç»Ÿè®¡ã€‚è¿™ä¸ªæ¡†æ¶è¿˜å¯ä»¥ç”¨æ¥åšï¼š\nåˆ†å¸ƒå¼çš„æ’åº åˆ†å¸ƒå¼çš„æœç´¢ Webé“¾æ¥å›¾éå† \u0026hellip; Fig 1.","title":"MapReduce"},{"content":"","permalink":"https://chenghuawang.github.io/keep-moving-forward/about/news/","summary":"","title":"ğŸ‰NewsğŸ‰"},{"content":"HiğŸ‘‹, I\u0026rsquo;m Chenghua Wang, currently a postgraduate CS student at BUPT.\nI\u0026rsquo;m interested in AI\u0026amp;Sys. I\u0026rsquo;ve struggled for almost one and half years on computer vision(Dehazing, Multi-label classification. July 1 2021 -\u0026gt; Dec 31 2022) contact me: chenghua.wang.edu@gmail.com\nResearch Interests Machine Learning Infrastructure\nML Compiler NNCV(ZJGSU, BS dissertation), it contains an Aten-lang auto-parallel language(using Polyhedra Algorithms) and a set of deep learning compilation pipelines(Based on MLIR). Distributed and Parallel System Design Computer Vision\nlow-level tasks(ZJGSU, Image dehazing) multi-label multi-class classification object detection Research Experience Multimedia And Computer Vision Laboratory, ZJGSU. July 1 2021 -\u0026gt; Dec 31 2022. Image Dehazing Medical Image Processing(Palm-print, multi-class multi-label classification) Projects [Projects(click to expand)]\rnncv\nNeural Network inference\u0026amp;compile toolchain for Computer Vision.\nA Project of my BS dissertation\nAn Aten language support Polyhedral model for CPU(X86 with AVX2) target. A small pipeline which use tiling and vectorization method to optimize model from torch. Support X86(with AVX2) and partial Tensor Core instruction. using command below to compile a model from torch:\n$nncv-c -target HostWParallel -split-params res18.mlir -o optimized.mlir call from C++ side:\n#include \u0026#34;libnncv/DataType.hpp\u0026#34; #include \u0026#34;libnncv/SystemIo.hpp\u0026#34; using namespace nncv::rt; MemRefFlatArray params(dataType::kFloat32); params.read(\u0026#34;model.bin\u0026#34;) optimized_res18_forward(/*dst*/..., /*src*/..., params.get()); mgloria\nA Matrix lib based on SIMD and expression template(Lazy Compute). On CPU/GPU. Currently, GPU functionality is not fully implemented\n#include \u0026#34;mgloria/core.hpp\u0026#34; inline void __test_tensor_basic_OP__() { using namespace mgloria; InitTensorComputeMachine\u0026lt;CPU\u0026gt;(0); struct ReLU { MGLORIA_INLINE_NORMAL static float Do(float t) { if (t \u0026gt; 0.f) return t; return 0.f; } }; auto __stream__ = NewStream\u0026lt;CPU\u0026gt;(0); Tensor\u0026lt;CPU, 3\u0026gt; A = NewTensor(makeShape3d(2, 3, 5), true, 2.f, true, __stream__); Tensor\u0026lt;CPU, 3\u0026gt; B = NewTensor(makeShape3d(2, 3, 5), true, 1.f, true, __stream__); Tensor\u0026lt;CPU, 3\u0026gt; C = NewTensor(makeShape3d(2, 3, 5), true, 5.f, true, __stream__); A = B + C; // A = expr::implicit_dot(B, C); A = expr::Func\u0026lt;ReLU\u0026gt;(A); std::cout \u0026lt;\u0026lt; A; std::cout \u0026lt;\u0026lt; B; std::cout \u0026lt;\u0026lt; C; FreeStream(__stream__); ShutdownTensorComputeMachine\u0026lt;CPU\u0026gt;(0); } covalent bond\nA tool for managing distributed database, gathering/cleaning data, etc. covalentBond(cb) using Op graph concept to allow users to easily build query logic and data manipulation logic. We took a lot of inspiration from torch and bound most of cb\u0026rsquo;s operators in lua, making it very easy for users to construct and overload the basic behavior of graphs. This project is for 2022-2023 Fall, SE lecture.\ndaydream engine\nA render lib. Compatible with ShaderToy, can switch between 2d and 3d rendering modes. For 2022-2023 Fall, CG lecture. This lib is shown as a 3d editor below(this editor is also a part of daydream lib):\nkeep-moving-forward\nSome notes of papars I read, and some tech report. Including topics: Distributed system, Machine learning system(compiler), HPC, AI\nimage-dehazing-the-end\nA tech report of my image dehazing research from Jan 1 2022 to Dec 31 2022\npic 1(a) real-world id=3\rpic 1(b) dehazed id=3\rpic 2(a) real-world id=5\rpic 2(b) dehazed id=5 pic 3(a) real-world id=104\rpic 3(b) dehazed id=104 pic 4(a) real-world id=8\rpic 4(b) dehazed id=8 pic 5(a) real-world id=12\rpic 5(b) dehazed id=12 Languages \u0026amp; Skills Languages used: c, c++, python, golang, asm(x86, risc-v), cuda, glsl, lua, dart\nSkills: MLIR, pytorch, paddlepaddle, opencv, opengl, mysql, redis, flutter, nginx, django\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/about/about/","summary":"HiğŸ‘‹, I\u0026rsquo;m Chenghua Wang, currently a postgraduate CS student at BUPT.\nI\u0026rsquo;m interested in AI\u0026amp;Sys. I\u0026rsquo;ve struggled for almost one and half years on computer vision(Dehazing, Multi-label classification. July 1 2021 -\u0026gt; Dec 31 2022) contact me: chenghua.wang.edu@gmail.com\nResearch Interests Machine Learning Infrastructure\nML Compiler NNCV(ZJGSU, BS dissertation), it contains an Aten-lang auto-parallel language(using Polyhedra Algorithms) and a set of deep learning compilation pipelines(Based on MLIR). Distributed and Parallel System Design Computer Vision","title":"About"},{"content":" æœ¬æ–‡è¿˜æ²¡å®Œæˆä¿®æ”¹ã€‚\n1. å‰ç½®çŸ¥è¯† å¯¹äºå‰ç½®çŸ¥è¯†ï¼Œé»˜è®¤å·²ç»é€šè¿‡äº† MIT 6.S081 å³ä»¥ä¸Šéš¾åº¦çš„ OS è¯¾ç¨‹å†ç»ƒï¼›æœ‰ Deep Learning æ–¹é¢çš„è¯¾ç¨‹åŸºç¡€æˆ–è€…ç§‘ç ”ç»å†ï¼›åœ¨ä½“ç³»ç»“æ„ä¸Šæœ‰ä¸€å®šçš„äº†è§£(ä» CSAPP åˆ°è®¡ç»„å­¦å®Œ)ã€‚å¯¹äº C++ ç¼–ç¨‹è¾ƒä¸ºç†Ÿç»ƒï¼Œèƒ½å¤Ÿä½¿ç”¨ CMake æ„å»ºä¸­å‹é¡¹ç›®ï¼›èƒ½å¤Ÿä½¿ç”¨ Pybindï¼Œå¯¹äº Python é«˜çº§ç¼–ç¨‹è¾ƒä¸ºç†Ÿç»ƒã€‚åœ¨ç¼–è¯‘å·¥å…·é“¾(Clang, LLVM) ä¸Šæœ‰ä¸€å®šçš„äº†è§£ï¼Œèƒ½å¤Ÿä½¿ç”¨ã€‚å¯¹ CUDA ç¼–ç¨‹æ¨¡å‹æœ‰äº†è§£ï¼Œä¸è¦æ±‚ä½¿ç”¨ã€‚\n1.1 Courses 1.1.1 CMU15418 Parallel computing Note: 2023 çš„è§†é¢‘æ²¡æœ‰å…¬å¼€ï¼Œç›®å‰èƒ½å¤Ÿæ‰¾åˆ°çš„æœ€æ–°çš„è§†é¢‘æ˜¯ 2018 å¹´çš„ï¼Œè¿™ä¸ªé¢†åŸŸå‘å±•è¾ƒå¿«ï¼Œåˆæ¬¡å…¥é—¨è¿˜æ˜¯é€‰æ‹© CS267ã€‚\nSpring 2023 Homepage\nå¹¶è¡Œè®¡ç®—å…¥é—¨è¯¾ç¨‹ï¼ŒLab å·¥ä½œé‡éå¸¸çš„å·¨å¤§ã€‚æ¶‰åŠç°ä»£å¤šå¤„ç†å™¨ï¼ŒSIMDï¼Œåˆ†å¸ƒå¼é€šè®¯åè®®MPIï¼ŒGPUåŠ é€ŸCUDAç¼–ç¨‹ï¼Œå¼‚æ„è®¡ç®—ï¼ŒåŒæ­¥ï¼ŒCacheï¼Œç­‰ã€‚\n1.1.2 UCB CS267 Applications of Parallel Computers Spring 2022 Homepage\n1.1.3 Stanford 143: Compilers Homepage\nç°åœ¨æœ‰å¾ˆå¤šçš„è‡ªåŠ¨å¹¶è¡Œåšæ³•æƒ³è¦ä½¿ç”¨ç¼–è¯‘æŠ€æœ¯æ¥ç»Ÿä¸€çš„ç”Ÿæˆè°ƒåº¦ä»£ç å’Œä¼˜åŒ–åçš„ kernelï¼Œç¼–è¯‘æŠ€æœ¯æ˜¯å€¼å¾—å­¦ä¹ çš„ã€‚ä½†æ˜¯è¿™é—¨è¯¾æ˜¯ä¼ ç»Ÿç¼–è¯‘ï¼Œå’Œ MLIR é‚£ä¸€å¥—çš„åç«¯æ˜¯æœ‰å…±æ€§ä½†æ˜¯ä¸æ˜¯ä¸€è‡´çš„ï¼Œå»ºè®®åªçœ‹ç¼–è¯‘å‰ç«¯éƒ¨åˆ†ï¼Œåç«¯éƒ¨åˆ†å¯ä»¥è¾ƒä¸ºç®€ç•¥çš„æ¥çœ‹ã€‚\n1.2 Tools 1.2.1 CUDA 2023-04-18, CUDA: NSight System, link 2. Machine Learning System 2023-05-02, æµ…ææœºå™¨å­¦ä¹ ä¸­çš„å¹¶è¡Œæ¨¡å‹å’Œè‡ªåŠ¨å¹¶è¡Œæ–¹æ³•, link ","permalink":"https://chenghuawang.github.io/keep-moving-forward/about/hpc_ai/","summary":"æœ¬æ–‡è¿˜æ²¡å®Œæˆä¿®æ”¹ã€‚\n1. å‰ç½®çŸ¥è¯† å¯¹äºå‰ç½®çŸ¥è¯†ï¼Œé»˜è®¤å·²ç»é€šè¿‡äº† MIT 6.S081 å³ä»¥ä¸Šéš¾åº¦çš„ OS è¯¾ç¨‹å†ç»ƒï¼›æœ‰ Deep Learning æ–¹é¢çš„è¯¾ç¨‹åŸºç¡€æˆ–è€…ç§‘ç ”ç»å†ï¼›åœ¨ä½“ç³»ç»“æ„ä¸Šæœ‰ä¸€å®šçš„äº†è§£(ä» CSAPP åˆ°è®¡ç»„å­¦å®Œ)ã€‚å¯¹äº C++ ç¼–ç¨‹è¾ƒä¸ºç†Ÿç»ƒï¼Œèƒ½å¤Ÿä½¿ç”¨ CMake æ„å»ºä¸­å‹é¡¹ç›®ï¼›èƒ½å¤Ÿä½¿ç”¨ Pybindï¼Œå¯¹äº Python é«˜çº§ç¼–ç¨‹è¾ƒä¸ºç†Ÿç»ƒã€‚åœ¨ç¼–è¯‘å·¥å…·é“¾(Clang, LLVM) ä¸Šæœ‰ä¸€å®šçš„äº†è§£ï¼Œèƒ½å¤Ÿä½¿ç”¨ã€‚å¯¹ CUDA ç¼–ç¨‹æ¨¡å‹æœ‰äº†è§£ï¼Œä¸è¦æ±‚ä½¿ç”¨ã€‚\n1.1 Courses 1.1.1 CMU15418 Parallel computing Note: 2023 çš„è§†é¢‘æ²¡æœ‰å…¬å¼€ï¼Œç›®å‰èƒ½å¤Ÿæ‰¾åˆ°çš„æœ€æ–°çš„è§†é¢‘æ˜¯ 2018 å¹´çš„ï¼Œè¿™ä¸ªé¢†åŸŸå‘å±•è¾ƒå¿«ï¼Œåˆæ¬¡å…¥é—¨è¿˜æ˜¯é€‰æ‹© CS267ã€‚\nSpring 2023 Homepage\nå¹¶è¡Œè®¡ç®—å…¥é—¨è¯¾ç¨‹ï¼ŒLab å·¥ä½œé‡éå¸¸çš„å·¨å¤§ã€‚æ¶‰åŠç°ä»£å¤šå¤„ç†å™¨ï¼ŒSIMDï¼Œåˆ†å¸ƒå¼é€šè®¯åè®®MPIï¼ŒGPUåŠ é€ŸCUDAç¼–ç¨‹ï¼Œå¼‚æ„è®¡ç®—ï¼ŒåŒæ­¥ï¼ŒCacheï¼Œç­‰ã€‚\n1.1.2 UCB CS267 Applications of Parallel Computers Spring 2022 Homepage\n1.1.3 Stanford 143: Compilers Homepage\nç°åœ¨æœ‰å¾ˆå¤šçš„è‡ªåŠ¨å¹¶è¡Œåšæ³•æƒ³è¦ä½¿ç”¨ç¼–è¯‘æŠ€æœ¯æ¥ç»Ÿä¸€çš„ç”Ÿæˆè°ƒåº¦ä»£ç å’Œä¼˜åŒ–åçš„ kernelï¼Œç¼–è¯‘æŠ€æœ¯æ˜¯å€¼å¾—å­¦ä¹ çš„ã€‚ä½†æ˜¯è¿™é—¨è¯¾æ˜¯ä¼ ç»Ÿç¼–è¯‘ï¼Œå’Œ MLIR é‚£ä¸€å¥—çš„åç«¯æ˜¯æœ‰å…±æ€§ä½†æ˜¯ä¸æ˜¯ä¸€è‡´çš„ï¼Œå»ºè®®åªçœ‹ç¼–è¯‘å‰ç«¯éƒ¨åˆ†ï¼Œåç«¯éƒ¨åˆ†å¯ä»¥è¾ƒä¸ºç®€ç•¥çš„æ¥çœ‹ã€‚\n1.2 Tools 1.2.1 CUDA 2023-04-18, CUDA: NSight System, link 2.","title":"AI \u0026 Sys å…¥é—¨"},{"content":"Fundamental 2024-08-10, [Fundamental]From Online Softmax to Flash Attention V3 2024-08-11, [Fundamental] æ—‹è½¬ä½ç½®ç¼–ç (RoPE) Distributed System 2023-01-17, MapReduce\n2023-01-18, Google File System(GFS)\n2023-01-19, The Design of a Practical System for Fault-Tolerant Virtual Machines\nMLSys 2024 2024-05-25, âœ…[April 2024] AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration\nBest Paperï¼Œé‡åŒ–\n2024-06-21, âœ…[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference\nprompt cacheä¼˜åŒ–\n2024-06-25, âœ…[Oct 2023] QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models\nMoEé‡åŒ–\nArxiv 2024-06-17, âœ…[Mar 2024] Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs\nè¾¹ç¼˜Transformeréƒ¨ç½²ä¼˜åŒ– from OPPO\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/about/paper_posts/","summary":"Fundamental 2024-08-10, [Fundamental]From Online Softmax to Flash Attention V3 2024-08-11, [Fundamental] æ—‹è½¬ä½ç½®ç¼–ç (RoPE) Distributed System 2023-01-17, MapReduce\n2023-01-18, Google File System(GFS)\n2023-01-19, The Design of a Practical System for Fault-Tolerant Virtual Machines\nMLSys 2024 2024-05-25, âœ…[April 2024] AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration\nBest Paperï¼Œé‡åŒ–\n2024-06-21, âœ…[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference\nprompt cacheä¼˜åŒ–\n2024-06-25, âœ…[Oct 2023] QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models","title":"Paper Posts"},{"content":"Fundamental 2024-08-10, [Fundamental]From Online Softmax to Flash Attention V3 2024-08-11, [Fundamental] æ—‹è½¬ä½ç½®ç¼–ç (RoPE) MIT6.S081, XV6 Lab 2023-02-23, XV6 lab 1 Utilities 2023-02-25, XV6 lab 2 syscall 2023-03-02, XV6 lab 3 page table 2023-03-12, XV6 lab 4 traps 2023-03-17, XV6 lab 5 copy on write Tools 2023-04-18, CUDA: NSight System Parallel 2023-05-02, æµ…ææœºå™¨å­¦ä¹ ä¸­çš„å¹¶è¡Œæ¨¡å‹å’Œè‡ªåŠ¨å¹¶è¡Œæ–¹æ³• Framework 2024-06-28, mllmæ¡†æ¶æµ…æ-ä»¥QWen0.5Bä¸ºä¾‹ ","permalink":"https://chenghuawang.github.io/keep-moving-forward/about/tech_posts/","summary":"Fundamental 2024-08-10, [Fundamental]From Online Softmax to Flash Attention V3 2024-08-11, [Fundamental] æ—‹è½¬ä½ç½®ç¼–ç (RoPE) MIT6.S081, XV6 Lab 2023-02-23, XV6 lab 1 Utilities 2023-02-25, XV6 lab 2 syscall 2023-03-02, XV6 lab 3 page table 2023-03-12, XV6 lab 4 traps 2023-03-17, XV6 lab 5 copy on write Tools 2023-04-18, CUDA: NSight System Parallel 2023-05-02, æµ…ææœºå™¨å­¦ä¹ ä¸­çš„å¹¶è¡Œæ¨¡å‹å’Œè‡ªåŠ¨å¹¶è¡Œæ–¹æ³• Framework 2024-06-28, mllmæ¡†æ¶æµ…æ-ä»¥QWen0.5Bä¸ºä¾‹ ","title":"Tech Posts"},{"content":" ç›®å‰å¤´è„‘è¿˜æ˜¯ä¸€ç‰‡è’èŠœ\n","permalink":"https://chenghuawang.github.io/keep-moving-forward/about/thingking/","summary":"ç›®å‰å¤´è„‘è¿˜æ˜¯ä¸€ç‰‡è’èŠœ","title":"æ€è€ƒ"}]