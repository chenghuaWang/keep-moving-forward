<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Papers on Ubios Home</title>
    <link>https://chenghuawang.github.io/keep-moving-forward/papers/</link>
    <description>Recent content in Papers on Ubios Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 14 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://chenghuawang.github.io/keep-moving-forward/papers/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>【施工中】[Notes] The Deep Learning Compiler: A Comprehensive Survey</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/papers/dl_compiler_survey/</link>
      <pubDate>Wed, 14 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/papers/dl_compiler_survey/</guid>
      <description>Looking back for Looking forward这篇笔记记录了 Deep Learning Compiler Survey 1 的一些内容。因为文章是 2020 年发的，MLSys 这个领域最近发展的非常快速，我也会在文中补充一点内容，补充内容都会用 bullet 块指出。
简介
在不同的深度学习硬件上部署各种深度学习模型的困难，促进了社区内深度学习编译器的研究和开发。工业界和学术界都提出了一些深度学习编译器，如 Tensorflow XLA 和 TVM。同样，深度学习编译器将不同深度学习框架中描述的深度学习模型作为输入，然后为不同的深度学习硬件生成特定的优化代码作为输出。然而，现有的综述都没有全面地分析深度学习编译器的独特设计架构。在本文中，作者们对现有的深度学习编译器进行了全面的调查，详细剖析了普遍采用的设计，重点是面向深度学习的多级IR，以及前端/后端优化。作者对多级 IR 的设计进行了详细的分析，并说明了普遍采用的优化技术。最后，作者强调了深度学习编译器的几个潜在研究方向。这是第一篇关注深度学习编译器设计架构的综述论文，希望它能为未来的深度学习编译器研究铺平道路。
1. 介绍 深度学习(DL)的发展已经对各个科学领域产生了深远的影响。它不仅在人工智能，如自然语言处理(NLP) 2 和计算机视觉(CV) 3 中表现出令人惊讶的价值，而且在更广泛的领域也取得了巨大成功。诸如电子商务 4 、智能城市 5 和药物探索 6 等更广泛的应用中取得了巨大成功。随着多种类的深度学习模型出现，如卷积神经网络(CNN) 7 、递归神经网络(RNN) 8 、长短时记忆网络(LSTM) 9 和生成对抗网络(GAN) 10 ，深度学习进一步成为一种时代的趋势。为了能够使它们被广泛应用，简化各种深度学习模型是至关重要的。
随着工业界和学术界的不断努力，几个流行的深度学习框架已被提出，如 TensorFlow 11 、PyTorch 12 、MXNet 13 和 CNTK 14 ，这些框架简化了深度学习模型的实现。尽管每个框架因为自生的设计做了一些 tradeoffs，这使得每个框架都各有优劣。但在支持新兴的深度学习模型和现有的深度学习模型时，互操作性对于减少冗余的工作量变得非常重要。为了提供互操作性，ONNX 15 被提出，它定义了一个深度学习模型的统一格式，以促进不同DL框架之间的模型转换。
补充:
虽然 ONNX 的描述非常的美好，但是还是有非常多的不足。且不论其两个版本的 API 适配问题。ONNX 因为要适配不同框架的算子设计会把算子拆的非常的细，这导致最终出来的计算图可能是非常庞大的，这又需要引入 simplifier 去简化计算图。作为中间表示，我认为还是用 MLIR 这种通用 IR 来表示比较好，毕竟可以复用很多的东西。当然 ONNX 目前还是比较流行的方法。</description>
    </item>
    
    <item>
      <title>The Design of a Practical System for Fault-Tolerant Virtual Machines</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/papers/ft-vm/</link>
      <pubDate>Thu, 19 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/papers/ft-vm/</guid>
      <description>go back to home
Paper link
ACM SIGOPS Operating Systems Review, 2010, 44(4): 30-39.
Last Edit: Jan 19, 2023
Introduction 是的，这节内容还是 FT(fault-tolerance)。现在做 FT 主要有两种手段[2]：
State transfer Primary用来执行所有的任务，Primary发送该机器的所有状态(所有的内存变动，所有的磁盘变动，等)给Replica。State Transfer 虽然听起来非常的简单(实际上做起来也是的，相对于Replicated state machine)，但是需要占用非常大量的网络带宽来实现。
尽管如此(占用大量的网络资源，导致传输缓慢)，State Transfer是对多处理器友好的一种方式，而Replicated state machine则不是。
Replicated state machine Client 向 Primary 发送操作和数据(inputs)。Primary把这些操作和数据发送给Replicas，Replicas和Primary都会执行这些指令，都会受到这些数据(inputs)，所有的指令都以同样的顺序执行，只要Primary和Replicas初始的状态是一致的，那么二者就一直保持着同步(也意味着deterministic)。
在并行化的应用中，State transfer 是首选，毕竟在并行的时候，并行顺序对于Replicated state machine来说是异常难同步的。
主从复制时的挑战[2]：
要复制什么状态 primary需要等待backup吗 什么时候需要切换到backup 切换的时候异常情况是否能看到 如何提高创建新backup的速度 VM-FT使用的就是Replicated state machine的方法。为了能够捕获数据，并且做出一些软件中断，Primary和Backup都是在VM上运行的，由hypervisor来管理他们。
Arch VM-FT 总体的结构较为简单，论文中是一主一从的结构。VM-FT主要依赖于 Deterministic replay(确定性重放)。VM-FT 通过确定性重放来产生相关的日志条目，但不将日志写入磁盘，而是通过 logging channel 发送给backup(这里指备用机)。backup实时重放日志项。
因为一切都是在 logging channel 上做同步的。为了容错，必须在 logging channel 上实现严格的容错协议，有以下要求：</description>
    </item>
    
    <item>
      <title>Google File System(GFS)</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/papers/gfs/</link>
      <pubDate>Wed, 18 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/papers/gfs/</guid>
      <description>go back to home
Paper link
Proceedings of the 19th ACM Symposium on Operating Systems Principles, ACM, Bolton Landing, NY (2003), pp. 20-43
Last Edit: Jan 18, 2023
GFS 有非常多的东西，这里只写了一些重要的部分。像是snapshot，文件删除，高可用机制，Replica管理等没有具体提及。
Introduction GFS是google提出的一个可扩展分布式文件系统，为大型分布式数据密集型应用提供服务。可以在大规模的消费级机器集群上提供不错的容错能力。GFS在设计的时候主要依据6个假设(观察得出的):
节点失效经常发生。系统由非常多的消费级机器组成，大量用户同时进行访问，这使得节点很容易因为程序bug、磁盘故障、内存故障等原因失效。 存储以大文件为主。每个文件通常100MB或几GB。系统需要支持小文件，但不需要对其进行特殊的优化。 大容量连续读，小容量随机读取是文件系统中的常态。 写入也已大容量为主，小容量无需特殊优化。 支持原子的文件追加操作。使得大量用户可以并行追加文件，而不需要额外的加锁机制。 高吞吐量比低延时更重要 为什么设计一个优秀的分布式存储系统非常的困难:
Performance. 当数据量非常大的时候，数据分片(Sharding)是非常重要的。 Fault Tolerance. 但是由于数据在多台服务器上分片。由于多台服务器，整个系统出现故障的概率会大很多。因此需要容错机制 Replication. 复制数据副本到多台服务器上，但是为了用户能够拿到一致的数据，需要考虑一致性 Consistency. 为了一致性，不得不使用网络(极慢的数据交互方式)进行确认和同步。这又会影响性能(Performance)!!! 世界因此变成了一个美妙的环。:-)。这也是分布式的挑战之处。
GFS讨论了上述的这些主题和在实际生产场景中的应用。
Architecture Fig 1. GFS Arch[1] 一个GFS集群由一个Master节点和若干个Chunk Server节点组成。每个Chunk Server可以被许多个Client访问。GFS Chunk Server作为用户级进程在Linux服务器中运行，并且文件系统本身使用的就是Linux系统的那套。(所以文中说，没有特地的为GFS Chunk Server加入cache功能，因为Linux文件系统已经干了这件事)
Chunk: GFS中的文件在存储的时候会被分割成多个Chunk，每个Chunk的大小为64MB。在Chunk分配的时候，Master会分配一个Handle给Chunk，类似于指针。Chunk在google的实现中，使用3份副本。
Master: 维护元数据，记录文件被分割为哪些Chunk、以及这些Chunk的存储位置；它还负责Chunk的迁移、重新平衡(rebalancing)和垃圾回收；此外，Master通过心跳机制与ChunkServer通信，向其传递指令(是的，也是通过心跳机制)，并收集状态；
Client: 首先向Master询问该文件的Chunk在哪里，Chunk Server位置，再从 Chunk Server获取数据。Client并不会每次都向Master发送数据进行询问，它会cache一部分的数据(不是Chunk的，是某个文件对应的Chunk Server的位置，即Chunk的地址)，并且保持一定的时间。</description>
    </item>
    
    <item>
      <title>MapReduce</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/papers/mapreduce/</link>
      <pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/papers/mapreduce/</guid>
      <description>OSDI&#39;04: 6th Symposium on Operating Systems Design and Implementation
go back to home
Paper link
什么是 MapReduce 在MapReduce原文中是这么说的
MapReduce is a programming model and an associated implementation for processing and generating large data sets. [1]
这是一个较为简单的处理大型问题的分布式编程模型。其产生的原因是因为 google 想要让普通的程序员也能够通过一套简单的编程模型来编写分布式应用程序，以此来处理 google 内部的大数据。然后著名的 Jeff Dean 和 Sanjay Ghemawat 出马搞定了这个问题(在知乎上关于Jeff Dean的轶事:-))。MapReduce 在 google 内部运行很长的时间并且处理了很多业务，但是目前也败下阵来，具体原因参见 MapReduce 缺陷章节(MR早在2004年就出来了，其实是古早的技术了，其没有在性能上做文章，主要在可扩展性上)。
MapReduce 的设计框架和基本流程 MR实际上是一个非常简单的框架，思路也非常的直白。MapReduce 背后的核心思想是将数据集映射到一个 &amp;lt;key, value&amp;gt; pair的集合中，然后使用相同的键对所有pair进行整合。 整体概念很简单，但是如果你设想下下面的情况，MR实际上非常有用: 基本上所有的数据都能被映射到一个 &amp;lt;key, value&amp;gt; 对中，并且key和value可以是任意类型。
在论文中MR使用的样例是在超大的文件里做单词统计。这个框架还可以用来做：
分布式的排序 分布式的搜索 Web链接图遍历 &amp;hellip; Fig 1.</description>
    </item>
    
  </channel>
</rss>
