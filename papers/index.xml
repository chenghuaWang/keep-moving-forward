<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Papers on Ubios Home</title>
    <link>https://chenghuawang.github.io/keep-moving-forward/papers/</link>
    <description>Recent content in Papers on Ubios Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 14 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://chenghuawang.github.io/keep-moving-forward/papers/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[Notes] The Deep Learning Compiler: A Comprehensive Survey</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/papers/dl_compiler_survey/</link>
      <pubDate>Wed, 14 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/papers/dl_compiler_survey/</guid>
      <description>Looking back for Looking forward这篇笔记记录了 Deep Learning Compiler Survey 1 的一些内容。因为文章是 2020 年发的，MLSys 这个领域最近发展的非常快速，我也会在文中补充一点内容，补充内容都会用 bullet 块指出。
简介
1. 介绍 2. 相关工作 2.1 深度学习框架 2.2 深度学习硬件 3. 主流的深度学习编译器的设计 4. 深度学习编译器的主要模块 4.1 High-Level IR 4.2 Low-Level IR 4.3 前端优化 4.4 后端优化 5. 深度学习编译器的分类 6. 验证 7. 总结和未来方向的讨论 Li M, Liu Y, Liu X, et al. The deep learning compiler: A comprehensive survey[J]. IEEE Transactions on Parallel and Distributed Systems, 2020, 32(3): 708-727.</description>
    </item>
    
    <item>
      <title>The Design of a Practical System for Fault-Tolerant Virtual Machines</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/papers/ft-vm/</link>
      <pubDate>Thu, 19 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/papers/ft-vm/</guid>
      <description>go back to home
Paper link
ACM SIGOPS Operating Systems Review, 2010, 44(4): 30-39.
Last Edit: Jan 19, 2023
Introduction 是的，这节内容还是 FT(fault-tolerance)。现在做 FT 主要有两种手段[2]：
State transfer Primary用来执行所有的任务，Primary发送该机器的所有状态(所有的内存变动，所有的磁盘变动，等)给Replica。State Transfer 虽然听起来非常的简单(实际上做起来也是的，相对于Replicated state machine)，但是需要占用非常大量的网络带宽来实现。
尽管如此(占用大量的网络资源，导致传输缓慢)，State Transfer是对多处理器友好的一种方式，而Replicated state machine则不是。
Replicated state machine Client 向 Primary 发送操作和数据(inputs)。Primary把这些操作和数据发送给Replicas，Replicas和Primary都会执行这些指令，都会受到这些数据(inputs)，所有的指令都以同样的顺序执行，只要Primary和Replicas初始的状态是一致的，那么二者就一直保持着同步(也意味着deterministic)。
在并行化的应用中，State transfer 是首选，毕竟在并行的时候，并行顺序对于Replicated state machine来说是异常难同步的。
主从复制时的挑战[2]：
要复制什么状态 primary需要等待backup吗 什么时候需要切换到backup 切换的时候异常情况是否能看到 如何提高创建新backup的速度 VM-FT使用的就是Replicated state machine的方法。为了能够捕获数据，并且做出一些软件中断，Primary和Backup都是在VM上运行的，由hypervisor来管理他们。
Arch VM-FT 总体的结构较为简单，论文中是一主一从的结构。VM-FT主要依赖于 Deterministic replay(确定性重放)。VM-FT 通过确定性重放来产生相关的日志条目，但不将日志写入磁盘，而是通过 logging channel 发送给backup(这里指备用机)。backup实时重放日志项。
因为一切都是在 logging channel 上做同步的。为了容错，必须在 logging channel 上实现严格的容错协议，有以下要求：</description>
    </item>
    
    <item>
      <title>Google File System(GFS)</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/papers/gfs/</link>
      <pubDate>Wed, 18 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/papers/gfs/</guid>
      <description>go back to home
Paper link
Proceedings of the 19th ACM Symposium on Operating Systems Principles, ACM, Bolton Landing, NY (2003), pp. 20-43
Last Edit: Jan 18, 2023
GFS 有非常多的东西，这里只写了一些重要的部分。像是snapshot，文件删除，高可用机制，Replica管理等没有具体提及。
Introduction GFS是google提出的一个可扩展分布式文件系统，为大型分布式数据密集型应用提供服务。可以在大规模的消费级机器集群上提供不错的容错能力。GFS在设计的时候主要依据6个假设(观察得出的):
节点失效经常发生。系统由非常多的消费级机器组成，大量用户同时进行访问，这使得节点很容易因为程序bug、磁盘故障、内存故障等原因失效。 存储以大文件为主。每个文件通常100MB或几GB。系统需要支持小文件，但不需要对其进行特殊的优化。 大容量连续读，小容量随机读取是文件系统中的常态。 写入也已大容量为主，小容量无需特殊优化。 支持原子的文件追加操作。使得大量用户可以并行追加文件，而不需要额外的加锁机制。 高吞吐量比低延时更重要 为什么设计一个优秀的分布式存储系统非常的困难:
Performance. 当数据量非常大的时候，数据分片(Sharding)是非常重要的。 Fault Tolerance. 但是由于数据在多台服务器上分片。由于多台服务器，整个系统出现故障的概率会大很多。因此需要容错机制 Replication. 复制数据副本到多台服务器上，但是为了用户能够拿到一致的数据，需要考虑一致性 Consistency. 为了一致性，不得不使用网络(极慢的数据交互方式)进行确认和同步。这又会影响性能(Performance)!!! 世界因此变成了一个美妙的环。:-)。这也是分布式的挑战之处。
GFS讨论了上述的这些主题和在实际生产场景中的应用。
Architecture Fig 1. GFS Arch[1] 一个GFS集群由一个Master节点和若干个Chunk Server节点组成。每个Chunk Server可以被许多个Client访问。GFS Chunk Server作为用户级进程在Linux服务器中运行，并且文件系统本身使用的就是Linux系统的那套。(所以文中说，没有特地的为GFS Chunk Server加入cache功能，因为Linux文件系统已经干了这件事)
Chunk: GFS中的文件在存储的时候会被分割成多个Chunk，每个Chunk的大小为64MB。在Chunk分配的时候，Master会分配一个Handle给Chunk，类似于指针。Chunk在google的实现中，使用3份副本。
Master: 维护元数据，记录文件被分割为哪些Chunk、以及这些Chunk的存储位置；它还负责Chunk的迁移、重新平衡(rebalancing)和垃圾回收；此外，Master通过心跳机制与ChunkServer通信，向其传递指令(是的，也是通过心跳机制)，并收集状态；
Client: 首先向Master询问该文件的Chunk在哪里，Chunk Server位置，再从 Chunk Server获取数据。Client并不会每次都向Master发送数据进行询问，它会cache一部分的数据(不是Chunk的，是某个文件对应的Chunk Server的位置，即Chunk的地址)，并且保持一定的时间。</description>
    </item>
    
    <item>
      <title>MapReduce</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/papers/mapreduce/</link>
      <pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/papers/mapreduce/</guid>
      <description>OSDI&#39;04: 6th Symposium on Operating Systems Design and Implementation
go back to home
Paper link
什么是 MapReduce 在MapReduce原文中是这么说的
MapReduce is a programming model and an associated implementation for processing and generating large data sets. [1]
这是一个较为简单的处理大型问题的分布式编程模型。其产生的原因是因为 google 想要让普通的程序员也能够通过一套简单的编程模型来编写分布式应用程序，以此来处理 google 内部的大数据。然后著名的 Jeff Dean 和 Sanjay Ghemawat 出马搞定了这个问题(在知乎上关于Jeff Dean的轶事:-))。MapReduce 在 google 内部运行很长的时间并且处理了很多业务，但是目前也败下阵来，具体原因参见 MapReduce 缺陷章节(MR早在2004年就出来了，其实是古早的技术了，其没有在性能上做文章，主要在可扩展性上)。
MapReduce 的设计框架和基本流程 MR实际上是一个非常简单的框架，思路也非常的直白。MapReduce 背后的核心思想是将数据集映射到一个 &amp;lt;key, value&amp;gt; pair的集合中，然后使用相同的键对所有pair进行整合。 整体概念很简单，但是如果你设想下下面的情况，MR实际上非常有用: 基本上所有的数据都能被映射到一个 &amp;lt;key, value&amp;gt; 对中，并且key和value可以是任意类型。
在论文中MR使用的样例是在超大的文件里做单词统计。这个框架还可以用来做：
分布式的排序 分布式的搜索 Web链接图遍历 &amp;hellip; Fig 1.</description>
    </item>
    
  </channel>
</rss>
