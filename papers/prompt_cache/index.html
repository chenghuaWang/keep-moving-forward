<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>‚úÖ[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference - Ubios Home</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="‚úÖ[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference" />
<meta property="og:description" content="ËÉåÊôØÂíåÂä®Êú∫ ‰ª•KV Cache‰∏∫ÂêØÂèëÔºåÊé¢Á¥¢‰∫ÜÂØπtime-to-first-token (TTFT) LatencyÁöÑ‰ºòÂåñ„ÄÇÁ±ª‰ºº‰∫éKV CacheÔºåPrompt Cache(PC)Êé®ÁêÜÂä†ÈÄüÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂ§çÁî®Ê≥®ÊÑèÂäõÁöÑ‰∏≠Èó¥Áä∂ÊÄÅ(Attention States)„ÄÇÁÑ∂ËÄå‰∏éKV Cache‰∏çÂêåÁöÑÊòØÔºåPCÊòØÂú®‰∏çÂêåÁöÑprompt‰πãÈó¥ËøõË°åÂ§çÁî®„ÄÇ
Âú®Â§ßÈÉ®ÂàÜÁöÑLLM‰ªªÂä°‰∏≠ÔºåpromptÊúâÈáçÂè†(overlapping)ÁöÑÁé∞Ë±°ÔºåËøô‰∫õÈáçÂè†ÁöÑpromptÂèØ‰ª•Ë¢´Â≠òÂÇ®Ëµ∑Êù•ÔºåËøõËÄåÂú®Êé•‰∏ãÊù•ÁöÑLLMÂ§ÑÁêÜÈò∂ÊÆµÂèØ‰ª•ÂÉèKV Cache‰∏ÄÊ†∑ÔºåÊèêÂèñÂá∫Êù•Áõ¥Êé•‰ΩøÁî®„ÄÇÂú®TTFTÁöÑÊé®ÁêÜËøáÁ®ã‰∏≠ÔºåÂÖçÂéªËÆ°ÁÆó‰∏çÂêåprompt‰∏≠ÈáçÂè†ÈÉ®ÂàÜÁöÑÊ≥®ÊÑèÂäõÁä∂ÊÄÅÔºå‰ªéËÄåÁº©Áü≠TTFTÁöÑÁîüÊàêÊó∂Èó¥„ÄÇ
‰∏éKV Cache‰∏çÂêåÁöÑÁÇπÊòØÔºö
Áõ∏ÂêåÁöÑÊñáÊú¨ÊÆµÂèØËÉΩÂá∫Áé∞Âú®‰∏çÂêåpromptÁöÑ‰∏çÂêå‰ΩçÁΩÆÔºåÂ¶Ç‰ΩïÂØπÂÆÉ‰ª¨ÁöÑAttention StatesËøõË°åÂ§çÁî®„ÄÇÂõ†‰∏∫‰∏çÂêå‰ΩçÁΩÆÁöÑÊñáÊú¨ÊÆµÁöÑPosition EncodingËøõÂéªÁöÑÂÄºÊòØ‰∏ç‰∏ÄÊ†∑ÁöÑ„ÄÇÂú®KV Cache‰∏≠‰∏çÈúÄË¶ÅËÄÉËôëËøô‰∏ÄÁÇπÔºåÂõ†‰∏∫cacheÊòØ‰ªéÂâçÂæÄÂêéÁ∫øÊÄßÂ¢ûÈïøÁöÑÔºå‰ΩÜPromptÊâÄÂú®ÁöÑ‰ΩçÁΩÆÊòØ‰∏çÁ°ÆÂÆöÁöÑ„ÄÇ Â¶Ç‰Ωï‰ªé‰∏çÂêåÁöÑprompt‰∏≠ËØÜÂà´Âá∫Â∑≤ÁªèÁºìÂ≠òËøáÁöÑÊñáÊú¨„ÄÇ ÁÆóÊ≥ï ÂÆûÈ™åÁªèÈ™å ‰∏ÄÊÆµpromptÁöÑPositionÂÄº‰∏çËøûÁª≠Ê≤°ÊúâÂÖ≥Á≥ª„ÄÇÂè™Ë¶ÅËøô‰∏ÄÊÆµpromptÊú¨Ë∫´ÁöÑPositionÂÄºÊòØËøûÁª≠ÁöÑÂ∞±Ë°å„ÄÇÊÑèÊÄùÊòØÈÉ®ÂàÜËøûÁª≠ÂØπ‰∫éLLMÂ∞±Â§ü‰∫ÜÔºå‰∏ç‰∏ÄÂÆöË¶ÅÂÆåÂÖ®ËøûÁª≠„ÄÇËØ∑Ê≥®ÊÑèÔºöËøôÊòØ‰∏Ä‰∏™ÂÆûÈ™åÊÄßÈ™åËØÅÁöÑÁªìËÆ∫„ÄÇ
Prompt Schema Fig 1. Prompt Schema‰ΩúËÄÖÂõ¢ÈòüÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Prompt Markup Language(PML)„ÄÇ‰∏äÂõæ‰∏≠ÁöÑ‰æãÂ≠êÊúâÔºöÂèØ‰ª•Â§çÁî®ÁöÑmoduleÂíå‰∏çËÉΩÂ§çÁî®ÁöÑÂ°´ÂÖÖÈÉ®ÂàÜÔºåÂ°´ÂÖÖÈÉ®ÂàÜÈúÄË¶ÅÁî®ParamÊåáÂá∫ÔºåÂπ∂ÁªôÂá∫ÈïøÂ∫¶„ÄÇPrompt Attention States‰∏≠ÁöÑÁ∫¢Ëâ≤ÈÉ®ÂàÜÊòØÂèØ‰ª•Ë¢´Â§çÁî®ÁöÑÂå∫Âüü„ÄÇFig 2. ÂéüÂßãLLM/KV Cache/Prompt CacheÊàë‰ª¨Êù•ÂØπÊØî‰∏ãÊôÆÈÄöÁöÑËá™ÂõûÂΩíLLM„ÄÅ‰ΩøÁî®‰∫ÜKV CacheÁöÑLLMÂíå‰ΩøÁî®‰∫ÜPrompt CacheÁöÑLLM„ÄÇÊôÆÈÄöÁöÑLLMÊØèÊ¨°ÈÉΩË¶ÅÈÄöËøáËæìÂÖ•ÁöÑPromptÊù•È¢ÑÊµãÂá∫‰∏ã‰∏Ä‰∏™TokenÔºåPromptÊòØÂÖ®ÈáèÁöÑËÆ°ÁÆó„ÄÇ‰ΩøÁî®‰∫ÜKV CacheÁöÑLLMÔºåÊØèÊ¨°TokenÈ¢ÑÊµã‰∏çÁî®ÂÖ®ÈáèËÆ°ÁÆó‰∫ÜÔºåÂèØ‰ª•‰ΩøÁî®‰∏äÊ¨°AttentionÁöÑ‰∏≠Èó¥ÁªìÊûú„ÄÇËÄå‰ΩøÁî®‰∫ÜPrompt CacheÁöÑLLMÔºåÂú®ÂêéÊúüÈ¢ÑÊµãTokenÁöÑËøáÁ®ãÂíåÂéüÊù•ÁöÑKV CacheÊ≤°Êúâ‰ªÄ‰πàÂå∫Âà´„ÄÇ‰∏ªË¶ÅÂå∫Âà´ÊòØÂú®‰∏ÄÂºÄÂßãÁöÑPromptËæìÂÖ•ÁöÑÈò∂ÊÆµÔºåPrompt Cache‰∏≠Â∏∏Áî®ÁöÑPrompt Attention StatesÂèØ‰ª•Ë¢´Âà©Áî®Ëµ∑Êù•ÔºåËøô‰ºöÊûÅÂ§ßÁöÑÁº©ÂáèÁ¨¨‰∏Ä‰∏™TokenËæìÂá∫ÁöÑÊó∂Èó¥„ÄÇ Prompt SchemaÊúâÂæàÂ§öÁöÑÁªÜËäÇÔºåËøôÈáåÂè™ËÆ≤Â§ßËá¥ÁöÑÊÄùË∑ØÔºåÂÖ∑‰ΩìÁöÑËØ∑ÁúãÊñáÁ´†Âíå‰ª£Á†Å‰ªìÂ∫ì„ÄÇ
ÊàëÂØπmoduleÊÄé‰πàÂ§çÁî®‰∏çÊòØÂæàÁêÜËß£ÔºåÂ∫îËØ•ÊòØÈÄöËøáÂ∞ÜÊñáÊú¨ÂÜÖÂÆπËøõË°åsha256ÁºñÁ†ÅÊù•ÂØπÂÖ∂ËøõË°åËØÜÂà´„ÄÇ
Êú¨Êñá‰∏ªË¶ÅÊòØÂØπÈ¶ñTokenËæìÂá∫Êó∂Èó¥ÁöÑ‰ºòÂåñÔºåÂØπ‰∫éÁî®Êà∑Êù•ËØ¥ÂèØ‰ª•ÊúâÊõ¥Â•ΩÁöÑ‰ΩìÈ™å„ÄÇË¶ÅÊòØËÉΩÂÅö‰∏™ÂÖ®Â±ÄÁöÑPrompt CacheÊï∞ÊçÆÂ∫ìÔºåÂ∫îËØ•ÂèØ‰ª•ÁªôÂ§ßËßÑÊ®°ÁöÑLLM InferÁ≥ªÁªüÂ∏¶Êù•‰∏çÂ∞ëÁöÑÂ•ΩÂ§Ñ„ÄÇ" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chenghuawang.github.io/keep-moving-forward/papers/prompt_cache/" /><meta property="article:section" content="Papers" />
<meta property="article:published_time" content="2024-06-21T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-06-21T00:00:00+00:00" />

		<meta itemprop="name" content="‚úÖ[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference">
<meta itemprop="description" content="ËÉåÊôØÂíåÂä®Êú∫ ‰ª•KV Cache‰∏∫ÂêØÂèëÔºåÊé¢Á¥¢‰∫ÜÂØπtime-to-first-token (TTFT) LatencyÁöÑ‰ºòÂåñ„ÄÇÁ±ª‰ºº‰∫éKV CacheÔºåPrompt Cache(PC)Êé®ÁêÜÂä†ÈÄüÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂ§çÁî®Ê≥®ÊÑèÂäõÁöÑ‰∏≠Èó¥Áä∂ÊÄÅ(Attention States)„ÄÇÁÑ∂ËÄå‰∏éKV Cache‰∏çÂêåÁöÑÊòØÔºåPCÊòØÂú®‰∏çÂêåÁöÑprompt‰πãÈó¥ËøõË°åÂ§çÁî®„ÄÇ
Âú®Â§ßÈÉ®ÂàÜÁöÑLLM‰ªªÂä°‰∏≠ÔºåpromptÊúâÈáçÂè†(overlapping)ÁöÑÁé∞Ë±°ÔºåËøô‰∫õÈáçÂè†ÁöÑpromptÂèØ‰ª•Ë¢´Â≠òÂÇ®Ëµ∑Êù•ÔºåËøõËÄåÂú®Êé•‰∏ãÊù•ÁöÑLLMÂ§ÑÁêÜÈò∂ÊÆµÂèØ‰ª•ÂÉèKV Cache‰∏ÄÊ†∑ÔºåÊèêÂèñÂá∫Êù•Áõ¥Êé•‰ΩøÁî®„ÄÇÂú®TTFTÁöÑÊé®ÁêÜËøáÁ®ã‰∏≠ÔºåÂÖçÂéªËÆ°ÁÆó‰∏çÂêåprompt‰∏≠ÈáçÂè†ÈÉ®ÂàÜÁöÑÊ≥®ÊÑèÂäõÁä∂ÊÄÅÔºå‰ªéËÄåÁº©Áü≠TTFTÁöÑÁîüÊàêÊó∂Èó¥„ÄÇ
‰∏éKV Cache‰∏çÂêåÁöÑÁÇπÊòØÔºö
Áõ∏ÂêåÁöÑÊñáÊú¨ÊÆµÂèØËÉΩÂá∫Áé∞Âú®‰∏çÂêåpromptÁöÑ‰∏çÂêå‰ΩçÁΩÆÔºåÂ¶Ç‰ΩïÂØπÂÆÉ‰ª¨ÁöÑAttention StatesËøõË°åÂ§çÁî®„ÄÇÂõ†‰∏∫‰∏çÂêå‰ΩçÁΩÆÁöÑÊñáÊú¨ÊÆµÁöÑPosition EncodingËøõÂéªÁöÑÂÄºÊòØ‰∏ç‰∏ÄÊ†∑ÁöÑ„ÄÇÂú®KV Cache‰∏≠‰∏çÈúÄË¶ÅËÄÉËôëËøô‰∏ÄÁÇπÔºåÂõ†‰∏∫cacheÊòØ‰ªéÂâçÂæÄÂêéÁ∫øÊÄßÂ¢ûÈïøÁöÑÔºå‰ΩÜPromptÊâÄÂú®ÁöÑ‰ΩçÁΩÆÊòØ‰∏çÁ°ÆÂÆöÁöÑ„ÄÇ Â¶Ç‰Ωï‰ªé‰∏çÂêåÁöÑprompt‰∏≠ËØÜÂà´Âá∫Â∑≤ÁªèÁºìÂ≠òËøáÁöÑÊñáÊú¨„ÄÇ ÁÆóÊ≥ï ÂÆûÈ™åÁªèÈ™å ‰∏ÄÊÆµpromptÁöÑPositionÂÄº‰∏çËøûÁª≠Ê≤°ÊúâÂÖ≥Á≥ª„ÄÇÂè™Ë¶ÅËøô‰∏ÄÊÆµpromptÊú¨Ë∫´ÁöÑPositionÂÄºÊòØËøûÁª≠ÁöÑÂ∞±Ë°å„ÄÇÊÑèÊÄùÊòØÈÉ®ÂàÜËøûÁª≠ÂØπ‰∫éLLMÂ∞±Â§ü‰∫ÜÔºå‰∏ç‰∏ÄÂÆöË¶ÅÂÆåÂÖ®ËøûÁª≠„ÄÇËØ∑Ê≥®ÊÑèÔºöËøôÊòØ‰∏Ä‰∏™ÂÆûÈ™åÊÄßÈ™åËØÅÁöÑÁªìËÆ∫„ÄÇ
Prompt Schema Fig 1. Prompt Schema‰ΩúËÄÖÂõ¢ÈòüÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Prompt Markup Language(PML)„ÄÇ‰∏äÂõæ‰∏≠ÁöÑ‰æãÂ≠êÊúâÔºöÂèØ‰ª•Â§çÁî®ÁöÑmoduleÂíå‰∏çËÉΩÂ§çÁî®ÁöÑÂ°´ÂÖÖÈÉ®ÂàÜÔºåÂ°´ÂÖÖÈÉ®ÂàÜÈúÄË¶ÅÁî®ParamÊåáÂá∫ÔºåÂπ∂ÁªôÂá∫ÈïøÂ∫¶„ÄÇPrompt Attention States‰∏≠ÁöÑÁ∫¢Ëâ≤ÈÉ®ÂàÜÊòØÂèØ‰ª•Ë¢´Â§çÁî®ÁöÑÂå∫Âüü„ÄÇFig 2. ÂéüÂßãLLM/KV Cache/Prompt CacheÊàë‰ª¨Êù•ÂØπÊØî‰∏ãÊôÆÈÄöÁöÑËá™ÂõûÂΩíLLM„ÄÅ‰ΩøÁî®‰∫ÜKV CacheÁöÑLLMÂíå‰ΩøÁî®‰∫ÜPrompt CacheÁöÑLLM„ÄÇÊôÆÈÄöÁöÑLLMÊØèÊ¨°ÈÉΩË¶ÅÈÄöËøáËæìÂÖ•ÁöÑPromptÊù•È¢ÑÊµãÂá∫‰∏ã‰∏Ä‰∏™TokenÔºåPromptÊòØÂÖ®ÈáèÁöÑËÆ°ÁÆó„ÄÇ‰ΩøÁî®‰∫ÜKV CacheÁöÑLLMÔºåÊØèÊ¨°TokenÈ¢ÑÊµã‰∏çÁî®ÂÖ®ÈáèËÆ°ÁÆó‰∫ÜÔºåÂèØ‰ª•‰ΩøÁî®‰∏äÊ¨°AttentionÁöÑ‰∏≠Èó¥ÁªìÊûú„ÄÇËÄå‰ΩøÁî®‰∫ÜPrompt CacheÁöÑLLMÔºåÂú®ÂêéÊúüÈ¢ÑÊµãTokenÁöÑËøáÁ®ãÂíåÂéüÊù•ÁöÑKV CacheÊ≤°Êúâ‰ªÄ‰πàÂå∫Âà´„ÄÇ‰∏ªË¶ÅÂå∫Âà´ÊòØÂú®‰∏ÄÂºÄÂßãÁöÑPromptËæìÂÖ•ÁöÑÈò∂ÊÆµÔºåPrompt Cache‰∏≠Â∏∏Áî®ÁöÑPrompt Attention StatesÂèØ‰ª•Ë¢´Âà©Áî®Ëµ∑Êù•ÔºåËøô‰ºöÊûÅÂ§ßÁöÑÁº©ÂáèÁ¨¨‰∏Ä‰∏™TokenËæìÂá∫ÁöÑÊó∂Èó¥„ÄÇ Prompt SchemaÊúâÂæàÂ§öÁöÑÁªÜËäÇÔºåËøôÈáåÂè™ËÆ≤Â§ßËá¥ÁöÑÊÄùË∑ØÔºåÂÖ∑‰ΩìÁöÑËØ∑ÁúãÊñáÁ´†Âíå‰ª£Á†Å‰ªìÂ∫ì„ÄÇ
ÊàëÂØπmoduleÊÄé‰πàÂ§çÁî®‰∏çÊòØÂæàÁêÜËß£ÔºåÂ∫îËØ•ÊòØÈÄöËøáÂ∞ÜÊñáÊú¨ÂÜÖÂÆπËøõË°åsha256ÁºñÁ†ÅÊù•ÂØπÂÖ∂ËøõË°åËØÜÂà´„ÄÇ
Êú¨Êñá‰∏ªË¶ÅÊòØÂØπÈ¶ñTokenËæìÂá∫Êó∂Èó¥ÁöÑ‰ºòÂåñÔºåÂØπ‰∫éÁî®Êà∑Êù•ËØ¥ÂèØ‰ª•ÊúâÊõ¥Â•ΩÁöÑ‰ΩìÈ™å„ÄÇË¶ÅÊòØËÉΩÂÅö‰∏™ÂÖ®Â±ÄÁöÑPrompt CacheÊï∞ÊçÆÂ∫ìÔºåÂ∫îËØ•ÂèØ‰ª•ÁªôÂ§ßËßÑÊ®°ÁöÑLLM InferÁ≥ªÁªüÂ∏¶Êù•‰∏çÂ∞ëÁöÑÂ•ΩÂ§Ñ„ÄÇ"><meta itemprop="datePublished" content="2024-06-21T00:00:00+00:00" />
<meta itemprop="dateModified" content="2024-06-21T00:00:00+00:00" />
<meta itemprop="wordCount" content="52">
<meta itemprop="keywords" content="LLM Server,LLM Cache Optimize,LLM,MLSys 2024," />
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+SC:400,700">

	<link rel="stylesheet" href="/keep-moving-forward/css/style.css">
	

	<link rel="shortcut icon" href="/keep-moving-forward/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		
<header class="header">
	<div class="container header__container">
		
	<div class="logo logo--mixed" >
		<a class="logo__link" href="/keep-moving-forward/" title="Ubios Home" rel="home" >
			
			<div class="logo__item logo__text" >
					<div class="logo__title" >Ubios Home</div>
					<div class="logo__tagline">Remember brick walls let us show our dedication. They are there to separate us from the people who don&#39;t really want to achieve their childhood dreams. --Randy Pausch</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/about/">
				
				<span class="menu__text">About</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/hpc_ai/">
				
				<span class="menu__text">HPC &amp; AI ÂÖ•Âùë</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/lecture_notes/">
				
				<span class="menu__text">Lecture-Notes</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/paper_posts/">
				
				<span class="menu__text">Paper-Notes</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/tech_posts/">
				
				<span class="menu__text">Tech-Posts</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/thinking/">
				
				<span class="menu__text">Thinking</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/news/">
				
				<span class="menu__text">üéâNewsüéâ</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			


<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">‚úÖ[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference</h1>
			<p class="post__lead">MLSys 2024 Prompt Cache</p>
			<div class="post__meta meta"><div class="meta__item-author meta__item">
	<svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2 0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class="meta__text">chenghua.wang</span>
</div>
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2024-06-21T00:00:00Z">2024-06-21</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/keep-moving-forward/categories/aisys/" rel="category">AI&amp;Sys</a>
	</span>
</div></div>
		</header>

		
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li><a href="#ËÉåÊôØÂíåÂä®Êú∫">ËÉåÊôØÂíåÂä®Êú∫</a></li>
    <li><a href="#ÁÆóÊ≥ï">ÁÆóÊ≥ï</a>
      <ul>
        <li><a href="#ÂÆûÈ™åÁªèÈ™å">ÂÆûÈ™åÁªèÈ™å</a></li>
        <li><a href="#prompt-schema">Prompt Schema</a></li>
      </ul>
    </li>
  </ul>
</nav>
	</div>
</div><div class="content post__content clearfix">
			<h1 id="ËÉåÊôØÂíåÂä®Êú∫">ËÉåÊôØÂíåÂä®Êú∫</h1>
<p>‰ª•KV Cache‰∏∫ÂêØÂèëÔºåÊé¢Á¥¢‰∫ÜÂØπtime-to-first-token (TTFT) LatencyÁöÑ‰ºòÂåñ„ÄÇÁ±ª‰ºº‰∫éKV CacheÔºåPrompt Cache(PC)Êé®ÁêÜÂä†ÈÄüÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂ§çÁî®Ê≥®ÊÑèÂäõÁöÑ‰∏≠Èó¥Áä∂ÊÄÅ(Attention States)„ÄÇÁÑ∂ËÄå‰∏éKV Cache‰∏çÂêåÁöÑÊòØÔºåPCÊòØÂú®‰∏çÂêåÁöÑprompt‰πãÈó¥ËøõË°åÂ§çÁî®„ÄÇ</p>
<p>Âú®Â§ßÈÉ®ÂàÜÁöÑLLM‰ªªÂä°‰∏≠ÔºåpromptÊúâÈáçÂè†(overlapping)ÁöÑÁé∞Ë±°ÔºåËøô‰∫õÈáçÂè†ÁöÑpromptÂèØ‰ª•Ë¢´Â≠òÂÇ®Ëµ∑Êù•ÔºåËøõËÄåÂú®Êé•‰∏ãÊù•ÁöÑLLMÂ§ÑÁêÜÈò∂ÊÆµÂèØ‰ª•ÂÉèKV Cache‰∏ÄÊ†∑ÔºåÊèêÂèñÂá∫Êù•Áõ¥Êé•‰ΩøÁî®„ÄÇÂú®TTFTÁöÑÊé®ÁêÜËøáÁ®ã‰∏≠ÔºåÂÖçÂéªËÆ°ÁÆó‰∏çÂêåprompt‰∏≠ÈáçÂè†ÈÉ®ÂàÜÁöÑÊ≥®ÊÑèÂäõÁä∂ÊÄÅÔºå‰ªéËÄåÁº©Áü≠TTFTÁöÑÁîüÊàêÊó∂Èó¥„ÄÇ</p>
<p>‰∏éKV Cache‰∏çÂêåÁöÑÁÇπÊòØÔºö</p>
<ol>
<li>Áõ∏ÂêåÁöÑÊñáÊú¨ÊÆµÂèØËÉΩÂá∫Áé∞Âú®‰∏çÂêåpromptÁöÑ‰∏çÂêå‰ΩçÁΩÆÔºåÂ¶Ç‰ΩïÂØπÂÆÉ‰ª¨ÁöÑAttention StatesËøõË°åÂ§çÁî®„ÄÇÂõ†‰∏∫‰∏çÂêå‰ΩçÁΩÆÁöÑÊñáÊú¨ÊÆµÁöÑPosition EncodingËøõÂéªÁöÑÂÄºÊòØ‰∏ç‰∏ÄÊ†∑ÁöÑ„ÄÇÂú®KV Cache‰∏≠‰∏çÈúÄË¶ÅËÄÉËôëËøô‰∏ÄÁÇπÔºåÂõ†‰∏∫cacheÊòØ‰ªéÂâçÂæÄÂêéÁ∫øÊÄßÂ¢ûÈïøÁöÑÔºå‰ΩÜPromptÊâÄÂú®ÁöÑ‰ΩçÁΩÆÊòØ‰∏çÁ°ÆÂÆöÁöÑ„ÄÇ</li>
<li>Â¶Ç‰Ωï‰ªé‰∏çÂêåÁöÑprompt‰∏≠ËØÜÂà´Âá∫Â∑≤ÁªèÁºìÂ≠òËøáÁöÑÊñáÊú¨„ÄÇ</li>
</ol>
<h1 id="ÁÆóÊ≥ï">ÁÆóÊ≥ï</h1>
<h2 id="ÂÆûÈ™åÁªèÈ™å">ÂÆûÈ™åÁªèÈ™å</h2>
<p>‰∏ÄÊÆµpromptÁöÑPositionÂÄº‰∏çËøûÁª≠Ê≤°ÊúâÂÖ≥Á≥ª„ÄÇÂè™Ë¶ÅËøô‰∏ÄÊÆµpromptÊú¨Ë∫´ÁöÑPositionÂÄºÊòØËøûÁª≠ÁöÑÂ∞±Ë°å„ÄÇÊÑèÊÄùÊòØ<strong>ÈÉ®ÂàÜËøûÁª≠</strong>ÂØπ‰∫éLLMÂ∞±Â§ü‰∫ÜÔºå‰∏ç‰∏ÄÂÆöË¶Å<strong>ÂÆåÂÖ®ËøûÁª≠</strong>„ÄÇËØ∑Ê≥®ÊÑèÔºöËøôÊòØ‰∏Ä‰∏™ÂÆûÈ™åÊÄßÈ™åËØÅÁöÑÁªìËÆ∫„ÄÇ</p>
<h2 id="prompt-schema">Prompt Schema</h2>
<div align="center"> 
<img src="/keep-moving-forward/imgs/prompt_cache_1.png" width = "100%"/>
<br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Fig 1. Prompt Schema</div>
</div>
‰ΩúËÄÖÂõ¢ÈòüÂÆö‰πâ‰∫Ü‰∏Ä‰∏™Prompt Markup Language(PML)„ÄÇ‰∏äÂõæ‰∏≠ÁöÑ‰æãÂ≠êÊúâÔºöÂèØ‰ª•Â§çÁî®ÁöÑmoduleÂíå‰∏çËÉΩÂ§çÁî®ÁöÑÂ°´ÂÖÖÈÉ®ÂàÜÔºåÂ°´ÂÖÖÈÉ®ÂàÜÈúÄË¶ÅÁî®ParamÊåáÂá∫ÔºåÂπ∂ÁªôÂá∫ÈïøÂ∫¶„ÄÇPrompt Attention States‰∏≠ÁöÑÁ∫¢Ëâ≤ÈÉ®ÂàÜÊòØÂèØ‰ª•Ë¢´Â§çÁî®ÁöÑÂå∫Âüü„ÄÇ
<div align="center"> 
<img src="/keep-moving-forward/imgs/prompt_cache_2.png" width = "100%"/>
<br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Fig 2. ÂéüÂßãLLM/KV Cache/Prompt Cache</div>
</div>
<p>Êàë‰ª¨Êù•ÂØπÊØî‰∏ãÊôÆÈÄöÁöÑËá™ÂõûÂΩíLLM„ÄÅ‰ΩøÁî®‰∫ÜKV CacheÁöÑLLMÂíå‰ΩøÁî®‰∫ÜPrompt CacheÁöÑLLM„ÄÇÊôÆÈÄöÁöÑLLMÊØèÊ¨°ÈÉΩË¶ÅÈÄöËøáËæìÂÖ•ÁöÑPromptÊù•È¢ÑÊµãÂá∫‰∏ã‰∏Ä‰∏™TokenÔºåPromptÊòØÂÖ®ÈáèÁöÑËÆ°ÁÆó„ÄÇ‰ΩøÁî®‰∫ÜKV CacheÁöÑLLMÔºåÊØèÊ¨°TokenÈ¢ÑÊµã‰∏çÁî®ÂÖ®ÈáèËÆ°ÁÆó‰∫ÜÔºåÂèØ‰ª•‰ΩøÁî®‰∏äÊ¨°AttentionÁöÑ‰∏≠Èó¥ÁªìÊûú„ÄÇËÄå‰ΩøÁî®‰∫ÜPrompt CacheÁöÑLLMÔºåÂú®ÂêéÊúüÈ¢ÑÊµãTokenÁöÑËøáÁ®ãÂíåÂéüÊù•ÁöÑKV CacheÊ≤°Êúâ‰ªÄ‰πàÂå∫Âà´„ÄÇ‰∏ªË¶ÅÂå∫Âà´ÊòØÂú®‰∏ÄÂºÄÂßãÁöÑPromptËæìÂÖ•ÁöÑÈò∂ÊÆµÔºåPrompt Cache‰∏≠Â∏∏Áî®ÁöÑPrompt Attention StatesÂèØ‰ª•Ë¢´Âà©Áî®Ëµ∑Êù•ÔºåËøô‰ºöÊûÅÂ§ßÁöÑÁº©ÂáèÁ¨¨‰∏Ä‰∏™TokenËæìÂá∫ÁöÑÊó∂Èó¥„ÄÇ
Prompt SchemaÊúâÂæàÂ§öÁöÑÁªÜËäÇÔºåËøôÈáåÂè™ËÆ≤Â§ßËá¥ÁöÑÊÄùË∑ØÔºåÂÖ∑‰ΩìÁöÑËØ∑ÁúãÊñáÁ´†Âíå‰ª£Á†Å‰ªìÂ∫ì„ÄÇ</p>
<hr>
<p>ÊàëÂØπmoduleÊÄé‰πàÂ§çÁî®‰∏çÊòØÂæàÁêÜËß£ÔºåÂ∫îËØ•ÊòØÈÄöËøáÂ∞ÜÊñáÊú¨ÂÜÖÂÆπËøõË°åsha256ÁºñÁ†ÅÊù•ÂØπÂÖ∂ËøõË°åËØÜÂà´„ÄÇ</p>
<hr>
<p>Êú¨Êñá‰∏ªË¶ÅÊòØÂØπÈ¶ñTokenËæìÂá∫Êó∂Èó¥ÁöÑ‰ºòÂåñÔºåÂØπ‰∫éÁî®Êà∑Êù•ËØ¥ÂèØ‰ª•ÊúâÊõ¥Â•ΩÁöÑ‰ΩìÈ™å„ÄÇ<strong>Ë¶ÅÊòØËÉΩÂÅö‰∏™ÂÖ®Â±ÄÁöÑPrompt CacheÊï∞ÊçÆÂ∫ìÔºåÂ∫îËØ•ÂèØ‰ª•ÁªôÂ§ßËßÑÊ®°ÁöÑLLM InferÁ≥ªÁªüÂ∏¶Êù•‰∏çÂ∞ëÁöÑÂ•ΩÂ§Ñ„ÄÇ</strong></p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/keep-moving-forward/tags/llm-server/" rel="tag">LLM Server</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/keep-moving-forward/tags/llm-cache-optimize/" rel="tag">LLM Cache Optimize</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/keep-moving-forward/tags/llm/" rel="tag">LLM</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/keep-moving-forward/tags/mlsys-2024/" rel="tag">MLSys 2024</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="chenghua.wang avatar" src="/keep-moving-forward/img/Cornell_box.png" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About chenghua.wang</span>
	</div>
	<div class="authorbox__description">
		Currently working on AI&amp;Sys, CV (low-level) and LLM topics.
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/keep-moving-forward/papers/transformer-lite/" rel="prev">
			<span class="pager__subtitle">¬´&thinsp;Previous</span>
			<p class="pager__title">‚úÖ[Mar 2024] Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/keep-moving-forward/papers/mlsys2024-qmoe/" rel="next">
			<span class="pager__subtitle">Next&thinsp;¬ª</span>
			<p class="pager__title">‚úÖ[Oct 2023] QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models</p>
		</a>
	</div>
</nav>


			</div>
			<aside class="sidebar"><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH‚Ä¶" value="" name="q" aria-label="SEARCH‚Ä¶">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="don&#39;t use this search" value="don&#39;t use this searchhttps://chenghuawang.github.io/keep-moving-forward/">
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/tech/mllm-qwen/">mllmÊ°ÜÊû∂ÊµÖÊûê-‰ª•QWen0.5B‰∏∫‰æã</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/papers/mlsys2024-qmoe/">‚úÖ[Oct 2023] QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/papers/prompt_cache/">‚úÖ[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/papers/transformer-lite/">‚úÖ[Mar 2024] Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/papers/awq/">‚úÖ[April 2024] AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/tech/x86_avx_sgemm_6x16/">„ÄêÊñΩÂ∑•‰∏≠„Äë6xKx16 SGEMM Kernel on X86-AVX</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/tech/introduction_mldistri/">ÊµÖÊûêÊú∫Âô®Â≠¶‰π†‰∏≠ÁöÑÂπ∂Ë°åÊ®°ÂûãÂíåËá™Âä®Âπ∂Ë°åÊñπÊ≥ï</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/tech/cuda_nsight_system/">CUDA: NSight System</a></li>
		</ul>
	</div>
</div>
<div class="widget-taglist widget">
	<h4 class="widget__title">Tags</h4>
	<div class="widget__content">
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/cuda/" title="CUDA">CUDA (1)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/distributed-system/" title="Distributed System">Distributed System (1)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/edge/" title="Edge">Edge (1)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/kernel/" title="Kernel">Kernel (1)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/lecture/" title="Lecture">Lecture (5)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/llm/" title="LLM">LLM (5)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/llm-cache-optimize/" title="LLM Cache Optimize">LLM Cache Optimize (1)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/llm-server/" title="LLM Server">LLM Server (5)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/mlsys-2024/" title="MLSys 2024">MLSys 2024 (3)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/quantization/" title="Quantization">Quantization (2)</a>
	</div>
</div>
<div class="toc__block_div">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li><a href="#ËÉåÊôØÂíåÂä®Êú∫">ËÉåÊôØÂíåÂä®Êú∫</a></li>
    <li><a href="#ÁÆóÊ≥ï">ÁÆóÊ≥ï</a>
      <ul>
        <li><a href="#ÂÆûÈ™åÁªèÈ™å">ÂÆûÈ™åÁªèÈ™å</a></li>
        <li><a href="#prompt-schema">Prompt Schema</a></li>
      </ul>
    </li>
  </ul>
</nav>
	</div>
</div>

</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 chenghua.wang.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/keep-moving-forward/js/menu.js"></script>




<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { fonts: ["TeX"] }
  });
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async>
</script>
</body>
</html>