<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>âœ…[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference - Ubios Home</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="âœ…[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference" />
<meta property="og:description" content="èƒŒæ™¯å’ŒåŠ¨æœº ä»¥KV Cacheä¸ºå¯å‘ï¼Œæ¢ç´¢äº†å¯¹time-to-first-token (TTFT) Latencyçš„ä¼˜åŒ–ã€‚ç±»ä¼¼äºKV Cacheï¼ŒPrompt Cache(PC)æ¨ç†åŠ é€Ÿçš„æ ¸å¿ƒæ€æƒ³æ˜¯å¤ç”¨æ³¨æ„åŠ›çš„ä¸­é—´çŠ¶æ€(Attention States)ã€‚ç„¶è€Œä¸KV Cacheä¸åŒçš„æ˜¯ï¼ŒPCæ˜¯åœ¨ä¸åŒçš„promptä¹‹é—´è¿›è¡Œå¤ç”¨ã€‚
åœ¨å¤§éƒ¨åˆ†çš„LLMä»»åŠ¡ä¸­ï¼Œpromptæœ‰é‡å (overlapping)çš„ç°è±¡ï¼Œè¿™äº›é‡å çš„promptå¯ä»¥è¢«å­˜å‚¨èµ·æ¥ï¼Œè¿›è€Œåœ¨æ¥ä¸‹æ¥çš„LLMå¤„ç†é˜¶æ®µå¯ä»¥åƒKV Cacheä¸€æ ·ï¼Œæå–å‡ºæ¥ç›´æ¥ä½¿ç”¨ã€‚åœ¨TTFTçš„æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå…å»è®¡ç®—ä¸åŒpromptä¸­é‡å éƒ¨åˆ†çš„æ³¨æ„åŠ›çŠ¶æ€ï¼Œä»è€Œç¼©çŸ­TTFTçš„ç”Ÿæˆæ—¶é—´ã€‚
ä¸KV Cacheä¸åŒçš„ç‚¹æ˜¯ï¼š
ç›¸åŒçš„æ–‡æœ¬æ®µå¯èƒ½å‡ºç°åœ¨ä¸åŒpromptçš„ä¸åŒä½ç½®ï¼Œå¦‚ä½•å¯¹å®ƒä»¬çš„Attention Statesè¿›è¡Œå¤ç”¨ã€‚å› ä¸ºä¸åŒä½ç½®çš„æ–‡æœ¬æ®µçš„Position Encodingè¿›å»çš„å€¼æ˜¯ä¸ä¸€æ ·çš„ã€‚åœ¨KV Cacheä¸­ä¸éœ€è¦è€ƒè™‘è¿™ä¸€ç‚¹ï¼Œå› ä¸ºcacheæ˜¯ä»å‰å¾€åçº¿æ€§å¢é•¿çš„ï¼Œä½†Promptæ‰€åœ¨çš„ä½ç½®æ˜¯ä¸ç¡®å®šçš„ã€‚ å¦‚ä½•ä»ä¸åŒçš„promptä¸­è¯†åˆ«å‡ºå·²ç»ç¼“å­˜è¿‡çš„æ–‡æœ¬ã€‚ ç®—æ³• å®éªŒç»éªŒ ä¸€æ®µpromptçš„Positionå€¼ä¸è¿ç»­æ²¡æœ‰å…³ç³»ã€‚åªè¦è¿™ä¸€æ®µpromptæœ¬èº«çš„Positionå€¼æ˜¯è¿ç»­çš„å°±è¡Œã€‚æ„æ€æ˜¯éƒ¨åˆ†è¿ç»­å¯¹äºLLMå°±å¤Ÿäº†ï¼Œä¸ä¸€å®šè¦å®Œå…¨è¿ç»­ã€‚è¯·æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§éªŒè¯çš„ç»“è®ºã€‚
Prompt Schema Fig 1. Prompt Schemaä½œè€…å›¢é˜Ÿå®šä¹‰äº†ä¸€ä¸ªPrompt Markup Language(PML)ã€‚ä¸Šå›¾ä¸­çš„ä¾‹å­æœ‰ï¼šå¯ä»¥å¤ç”¨çš„moduleå’Œä¸èƒ½å¤ç”¨çš„å¡«å……éƒ¨åˆ†ï¼Œå¡«å……éƒ¨åˆ†éœ€è¦ç”¨ParamæŒ‡å‡ºï¼Œå¹¶ç»™å‡ºé•¿åº¦ã€‚Prompt Attention Statesä¸­çš„çº¢è‰²éƒ¨åˆ†æ˜¯å¯ä»¥è¢«å¤ç”¨çš„åŒºåŸŸã€‚Fig 2. åŸå§‹LLM/KV Cache/Prompt Cacheæˆ‘ä»¬æ¥å¯¹æ¯”ä¸‹æ™®é€šçš„è‡ªå›å½’LLMã€ä½¿ç”¨äº†KV Cacheçš„LLMå’Œä½¿ç”¨äº†Prompt Cacheçš„LLMã€‚æ™®é€šçš„LLMæ¯æ¬¡éƒ½è¦é€šè¿‡è¾“å…¥çš„Promptæ¥é¢„æµ‹å‡ºä¸‹ä¸€ä¸ªTokenï¼ŒPromptæ˜¯å…¨é‡çš„è®¡ç®—ã€‚ä½¿ç”¨äº†KV Cacheçš„LLMï¼Œæ¯æ¬¡Tokené¢„æµ‹ä¸ç”¨å…¨é‡è®¡ç®—äº†ï¼Œå¯ä»¥ä½¿ç”¨ä¸Šæ¬¡Attentionçš„ä¸­é—´ç»“æœã€‚è€Œä½¿ç”¨äº†Prompt Cacheçš„LLMï¼Œåœ¨åæœŸé¢„æµ‹Tokençš„è¿‡ç¨‹å’ŒåŸæ¥çš„KV Cacheæ²¡æœ‰ä»€ä¹ˆåŒºåˆ«ã€‚ä¸»è¦åŒºåˆ«æ˜¯åœ¨ä¸€å¼€å§‹çš„Promptè¾“å…¥çš„é˜¶æ®µï¼ŒPrompt Cacheä¸­å¸¸ç”¨çš„Prompt Attention Stateså¯ä»¥è¢«åˆ©ç”¨èµ·æ¥ï¼Œè¿™ä¼šæå¤§çš„ç¼©å‡ç¬¬ä¸€ä¸ªTokenè¾“å‡ºçš„æ—¶é—´ã€‚ Prompt Schemaæœ‰å¾ˆå¤šçš„ç»†èŠ‚ï¼Œè¿™é‡Œåªè®²å¤§è‡´çš„æ€è·¯ï¼Œå…·ä½“çš„è¯·çœ‹æ–‡ç« å’Œä»£ç ä»“åº“ã€‚
æˆ‘å¯¹moduleæ€ä¹ˆå¤ç”¨ä¸æ˜¯å¾ˆç†è§£ï¼Œåº”è¯¥æ˜¯é€šè¿‡å°†æ–‡æœ¬å†…å®¹è¿›è¡Œsha256ç¼–ç æ¥å¯¹å…¶è¿›è¡Œè¯†åˆ«ã€‚
æœ¬æ–‡ä¸»è¦æ˜¯å¯¹é¦–Tokenè¾“å‡ºæ—¶é—´çš„ä¼˜åŒ–ï¼Œå¯¹äºç”¨æˆ·æ¥è¯´å¯ä»¥æœ‰æ›´å¥½çš„ä½“éªŒã€‚è¦æ˜¯èƒ½åšä¸ªå…¨å±€çš„Prompt Cacheæ•°æ®åº“ï¼Œåº”è¯¥å¯ä»¥ç»™å¤§è§„æ¨¡çš„LLM Inferç³»ç»Ÿå¸¦æ¥ä¸å°‘çš„å¥½å¤„ã€‚" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chenghuawang.github.io/keep-moving-forward/papers/prompt_cache/" /><meta property="article:section" content="Papers" />
<meta property="article:published_time" content="2024-06-21T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-06-21T00:00:00+00:00" />

		<meta itemprop="name" content="âœ…[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference">
<meta itemprop="description" content="èƒŒæ™¯å’ŒåŠ¨æœº ä»¥KV Cacheä¸ºå¯å‘ï¼Œæ¢ç´¢äº†å¯¹time-to-first-token (TTFT) Latencyçš„ä¼˜åŒ–ã€‚ç±»ä¼¼äºKV Cacheï¼ŒPrompt Cache(PC)æ¨ç†åŠ é€Ÿçš„æ ¸å¿ƒæ€æƒ³æ˜¯å¤ç”¨æ³¨æ„åŠ›çš„ä¸­é—´çŠ¶æ€(Attention States)ã€‚ç„¶è€Œä¸KV Cacheä¸åŒçš„æ˜¯ï¼ŒPCæ˜¯åœ¨ä¸åŒçš„promptä¹‹é—´è¿›è¡Œå¤ç”¨ã€‚
åœ¨å¤§éƒ¨åˆ†çš„LLMä»»åŠ¡ä¸­ï¼Œpromptæœ‰é‡å (overlapping)çš„ç°è±¡ï¼Œè¿™äº›é‡å çš„promptå¯ä»¥è¢«å­˜å‚¨èµ·æ¥ï¼Œè¿›è€Œåœ¨æ¥ä¸‹æ¥çš„LLMå¤„ç†é˜¶æ®µå¯ä»¥åƒKV Cacheä¸€æ ·ï¼Œæå–å‡ºæ¥ç›´æ¥ä½¿ç”¨ã€‚åœ¨TTFTçš„æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå…å»è®¡ç®—ä¸åŒpromptä¸­é‡å éƒ¨åˆ†çš„æ³¨æ„åŠ›çŠ¶æ€ï¼Œä»è€Œç¼©çŸ­TTFTçš„ç”Ÿæˆæ—¶é—´ã€‚
ä¸KV Cacheä¸åŒçš„ç‚¹æ˜¯ï¼š
ç›¸åŒçš„æ–‡æœ¬æ®µå¯èƒ½å‡ºç°åœ¨ä¸åŒpromptçš„ä¸åŒä½ç½®ï¼Œå¦‚ä½•å¯¹å®ƒä»¬çš„Attention Statesè¿›è¡Œå¤ç”¨ã€‚å› ä¸ºä¸åŒä½ç½®çš„æ–‡æœ¬æ®µçš„Position Encodingè¿›å»çš„å€¼æ˜¯ä¸ä¸€æ ·çš„ã€‚åœ¨KV Cacheä¸­ä¸éœ€è¦è€ƒè™‘è¿™ä¸€ç‚¹ï¼Œå› ä¸ºcacheæ˜¯ä»å‰å¾€åçº¿æ€§å¢é•¿çš„ï¼Œä½†Promptæ‰€åœ¨çš„ä½ç½®æ˜¯ä¸ç¡®å®šçš„ã€‚ å¦‚ä½•ä»ä¸åŒçš„promptä¸­è¯†åˆ«å‡ºå·²ç»ç¼“å­˜è¿‡çš„æ–‡æœ¬ã€‚ ç®—æ³• å®éªŒç»éªŒ ä¸€æ®µpromptçš„Positionå€¼ä¸è¿ç»­æ²¡æœ‰å…³ç³»ã€‚åªè¦è¿™ä¸€æ®µpromptæœ¬èº«çš„Positionå€¼æ˜¯è¿ç»­çš„å°±è¡Œã€‚æ„æ€æ˜¯éƒ¨åˆ†è¿ç»­å¯¹äºLLMå°±å¤Ÿäº†ï¼Œä¸ä¸€å®šè¦å®Œå…¨è¿ç»­ã€‚è¯·æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§éªŒè¯çš„ç»“è®ºã€‚
Prompt Schema Fig 1. Prompt Schemaä½œè€…å›¢é˜Ÿå®šä¹‰äº†ä¸€ä¸ªPrompt Markup Language(PML)ã€‚ä¸Šå›¾ä¸­çš„ä¾‹å­æœ‰ï¼šå¯ä»¥å¤ç”¨çš„moduleå’Œä¸èƒ½å¤ç”¨çš„å¡«å……éƒ¨åˆ†ï¼Œå¡«å……éƒ¨åˆ†éœ€è¦ç”¨ParamæŒ‡å‡ºï¼Œå¹¶ç»™å‡ºé•¿åº¦ã€‚Prompt Attention Statesä¸­çš„çº¢è‰²éƒ¨åˆ†æ˜¯å¯ä»¥è¢«å¤ç”¨çš„åŒºåŸŸã€‚Fig 2. åŸå§‹LLM/KV Cache/Prompt Cacheæˆ‘ä»¬æ¥å¯¹æ¯”ä¸‹æ™®é€šçš„è‡ªå›å½’LLMã€ä½¿ç”¨äº†KV Cacheçš„LLMå’Œä½¿ç”¨äº†Prompt Cacheçš„LLMã€‚æ™®é€šçš„LLMæ¯æ¬¡éƒ½è¦é€šè¿‡è¾“å…¥çš„Promptæ¥é¢„æµ‹å‡ºä¸‹ä¸€ä¸ªTokenï¼ŒPromptæ˜¯å…¨é‡çš„è®¡ç®—ã€‚ä½¿ç”¨äº†KV Cacheçš„LLMï¼Œæ¯æ¬¡Tokené¢„æµ‹ä¸ç”¨å…¨é‡è®¡ç®—äº†ï¼Œå¯ä»¥ä½¿ç”¨ä¸Šæ¬¡Attentionçš„ä¸­é—´ç»“æœã€‚è€Œä½¿ç”¨äº†Prompt Cacheçš„LLMï¼Œåœ¨åæœŸé¢„æµ‹Tokençš„è¿‡ç¨‹å’ŒåŸæ¥çš„KV Cacheæ²¡æœ‰ä»€ä¹ˆåŒºåˆ«ã€‚ä¸»è¦åŒºåˆ«æ˜¯åœ¨ä¸€å¼€å§‹çš„Promptè¾“å…¥çš„é˜¶æ®µï¼ŒPrompt Cacheä¸­å¸¸ç”¨çš„Prompt Attention Stateså¯ä»¥è¢«åˆ©ç”¨èµ·æ¥ï¼Œè¿™ä¼šæå¤§çš„ç¼©å‡ç¬¬ä¸€ä¸ªTokenè¾“å‡ºçš„æ—¶é—´ã€‚ Prompt Schemaæœ‰å¾ˆå¤šçš„ç»†èŠ‚ï¼Œè¿™é‡Œåªè®²å¤§è‡´çš„æ€è·¯ï¼Œå…·ä½“çš„è¯·çœ‹æ–‡ç« å’Œä»£ç ä»“åº“ã€‚
æˆ‘å¯¹moduleæ€ä¹ˆå¤ç”¨ä¸æ˜¯å¾ˆç†è§£ï¼Œåº”è¯¥æ˜¯é€šè¿‡å°†æ–‡æœ¬å†…å®¹è¿›è¡Œsha256ç¼–ç æ¥å¯¹å…¶è¿›è¡Œè¯†åˆ«ã€‚
æœ¬æ–‡ä¸»è¦æ˜¯å¯¹é¦–Tokenè¾“å‡ºæ—¶é—´çš„ä¼˜åŒ–ï¼Œå¯¹äºç”¨æˆ·æ¥è¯´å¯ä»¥æœ‰æ›´å¥½çš„ä½“éªŒã€‚è¦æ˜¯èƒ½åšä¸ªå…¨å±€çš„Prompt Cacheæ•°æ®åº“ï¼Œåº”è¯¥å¯ä»¥ç»™å¤§è§„æ¨¡çš„LLM Inferç³»ç»Ÿå¸¦æ¥ä¸å°‘çš„å¥½å¤„ã€‚"><meta itemprop="datePublished" content="2024-06-21T00:00:00+00:00" />
<meta itemprop="dateModified" content="2024-06-21T00:00:00+00:00" />
<meta itemprop="wordCount" content="52">
<meta itemprop="keywords" content="LLM Server,LLM Cache Optimize,LLM,MLSys 2024," />
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+SC:400,700">

	<link rel="stylesheet" href="/keep-moving-forward/css/style.css">
	

	<link rel="shortcut icon" href="/keep-moving-forward/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		
<header class="header">
	<div class="container header__container">
		
	<div class="logo logo--mixed" >
		<a class="logo__link" href="/keep-moving-forward/" title="Ubios Home" rel="home" >
			
			<div class="logo__item logo__text" >
					<div class="logo__title" >Ubios Home</div>
					<div class="logo__tagline">Remember brick walls let us show our dedication. They are there to separate us from the people who don&#39;t really want to achieve their childhood dreams. --Randy Pausch</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/about/">
				
				<span class="menu__text">About</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/hpc_ai/">
				
				<span class="menu__text">HPC &amp; AI å…¥å‘</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/lecture_notes/">
				
				<span class="menu__text">Lecture-Notes</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/paper_posts/">
				
				<span class="menu__text">Paper-Notes</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/tech_posts/">
				
				<span class="menu__text">Tech-Posts</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/thinking/">
				
				<span class="menu__text">Thinking</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/news/">
				
				<span class="menu__text">ğŸ‰NewsğŸ‰</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			


<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">âœ…[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference</h1>
			<p class="post__lead">MLSys 2024 Prompt Cache</p>
			<div class="post__meta meta"><div class="meta__item-author meta__item">
	<svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2 0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class="meta__text">chenghua.wang</span>
</div>
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2024-06-21T00:00:00Z">2024-06-21</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/keep-moving-forward/categories/aisys/" rel="category">AI&amp;Sys</a>
	</span>
</div></div>
		</header>

		
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li><a href="#èƒŒæ™¯å’ŒåŠ¨æœº">èƒŒæ™¯å’ŒåŠ¨æœº</a></li>
    <li><a href="#ç®—æ³•">ç®—æ³•</a>
      <ul>
        <li><a href="#å®éªŒç»éªŒ">å®éªŒç»éªŒ</a></li>
        <li><a href="#prompt-schema">Prompt Schema</a></li>
      </ul>
    </li>
  </ul>
</nav>
	</div>
</div><div class="content post__content clearfix">
			<h1 id="èƒŒæ™¯å’ŒåŠ¨æœº">èƒŒæ™¯å’ŒåŠ¨æœº</h1>
<p>ä»¥KV Cacheä¸ºå¯å‘ï¼Œæ¢ç´¢äº†å¯¹time-to-first-token (TTFT) Latencyçš„ä¼˜åŒ–ã€‚ç±»ä¼¼äºKV Cacheï¼ŒPrompt Cache(PC)æ¨ç†åŠ é€Ÿçš„æ ¸å¿ƒæ€æƒ³æ˜¯å¤ç”¨æ³¨æ„åŠ›çš„ä¸­é—´çŠ¶æ€(Attention States)ã€‚ç„¶è€Œä¸KV Cacheä¸åŒçš„æ˜¯ï¼ŒPCæ˜¯åœ¨ä¸åŒçš„promptä¹‹é—´è¿›è¡Œå¤ç”¨ã€‚</p>
<p>åœ¨å¤§éƒ¨åˆ†çš„LLMä»»åŠ¡ä¸­ï¼Œpromptæœ‰é‡å (overlapping)çš„ç°è±¡ï¼Œè¿™äº›é‡å çš„promptå¯ä»¥è¢«å­˜å‚¨èµ·æ¥ï¼Œè¿›è€Œåœ¨æ¥ä¸‹æ¥çš„LLMå¤„ç†é˜¶æ®µå¯ä»¥åƒKV Cacheä¸€æ ·ï¼Œæå–å‡ºæ¥ç›´æ¥ä½¿ç”¨ã€‚åœ¨TTFTçš„æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå…å»è®¡ç®—ä¸åŒpromptä¸­é‡å éƒ¨åˆ†çš„æ³¨æ„åŠ›çŠ¶æ€ï¼Œä»è€Œç¼©çŸ­TTFTçš„ç”Ÿæˆæ—¶é—´ã€‚</p>
<p>ä¸KV Cacheä¸åŒçš„ç‚¹æ˜¯ï¼š</p>
<ol>
<li>ç›¸åŒçš„æ–‡æœ¬æ®µå¯èƒ½å‡ºç°åœ¨ä¸åŒpromptçš„ä¸åŒä½ç½®ï¼Œå¦‚ä½•å¯¹å®ƒä»¬çš„Attention Statesè¿›è¡Œå¤ç”¨ã€‚å› ä¸ºä¸åŒä½ç½®çš„æ–‡æœ¬æ®µçš„Position Encodingè¿›å»çš„å€¼æ˜¯ä¸ä¸€æ ·çš„ã€‚åœ¨KV Cacheä¸­ä¸éœ€è¦è€ƒè™‘è¿™ä¸€ç‚¹ï¼Œå› ä¸ºcacheæ˜¯ä»å‰å¾€åçº¿æ€§å¢é•¿çš„ï¼Œä½†Promptæ‰€åœ¨çš„ä½ç½®æ˜¯ä¸ç¡®å®šçš„ã€‚</li>
<li>å¦‚ä½•ä»ä¸åŒçš„promptä¸­è¯†åˆ«å‡ºå·²ç»ç¼“å­˜è¿‡çš„æ–‡æœ¬ã€‚</li>
</ol>
<h1 id="ç®—æ³•">ç®—æ³•</h1>
<h2 id="å®éªŒç»éªŒ">å®éªŒç»éªŒ</h2>
<p>ä¸€æ®µpromptçš„Positionå€¼ä¸è¿ç»­æ²¡æœ‰å…³ç³»ã€‚åªè¦è¿™ä¸€æ®µpromptæœ¬èº«çš„Positionå€¼æ˜¯è¿ç»­çš„å°±è¡Œã€‚æ„æ€æ˜¯<strong>éƒ¨åˆ†è¿ç»­</strong>å¯¹äºLLMå°±å¤Ÿäº†ï¼Œä¸ä¸€å®šè¦<strong>å®Œå…¨è¿ç»­</strong>ã€‚è¯·æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§éªŒè¯çš„ç»“è®ºã€‚</p>
<h2 id="prompt-schema">Prompt Schema</h2>
<div align="center"> 
<img src="/keep-moving-forward/imgs/prompt_cache_1.png" width = "100%"/>
<br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Fig 1. Prompt Schema</div>
</div>
ä½œè€…å›¢é˜Ÿå®šä¹‰äº†ä¸€ä¸ªPrompt Markup Language(PML)ã€‚ä¸Šå›¾ä¸­çš„ä¾‹å­æœ‰ï¼šå¯ä»¥å¤ç”¨çš„moduleå’Œä¸èƒ½å¤ç”¨çš„å¡«å……éƒ¨åˆ†ï¼Œå¡«å……éƒ¨åˆ†éœ€è¦ç”¨ParamæŒ‡å‡ºï¼Œå¹¶ç»™å‡ºé•¿åº¦ã€‚Prompt Attention Statesä¸­çš„çº¢è‰²éƒ¨åˆ†æ˜¯å¯ä»¥è¢«å¤ç”¨çš„åŒºåŸŸã€‚
<div align="center"> 
<img src="/keep-moving-forward/imgs/prompt_cache_2.png" width = "100%"/>
<br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Fig 2. åŸå§‹LLM/KV Cache/Prompt Cache</div>
</div>
<p>æˆ‘ä»¬æ¥å¯¹æ¯”ä¸‹æ™®é€šçš„è‡ªå›å½’LLMã€ä½¿ç”¨äº†KV Cacheçš„LLMå’Œä½¿ç”¨äº†Prompt Cacheçš„LLMã€‚æ™®é€šçš„LLMæ¯æ¬¡éƒ½è¦é€šè¿‡è¾“å…¥çš„Promptæ¥é¢„æµ‹å‡ºä¸‹ä¸€ä¸ªTokenï¼ŒPromptæ˜¯å…¨é‡çš„è®¡ç®—ã€‚ä½¿ç”¨äº†KV Cacheçš„LLMï¼Œæ¯æ¬¡Tokené¢„æµ‹ä¸ç”¨å…¨é‡è®¡ç®—äº†ï¼Œå¯ä»¥ä½¿ç”¨ä¸Šæ¬¡Attentionçš„ä¸­é—´ç»“æœã€‚è€Œä½¿ç”¨äº†Prompt Cacheçš„LLMï¼Œåœ¨åæœŸé¢„æµ‹Tokençš„è¿‡ç¨‹å’ŒåŸæ¥çš„KV Cacheæ²¡æœ‰ä»€ä¹ˆåŒºåˆ«ã€‚ä¸»è¦åŒºåˆ«æ˜¯åœ¨ä¸€å¼€å§‹çš„Promptè¾“å…¥çš„é˜¶æ®µï¼ŒPrompt Cacheä¸­å¸¸ç”¨çš„Prompt Attention Stateså¯ä»¥è¢«åˆ©ç”¨èµ·æ¥ï¼Œè¿™ä¼šæå¤§çš„ç¼©å‡ç¬¬ä¸€ä¸ªTokenè¾“å‡ºçš„æ—¶é—´ã€‚
Prompt Schemaæœ‰å¾ˆå¤šçš„ç»†èŠ‚ï¼Œè¿™é‡Œåªè®²å¤§è‡´çš„æ€è·¯ï¼Œå…·ä½“çš„è¯·çœ‹æ–‡ç« å’Œä»£ç ä»“åº“ã€‚</p>
<hr>
<p>æˆ‘å¯¹moduleæ€ä¹ˆå¤ç”¨ä¸æ˜¯å¾ˆç†è§£ï¼Œåº”è¯¥æ˜¯é€šè¿‡å°†æ–‡æœ¬å†…å®¹è¿›è¡Œsha256ç¼–ç æ¥å¯¹å…¶è¿›è¡Œè¯†åˆ«ã€‚</p>
<hr>
<p>æœ¬æ–‡ä¸»è¦æ˜¯å¯¹é¦–Tokenè¾“å‡ºæ—¶é—´çš„ä¼˜åŒ–ï¼Œå¯¹äºç”¨æˆ·æ¥è¯´å¯ä»¥æœ‰æ›´å¥½çš„ä½“éªŒã€‚<strong>è¦æ˜¯èƒ½åšä¸ªå…¨å±€çš„Prompt Cacheæ•°æ®åº“ï¼Œåº”è¯¥å¯ä»¥ç»™å¤§è§„æ¨¡çš„LLM Inferç³»ç»Ÿå¸¦æ¥ä¸å°‘çš„å¥½å¤„ã€‚</strong></p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/keep-moving-forward/tags/llm-server/" rel="tag">LLM Server</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/keep-moving-forward/tags/llm-cache-optimize/" rel="tag">LLM Cache Optimize</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/keep-moving-forward/tags/llm/" rel="tag">LLM</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/keep-moving-forward/tags/mlsys-2024/" rel="tag">MLSys 2024</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="chenghua.wang avatar" src="/keep-moving-forward/img/Cornell_box.png" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About chenghua.wang</span>
	</div>
	<div class="authorbox__description">
		Currently working on AI&amp;Sys, CV (low-level) and LLM topics.
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/keep-moving-forward/papers/transformer-lite/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">âœ…[Mar 2024] Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/keep-moving-forward/papers/mlsys2024-qmoe/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">âœ…[Oct 2023] QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models</p>
		</a>
	</div>
</nav>


			</div>
			<aside class="sidebar"><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCHâ€¦" value="" name="q" aria-label="SEARCHâ€¦">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="don&#39;t use this search" value="don&#39;t use this searchhttps://chenghuawang.github.io/keep-moving-forward/">
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/tech/mllm-qwen/">mllmæ¡†æ¶æµ…æ-ä»¥QWen0.5Bä¸ºä¾‹</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/papers/mlsys2024-qmoe/">âœ…[Oct 2023] QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/papers/prompt_cache/">âœ…[April 2024] Prompt Cache: Modular Attention Reuse for Low-Latency Inference</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/papers/transformer-lite/">âœ…[Mar 2024] Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/papers/awq/">âœ…[April 2024] AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/tech/x86_avx_sgemm_6x16/">ã€æ–½å·¥ä¸­ã€‘6xKx16 SGEMM Kernel on X86-AVX</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/tech/introduction_mldistri/">æµ…ææœºå™¨å­¦ä¹ ä¸­çš„å¹¶è¡Œæ¨¡å‹å’Œè‡ªåŠ¨å¹¶è¡Œæ–¹æ³•</a></li>
			<li class="widget__item"><a class="widget__link" href="/keep-moving-forward/tech/cuda_nsight_system/">CUDA: NSight System</a></li>
		</ul>
	</div>
</div>
<div class="widget-taglist widget">
	<h4 class="widget__title">Tags</h4>
	<div class="widget__content">
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/cuda/" title="CUDA">CUDA (1)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/distributed-system/" title="Distributed System">Distributed System (1)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/edge/" title="Edge">Edge (1)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/kernel/" title="Kernel">Kernel (1)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/lecture/" title="Lecture">Lecture (5)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/llm/" title="LLM">LLM (5)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/llm-cache-optimize/" title="LLM Cache Optimize">LLM Cache Optimize (1)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/llm-server/" title="LLM Server">LLM Server (5)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/mlsys-2024/" title="MLSys 2024">MLSys 2024 (3)</a>
		<a class="widget-taglist__link widget__link btn" href="/keep-moving-forward/tags/quantization/" title="Quantization">Quantization (2)</a>
	</div>
</div>
<div class="toc__block_div">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li><a href="#èƒŒæ™¯å’ŒåŠ¨æœº">èƒŒæ™¯å’ŒåŠ¨æœº</a></li>
    <li><a href="#ç®—æ³•">ç®—æ³•</a>
      <ul>
        <li><a href="#å®éªŒç»éªŒ">å®éªŒç»éªŒ</a></li>
        <li><a href="#prompt-schema">Prompt Schema</a></li>
      </ul>
    </li>
  </ul>
</nav>
	</div>
</div>

</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 chenghua.wang.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/keep-moving-forward/js/menu.js"></script>




<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { fonts: ["TeX"] }
  });
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async>
</script>
</body>
</html>