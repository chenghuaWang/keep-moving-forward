<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CUDA on Ubios Home</title>
    <link>https://chenghuawang.github.io/keep-moving-forward/tags/cuda/</link>
    <description>Recent content in CUDA on Ubios Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 21 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://chenghuawang.github.io/keep-moving-forward/tags/cuda/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How to Optimize Convolution</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/how_to_optimize_convlution/</link>
      <pubDate>Fri, 21 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/how_to_optimize_convlution/</guid>
      <description>此篇文章记录了一个个人项目(NNCV，面向计算机视觉的神经网络编译推理框架) 中的 Conv 实现和加速过程
1. Algorithms 1.0 naive 首先，先祭出 [4] CS231n 中包浆的图，对于 naive 的做法，就是按照卷积的原理来做，不做任何的优化。
Conv from CS231n[4]. 1.1 img2col &amp;amp; img2row 1.2 Winograd 1.2.x winograd impl in NCNN 1.3 Conv on mobile device 1.4 Depth Wise Conv 2. Handcraft kernel impl 2.0 Data Layout 一般 4D-Tensor 数据布局的形式是 NCHW 和 NHWC，其中 N 表示 Batch size，C 表示 Channel，H 表示 Height，W 表示 Width。本文中所有的例子都是 NCHW 的 4D-Tensor。
NCHW Datalayout[5]. 使用上述图像 [5] 来展示数据排布。对于 NCHW 排列方法来说：</description>
    </item>
    
    <item>
      <title>CUDA: NSight System</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/cuda_nsight_system/</link>
      <pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/cuda_nsight_system/</guid>
      <description>NSight System Document
WSL 2 的 cudaMallocHost() 不能正常申请到 VM 的内存。也许是 WSL 2 上的 cuda 是 ubuntu20.04 的版本，不是 WSL 2 特供版。WSL 2 的 cuda 也有一些限制，详细见 WSL2 User guide 。
1. 什么是 Nsight System 我们先看下 Nsight System 官网对该工具的描述：
NVIDIA Nsight™ Systems is a system-wide performance analysis tool designed to visualize an application’s algorithms, help you identify the largest opportunities to optimize, and tune to scale efficiently across any quantity or size of CPUs and GPUs, from large servers to our smallest system on a chip (SoC).</description>
    </item>
    
  </channel>
</rss>
