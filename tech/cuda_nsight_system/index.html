<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>CUDA: NSight System - Ubios Home</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CUDA: NSight System" />
<meta property="og:description" content="NSight System Document
WSL 2 çš„ cudaMallocHost() ä¸èƒ½æ­£å¸¸ç”³è¯·åˆ° VM çš„å†…å­˜ã€‚ä¹Ÿè®¸æ˜¯ WSL 2 ä¸Šçš„ cuda æ˜¯ ubuntu20.04 çš„ç‰ˆæœ¬ï¼Œä¸æ˜¯ WSL 2 ç‰¹ä¾›ç‰ˆã€‚WSL 2 çš„ cuda ä¹Ÿæœ‰ä¸€äº›é™åˆ¶ï¼Œè¯¦ç»†è§ WSL2 User guide ã€‚
1. ä»€ä¹ˆæ˜¯ Nsight System æˆ‘ä»¬å…ˆçœ‹ä¸‹ Nsight System å®˜ç½‘å¯¹è¯¥å·¥å…·çš„æè¿°ï¼š
NVIDIA Nsightâ„¢ Systems is a system-wide performance analysis tool designed to visualize an applicationâ€™s algorithms, help you identify the largest opportunities to optimize, and tune to scale efficiently across any quantity or size of CPUs and GPUs, from large servers to our smallest system on a chip (SoC)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chenghuawang.github.io/keep-moving-forward/tech/cuda_nsight_system/" /><meta property="article:section" content="Tech" />
<meta property="article:published_time" content="2023-04-18T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-04-18T00:00:00+00:00" />

		<meta itemprop="name" content="CUDA: NSight System">
<meta itemprop="description" content="NSight System Document
WSL 2 çš„ cudaMallocHost() ä¸èƒ½æ­£å¸¸ç”³è¯·åˆ° VM çš„å†…å­˜ã€‚ä¹Ÿè®¸æ˜¯ WSL 2 ä¸Šçš„ cuda æ˜¯ ubuntu20.04 çš„ç‰ˆæœ¬ï¼Œä¸æ˜¯ WSL 2 ç‰¹ä¾›ç‰ˆã€‚WSL 2 çš„ cuda ä¹Ÿæœ‰ä¸€äº›é™åˆ¶ï¼Œè¯¦ç»†è§ WSL2 User guide ã€‚
1. ä»€ä¹ˆæ˜¯ Nsight System æˆ‘ä»¬å…ˆçœ‹ä¸‹ Nsight System å®˜ç½‘å¯¹è¯¥å·¥å…·çš„æè¿°ï¼š
NVIDIA Nsightâ„¢ Systems is a system-wide performance analysis tool designed to visualize an applicationâ€™s algorithms, help you identify the largest opportunities to optimize, and tune to scale efficiently across any quantity or size of CPUs and GPUs, from large servers to our smallest system on a chip (SoC)."><meta itemprop="datePublished" content="2023-04-18T00:00:00+00:00" />
<meta itemprop="dateModified" content="2023-04-18T00:00:00+00:00" />
<meta itemprop="wordCount" content="1190">
<meta itemprop="keywords" content="CUDA," />
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+SC:400,700">

	<link rel="stylesheet" href="/keep-moving-forward/css/style.css">
	

	<link rel="shortcut icon" href="/keep-moving-forward/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		
<header class="header">
	<div class="container header__container">
		
	<div class="logo logo--mixed" >
		<a class="logo__link" href="/keep-moving-forward/" title="Ubios Home" rel="home" >
			
			<div class="logo__item logo__text" >
					<div class="logo__title" >Ubios Home</div>
					<div class="logo__tagline">Remember brick walls let us show our dedication. They are there to separate us from the people who don&#39;t really want to achieve their childhood dreams. --Randy Pausch</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/about/">
				
				<span class="menu__text">About</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/hpc_ai/">
				
				<span class="menu__text">HPC &amp; AI å…¥å‘</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/lecture_notes/">
				
				<span class="menu__text">Lecture-Notes</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/paper_posts/">
				
				<span class="menu__text">Paper-Notes</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/tech_posts/">
				
				<span class="menu__text">Tech-Posts</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/thinking/">
				
				<span class="menu__text">Thinking</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/keep-moving-forward/about/news/">
				
				<span class="menu__text">ğŸ‰NewsğŸ‰</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			


<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CUDA: NSight System</h1>
			<p class="post__lead">Usage of Nsight System</p>
			<div class="post__meta meta"><div class="meta__item-author meta__item">
	<svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2 0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class="meta__text">chenghua.wang</span>
</div>
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2023-04-18T00:00:00Z">2023-04-18</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/keep-moving-forward/categories/hpc&#43;ai-tools/" rel="category">HPC&#43;AI Tools</a>
	</span>
</div></div>
		</header>

		
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li><a href="#1-ä»€ä¹ˆæ˜¯-nsight-system">1. ä»€ä¹ˆæ˜¯ Nsight System</a></li>
            <li><a href="#2-å¦‚ä½•ä½¿ç”¨-nsight-system">2. å¦‚ä½•ä½¿ç”¨ Nsight System</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
	</div>
</div><div class="content post__content clearfix">
			<p><a href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html">NSight System Document</a></p>
<blockquote>
<p>WSL 2 çš„ cudaMallocHost() ä¸èƒ½æ­£å¸¸ç”³è¯·åˆ° VM çš„å†…å­˜ã€‚ä¹Ÿè®¸æ˜¯ WSL 2 ä¸Šçš„ cuda æ˜¯ ubuntu20.04 çš„ç‰ˆæœ¬ï¼Œä¸æ˜¯ WSL 2 ç‰¹ä¾›ç‰ˆã€‚WSL 2 çš„ cuda ä¹Ÿæœ‰ä¸€äº›é™åˆ¶ï¼Œè¯¦ç»†è§ <a href="https://docs.nvidia.com/cuda/wsl-user-guide/index.html#known-limitations-for-linux-cuda-applications">WSL2 User guide</a> ã€‚</p>
</blockquote>
<hr>
<h3 id="1-ä»€ä¹ˆæ˜¯-nsight-system">1. ä»€ä¹ˆæ˜¯ Nsight System</h3>
<p>æˆ‘ä»¬å…ˆçœ‹ä¸‹ Nsight System å®˜ç½‘å¯¹è¯¥å·¥å…·çš„æè¿°ï¼š</p>
<blockquote>
<p>NVIDIA Nsightâ„¢ Systems is a system-wide performance analysis tool designed to visualize an applicationâ€™s algorithms, help you identify the largest opportunities to optimize, and tune to scale efficiently across any quantity or size of CPUs and GPUs, from large servers to our smallest system on a chip (SoC).</p>
</blockquote>
<p>å¦‚ gperoftools ä¸€æ ·ï¼Œè¿™æ˜¯ä¸ªæ€§èƒ½è°ƒä¼˜å·¥å…·ï¼Œèšç„¦åœ¨ N å®¶çš„ GPU ä¸Šï¼Œå½“ç„¶ï¼ŒCPU ä¹Ÿæ˜¯åœ¨å…¶æ€§èƒ½åˆ†æçš„èŒƒå›´å†…ã€‚Nsight system æ›´å¤šçš„æ—¶å€™æ˜¯æŸ¥çœ‹ Memory Stream(Host2Device, Device2Host) å’Œ è®¡ç®— Kernel ä¹‹é—´çš„å…³ç³»ï¼ŒæŸ¥çœ‹æœ‰æ— åˆç†çš„å¡«å……æ»¡æµæ°´çº¿ï¼Œæ›´å¥½çš„åˆ©ç”¨ GPU çš„å¹¶è¡Œæ€§ã€‚</p>
<p>Nsight system ä¸»è¦æ˜¯é€šè¿‡é‡‡æ ·å’Œè¿½è¸ªæ¥åšæŠ“å–ç³»ç»Ÿä¿¡æ¯ï¼š</p>
<ul>
<li>sampling æ˜¯ç¡¬ä»¶å±‚é¢çš„å®ç° ï¼Œåˆ©ç”¨äº†Linux OS&rsquo; perf subsystemï¼Œè·ŸLinux perfå·¥å…·ç”¨çš„ä¸€æ ·ï¼Œå‘¨æœŸæ€§åœ°åœæ­¢ç›®æ ‡ç¨‹åºï¼ˆæ¯”å¦‚æ¯100wä¸ªcycleï¼‰ï¼Œæ”¶é›†æ¯ä¸ªçº¿ç¨‹çš„ CPU Instruction Pointers(IP, æŒ‡ä»¤æŒ‡é’ˆ)ï¼Œä¾¿äºäº†è§£æŸä¸€æ—¶åˆ»ç³»ç»Ÿçš„æ‰§è¡ŒçŠ¶æ€ã€‚</li>
<li>tracing æ˜¯ç²¾ç¡®åœ°é‡‡é›†å„ä¸ªæ´»åŠ¨å¼€å§‹å’Œç»“æŸçš„æ—¶é—´ï¼Œä¾¿äºäº†è§£ç³»ç»Ÿå„ä¸ªç¯èŠ‚çš„æ—¶é—´å¼€é”€å’Œè¿è½¬æƒ…å†µã€‚</li>
</ul>
<h3 id="2-å¦‚ä½•ä½¿ç”¨-nsight-system">2. å¦‚ä½•ä½¿ç”¨ Nsight System</h3>
<p>æˆ‘ä»¥ BGR 2 YUV çš„ä¾‹å­(ä»£ç æ¥è‡ªäº[1])æ¥å±•ç¤ºäº† Nsight system çš„ä¿¡æ¯ã€‚è¯¥ç¤ºä¾‹ä½¿ç”¨äº†ä¸¤ç§æ–¹å¼ï¼š1. å• Stream æ‰§è¡Œï¼›2. 16 Stream æ‰§è¡Œ(Stream çš„æ•°é‡æ²¡æœ‰æ˜ç¡®çš„é™åˆ¶ï¼Œä½†æ˜¯è²Œä¼¼åœ¨æˆ‘çš„æœºå™¨ä¸Šï¼Œæ€§èƒ½æœ€ä¼˜çš„ç»“æœå°±æ˜¯ 16ï¼Œåº”è¯¥ stream å¤šäº†ä»¥åå°±åä¼šè¢«åŠ å…¥è°ƒåº¦é˜Ÿåˆ—äº†)ã€‚</p>
<p>ä¸€èˆ¬åœ¨è°ƒä¼˜çš„æ—¶å€™å…ˆä½¿ç”¨ Nsight system æ¥å¤§ä½“çš„çœ‹ä¸€ä¸‹åŒæ­¥ï¼Œoverlap æ•°æ®æ¬è¿å’Œè®¡ç®—ç­‰æ˜¯ä¸æ˜¯åˆç†ã€‚å¯¹äº Kernel çš„è°ƒä¼˜ä¸€èˆ¬æ˜¯åœ¨ Nsight compute ä¸­ã€‚å½“ç„¶ï¼Œè¯¥å·¥å…·å®é™…ä¸Šä¹Ÿå¯ä»¥æ¥ç›‘æµ‹ Graphic ç›¸å…³çš„ä¸œè¥¿ï¼Œä¸ä»…ä»…æ˜¯åªæœ‰ CUDAã€‚</p>
<p>ä¸ºäº†ä¾¿åˆ©ï¼Œç›´æ¥ä½¿ç”¨ GUI ç•Œé¢æ¥æ“ä½œï¼Œä¸ªäººä¹Ÿæ¨è GUI å¯åŠ¨ï¼Œæ¯•ç«Ÿæœ€ç»ˆè¿˜æ˜¯è¦çœ‹æ—¶é—´è½´å›¾æ¥çš„ç›´è§‚ã€‚å¯¹äºæ²¡è£… GUI çš„æœºå™¨ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ SSH è¿œç¨‹è¿æ¥å®ƒï¼Œä¾¿äºæ“ä½œã€‚</p>
<p>å¯¹äº BGR 2 YUV çš„ä¾‹å­ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨ GUI ä¸­è®¾ç½®ç¨‹åºçš„ä½ç½®å’Œç¨‹åºçš„å¯åŠ¨å‘½ä»¤å³å¯é…ç½®å®Œæˆä¸€ä¸ª Nsight system Projectã€‚(å¯ä»¥çœ‹åˆ°ï¼Œè¿™ä¸ªperfå·¥å…·è¿˜æ”¯æŒå¾ˆå¤šçš„ä¿¡æ¯ç»Ÿè®¡ï¼Œå¦‚ Vulkan å’Œ OpenGL)</p>
<div align="center"> 
<img src="/keep-moving-forward/imgs/nsight_system_project_setting.png" width = "60%"/>
<br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Fig 1. NSight System Project Settings.</div>
</div>
<p>åœ¨é…ç½®å®Œé‡‡æ ·ä¿¡æ¯ï¼Œéœ€è¦è¿½è¸ªçš„ä¿¡æ¯åï¼Œç‚¹å‡» Start å°±æ„‰å¿«çš„å¼€å§‹ç¨‹åºçš„åˆ†æäº†ã€‚åœ¨åˆ†æåçš„ Timeline View ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥æ¸…æ™°çš„çœ‹åˆ°æ¯ä¸ªé˜¶æ®µçš„æ—¶é—´æ¶ˆè€—ã€‚</p>
<div align="center"> 
<img src="/keep-moving-forward/imgs/nsight_system_no_stream.png" width = "80%"/>
<br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Fig 2. 1 Stream.</div>
</div>
<p>æ¯”å¦‚åœ¨ BGR 2 YUV çš„ç¬¬ä¸€ä¸ªä¾‹å­ä¸­(ä¸Šå›¾ï¼Œåªä½¿ç”¨å•ä¸ªStream)ï¼Œä»æ—¶é—´è½´ä¸Šå¯ä»¥çœ‹åˆ°å¹¶è¡Œæ€§å¹¶æ²¡æœ‰èµ·æ¥ï¼Œæˆ‘ä»¬å¯ä»¥å¤šå¼€å‡ ä¸ª Stream è®©æ•°æ®ä¼ è¾“å’Œè®¡ç®—å¹¶è¡Œèµ·æ¥ã€‚é€šè®©æ¯ä¸ª Stream åšä¸åŒçš„å·¥ä½œ(æ•°æ®æ¬è¿ï¼Œè®¡ç®—)ï¼Œæ¥æœ€å¤§åŒ–å¹¶è¡Œã€‚å¦‚ä¸‹å›¾æ‰€ç¤º:</p>
<div align="center"> 
<img src="/keep-moving-forward/imgs/nsight_system_16_stream.png" width = "80%"/>
<br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Fig 3. 16 streams.</div>
</div>
<hr>
<p><strong>code:</strong></p>
<details><summary>[Click to expand]</summary>
<p>ä¸»é¡¹ç›® CMake è®¾ç½®</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cmake" data-lang="cmake"><span style="display:flex;"><span>cmake_minimum_required(<span style="color:#e6db74">VERSION</span> <span style="color:#e6db74">3.18</span>)<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>project(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">cmake_learn</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">LANGUAGES</span> <span style="color:#e6db74">CXX</span> <span style="color:#e6db74">CUDA</span>
</span></span><span style="display:flex;"><span>)<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>if(<span style="color:#e6db74">CUDA_ENABLE</span>)<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>    enable_language(<span style="color:#e6db74">CUDA</span>)<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>endif()<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>set(<span style="color:#e6db74">CMAKE_EXPORT_COMPILE_COMMANDS</span> <span style="color:#e6db74">ON</span> <span style="color:#e6db74">CACHE</span> <span style="color:#e6db74">BOOL</span> <span style="color:#e6db74">&#34;&#34;</span>)<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>message(<span style="color:#e6db74">STATUS</span> <span style="color:#e6db74">&#34;cuda version: &#34;</span> <span style="color:#f92672">${</span>CUDA_VERSION_STRING<span style="color:#f92672">}</span>)<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>include_directories(<span style="color:#f92672">${</span>CUDA_INCLUDE_DIRS<span style="color:#f92672">}</span>)<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>add_subdirectory(<span style="color:#e6db74">&#34;./stream&#34;</span>)<span style="color:#960050;background-color:#1e0010">
</span></span></span></code></pre></div><p>å­é¡¹ç›® CMake è®¾ç½®</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cmake" data-lang="cmake"><span style="display:flex;"><span>project(<span style="color:#e6db74">cuda_stream</span>)<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>add_executable(<span style="color:#e6db74">cuda_stream</span> <span style="color:#e6db74">main.cu</span>)<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>add_compile_options(<span style="color:#e6db74">--cuda-gpu-arch=sm_20</span>)<span style="color:#960050;background-color:#1e0010">
</span></span></span></code></pre></div><p>main.cu</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;vector&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;random&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;iostream&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;cuda.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;cuda_runtime.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#ifdef DEBUG
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#define CUDA_CALL(F)  if( (F) != cudaSuccess ) \
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  {printf(&#34;Error %s at %s:%d\n&#34;, cudaGetErrorString(cudaGetLastError()), \
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   __FILE__,__LINE__); exit(-1);}
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#define CUDA_CHECK()  if( (cudaPeekAtLastError()) != cudaSuccess ) \
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  {printf(&#34;Error %s at %s:%d\n&#34;, cudaGetErrorString(cudaGetLastError()), \
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">   __FILE__,__LINE__-1); exit(-1);}
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#else
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#define CUDA_CALL(F) (F)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#define CUDA_CHECK()
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#endif
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">PrintDeviceInfo</span>();
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">GenerateBgra8K</span>(<span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> buffer, <span style="color:#66d9ef">int</span> dataSize);
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">convertPixelFormatCpu</span>(<span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> inputBgra, <span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> outputYuv, <span style="color:#66d9ef">int</span> numPixels);
</span></span><span style="display:flex;"><span>__global__ <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">convertPixelFormat</span>(<span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> inputBgra, <span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> outputYuv, <span style="color:#66d9ef">int</span> numPixels);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>  PrintDeviceInfo();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> bgraBuffer;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> yuvBuffer;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> deviceBgraBuffer;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> deviceYuvBuffer;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">int</span> dataSizeBgra <span style="color:#f92672">=</span> <span style="color:#ae81ff">7680</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">4320</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">4</span>;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">int</span> dataSizeYuv <span style="color:#f92672">=</span> <span style="color:#ae81ff">7680</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">4320</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">3</span>;
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaMallocHost(<span style="color:#f92672">&amp;</span>bgraBuffer, dataSizeBgra));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaMallocHost(<span style="color:#f92672">&amp;</span>yuvBuffer, dataSizeYuv));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaMalloc(<span style="color:#f92672">&amp;</span>deviceBgraBuffer, dataSizeBgra));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaMalloc(<span style="color:#f92672">&amp;</span>deviceYuvBuffer, dataSizeYuv));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">&gt;</span> yuvCpuBuffer(dataSizeYuv);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  cudaEvent_t start, stop;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">float</span> elapsedTime;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">float</span> elapsedTimeTotal;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">float</span> dataRate;
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventCreate(<span style="color:#f92672">&amp;</span>start));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventCreate(<span style="color:#f92672">&amp;</span>stop));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; &#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Generating 7680 x 4320 BRGA8888 image, data size: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> dataSizeBgra <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  GenerateBgra8K(bgraBuffer, dataSizeBgra);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; &#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Computing results using CPU.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; &#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventRecord(start, <span style="color:#ae81ff">0</span>));
</span></span><span style="display:flex;"><span>  convertPixelFormatCpu(bgraBuffer, yuvCpuBuffer.data(), <span style="color:#ae81ff">7680</span><span style="color:#f92672">*</span><span style="color:#ae81ff">4320</span>);
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventRecord(stop, <span style="color:#ae81ff">0</span>));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventSynchronize(stop));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventElapsedTime(<span style="color:#f92672">&amp;</span>elapsedTime, start, stop));
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Whole process took &#34;</span> <span style="color:#f92672">&lt;&lt;</span> elapsedTime <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;ms.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; &#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Computing results using GPU, default stream.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; &#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Move data to GPU.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventRecord(start, <span style="color:#ae81ff">0</span>));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaMemcpy(deviceBgraBuffer, bgraBuffer, dataSizeBgra, cudaMemcpyHostToDevice));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventRecord(stop, <span style="color:#ae81ff">0</span>));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventSynchronize(stop));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventElapsedTime(<span style="color:#f92672">&amp;</span>elapsedTime, start, stop));
</span></span><span style="display:flex;"><span>  dataRate <span style="color:#f92672">=</span> dataSizeBgra<span style="color:#f92672">/</span>(elapsedTime<span style="color:#f92672">/</span><span style="color:#ae81ff">1000.0</span>)<span style="color:#f92672">/</span><span style="color:#ae81ff">1.0e9</span>;
</span></span><span style="display:flex;"><span>  elapsedTimeTotal <span style="color:#f92672">=</span> elapsedTime;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;        Data transfer took &#34;</span> <span style="color:#f92672">&lt;&lt;</span> elapsedTime <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;ms.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;        Performance is &#34;</span> <span style="color:#f92672">&lt;&lt;</span> dataRate <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;GB/s.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Convert 8-bit BGRA to 8-bit YUV.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventRecord(start, <span style="color:#ae81ff">0</span>));
</span></span><span style="display:flex;"><span>  convertPixelFormat<span style="color:#f92672">&lt;&lt;&lt;</span><span style="color:#ae81ff">32400</span>, <span style="color:#ae81ff">1024</span><span style="color:#f92672">&gt;&gt;&gt;</span>(deviceBgraBuffer, deviceYuvBuffer, <span style="color:#ae81ff">7680</span><span style="color:#f92672">*</span><span style="color:#ae81ff">4320</span>);
</span></span><span style="display:flex;"><span>  CUDA_CHECK();
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaDeviceSynchronize());
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventRecord(stop, <span style="color:#ae81ff">0</span>));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventSynchronize(stop));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventElapsedTime(<span style="color:#f92672">&amp;</span>elapsedTime, start, stop));
</span></span><span style="display:flex;"><span>  dataRate <span style="color:#f92672">=</span> dataSizeBgra<span style="color:#f92672">/</span>(elapsedTime<span style="color:#f92672">/</span><span style="color:#ae81ff">1000.0</span>)<span style="color:#f92672">/</span><span style="color:#ae81ff">1.0e9</span>;
</span></span><span style="display:flex;"><span>  elapsedTimeTotal <span style="color:#f92672">+=</span> elapsedTime;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;        Processing of 8K image took &#34;</span> <span style="color:#f92672">&lt;&lt;</span> elapsedTime <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;ms.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;        Performance is &#34;</span> <span style="color:#f92672">&lt;&lt;</span> dataRate <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;GB/s.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Move data to CPU.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventRecord(start, <span style="color:#ae81ff">0</span>));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaMemcpy(yuvBuffer, deviceYuvBuffer, dataSizeYuv, cudaMemcpyDeviceToHost));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventRecord(stop, <span style="color:#ae81ff">0</span>));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventSynchronize(stop));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventElapsedTime(<span style="color:#f92672">&amp;</span>elapsedTime, start, stop));
</span></span><span style="display:flex;"><span>  dataRate <span style="color:#f92672">=</span> dataSizeYuv<span style="color:#f92672">/</span>(elapsedTime<span style="color:#f92672">/</span><span style="color:#ae81ff">1000.0</span>)<span style="color:#f92672">/</span><span style="color:#ae81ff">1.0e9</span>;
</span></span><span style="display:flex;"><span>  elapsedTimeTotal <span style="color:#f92672">+=</span> elapsedTime;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;        Data transfer took &#34;</span> <span style="color:#f92672">&lt;&lt;</span> elapsedTime <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;ms.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;        Performance is &#34;</span> <span style="color:#f92672">&lt;&lt;</span> dataRate <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;GB/s.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Whole process took &#34;</span> <span style="color:#f92672">&lt;&lt;</span> elapsedTimeTotal <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;ms.&#34;</span> <span style="color:#f92672">&lt;&lt;</span>std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Compare CPU and GPU results ...&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">bool</span> foundMistake <span style="color:#f92672">=</span> false;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; i<span style="color:#f92672">&lt;</span>dataSizeYuv; i<span style="color:#f92672">++</span>){
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span>(yuvCpuBuffer[i]<span style="color:#f92672">!=</span>yuvBuffer[i]){
</span></span><span style="display:flex;"><span>      foundMistake <span style="color:#f92672">=</span> true;
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">break</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span>(foundMistake){
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;        Results are NOT the same.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;        Results are the same.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">int</span> nStreams <span style="color:#f92672">=</span> <span style="color:#ae81ff">16</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; &#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Computing results using GPU, using &#34;</span><span style="color:#f92672">&lt;&lt;</span> nStreams <span style="color:#f92672">&lt;&lt;</span><span style="color:#e6db74">&#34; streams.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; &#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  cudaStream_t streams[nStreams];
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Creating &#34;</span> <span style="color:#f92672">&lt;&lt;</span> nStreams <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; CUDA streams.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> nStreams; i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>    CUDA_CALL(cudaStreamCreate(<span style="color:#f92672">&amp;</span>streams[i]));
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">int</span> brgaOffset <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">int</span> yuvOffset <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">int</span> brgaChunkSize <span style="color:#f92672">=</span> dataSizeBgra <span style="color:#f92672">/</span> nStreams;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">int</span> yuvChunkSize <span style="color:#f92672">=</span> dataSizeYuv <span style="color:#f92672">/</span> nStreams;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventRecord(start, <span style="color:#ae81ff">0</span>));
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; i<span style="color:#f92672">&lt;</span>nStreams; i<span style="color:#f92672">++</span>)
</span></span><span style="display:flex;"><span>  {
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;        Launching stream &#34;</span> <span style="color:#f92672">&lt;&lt;</span> i <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>    brgaOffset <span style="color:#f92672">=</span> brgaChunkSize<span style="color:#f92672">*</span>i;
</span></span><span style="display:flex;"><span>    yuvOffset <span style="color:#f92672">=</span> yuvChunkSize<span style="color:#f92672">*</span>i;
</span></span><span style="display:flex;"><span>    CUDA_CALL(cudaMemcpyAsync(  deviceBgraBuffer<span style="color:#f92672">+</span>brgaOffset,
</span></span><span style="display:flex;"><span>                                bgraBuffer<span style="color:#f92672">+</span>brgaOffset,
</span></span><span style="display:flex;"><span>                                brgaChunkSize,
</span></span><span style="display:flex;"><span>                                cudaMemcpyHostToDevice,
</span></span><span style="display:flex;"><span>                                streams[i] ));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    convertPixelFormat<span style="color:#f92672">&lt;&lt;&lt;</span><span style="color:#ae81ff">4096</span>, <span style="color:#ae81ff">1024</span>, <span style="color:#ae81ff">0</span>, streams[i]<span style="color:#f92672">&gt;&gt;&gt;</span>(deviceBgraBuffer<span style="color:#f92672">+</span>brgaOffset, deviceYuvBuffer<span style="color:#f92672">+</span>yuvOffset, brgaChunkSize<span style="color:#f92672">/</span><span style="color:#ae81ff">4</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    CUDA_CALL(cudaMemcpyAsync(  yuvBuffer<span style="color:#f92672">+</span>yuvOffset,
</span></span><span style="display:flex;"><span>                                deviceYuvBuffer<span style="color:#f92672">+</span>yuvOffset,
</span></span><span style="display:flex;"><span>                                yuvChunkSize,
</span></span><span style="display:flex;"><span>                                cudaMemcpyDeviceToHost,
</span></span><span style="display:flex;"><span>                                streams[i] ));
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  CUDA_CHECK();
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaDeviceSynchronize());
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventRecord(stop, <span style="color:#ae81ff">0</span>));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventSynchronize(stop));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaEventElapsedTime(<span style="color:#f92672">&amp;</span>elapsedTime, start, stop));
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Whole process took &#34;</span> <span style="color:#f92672">&lt;&lt;</span> elapsedTime <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;ms.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Compare CPU and GPU results ...&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; i<span style="color:#f92672">&lt;</span>dataSizeYuv; i<span style="color:#f92672">++</span>){
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span>(yuvCpuBuffer[i]<span style="color:#f92672">!=</span>yuvBuffer[i]){
</span></span><span style="display:flex;"><span>      foundMistake <span style="color:#f92672">=</span> true;
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">break</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span>(foundMistake){
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;        Results are NOT the same.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;        Results are the same.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaFreeHost(bgraBuffer));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaFreeHost(yuvBuffer));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaFree(deviceBgraBuffer));
</span></span><span style="display:flex;"><span>  CUDA_CALL(cudaFree(deviceYuvBuffer));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">PrintDeviceInfo</span>(){
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">int</span> deviceCount <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>  cudaGetDeviceCount(<span style="color:#f92672">&amp;</span>deviceCount);
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Number of device(s): &#34;</span> <span style="color:#f92672">&lt;&lt;</span> deviceCount <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span> (deviceCount <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>) {
</span></span><span style="display:flex;"><span>      std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;There is no device supporting CUDA&#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">return</span>;
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  cudaDeviceProp info;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; i<span style="color:#f92672">&lt;</span>deviceCount; i<span style="color:#f92672">++</span>){
</span></span><span style="display:flex;"><span>    cudaGetDeviceProperties(<span style="color:#f92672">&amp;</span>info, i);
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Device &#34;</span> <span style="color:#f92672">&lt;&lt;</span> i <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Name:                    &#34;</span> <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>string(info.name) <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Glocbal memory:          &#34;</span> <span style="color:#f92672">&lt;&lt;</span> info.totalGlobalMem<span style="color:#f92672">/</span><span style="color:#ae81ff">1024.0</span><span style="color:#f92672">/</span><span style="color:#ae81ff">1024.0</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; MB&#34;</span><span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Shared memory per block: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> info.sharedMemPerBlock<span style="color:#f92672">/</span><span style="color:#ae81ff">1024.0</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; KB&#34;</span><span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Warp size:               &#34;</span> <span style="color:#f92672">&lt;&lt;</span> info.warpSize<span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Max thread per block:    &#34;</span> <span style="color:#f92672">&lt;&lt;</span> info.maxThreadsPerBlock<span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Thread dimension limits: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> info.maxThreadsDim[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; x &#34;</span>
</span></span><span style="display:flex;"><span>                                                 <span style="color:#f92672">&lt;&lt;</span> info.maxThreadsDim[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; x &#34;</span>
</span></span><span style="display:flex;"><span>                                                 <span style="color:#f92672">&lt;&lt;</span> info.maxThreadsDim[<span style="color:#ae81ff">2</span>]<span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Max grid size:           &#34;</span> <span style="color:#f92672">&lt;&lt;</span> info.maxGridSize[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; x &#34;</span>
</span></span><span style="display:flex;"><span>                                                 <span style="color:#f92672">&lt;&lt;</span> info.maxGridSize[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; x &#34;</span>
</span></span><span style="display:flex;"><span>                                                 <span style="color:#f92672">&lt;&lt;</span> info.maxGridSize[<span style="color:#ae81ff">2</span>]<span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;    Compute capability:      &#34;</span> <span style="color:#f92672">&lt;&lt;</span> info.major <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;.&#34;</span> <span style="color:#f92672">&lt;&lt;</span> info.minor <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">GenerateBgra8K</span>(<span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> buffer, <span style="color:#66d9ef">int</span> dataSize){
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>random_device rd;
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>mt19937 gen(rd());
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>uniform_int_distribution<span style="color:#f92672">&lt;&gt;</span> sampler(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; i<span style="color:#f92672">&lt;</span>dataSize<span style="color:#f92672">/</span><span style="color:#ae81ff">4</span>; i<span style="color:#f92672">++</span>){
</span></span><span style="display:flex;"><span>    buffer[i<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>] <span style="color:#f92672">=</span> sampler(gen);
</span></span><span style="display:flex;"><span>    buffer[i<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">=</span> sampler(gen);
</span></span><span style="display:flex;"><span>    buffer[i<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">2</span>] <span style="color:#f92672">=</span> sampler(gen);
</span></span><span style="display:flex;"><span>    buffer[i<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">255</span>;
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">convertPixelFormatCpu</span>(<span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> inputBgra, <span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> outputYuv, <span style="color:#66d9ef">int</span> numPixels){
</span></span><span style="display:flex;"><span>  short3 yuv16;
</span></span><span style="display:flex;"><span>  char3 yuv8;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> idx<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; idx<span style="color:#f92672">&lt;</span>numPixels; idx<span style="color:#f92672">++</span>){
</span></span><span style="display:flex;"><span>    yuv16.x <span style="color:#f92672">=</span> <span style="color:#ae81ff">66</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">2</span>] <span style="color:#f92672">+</span> <span style="color:#ae81ff">129</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> <span style="color:#ae81ff">25</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>];
</span></span><span style="display:flex;"><span>    yuv16.y <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">38</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">2</span>] <span style="color:#f92672">+</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">74</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> <span style="color:#ae81ff">112</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>];
</span></span><span style="display:flex;"><span>    yuv16.z <span style="color:#f92672">=</span> <span style="color:#ae81ff">112</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">2</span>] <span style="color:#f92672">+</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">94</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">18</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>];
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    yuv8.x <span style="color:#f92672">=</span> (yuv16.x<span style="color:#f92672">&gt;&gt;</span><span style="color:#ae81ff">8</span>)<span style="color:#f92672">+</span><span style="color:#ae81ff">16</span>;
</span></span><span style="display:flex;"><span>    yuv8.y <span style="color:#f92672">=</span> (yuv16.y<span style="color:#f92672">&gt;&gt;</span><span style="color:#ae81ff">8</span>)<span style="color:#f92672">+</span><span style="color:#ae81ff">128</span>;
</span></span><span style="display:flex;"><span>    yuv8.z <span style="color:#f92672">=</span> (yuv16.z<span style="color:#f92672">&gt;&gt;</span><span style="color:#ae81ff">8</span>)<span style="color:#f92672">+</span><span style="color:#ae81ff">128</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span>(<span style="color:#66d9ef">reinterpret_cast</span><span style="color:#f92672">&lt;</span>char3<span style="color:#f92672">*&gt;</span>(<span style="color:#f92672">&amp;</span>outputYuv[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">3</span>])) <span style="color:#f92672">=</span> yuv8;
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">convertPixelFormat</span>(<span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> inputBgra, <span style="color:#66d9ef">uint8_t</span><span style="color:#f92672">*</span> outputYuv, <span style="color:#66d9ef">int</span> numPixels){
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">int</span> stride <span style="color:#f92672">=</span> gridDim.x <span style="color:#f92672">*</span> blockDim.x;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">int</span> idx <span style="color:#f92672">=</span> threadIdx.x <span style="color:#f92672">+</span> blockIdx.x <span style="color:#f92672">*</span> blockDim.x;
</span></span><span style="display:flex;"><span>  short3 yuv16;
</span></span><span style="display:flex;"><span>  char3 yuv8;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">while</span>(idx<span style="color:#f92672">&lt;=</span>numPixels){
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span>(idx<span style="color:#f92672">&lt;</span>numPixels){
</span></span><span style="display:flex;"><span>      yuv16.x <span style="color:#f92672">=</span> <span style="color:#ae81ff">66</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">2</span>] <span style="color:#f92672">+</span> <span style="color:#ae81ff">129</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> <span style="color:#ae81ff">25</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>];
</span></span><span style="display:flex;"><span>      yuv16.y <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">38</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">2</span>] <span style="color:#f92672">+</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">74</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> <span style="color:#ae81ff">112</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>];
</span></span><span style="display:flex;"><span>      yuv16.z <span style="color:#f92672">=</span> <span style="color:#ae81ff">112</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">2</span>] <span style="color:#f92672">+</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">94</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">18</span><span style="color:#f92672">*</span>inputBgra[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>];
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      yuv8.x <span style="color:#f92672">=</span> (yuv16.x<span style="color:#f92672">&gt;&gt;</span><span style="color:#ae81ff">8</span>)<span style="color:#f92672">+</span><span style="color:#ae81ff">16</span>;
</span></span><span style="display:flex;"><span>      yuv8.y <span style="color:#f92672">=</span> (yuv16.y<span style="color:#f92672">&gt;&gt;</span><span style="color:#ae81ff">8</span>)<span style="color:#f92672">+</span><span style="color:#ae81ff">128</span>;
</span></span><span style="display:flex;"><span>      yuv8.z <span style="color:#f92672">=</span> (yuv16.z<span style="color:#f92672">&gt;&gt;</span><span style="color:#ae81ff">8</span>)<span style="color:#f92672">+</span><span style="color:#ae81ff">128</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">*</span>(<span style="color:#66d9ef">reinterpret_cast</span><span style="color:#f92672">&lt;</span>char3<span style="color:#f92672">*&gt;</span>(<span style="color:#f92672">&amp;</span>outputYuv[idx<span style="color:#f92672">*</span><span style="color:#ae81ff">3</span>])) <span style="color:#f92672">=</span> yuv8;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    idx <span style="color:#f92672">+=</span> stride;
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div></details>
<hr>
<p><strong>Reference:</strong></p>
<p>[1] <a href="https://zhuanlan.zhihu.com/p/51402722">CUDAéšç¬”ä¹‹Streamçš„ä½¿ç”¨</a></p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/keep-moving-forward/tags/cuda/" rel="tag">CUDA</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="chenghua.wang avatar" src="/keep-moving-forward/img/Cornell_box.png" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About chenghua.wang</span>
	</div>
	<div class="authorbox__description">
		Learning and developing Machine learning infrastructure now. Did some works in Computer Vision and Graphics.
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/keep-moving-forward/tech/xv6_lab5_cow/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">XV6 Lab 5: Copy On Write</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/keep-moving-forward/tech/how_to_optimize_convlution/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">How to Optimize Convolution</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 chenghua.wang.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/keep-moving-forward/js/menu.js"></script>




<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { fonts: ["TeX"] }
  });
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async>
</script>
</body>
</html>