<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/keep-moving-forward/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=keep-moving-forward/livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>[Fundamental] From Online Softmax to Flash Attention V3 | Ubios Home</title>
<meta name="keywords" content="LLM Server, LLM">
<meta name="description" content="Flash Attention from Fundamental Series">
<meta name="author" content="chenghua.Wang">
<link rel="canonical" href="http://localhost:1313/keep-moving-forward/tech/fundamental_from_online_softmax_to_flash_attentionv3/">
<link crossorigin="anonymous" href="/keep-moving-forward/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/keep-moving-forward/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/keep-moving-forward/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/keep-moving-forward/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/keep-moving-forward/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/keep-moving-forward/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/keep-moving-forward/tech/fundamental_from_online_softmax_to_flash_attentionv3/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>



  

<meta property="og:title" content="[Fundamental] From Online Softmax to Flash Attention V3" />
<meta property="og:description" content="Flash Attention from Fundamental Series" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/keep-moving-forward/tech/fundamental_from_online_softmax_to_flash_attentionv3/" /><meta property="article:section" content="tech" />
<meta property="article:published_time" content="2024-08-10T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-08-10T00:00:00+00:00" />



<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[Fundamental] From Online Softmax to Flash Attention V3"/>
<meta name="twitter:description" content="Flash Attention from Fundamental Series"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Technique",
      "item": "http://localhost:1313/keep-moving-forward/tech/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "[Fundamental] From Online Softmax to Flash Attention V3",
      "item": "http://localhost:1313/keep-moving-forward/tech/fundamental_from_online_softmax_to_flash_attentionv3/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "[Fundamental] From Online Softmax to Flash Attention V3",
  "name": "[Fundamental] From Online Softmax to Flash Attention V3",
  "description": "Flash Attention from Fundamental Series",
  "keywords": [
    "LLM Server", "LLM"
  ],
  "articleBody": "0x00 Materials æœ¬æ–‡æ˜¯å¯¹Flash Attentionçš„å­¦ä¹ ç¬”è®°ï¼Œå…¶ä¸­æœ‰ä¸å°‘å†…å®¹æ˜¯æ‘˜è‡ªä¸šå†…çš„å‰è¾ˆä»¬çš„æ–‡ç« ï¼Œåœ¨æ­¤ä¸€å¹¶æ„Ÿè°¢ã€‚æ‰€å‚è€ƒçš„èµ„æ–™ã€æ‘˜å½•çš„æ–‡ç« æ¥æºåœ¨ä¸‹é¢åˆ—å‡ºï¼š\nFrom Online Softmax to FlashAttention(CSE599m, ML for ML System) ,æœ¬æ–‡çš„è¡Œæ–‡é€»è¾‘ä¹Ÿæ˜¯æŒ‰ç…§è¿™ç¯‡æ–‡ç« æ¥çš„ã€‚å¼ºçƒˆå®‰åˆ©CSE599mç»™å…¥é—¨ML Systemçš„æ–°äººã€‚\nFlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\nFlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning\nã€BBufçš„CUDAç¬”è®°ã€‘åå››ï¼ŒOpenAI Tritonå…¥é—¨ç¬”è®°ä¸‰ FusedAttention\n[Attentionä¼˜åŒ–][2wå­—]ğŸ”¥åŸç†\u0026å›¾è§£: ä»Online-Softmaxåˆ°FlashAttention V1/V2/V3\n0x01 é—®é¢˜å®šä¹‰ $$ \\text{Attention} = \\text{Softmax}(\\frac{QK^T}{\\sqrt{d_k}})V $$\n$$ Q,K,V \\in \\mathbb{R}^{N\\times D} $$\nå…¶ä¸­$N$è¡¨ç¤ºSequence Length,$D$è¡¨ç¤ºDimensionã€‚æˆ‘ä»¬å…ˆæ¥è€ƒè™‘æœ€ç®€å•çš„è®¡ç®—æ–¹å¼ï¼š\n$$ S = QK^T $$\n$$ P = \\text{Softmax}(S) $$\n$$ O = PV $$\nåœ¨è¿™ä¸ªNaiveçš„è®¡ç®—æ–¹å¼ä¸­ï¼Œ$P,S \\in \\mathbb R^{N\\times N}$ï¼Œè¿™æ„å‘³ç€ä¸ºäº†è®¡ç®—Pï¼Œæˆ‘ä»¬éœ€è¦å¤šä¿å­˜ä¸€ä¸ª$N\\times N$çš„çŸ©é˜µï¼Œè¿™ä¸ªæƒ…å†µä¸‹å†…å­˜çš„éœ€æ±‚æ˜¯$O(N^2)$çš„ï¼Œå¾ˆå®¹æ˜“çˆ†æ˜¾å­˜ï¼›ä¸”ä¸ºäº†è®¡ç®—$Så’ŒP$åŠ¿å¿…éœ€è¦ä»HBMä¸­è¿›è¡Œå¤§é‡çš„è¯»å†™æ“ä½œï¼ŒIOçš„è®¿é—®æ¬¡æ•°æ˜¯$O(N^2 + ND)$å¤æ‚åº¦çš„ã€‚éšç€ç°åœ¨çš„Context Lengthéœ€æ±‚è¶Šæ¥è¶Šå¤§ï¼Œåœ¨$N$å˜å¤§çš„æ—¶å€™ï¼Œæ˜¯å¾ˆå®¹æ˜“çˆ†æ˜¾å­˜çš„ã€‚æ€»ç»“é—®é¢˜ï¼Œä¸»è¦æœ‰ï¼š\nSequence Length($N$)è¶Šå¤§ï¼Œä¼ ç»Ÿçš„Attentionè®¡ç®—æ–¹æ³•å¾ˆå®¹æ˜“çˆ†æ˜¾å­˜ã€‚ ä¼ ç»Ÿçš„Attentionè®¡ç®—æ–¹å¼å¯¹HBMçš„è®¿é—®å¤æ‚åº¦æ˜¯å¹³æ–¹çº§åˆ«çš„ï¼Œè¶Šé•¿çš„$N$ï¼Œè€—æ—¶è¶Šé•¿ã€‚ HBM / Shared Mem IO BandwidthFrom FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\nè€ƒè™‘åˆ°HBMï¼ŒShared Memoryçš„é€Ÿåº¦å·®å¼‚ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå‡å°‘HBM Accessè€Œå°†æ›´å¤šçš„IO Accessæ“ä½œæ”¾åœ¨Shared Memoryä¸­ã€‚\n0x02 Online Softmax æˆ‘ä»¬å†æ¥çœ‹ä¸‹Safe Softmaxçš„é€»è¾‘:\n$$ S_i = \\frac{e^{x_i - M}}{\\sum_{i=0}^N e^{x_i - M}}, M = \\max{X},X \\in \\mathbb{R}^{N} $$ ã€‚æˆ‘ä»¬å…ˆç”¨ä¸€ä¸ªéå¸¸naiveçš„æ€è·¯æ¥å®ç°è¿™ä¸ªSoftmaxï¼Œè¿™é‡Œä½¿ç”¨From Online Softmax to FlashAttentionæ–‡ç« ä¸­çš„ä¼ªä»£ç æ¥è§£é‡Šï¼š\nOnline Softmax ä¼ªä»£ç From From Online Softmax to FlashAttention(CSE599m, ML for ML System)\nåœ¨è¿™ä¸ªç®€å•çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸‰ä¸ªå¾ªç¯æ¥è¿›è¡Œè®¡ç®—ï¼Œè¿™è¦æ±‚æˆ‘ä»¬å¯¹$[1; N]$è¿›è¡Œä¸‰æ¬¡è¿­ä»£ã€‚è€ŒSelf-Attentionä¸­ï¼Œå› ä¸ºSRAMæ”¾ä¸ä¸‹é‚£ä¹ˆå¤šçš„æ•°æ®ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸‰æ¬¡è®¿é—®$Q$å’Œ $K$ï¼ˆå¹¶ä¸”é‡æ–°è®¡ç®—ï¼‰ï¼Œè¿™åœ¨$I/O$æ•ˆç‡ä¸Šæ˜¯ä¸åˆ©çš„ã€‚\né‚£ä¹ˆï¼Œæœ‰æ²¡æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥åˆå¹¶ä¸€äº›Passï¼Œå°±åƒæ˜¯æˆ‘ä»¬ç»å¸¸åœ¨Kernel Fusionä¸­åšçš„é‚£æ ·å‘¢ï¼Ÿåˆçœ‹ä¼¼ä¹å›°éš¾ï¼Œå› ä¸ºå…¬å¼(8)ä¾èµ–äºå…¬å¼(7)æ‰€å¾—åˆ°çš„è®¡ç®—ç»“æœï¼Œä½†æ˜¯ï¼Œä½¿ç”¨ä¸€äº›å˜æ¢ï¼Œå¯ä»¥å…è®¸æˆ‘ä»¬ä»¥é‡è®¡ç®—ä¸€éƒ¨åˆ†æ•°æ®ä¸ºä»£ä»·æ¥åˆå¹¶å…¬å¼(7, 8)ã€‚\nç°åœ¨ï¼Œæˆ‘ä»¬æ¥æ¨å¯¼ä¸‹å…¬å¼ï¼Œ\n$$ \\begin{aligned} d_{i}^{\\prime}\u0026 =\\sum_{j=1}^ie^{x_j-m_i} \\\\ \u0026= \\left(\\sum_{j=1}^{i-1} e^{x_j-m_i}\\right)+e^{x_i-m_i} \\\\ \u0026= \\left(\\sum_{j=1}^{i-1} e^{x_j-m_{i-1}}\\right)e^{m_{i-1}-m_i}+e^{x_i-m_i} \\\\ \u0026= d_{i-1}â€™ e^{m_{i-1}-m_i}+e^{x_i-m_i} \\end{aligned} $$\næˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ä¸ªé€’æ¨çš„å…¬å¼ï¼Œå…¶ä¸­$d_N^{\\prime}$ä¸ºæœ€åæˆ‘ä»¬éœ€è¦çš„åŠ å’Œï¼Œå³$\\sum_{i=0}^{N}e^{x_i-m_N}$ã€‚åœ¨è¿™ä¸ªé€’æ¨å…¬å¼ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ–°çš„$m$æ¥ä¿®æ­£ä¹‹å‰çš„$d_i^{\\prime}$ï¼Œä¹‹å‰é”™è¯¯çš„$m$å¯ä»¥é€šè¿‡å¹‚ç›¸ä¹˜çš„è®¡ç®—è§„åˆ™æ¶ˆå»ã€‚æ€»çš„è®¡ç®—æµç¨‹è¢«ç¼©å‡ä¸º2ä¸ªPassï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\nOnline Softmax 2 passes ä¼ªä»£ç From From Online Softmax to FlashAttention(CSE599m, ML for ML System)\nä½†æ˜¯ï¼Œè¿™ä¸ªè®¡ç®—æ–¹å¼è¿˜æ˜¯æœ‰ä¸¤ä¸ªPassï¼Œæˆ‘ä»¬èƒ½ä¸èƒ½å°†æ‰€æœ‰çš„è®¡ç®—Fuseåˆ°ä¸€ä¸ªPassä¸­å»å‘¢ï¼Ÿ\nåœ¨Online Softmaxä¸­å¾ˆéš¾åšåˆ°è¿™ä¸€ç‚¹ï¼Œå› ä¸º$a_i$æ‰€éœ€è¦çš„$m_N,d_N^{\\prime}$ä¾èµ–äºå…¨å±€æ›´æ–°ã€‚è€Œ$a_i$æ˜¯ä¸€ä¸ªæ— æ³•å…¨å±€æ›´æ–°çš„å˜é‡ï¼Œé™¤éåœ¨ç¬¬ä¸€ä¸ªPassä¸­å†åµŒå¥—ä¸€ä¸ªå¾ªç¯ï¼Œè¿™æ ·è¿èƒŒäº†æˆ‘ä»¬ç®€åŒ–è®¡ç®—çš„åˆè¡·ã€‚ä½†æ˜¯ï¼Œå°†é—®é¢˜æ”¾åœ¨Self-Attentionçš„è®¡ç®—çš„æ—¶å€™ï¼Œå°±å˜å¾—ä¸ä¸€æ ·äº†ã€‚\næˆ‘ä»¬åœ¨è¿™é‡Œå†ç†è§£ä¸‹ï¼Œä¸ºä»€ä¹ˆ2Passçš„Online Safe Softmaxæ˜¯é‡è¦çš„ï¼Œåœ¨Self-Attentionçš„è®¡ç®—ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸‹é¢2ä¸ªä¸»è¦çš„é—®é¢˜ï¼š\néœ€è¦æå‰è®¡ç®—å¥½$QK^T$ï¼Œä¿å­˜åœ¨å…¨å±€æ˜¾å­˜ä¸­ï¼Œéœ€è¦$O(N^2)$çš„æ˜¾å­˜ï¼Œå®¹æ˜“çˆ†æ˜¾å­˜ã€‚ åœ¨ç®—æ³•ä¸­Onlineè®¡ç®—ï¼Œæ¯æ¬¡å¾ªç¯ä¸­å»åŠ è½½ä¸€éƒ¨åˆ†$Q,K$åˆ°ç‰‡ä¸Šå†…å­˜ï¼Œè®¡ç®—å¾—åˆ°éƒ¨åˆ†çš„$QK^T$ã€‚ æ€»çš„æ¥è¯´ï¼ŒOnline Softmaxè§£å†³çš„æ˜¯æ˜¾å­˜ä¸è¶³çš„é—®é¢˜ï¼Œä½†æ˜¯å› ä¸ºæœ‰ä¸¤ä¸ªPassï¼Œè¿˜æ˜¯å­˜åœ¨HBM R/Wæ¬¡æ•°è¾ƒå¤šï¼Œæœ‰Memory Boundï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ¶ˆé™¤è¿™ä¸ªç“¶é¢ˆã€‚è™½ç„¶ç°åœ¨æˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸€ä¸ª$d_i^{\\prime}$åšScaleï¼Œä½†æ˜¯è€ƒè™‘åˆ°ç›®å‰æ˜¾å¡å¹¶ä¸æ˜¯Compute Boundï¼Œè¿™å¤šä½™çš„è®¡ç®—æ˜¯å¯ä»¥æš‚æ—¶ä¸å»è€ƒè™‘çš„ã€‚\n0x03 FA1 è™½ç„¶åœ¨Online Softmaxä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰åŠæ³•å¾—åˆ°ä¸€ä¸ª1 Passçš„ç®—æ³•ï¼Œä½†æ˜¯åœ¨Self-Attentionä¸­ï¼Œæˆ‘ä»¬éœ€è¦çš„æ˜¯è®¡ç®—å‡º$O=A\\times V$ï¼Œè€Œä¸æ˜¯$A$ï¼Œè¿™æœ‰ä»€ä¹ˆä¸åŒå‘¢ï¼Ÿæˆ‘ä»¬æ¥æ¨å¯¼ä¸‹å…¬å¼ï¼Œä¸è¿‡é¦–å…ˆï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹åŸå§‹çš„Self-Attentionæ˜¯æ€ä¹ˆæ±‚è§£çš„ï¼š\nåŸå§‹çš„Self-Attention ä¼ªä»£ç From From Online Softmax to FlashAttention(CSE599m, ML for ML System)\nè¿™å¼ æœªæ‰“ç æµç¨‹å›¾ä»ç„¶æ˜¯ä»CSE 599mä¸­å€Ÿç”¨çš„ã€‚å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ç¬¬ä¸€ä¸ªPassä¸­ï¼Œå°±æ˜¯0x02ç« èŠ‚ä¸­æåŠçš„Online Softmaxï¼›åœ¨ç¬¬äºŒä¸ªPassä¸­ï¼Œ$o_i$çš„è®¡ç®—å¯èƒ½ç¨æœ‰ç‚¹éš¾ä»¥ç†è§£ï¼Œå¯ä»¥ç”»å¼ å›¾ã€‚å®é™…ä¸Šå°±æ˜¯éå†$a_i$å°±æ˜¯$\\text{Attention}$çŸ©é˜µçš„ä¸€è¡Œï¼Œæ‹¿æ¯ä¸€è¡Œçš„æ¯ä¸ªå€¼$a_i$å»ä¹˜$V$çŸ©é˜µçš„æ¯ä¸€è¡Œï¼Œå°±æ˜¯è¡Œä¹˜åˆ—æ“ä½œã€‚è¿™ä¸ªæ“ä½œå¯ä»¥åŒæ—¶æŠŠ$O$çŸ©é˜µçš„ä¸€è¡Œç»™ç®—å‡ºæ¥ã€‚\n$$o_i^{\\prime}:=\\left(\\sum_{j=1}^i\\frac{e^{x_j-m_i}}{d_i^{\\prime}}V[j,:]\\right)$$\nä¸Šé¢çš„å…¬å¼å°±æ˜¯æŠŠPass2å†…éƒ¨çš„è®¡ç®—æ•´åˆåœ¨äº†ä¸€èµ·ï¼Œå’Œ0x02ç« èŠ‚çš„æ¨å¯¼ä¸€æ ·ï¼Œæˆ‘ä»¬ä¹Ÿå»å°è¯•åšé€’æ¨ï¼š\n$$ \\begin{aligned} o_i^{\\prime}\u0026 =\\sum_{j=1}^i\\frac{e^{x_j-m_i}}{d_i'}V[j,:] \\\\ \u0026= \\left(\\sum_{j=1}^{i-1}\\frac{e^{x_j-m_i}}{d_i'}V[j,:] \\right)+\\frac{e^{x_i-m_i}}{d_i'}V[i,: ] \\\\ \u0026= \\left(\\sum_{j=1}^{i-1}\\frac{e^{x_j-m_{i-1}}}{d_{i-1}^{\\prime}}\\frac{e^{x_j-m_i}}{e^{x_j-m_{i-1}}}\\frac{d_{i-1}^{\\prime}}{d_i^{\\prime}}V[j,.]\\right)+\\frac{e^{x_i-m_i}}{d_i^{\\prime}}V[i,.] \\\\ \u0026= \\left(\\sum_{j=1}^{i-1}\\frac{e^{x_j-m_{i-1}}}{d_{i-1}^{\\prime}}V[j,:]\\right)\\frac{d_{i-1}^{\\prime}}{d_i^{\\prime}}e^{m_{i-1}-m_i}+\\frac{e^{x_i-m_i}}{d_i^{\\prime}}V[i,:] \\\\ \u0026=\\begin{array}{c}\\boldsymbol{o}_{i-1}^{\\prime}\\frac{d_{i-1}^{\\prime}e^{m_{i-1}-m_i}}{d_i^{\\prime}}+\\frac{e^{x_i-m_i}}{d_i^{\\prime}}V[i,:]\\end{array} \\end{aligned} $$ å¯ä»¥æ¨å¯¼å‡ºå’ŒOnline Softmaxç›¸ä¼¼çš„å½¢å¼ï¼Œè‡³æ­¤ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºäº†FAç®—æ³•ã€‚\nFA1 ä¼ªä»£ç From From Online Softmax to FlashAttention(CSE599m, ML for ML System)\nå¯ä»¥çœ‹å‡ºï¼Œåœ¨FAç®—æ³•ä¸­ï¼Œ$Q,K,V$éƒ½å¯ä»¥åˆ†å—è½½å…¥ï¼Œæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥å¾—åˆ°FAçš„Tilingæ–¹æ³•ï¼š\nFA1 TiledFrom From Online Softmax to FlashAttention(CSE599m, ML for ML System)\nåœ¨è¿™ç§æ”¹è¿›çš„TilingæŠ€æœ¯ä¸­ï¼ŒKçŸ©é˜µè¢«åˆ’åˆ†ä¸ºå¤šä¸ªè¾ƒå°çš„åŒºå—ï¼ŒåŒæ ·çš„æ–¹æ³•ä¹Ÿé€‚ç”¨äºQçŸ©é˜µã€‚è¿™äº›è¾ƒå°çš„åŒºå—å¯ä»¥è¢«åŠ è½½åˆ°SRAMä¸­ï¼Œä»¥ä¾¿äºè¿›è¡Œé«˜æ•ˆçš„è®¡ç®—ã€‚ä¸€æ—¦è¿™äº›åŒºå—è¢«åŠ è½½ï¼Œå°±å¯ä»¥åœ¨kernelå†…éƒ¨å®Œæˆæ•´ä¸ªæ³¨æ„åŠ›æœºåˆ¶çš„è®¡ç®—è¿‡ç¨‹ã€‚ä»ç®—æ³•çš„è§’åº¦æ¥çœ‹ï¼Œç°åœ¨åªéœ€è¦ä¸€æ¬¡æ€§åŠ è½½Qã€Kã€VçŸ©é˜µï¼Œå°±èƒ½åœ¨å†…æ ¸ä¸­å®Œæˆæ‰€æœ‰çš„æ³¨æ„åŠ›è®¡ç®—ã€‚è¿™ç§ä¼˜åŒ–æ–¹æ³•å°†åŸå§‹3-pass Self Attentionè½¬å˜ä¸º1-pass FlashAttentionï¼Œä¸ä»…èŠ‚çœäº†å­˜å‚¨ä¸­é—´çŸ©é˜µæ‰€éœ€çš„æ˜¾å­˜ï¼Œè¿˜å‡å°‘äº†å¯¹Qå’ŒKçŸ©é˜µçš„HBM R/Wçš„æ¬¡æ•°ã€‚\næœ€ç»ˆï¼ŒFAçš„ç®—æ³•å¯ä»¥è¢«ä¸‹é¢çš„ä¼ªä»£ç æ¥è¡¨ç¤ºï¼š\nFA1 tiled ä¼ªä»£ç From From Online Softmax to FlashAttention(CSE599m, ML for ML System)\næ­¤æ—¶ï¼Œæˆ‘ä»¬å†çœ‹FAçš„ç®—æ³•æµç¨‹å›¾ï¼Œå°±ä¸æ„Ÿè§‰é™Œç”Ÿäº†ã€‚å’Œä¸Šæ–‡ä¸­çš„æ¨å¯¼æ€è·¯ä¸€è‡´ï¼š\nFA1 åŸæ–‡ ä¼ªä»£ç From FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\nåœ¨ç¬¬6è¡Œï¼ŒFAè½½å…¥$K,V$åˆ†å—ï¼Œç„¶ååœ¨ç¬¬8è¡Œéå†å®Œæˆæ‰€æœ‰çš„$Q$ï¼ˆè¿™é‡Œæœ‰ä¸ªæ˜¾è€Œæ˜“è§çš„é—®é¢˜ï¼Œ$Q$çš„éå†æ”¾åœ¨æœ€å¤–é¢ä¼šå¥½å¾ˆå¤šï¼‰ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œå†æ¢è®¨ä¸‹ä¸ºä»€ä¹ˆåˆ†å—$B_c=\\lceil \\frac{M}{4d} \\rceil, B_r=\\min (\\lceil \\frac{M}{4d} \\rceil, d)$ã€‚\nè¿™æ ·è®¾ç½®çš„ç›®çš„æ˜¯ï¼Œä¸ºäº†ç¡®ä¿SRAMèƒ½å¤Ÿæ”¾ä¸‹æ‰€æœ‰$Q, K, V$çš„å°å—ï¼Œå…¶ä¸­$M$å°±æ˜¯ç³»ç»Ÿå¯ç”¨çš„SRAMä¸Šé™ã€‚é‚£ä¹ˆï¼Œå¯¹äºæ¯ä¸€ä¸ª$Q$çš„åˆ†å—$Q_i,O_i$ä»¥åŠ$K, V$çš„åˆ†å—$K_i, V_i$éœ€è¦çš„å…±äº«å†…å­˜ä¸ºï¼š\n$$ \\begin{gathered} SRAM(Q_{i})=B_{r}\\times d=\\min\\left(\\left\\lceil\\frac{M}{4d}\\right\\rceil,d\\right)\\times d\u003c\\lceil\\frac{M}{4}\\rceil \\\\ SRAM(O_i)=B_r\\times d=\\min\\left(\\left\\lceil\\frac{M}{4d}\\right\\rceil,d\\right)\\times d\u003c\\lceil\\frac{M}{4}\\rceil \\\\ SRAM(K_{j},V_{j})=2\\times B_{c}\\times d=2\\times\\left\\lceil\\frac{M}{4d}\\right\\rceil\\times d\u003c\\lceil\\frac{M}{2}\\rceil \\end{gathered} $$\nåœ¨è¿™ä¸ªæƒ…å†µä¸‹ï¼ŒSRAMåŸºæœ¬ä¸Šå¯ä»¥è¢«å æ»¡ã€‚FA1åŸå§‹è®ºæ–‡ä¸­è¯´é“ï¼ŒBlock Size è¶Šå¤§ï¼ŒHBM Accesses è¶Šä½ï¼Œåœ¨256é™„è¿‘åŸºæœ¬å°±æ˜¯æ•ˆç‡æœ€ä¼˜çš„è½¬æŠ˜ç‚¹ã€‚\nFA1 Block Size å®éªŒFrom FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\næ–‡ä¸­çš„å®éªŒæ¡ä»¶æ˜¯A100GPUï¼ŒGPT-2 medium (seq. length 1024, head dim. 64, 16 heads, batch size 64)\n0x04 FA2 åœ¨0x03ç« èŠ‚ä¸­æˆ‘ä»¬æåˆ°ï¼šç„¶ååœ¨ç¬¬8è¡Œéå†å®Œæˆæ‰€æœ‰çš„$Q$ï¼ˆè¿™é‡Œæœ‰ä¸ªæ˜¾è€Œæ˜“è§çš„é—®é¢˜ï¼Œ$Q$çš„éå†æ”¾åœ¨æœ€å¤–é¢ä¼šå¥½å¾ˆå¤šï¼‰ï¼Œè¿™ç‚¹å°±æ˜¯FA2ä¼˜åŒ–çš„å¾ˆé‡è¦çš„ä¸€ç‚¹ã€‚\nFA2ä¸€å…±åšäº†ä¸»è¦çš„å‡ ç§ä¼˜åŒ–ï¼š\nä¼˜åŒ–äº†Scaleçš„æ—¶æœºï¼Œä½¿å¾—é™¤æ³•çš„æ¬¡æ•°è¢«å¤§å¤§å‡å°‘\nForwardä¼˜åŒ–äº†å¾ªç¯çš„é¡ºåºï¼Œä½¿å¾—HBM Accessæ›´åŠ çš„é«˜æ•ˆã€‚Backwardæ²¡æœ‰\nForward/Backwardå‡å¢åŠ äº†Seqç»´åº¦çš„å¹¶è¡Œ\nWarpçš„åˆ†é…æ›´åŠ çš„åˆç†ï¼Œé¿å…Split-K(ä¸æ˜¯å¾ˆç†è§£ï¼Ÿ)\nä¼˜åŒ–äº†Scaleçš„æ—¶æœºï¼Œä½¿å¾—é™¤æ³•çš„æ¬¡æ•°è¢«å¤§å¤§å‡å°‘ è™½ç„¶ä¸€èˆ¬æ¥è¯´ï¼Œématmulè¿ç®—FLOPsè¦æ¯”matmulä½ï¼Œä½†æ˜¯ématmulè®¡ç®—ä½¿ç”¨çš„æ˜¯CUDA Coresï¼Œè€ŒçŸ©é˜µè®¡ç®—å¯ä»¥åˆ©ç”¨Tensor CoresåŠ é€Ÿã€‚åŸºäºTensor Coresçš„matmulè¿ç®—ååæ˜¯ä¸ä½¿ç”¨Tensor Coresçš„ématmulè¿ç®—ååçš„16xã€‚\nä¸FA1ç›¸æ¯”ï¼ŒFA2çš„ä¸»è¦ä¸åŒç‚¹æ˜¯è®¡ç®—æ¯ä¸€æ¬¡çš„$\\boldsymbol{O}^{(n)}$çš„é€»è¾‘ï¼Œè¿™é‡Œä»¥$\\boldsymbol{O}^{(1)},\\boldsymbol{O}^{(2)}$ä¸ºä¾‹æ¥è¯´æ˜ï¼Œåœ¨FA2ä¸­ï¼š\n$$ \\begin{gathered} \\tilde{\\mathbf{o}}^{(1)} =e^{s^{(1)}-m^{(1)}}\\mathbf{V}^{(1)}\\in\\mathbb{R}^{B_{r}\\times d} \\\\ \\tilde{\\mathrm{o}}^{(2)} =e^{s^{(1)}-m}\\mathbf{V}^{(1)}+e^{s^{(2)}-m}\\mathbf{V}^{(2)} \\\\ \\mathrm{o}^{(2)} =\\mathrm{diag}\\left(\\ell^{(2)}\\right)^{-1}\\tilde{\\mathbf{O}}^{(2)}=\\mathbf{O} \\end{gathered} $$\nå…¶ä¸­ï¼Œ$\\tilde{\\mathrm{o}}^{(2)} =e^{s^{(1)}-m}\\mathbf{V}^{(1)}+e^{s^{(2)}-m}\\mathbf{V}^{(2)}$åœ¨è®¡ç®—çš„æ—¶å€™ï¼Œ$e^{s^{(1)}-m}\\mathbf{V}^{(1)}$è¿™ä¸€é¡¹æ˜¯å¯¹$\\tilde{\\mathbf{o}}^{(1)}$åšäº†ç¼©æ”¾ï¼Œç¼©æ”¾å› å­æ˜¯$e^{m^{(1)} - m}$ã€‚ä¹Ÿå°±æ˜¯ï¼š\n$$\\tilde{\\mathrm{o}}^{(2)} = e^{m^{(1)} - m} \\tilde{\\mathbf{o}}^{(1)} +e^{s^{(2)}-m}\\mathbf{V}^{(2)}$$\nç›¸æ¯”äºåŸæ¥çš„FA1ï¼Œæˆ‘ä»¬é¦–å…ˆè®¡ç®—Softmaxçš„åˆ†å­éƒ¨åˆ†ï¼Œåœ¨æœ€åæ‰ç®—ä¸Šåˆ†æ¯ã€‚è¿™æ ·å‡å°‘äº†æ¯æ¬¡è¿­ä»£è€Œå¿…é¡»çš„åˆ†æ¯ç¼©æ”¾ã€‚è€ŒåŸæœ¬çš„FA1çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹å¼æ‰€ç¤ºï¼š\n$$ \\mathbf{O}_{i}\\leftarrow\\mathrm{diag}\\left(\\ell_{i}^{\\mathrm{new}}\\right)^{-1}\\left(\\mathrm{diag}(\\ell_{i})e^{{m_{i}-m_{i}^{\\mathrm{new}}}}\\mathbf{O}_{i}+e^{{\\tilde{m}_{ij}-m_{i}^{\\mathrm{new}}}}\\mathbf{\\tilde{P}}_{ij}\\mathbf{V}_{j}\\right) $$ FA2çš„è®¡ç®—ä¸­ï¼Œå…ˆä¸åœ¨æ¯ä¸ªblockçš„æ¯æ¬¡è¿­ä»£è®¡ç®—ä¸­æ‰§è¡Œå…¨éƒ¨çš„rescaleæ“ä½œï¼Œè€Œæ˜¯æœ€åæ‰§è¡Œä¸€æ¬¡rescaleã€‚æ¯æ¬¡è®¡ç®—å¯ä»¥å‡å°‘ä¸€æ¬¡é™¤æ³•è¿ç®—ã€‚\nFA2 ä¼ªä»£ç From From Online Softmax to FlashAttention(CSE599m, ML for ML System)\nå¯ä»¥çœ‹åˆ°åœ¨åŸæ–‡çš„ä¼ªä»£ç ä¸­ï¼Œåœ¨$T_c$å¾ªç¯ç»“æŸåï¼Œæ‰å»åšäº†åˆ†æ¯ä¸Šçš„è®¡ç®—ã€‚\nç¬¬åè¡Œçš„$\\text{diag}^{-1}$æ˜¯é”™çš„ï¼ŒæŠŠ$^{-1}$å»æ‰ã€‚\nä¼˜åŒ–äº†å¾ªç¯çš„é¡ºåºï¼Œå¢åŠ äº†Seqç»´åº¦çš„å¹¶è¡Œ FA1çš„ä¸¤é‡å¾ªç¯ä¸­ï¼Œæ˜¯å…ˆå¤–å±‚å¾ªç¯load K, Vï¼Œç„¶åå†…å±‚å¾ªç¯å†load Qã€‚è¿™å°±ä¼šå¯¼è‡´å†…å±‚å¾ªç¯ï¼Œæ¯æ¬¡è®¡ç®—çš„åªæ˜¯Qiçš„ä¸€éƒ¨åˆ†ï¼Œæ¯æ¬¡å†…å¾ªç¯çš„è¿­ä»£éƒ½éœ€è¦å¯¹Oiè¿›è¡Œå…¨å±€å†…å­˜çš„è¯»å†™ã€‚è€Œä¸”ï¼Œä¸€ä¸ªæ˜¾è€Œæ˜“è§çš„äº‹å®å°±æ˜¯ï¼Œåœ¨Attentionçš„è®¡ç®—ä¸­ï¼Œä¸åŒqueryçš„Attentionè®¡ç®—æ˜¯å®Œå…¨ç‹¬ç«‹çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœå¤–éƒ¨å¾ªç¯æ˜¯å…ˆload Qï¼Œé‚£ä¹ˆå°±å¯ä»¥æŠŠä¸åŒçš„queryå—çš„Attentionåˆ†é…ä¸åŒthread blockè¿›è¡Œè®¡ç®—ï¼Œè¿™äº›thread blockä¹‹é—´æ˜¯ä¸éœ€è¦é€šä¿¡çš„ã€‚æ²¡é”™ï¼Œåœ¨FA2ä¸­ï¼Œæ­£æ˜¯è¿™æ ·åšçš„ï¼Œå¯¹äºforward passï¼Œç®—æ³•è°ƒæ¢äº†å¾ªç¯çš„é¡ºåºï¼Œå…ˆload Qï¼Œå†load K, Vã€‚\nFA2å¢åŠ seqlenå¹¶è¡Œï¼Œæé«˜äº†occupancyï¼Œå¹¶ä¸”å¯¹äºforward passï¼ŒQ*K^Tåœ¨ã€è¡Œã€‘æ–¹å‘çš„seqlenä¸Šå¤©ç„¶å¯ä»¥å¹¶è¡Œï¼Œthread blockä¹‹é—´ä¸éœ€è¦é¢å¤–çš„é€šä¿¡ã€‚\nWarpçš„åˆ†é…æ›´åŠ çš„åˆç†ï¼Œé¿å…Split-K æ‘˜è‡ª FlashAttentionæ ¸å¿ƒé€»è¾‘ä»¥åŠV1 V2å·®å¼‚æ€»ç»“\nWarp Split-KFrom From Online Softmax to FlashAttention(CSE599m, ML for ML System)\né¦–å…ˆçœ‹fwdï¼Œç›¸æ¯”V1ï¼ŒV2æ”¹è¿›äº†Warp Partitionï¼š4ä¸ªwarpä¼šä»smemçš„K/V tile loadåŒæ ·çš„æ•°æ®åšmmaè®¡ç®—ï¼Œä½†æ˜¯load ä¸åŒQï¼ŒæŠŠV1 sliced-K sliced-V æ”¹æˆäº†v2 sliced-Qï¼ŒV1çš„åšæ³•æ˜¯éœ€è¦warpä¹‹é—´äº§ç”ŸåŒæ­¥é€šä¿¡çš„ï¼Œå› ä¸ºåœ¨è®¡ç®—QKç»“æœä¹˜Vçš„æ—¶å€™ï¼Œå¦‚å›¾æ‰€ç¤ºéœ€è¦è·¨warp reductionå¾—åˆ°Oçš„ç»“æœï¼Œè€Œä¸”fwdçš„ç›®çš„æ˜¯æ²¿ç€è¡Œæ–¹å‘è®¡ç®—softmaxï¼Œè¡Œæ–¹å‘ä¿¡æ¯æœ€åè¦æ±‡æ€»çš„ï¼Œè¿™ä¹Ÿéœ€è¦è·¨warpä¸åŒã€‚V2å°±ä¸éœ€è¦äº†ï¼Œè¿™æ ·å¯ä»¥å‡å°‘åŒæ­¥å¼€é”€ã€‚\n0x05 Causal Maskæ€ä¹ˆç”¨ï¼Ÿ æ‘˜è‡ª [Attentionä¼˜åŒ–][2wå­—]ğŸ”¥åŸç†\u0026å›¾è§£: ä»Online-Softmaxåˆ°FlashAttention V1/V2/V3\néå¸¸ç®€å•çš„Early Exité€»è¾‘ï¼š\næƒ…å†µ0: å…¨Early Exitã€‚å…¨0çš„maskå¯ä»¥ç›´æ¥è¿”å›0ï¼Œæ— éœ€$Q\\times K^T$ï¼Œæ— éœ€causal maskã€‚\næƒ…å†µ1: éƒ¨åˆ†Early Exitã€‚å…¨1çš„maskï¼Œåªéœ€$\\text{Softmax}(Q\\times K^T)$ï¼Œæ— éœ€causal maskã€‚\næƒ…å†µ3: æ— æ³•Early Exitã€‚0-1æ··åˆçš„causal maskï¼Œéœ€QxK^Tï¼Œéœ€è¦causal maskï¼Œç„¶å$\\text{Softmax}(\\text{Mask}(Q \\times K^T))$ã€‚\nMasked ç¤ºæ„å›¾[Attentionä¼˜åŒ–][2wå­—]ğŸ”¥åŸç†\u0026å›¾è§£: ä»Online-Softmaxåˆ°FlashAttention V1/V2/V3\n0x06 MHA/GQA/MQA åœ¨FlashAttentionä¸­ï¼Œä¹Ÿæ”¯æŒMQAå’ŒGQAã€‚å¯¹äºMQAå’ŒGQAçš„æƒ…å½¢ï¼ŒFlashAttentioné‡‡ç”¨Indexingçš„æ–¹å¼ï¼Œè€Œä¸æ˜¯ç›´æ¥å¤åˆ¶å¤šä»½KV Headçš„å†…å®¹åˆ°æ˜¾å­˜ç„¶åå†è¿›è¡Œè®¡ç®—ã€‚Indexingï¼Œå³é€šè¿‡ä¼ å…¥KV/KV Headç´¢å¼•åˆ°Kernelä¸­ï¼Œç„¶åè®¡ç®—å†…å­˜åœ°å€ï¼Œç›´æ¥ä»å†…å­˜ä¸­è¯»å–KVã€‚\n0x07 IOå¤æ‚åº¦åˆ†æ å› ä¸ºFAä¸»è¦æ˜¯ä¼˜åŒ–IO Accesï¼Œæ‰€ä»¥æˆ‘ä»¬åˆ†æä¸‹FAçš„IOå¤æ‚åº¦ã€‚æˆ‘ä»¬å‡è®¾Sequenceçš„é•¿åº¦æ˜¯$N$ï¼Œæ¯ä¸ªå¤´çš„ç»´åº¦æ˜¯$d$ï¼ŒSRAMçš„å¤§å°æ˜¯$M,d \\le M \\le Nd$ã€‚\nä½¿ç”¨åŸå§‹çš„Self Attentionç®—æ³•çš„IOå¤æ‚åº¦æ˜¯$\\Theta(Nd + N^2)$ï¼ŒFA1çš„IOå¤æ‚åº¦æ˜¯$\\Theta(N^2d^2M^{-1})$ï¼Œè€ƒè™‘åˆ°$d$ä¸€èˆ¬æ˜¯64-128ï¼Œè€Œ$M$ä¸€èˆ¬æ˜¯100KBï¼Œæ‰€ä»¥FA1çš„è®¿å­˜æ¬¡æ•°å°äºåŸå§‹çš„åšæ³•ã€‚\nMemory Accesseså’Œdçš„å¹³æ–¹æˆæ­£æ¯”å…³ç³»ï¼Œå½“dè¶Šå¤§ï¼ŒFAçš„Memory Accessesä¼šå¢é•¿å‰§çƒˆã€‚æ¯”å¦‚å¯¹äºN=2K, M=192KB, å½“d=256æ—¶ï¼Œä¾ç„¶æ»¡è¶³ FA IO Acesses \u003c Naive Attentionï¼Œä½†æ˜¯å½“d=512æ—¶ï¼Œè¿™ä¸ªç»“è®ºå°±ä¼šåè¿‡æ¥ï¼Œå˜æˆæ˜¯ FA IO Acesses \u003e Naive Attention IO Acessesï¼Œå¹¶ä¸”ç”±äºFAæœ¬èº«çš„FLOPSå°±æ˜¯æ¯”Naive Attentioné«˜çš„ï¼Œäºæ˜¯ï¼Œæ­¤æ—¶æ— è®ºæ˜¯IOè¿˜æ˜¯FLOPSï¼ŒFAéƒ½ä¼šæ¯”Naive Attentioné«˜ï¼Œæ— è®ºæ˜¯è®¿å­˜è¿˜æ˜¯è®¡ç®—é‡éƒ½æ²¡æœ‰ä¼˜åŠ¿ï¼Œå”¯ä¸€å‰©ä¸‹çš„ä¼˜åŠ¿ï¼Œåº”è¯¥å°±åªå‰©èŠ‚çœæ˜¾å­˜äº†ï¼ˆä¸éœ€è¦ä¿å­˜ä¸­é—´çš„Så’ŒPçŸ©é˜µï¼ŒO(N^2)çš„å†…å­˜å¤æ‚åº¦ï¼‰\n0x08 Tritonä»£ç  å…ˆå†æ¥å¤ä¹ ä¸‹Blockæ˜¯æ€ä¹ˆåˆ‡å—çš„ï¼Œè¿™é‡Œçš„å›¾æ‘˜è‡ªBBufçš„ ç¬”è®°å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼šFlash Attention V2ï¼Œä»åŸç†åˆ°å¹¶è¡Œè®¡ç®—ã€‚\nBlockåˆ‡å—æ–¹å‘å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼šFlash Attention V2ï¼Œä»åŸç†åˆ°å¹¶è¡Œè®¡ç®—\nå¢åŠ äº†Seqç»´åº¦çš„å¹¶è¡Œä»¥åï¼š\nSeqç»´åº¦åˆ‡å—æ–¹å‘å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼šFlash Attention V2ï¼Œä»åŸç†åˆ°å¹¶è¡Œè®¡ç®—\nä¸V1ä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨Qçš„seq_lenç»´åº¦ä¸Šä¹Ÿåšäº†åˆ‡åˆ†ï¼Œå°†å…¶åˆ†æˆå››ä»½ï¼Œå³num_m_block = 4ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬å…±æœ‰1_2_4 = 8ä¸ªblockåœ¨è·‘ã€‚è¿™äº›blockä¹‹é—´çš„è¿ç®—ä¹Ÿæ˜¯ç‹¬ç«‹çš„ï¼Œ å› ä¸ºï¼š\nheadçš„è®¡ç®—æ˜¯ç‹¬ç«‹çš„ï¼Œæ‰€ä»¥çº¢è‰²blockå’Œè“è‰²blockäº’ä¸å¹²æ‰° é‡‡ç”¨Qåšå¤–å¾ªç¯ï¼ŒKVåšå†…å¾ªç¯æ—¶ï¼Œè¡Œä¸è¡Œä¹‹é—´çš„blockæ˜¯ç‹¬ç«‹çš„ï¼Œå› æ­¤ä¸åŒè¡Œçš„blockäº’ç›¸ä¸å¹²æ‰°ã€‚ æ¯ä¸ªblockä»Qä¸ŠåŠ è½½å¯¹åº”ä½ç½®çš„åˆ‡å—ï¼ŒåŒæ—¶ä»KVä¸ŠåŠ è½½head0çš„åˆ‡å—ï¼Œè®¡ç®—å‡ºè‡ªå·±æ‰€ç»´æŠ¤çš„é‚£éƒ¨åˆ†Oï¼Œç„¶åå†™å…¥Oçš„å¯¹åº”ä½ç½®ã€‚\næˆ‘ä»¬ä½¿ç”¨OpenAI Tritonçš„FA2 Tutorialä»£ç æ¥åˆ†æã€‚\nä¸‹é¢çš„ä»£ç æ˜¯æ¯ä¸€ä¸ªå­Blockä¸­çš„æœ€å†…å±‚çš„ä»£ç ï¼Œå…¶ä¸­qæ˜¯æœ€å¤–å±‚å¾ªç¯çš„å­å—ï¼›K_block_ptrã€V_block_ptræ˜¯$K$ã€$V$çš„å­å—ï¼Œéœ€è¦ä¸€æ¬¡forå¾ªç¯å®Œæ•´çš„éå†ã€‚\n@triton.jit def _attn_fwd_inner(acc, l_i, m_i, q, # K_block_ptr, V_block_ptr, # start_m, qk_scale, # BLOCK_M: tl.constexpr, HEAD_DIM: tl.constexpr, BLOCK_N: tl.constexpr, # STAGE: tl.constexpr, offs_m: tl.constexpr, offs_n: tl.constexpr, # N_CTX: tl.constexpr, fp8_v: tl.constexpr): # range of values handled by this stage # æ ¹æ®STAGEçš„å€¼ï¼Œå‡½æ•°å®šä¹‰äº†å¤„ç†çš„é”®ï¼ˆKï¼‰å’Œå€¼ï¼ˆVï¼‰çš„èŒƒå›´ã€‚ # ä¸åŒçš„STAGEå¯¹åº”ä¸åŒçš„å¤„ç†èŒƒå›´ï¼Œæ”¯æŒå› æœï¼ˆcausalï¼‰å’Œéå› æœï¼ˆnon-causalï¼‰çš„è‡ªæ³¨æ„åŠ›ã€‚ if STAGE == 1: # ä½¿ç”¨ Mask lo, hi = 0, start_m * BLOCK_M elif STAGE == 2: # ä½¿ç”¨ Mask lo, hi = start_m * BLOCK_M, (start_m + 1) * BLOCK_M lo = tl.multiple_of(lo, BLOCK_M) # causal = Falseï¼Œä¸ä½¿ç”¨ Mask else: lo, hi = 0, N_CTX # tl.advance æ ¹æ®æ­¥é•¿è°ƒæ•´K_block_ptrçš„æŒ‡å‘ K_block_ptr = tl.advance(K_block_ptr, (0, lo)) V_block_ptr = tl.advance(V_block_ptr, (lo, 0)) # å¯¹K,V Blockåšå®Œæ•´çš„éå† for start_n in range(lo, hi, BLOCK_N): start_n = tl.multiple_of(start_n, BLOCK_N) # -- compute qk ---- # åŠ è½½ K Block k = tl.load(K_block_ptr) # ä¼ªä»£ç  line8: q x k qk = tl.dot(q, k) if STAGE == 2: # Mask mask = offs_m[:, None] \u003e= (start_n + offs_n[None, :]) # Mask åŒºåŸŸåŠ ä¸Š -INF qk = qk * qk_scale + tl.where(mask, 0, -1.0e6) # ä¼ªä»£ç  line 9: Safe online softmax çš„ max m_ij = tl.maximum(m_i, tl.max(qk, 1)) # ä¼ªä»£ç  line 9: s - m qk -= m_ij[:, None] else: # ä¼ªä»£ç  line 9: Safe online softmax çš„ maxï¼Œå’Œä¼ªä»£ç çš„åŒºåˆ«æ˜¯è¿™é‡Œæœ‰ qk_scaleï¼Œç¨åè§£é‡Š m_ij = tl.maximum(m_i, tl.max(qk, 1) * qk_scale) # ä¼ªä»£ç  line 9: s - m. å’Œä¼ªä»£ç çš„åŒºåˆ«æ˜¯è¿™é‡Œæœ‰ qk_scaleï¼Œç¨åè§£é‡Š qk = qk * qk_scale - m_ij[:, None] # ä¼ªä»£ç  line 9: p = exp(s-m) p = tl.math.exp2(qk) # ä¼ªä»£ç  line 9: rowsum(p) l_ij = tl.sum(p, 1) # -- update m_i and l_i # ä¼ªä»£ç  line 10 alpha = tl.math.exp2(m_i - m_ij) l_i = l_i * alpha + l_ij # -- update output accumulator -- # ä¼ªä»£ç  line 10: è¿™é‡Œçš„ acc æ˜¯ä¼ªä»£ç ä¸­çš„ O_i acc = acc * alpha[:, None] # update acc v = tl.load(V_block_ptr) if fp8_v: p = p.to(tl.float8e5) else: p = p.to(tl.float16) # ä¼ªä»£ç  line 10. acc = tl.dot(p, v, acc) # update m_i and l_i m_i = m_ij # æ›´æ–°ä¸‹ä¸€è½®çš„ K,V Blockçš„æŒ‡é’ˆ V_block_ptr = tl.advance(V_block_ptr, (BLOCK_N, 0)) K_block_ptr = tl.advance(K_block_ptr, (0, BLOCK_N)) return acc, l_i, m_i ä¸‹é¢æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹è°ƒç”¨è¿™ä¸ªå­å—å‡½æ•°çš„å‡½æ•°ã€‚\n@triton.autotune(list(filter(keep, configs)), key=[\"N_CTX\", \"HEAD_DIM\"]) @triton.jit def _attn_fwd(Q, K, V, sm_scale, M, Out, # stride_qz, stride_qh, stride_qm, stride_qk, # stride_kz, stride_kh, stride_kn, stride_kk, # stride_vz, stride_vh, stride_vk, stride_vn, # stride_oz, stride_oh, stride_om, stride_on, # Z, H, N_CTX, # HEAD_DIM: tl.constexpr, # BLOCK_M: tl.constexpr, # BLOCK_N: tl.constexpr, # STAGE: tl.constexpr # ): tl.static_assert(BLOCK_N \u003c= HEAD_DIM) # è¾“å…¥å‚æ•°é‡Œçš„Zå’ŒHåˆ†åˆ«è¡¨ç¤ºbatch sizeå’Œæ³¨æ„åŠ›å¤´æ•° # q.shape is [Batch, Head, Seq, Dim] # å¯åŠ¨çš„æ—¶å€™ [grid] æ˜¯ # grid = lambda args: (triton.cdiv(q.shape[2], args[\"BLOCK_M\"]), q.shape[0] * q.shape[1], 1) # start_mè¡¨ç¤ºå½“å‰kernel program å®ä¾‹å¯¹åº”çš„seqç»´åº¦çš„åç§»ï¼Œè€Œoff_hzè¡¨ç¤ºçš„æ˜¯batch*headsç»´åº¦çš„åç§»ã€‚ start_m = tl.program_id(0) # seq off_hz = tl.program_id(1) # batch * heads # è¿™ä¸¤è¡Œè®¡ç®—äº†ä¸¤ä¸ªåç§»é‡off_zå’Œoff_hï¼Œå®ƒä»¬åˆ†åˆ«ä»£è¡¨åœ¨batchï¼ˆæˆ–headsï¼‰ä¸­çš„ä½ç½®ã€‚ off_z = off_hz // H # è¡¨ç¤ºåœ¨å“ªä¸ª Batch off_h = off_hz % H # è¡¨ç¤ºåœ¨å“ªä¸ª Head # è®¡ç®—ç”¨äºå®šä½Qã€Kå’ŒVå¼ é‡ä¸­å½“å‰å¤„ç†å—çš„åç§»é‡ã€‚è¿™æ˜¯åŸºäºå…ˆå‰è®¡ç®—çš„åç§»é‡å’Œæä¾›çš„æ­¥é•¿å‚æ•°ã€‚ qvk_offset = off_z.to(tl.int64) * stride_qz + off_h.to(tl.int64) * stride_qh # block pointers # ä½¿ç”¨tl.make_block_ptråˆ›å»ºä¸€ä¸ªæŒ‡å‘Qå¼ é‡å½“å‰å¤„ç†å—çš„æŒ‡é’ˆã€‚è¿™ä¸ªå‡½æ•°è°ƒç”¨æŒ‡å®šäº†åŸºç¡€åœ°å€ã€å½¢çŠ¶ã€æ­¥é•¿ã€åç§»é‡å’Œå—å½¢çŠ¶ç­‰ï¼Œä»¥åŠå¦‚ä½•åœ¨å†…å­˜ä¸­è®¿é—®è¿™ä¸ªæ•°æ®å—ã€‚ # N_CTX æ˜¯q.shape[2]ï¼Œè¡¨ç¤ºçš„æ˜¯åºåˆ—é•¿åº¦ï¼ŒBLOCK_DMODELæ˜¯Lkï¼Œè¡¨ç¤ºçš„æ˜¯æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„éšè—å±‚ç»´åº¦å¤§å° # ä¸‹é¢å‡ ä¸ªmake_block_ptråˆ›å»ºçš„å¼ é‡ç±»ä¼¼ï¼Œåˆ†åˆ«æ˜¯å¯¹Kï¼ŒVä»¥åŠè¾“å‡ºOåˆ›å»ºæŒ‡å‘å½“å‰å¤„ç†å—çš„æŒ‡é’ˆ Q_block_ptr = tl.make_block_ptr( base=Q + qvk_offset, shape=(N_CTX, HEAD_DIM), strides=(stride_qm, stride_qk), offsets=(start_m * BLOCK_M, 0), block_shape=(BLOCK_M, HEAD_DIM), order=(1, 0), ) v_order: tl.constexpr = (0, 1) if V.dtype.element_ty == tl.float8e5 else (1, 0) V_block_ptr = tl.make_block_ptr( base=V + qvk_offset, shape=(N_CTX, HEAD_DIM), strides=(stride_vk, stride_vn), offsets=(0, 0), block_shape=(BLOCK_N, HEAD_DIM), order=v_order, ) K_block_ptr = tl.make_block_ptr( base=K + qvk_offset, shape=(HEAD_DIM, N_CTX), strides=(stride_kk, stride_kn), offsets=(0, 0), block_shape=(HEAD_DIM, BLOCK_N), order=(0, 1), ) O_block_ptr = tl.make_block_ptr( base=Out + qvk_offset, shape=(N_CTX, HEAD_DIM), strides=(stride_om, stride_on), offsets=(start_m * BLOCK_M, 0), block_shape=(BLOCK_M, HEAD_DIM), order=(1, 0), ) # initialize offsets # è®¡ç®—Mç»´åº¦ï¼ˆseqç»´åº¦ï¼‰ä¸Šæ¯ä¸ªçº¿ç¨‹åº”å¤„ç†çš„å…ƒç´ çš„èµ·å§‹åç§»é‡ã€‚ offs_m = start_m * BLOCK_M + tl.arange(0, BLOCK_M) # è®¡ç®—Nç»´åº¦ï¼ˆbatch*headsç»´åº¦ï¼‰ä¸Šæ¯ä¸ªçº¿ç¨‹åº”å¤„ç†çš„å…ƒç´ çš„åç§»é‡ã€‚ offs_n = tl.arange(0, BLOCK_N) # initialize pointer to m and l # åˆå§‹åŒ–må‘é‡ï¼Œmç”¨äºå­˜å‚¨æ¯ä¸ªmç»´åº¦ä¸Šçš„æœ€å¤§logitï¼Œåˆå§‹åŒ–ä¸ºè´Ÿæ— ç©·å¤§ã€‚ m_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\"inf\") # åˆå§‹åŒ–lå‘é‡ï¼Œlç”¨äºç´¯è®¡softmaxçš„åˆ†æ¯ï¼Œåˆå§‹åŒ–ä¸º1ã€‚ l_i = tl.zeros([BLOCK_M], dtype=tl.float32) + 1.0 # åˆå§‹åŒ–ç´¯åŠ å™¨ï¼Œç”¨äºç´¯ç§¯æ³¨æ„åŠ›åŠ æƒå’Œã€‚æ³¨æ„è¿™é‡Œçš„shapeæ˜¯(BLOCK_M, BLOCK_DMODEL) acc = tl.zeros([BLOCK_M, HEAD_DIM], dtype=tl.float32) # load scales qk_scale = sm_scale qk_scale *= 1.44269504 # 1/log(2) # load q: it will stay in SRAM throughout # å°†QçŸ©é˜µçš„å½“å‰å—åŠ è½½åˆ°SRAMä¸­ï¼Œæ­¤æ•°æ®åœ¨æ•´ä¸ªè®¡ç®—è¿‡ç¨‹ä¸­ä¿æŒä¸å˜ã€‚ q = tl.load(Q_block_ptr) # stage 1: off-band # For causal = True, STAGE = 3 and _attn_fwd_inner gets 1 as its STAGE # For causal = False, STAGE = 1, and _attn_fwd_inner gets 3 as its STAGE if STAGE \u0026 1: acc, l_i, m_i = _attn_fwd_inner(acc, l_i, m_i, q, K_block_ptr, V_block_ptr, # start_m, qk_scale, # BLOCK_M, HEAD_DIM, BLOCK_N, # 4 - STAGE, offs_m, offs_n, N_CTX, V.dtype.element_ty == tl.float8e5 # ) # stage 2: on-band if STAGE \u0026 2: # barrier makes it easier for compielr to schedule the # two loops independently acc, l_i, m_i = _attn_fwd_inner(acc, l_i, m_i, q, K_block_ptr, V_block_ptr, # start_m, qk_scale, # BLOCK_M, HEAD_DIM, BLOCK_N, # 2, offs_m, offs_n, N_CTX, V.dtype.element_ty == tl.float8e5 # ) # epilogue m_i += tl.math.log2(l_i) acc = acc / l_i[:, None] m_ptrs = M + off_hz * N_CTX + offs_m tl.store(m_ptrs, m_i) tl.store(O_block_ptr, acc.to(Out.type.element_ty)) éœ€è¦ç‰¹åˆ«æ³¨æ„çš„æ˜¯è¿™æ®µä»£ç æœ€åçš„epilogueéƒ¨åˆ†å°±å¯¹åº”äº†FlashAttention V2ä¼ªä»£ç ä¸­çš„12è¡Œä»¥åçš„å†…å®¹ï¼Œæ ¹æ®softmaxçš„åˆ†æ¯éƒ¨åˆ†è¾ƒæ­£è¾“å‡ºã€‚æ­¤å¤–ï¼ŒTritonçš„å®ç°é‡Œé¢è€ƒè™‘äº†ä¸€äº›paperé‡Œé¢æ²¡æœ‰çš„ä¸œè¥¿æ¯”å¦‚qk_scaleï¼Œcausal maskï¼Œå¯¹Q*Kçš„ç»“æœSåº”ç”¨äº†å‡æ‰mï¼Œä½¿å¾—æ•´ä¸ªå®ç°çœ‹èµ·æ¥è¦å¤æ‚ä¸å°‘ï¼Œä½†æ•´ä½“çš„ç®—æ³•é€»è¾‘å’Œå¹¶è¡Œè®¾ç½®å’Œpaperè¿˜æ˜¯ä¸€è‡´çš„ã€‚\næœ€ååœ¨Attentionä¸­ä½¿ç”¨è¿™ä¸ªå‡½æ•°\nclass _attention(torch.autograd.Function): @staticmethod def forward(ctx, q, k, v, causal, sm_scale): # shape constraints HEAD_DIM_Q, HEAD_DIM_K = q.shape[-1], k.shape[-1] # when v is in float8_e5m2 it is transposed. HEAD_DIM_V = v.shape[-1] assert HEAD_DIM_Q == HEAD_DIM_K and HEAD_DIM_K == HEAD_DIM_V assert HEAD_DIM_K in {16, 32, 64, 128, 256} o = torch.empty_like(q) stage = 3 if causal else 1 extra_kern_args = {} # Tuning for AMD target if is_hip(): waves_per_eu = 3 if HEAD_DIM_K \u003c= 64 else 2 extra_kern_args = {\"waves_per_eu\": waves_per_eu, \"allow_flush_denorm\": True} # q.shape is [Batch, Head, Seq, Dim] grid = lambda args: (triton.cdiv(q.shape[2], args[\"BLOCK_M\"]), q.shape[0] * q.shape[1], 1) M = torch.empty((q.shape[0], q.shape[1], q.shape[2]), device=q.device, dtype=torch.float32) # Launch Kernel. _attn_fwd[grid]( q, k, v, sm_scale, M, o, # q.stride(0), q.stride(1), q.stride(2), q.stride(3), # k.stride(0), k.stride(1), k.stride(2), k.stride(3), # v.stride(0), v.stride(1), v.stride(2), v.stride(3), # o.stride(0), o.stride(1), o.stride(2), o.stride(3), # q.shape[0], q.shape[1], # N_CTX=q.shape[2], # HEAD_DIM=HEAD_DIM_K, # STAGE=stage, # **extra_kern_args) ctx.save_for_backward(q, k, v, o, M) ctx.grid = grid ctx.sm_scale = sm_scale ctx.HEAD_DIM = HEAD_DIM_K ctx.causal = causal return o 0x09 CUDAä»£ç  0x0A FA 3 0x0B æ€è€ƒ CPUä¸Šä½¿ç”¨è¿™ä¸ªé è°±å—ï¼ŸCPUä¸Šå¹¶è¡Œåº¦è¾ƒä½ï¼Œç”¨è¿™ä¸ªæ²¡æœ‰å¿…è¦ï¼Œä½†æ˜¯å¯ä»¥è€ƒè™‘åˆ†å—å’ŒMaskæ··åˆçš„MatMulæ¥å‡å°‘è®¡ç®—é‡ï¼Œä¹Ÿå°±æ˜¯Early Exitã€‚ ",
  "wordCount" : "1483",
  "inLanguage": "en",
  "datePublished": "2024-08-10T00:00:00Z",
  "dateModified": "2024-08-10T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "chenghua.Wang"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/keep-moving-forward/tech/fundamental_from_online_softmax_to_flash_attentionv3/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Ubios Home",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/keep-moving-forward/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/keep-moving-forward/" accesskey="h" title="Ubios Home (Alt + H)">Ubios Home</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/keep-moving-forward/about/about/" title="å…³äºæˆ‘">
                    <span>å…³äºæˆ‘</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/keep-moving-forward/about/tech_posts/" title="æŠ€æœ¯ç›¸å…³">
                    <span>æŠ€æœ¯ç›¸å…³</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/keep-moving-forward/about/paper_posts/" title="è®ºæ–‡è§£æ">
                    <span>è®ºæ–‡è§£æ</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/keep-moving-forward/about/news/" title="ğŸ‰NewsğŸ‰">
                    <span>ğŸ‰NewsğŸ‰</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/keep-moving-forward/about/thingking/" title="æ€è€ƒ">
                    <span>æ€è€ƒ</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/keep-moving-forward/about/hpc_ai/" title="AI&amp;Sys å…¥é—¨">
                    <span>AI&amp;Sys å…¥é—¨</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/keep-moving-forward/tags/" title="æ ‡ç­¾">
                    <span>æ ‡ç­¾</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/keep-moving-forward/series" title="ç³»åˆ—æ–‡ç« ">
                    <span>ç³»åˆ—æ–‡ç« </span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/keep-moving-forward/">Home</a>&nbsp;Â»&nbsp;<a href="http://localhost:1313/keep-moving-forward/tech/">Technique</a></div>
    <h1 class="post-title entry-hint-parent">
      [Fundamental] From Online Softmax to Flash Attention V3
    </h1>
    <div class="post-meta"><span title='2024-08-10 00:00:00 +0000 UTC'>August 10, 2024</span>&nbsp;Â·&nbsp;7 min&nbsp;Â·&nbsp;chenghua.Wang

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#0x00-materials" aria-label="0x00 Materials">0x00 Materials</a></li>
                <li>
                    <a href="#0x01-%e9%97%ae%e9%a2%98%e5%ae%9a%e4%b9%89" aria-label="0x01 é—®é¢˜å®šä¹‰">0x01 é—®é¢˜å®šä¹‰</a></li>
                <li>
                    <a href="#0x02-online-softmax" aria-label="0x02 Online Softmax">0x02 Online Softmax</a></li>
                <li>
                    <a href="#0x03-fa1" aria-label="0x03 FA1">0x03 FA1</a></li>
                <li>
                    <a href="#0x04-fa2" aria-label="0x04 FA2">0x04 FA2</a><ul>
                        
                <li>
                    <a href="#%e4%bc%98%e5%8c%96%e4%ba%86scale%e7%9a%84%e6%97%b6%e6%9c%ba%e4%bd%bf%e5%be%97%e9%99%a4%e6%b3%95%e7%9a%84%e6%ac%a1%e6%95%b0%e8%a2%ab%e5%a4%a7%e5%a4%a7%e5%87%8f%e5%b0%91" aria-label="ä¼˜åŒ–äº†Scaleçš„æ—¶æœºï¼Œä½¿å¾—é™¤æ³•çš„æ¬¡æ•°è¢«å¤§å¤§å‡å°‘">ä¼˜åŒ–äº†Scaleçš„æ—¶æœºï¼Œä½¿å¾—é™¤æ³•çš„æ¬¡æ•°è¢«å¤§å¤§å‡å°‘</a></li>
                <li>
                    <a href="#%e4%bc%98%e5%8c%96%e4%ba%86%e5%be%aa%e7%8e%af%e7%9a%84%e9%a1%ba%e5%ba%8f%e5%a2%9e%e5%8a%a0%e4%ba%86seq%e7%bb%b4%e5%ba%a6%e7%9a%84%e5%b9%b6%e8%a1%8c" aria-label="ä¼˜åŒ–äº†å¾ªç¯çš„é¡ºåºï¼Œå¢åŠ äº†Seqç»´åº¦çš„å¹¶è¡Œ">ä¼˜åŒ–äº†å¾ªç¯çš„é¡ºåºï¼Œå¢åŠ äº†Seqç»´åº¦çš„å¹¶è¡Œ</a></li>
                <li>
                    <a href="#warp%e7%9a%84%e5%88%86%e9%85%8d%e6%9b%b4%e5%8a%a0%e7%9a%84%e5%90%88%e7%90%86%e9%81%bf%e5%85%8dsplit-k" aria-label="Warpçš„åˆ†é…æ›´åŠ çš„åˆç†ï¼Œé¿å…Split-K">Warpçš„åˆ†é…æ›´åŠ çš„åˆç†ï¼Œé¿å…Split-K</a></li></ul>
                </li>
                <li>
                    <a href="#0x05-causal-mask%e6%80%8e%e4%b9%88%e7%94%a8" aria-label="0x05 Causal Maskæ€ä¹ˆç”¨ï¼Ÿ">0x05 Causal Maskæ€ä¹ˆç”¨ï¼Ÿ</a></li>
                <li>
                    <a href="#0x06-mhagqamqa" aria-label="0x06 MHA/GQA/MQA">0x06 MHA/GQA/MQA</a></li>
                <li>
                    <a href="#0x07-io%e5%a4%8d%e6%9d%82%e5%ba%a6%e5%88%86%e6%9e%90" aria-label="0x07 IOå¤æ‚åº¦åˆ†æ">0x07 IOå¤æ‚åº¦åˆ†æ</a></li>
                <li>
                    <a href="#0x08-triton%e4%bb%a3%e7%a0%81" aria-label="0x08 Tritonä»£ç ">0x08 Tritonä»£ç </a></li>
                <li>
                    <a href="#0x09-cuda%e4%bb%a3%e7%a0%81" aria-label="0x09 CUDAä»£ç ">0x09 CUDAä»£ç </a></li>
                <li>
                    <a href="#0x0a-fa-3" aria-label="0x0A FA 3">0x0A FA 3</a></li>
                <li>
                    <a href="#0x0b-%e6%80%9d%e8%80%83" aria-label="0x0B æ€è€ƒ">0x0B æ€è€ƒ</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="0x00-materials">0x00 Materials<a hidden class="anchor" aria-hidden="true" href="#0x00-materials">#</a></h1>
<p>æœ¬æ–‡æ˜¯å¯¹Flash Attentionçš„å­¦ä¹ ç¬”è®°ï¼Œå…¶ä¸­æœ‰ä¸å°‘å†…å®¹æ˜¯æ‘˜è‡ªä¸šå†…çš„å‰è¾ˆä»¬çš„æ–‡ç« ï¼Œåœ¨æ­¤ä¸€å¹¶æ„Ÿè°¢ã€‚æ‰€å‚è€ƒçš„èµ„æ–™ã€æ‘˜å½•çš„æ–‡ç« æ¥æºåœ¨ä¸‹é¢åˆ—å‡ºï¼š</p>
<ol>
<li>
<p><a href="https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf">From Online Softmax to FlashAttention(CSE599m, ML for ML System)</a> ,æœ¬æ–‡çš„è¡Œæ–‡é€»è¾‘ä¹Ÿæ˜¯æŒ‰ç…§è¿™ç¯‡æ–‡ç« æ¥çš„ã€‚å¼ºçƒˆå®‰åˆ©CSE599mç»™å…¥é—¨ML Systemçš„æ–°äººã€‚</p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2205.14135">FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a></p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/2307.08691">FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning</a></p>
</li>
<li>
<p><a href="https://cloud.tencent.com/developer/article/2392140">ã€BBufçš„CUDAç¬”è®°ã€‘åå››ï¼ŒOpenAI Tritonå…¥é—¨ç¬”è®°ä¸‰ FusedAttention</a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/668888063">[Attentionä¼˜åŒ–][2wå­—]ğŸ”¥åŸç†&amp;å›¾è§£: ä»Online-Softmaxåˆ°FlashAttention V1/V2/V3</a></p>
</li>
</ol>
<h1 id="0x01-é—®é¢˜å®šä¹‰">0x01 é—®é¢˜å®šä¹‰<a hidden class="anchor" aria-hidden="true" href="#0x01-é—®é¢˜å®šä¹‰">#</a></h1>
<p>$$
\text{Attention} = \text{Softmax}(\frac{QK^T}{\sqrt{d_k}})V
$$</p>
<p>$$
Q,K,V \in \mathbb{R}^{N\times D}
$$</p>
<p>å…¶ä¸­$N$è¡¨ç¤ºSequence Length,$D$è¡¨ç¤ºDimensionã€‚æˆ‘ä»¬å…ˆæ¥è€ƒè™‘æœ€ç®€å•çš„è®¡ç®—æ–¹å¼ï¼š</p>
<p>$$
S = QK^T
$$</p>
<p>$$
P = \text{Softmax}(S)
$$</p>
<p>$$
O = PV
$$</p>
<p>åœ¨è¿™ä¸ªNaiveçš„è®¡ç®—æ–¹å¼ä¸­ï¼Œ$P,S \in \mathbb R^{N\times N}$ï¼Œè¿™æ„å‘³ç€ä¸ºäº†è®¡ç®—Pï¼Œæˆ‘ä»¬éœ€è¦å¤šä¿å­˜ä¸€ä¸ª$N\times N$çš„çŸ©é˜µï¼Œè¿™ä¸ªæƒ…å†µä¸‹å†…å­˜çš„éœ€æ±‚æ˜¯$O(N^2)$çš„ï¼Œå¾ˆå®¹æ˜“çˆ†æ˜¾å­˜ï¼›ä¸”ä¸ºäº†è®¡ç®—$Så’ŒP$åŠ¿å¿…éœ€è¦ä»HBMä¸­è¿›è¡Œå¤§é‡çš„è¯»å†™æ“ä½œï¼ŒIOçš„è®¿é—®æ¬¡æ•°æ˜¯$O(N^2 + ND)$å¤æ‚åº¦çš„ã€‚éšç€ç°åœ¨çš„Context Lengthéœ€æ±‚è¶Šæ¥è¶Šå¤§ï¼Œåœ¨$N$å˜å¤§çš„æ—¶å€™ï¼Œæ˜¯å¾ˆå®¹æ˜“çˆ†æ˜¾å­˜çš„ã€‚æ€»ç»“é—®é¢˜ï¼Œä¸»è¦æœ‰ï¼š</p>
<ol>
<li>Sequence Length($N$)è¶Šå¤§ï¼Œä¼ ç»Ÿçš„Attentionè®¡ç®—æ–¹æ³•å¾ˆå®¹æ˜“çˆ†æ˜¾å­˜ã€‚</li>
<li>ä¼ ç»Ÿçš„Attentionè®¡ç®—æ–¹å¼å¯¹HBMçš„è®¿é—®å¤æ‚åº¦æ˜¯å¹³æ–¹çº§åˆ«çš„ï¼Œè¶Šé•¿çš„$N$ï¼Œè€—æ—¶è¶Šé•¿ã€‚</li>
</ol>
<figure>
    <img loading="lazy" src="hbm-shared-speed.png"
         alt="From FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"/> <figcaption>
            HBM / Shared Mem IO Bandwidth<p>From <a href="https://arxiv.org/pdf/2205.14135">FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a></p>
        </figcaption>
</figure>

<p>è€ƒè™‘åˆ°HBMï¼ŒShared Memoryçš„é€Ÿåº¦å·®å¼‚ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå‡å°‘HBM Accessè€Œå°†æ›´å¤šçš„IO Accessæ“ä½œæ”¾åœ¨Shared Memoryä¸­ã€‚</p>
<h1 id="0x02-online-softmax">0x02 Online Softmax<a hidden class="anchor" aria-hidden="true" href="#0x02-online-softmax">#</a></h1>
<p>æˆ‘ä»¬å†æ¥çœ‹ä¸‹Safe Softmaxçš„é€»è¾‘:</p>
<p>$$
S_i = \frac{e^{x_i - M}}{\sum_{i=0}^N e^{x_i - M}}, M = \max{X},X \in \mathbb{R}^{N}
$$
ã€‚æˆ‘ä»¬å…ˆç”¨ä¸€ä¸ªéå¸¸naiveçš„æ€è·¯æ¥å®ç°è¿™ä¸ªSoftmaxï¼Œè¿™é‡Œä½¿ç”¨From Online Softmax to FlashAttentionæ–‡ç« ä¸­çš„ä¼ªä»£ç æ¥è§£é‡Šï¼š</p>
<figure>
    <img loading="lazy" src="online-softmax.png"
         alt="From From Online Softmax to FlashAttention(CSE599m, ML for ML System)"/> <figcaption>
            Online Softmax ä¼ªä»£ç <p>From <a href="https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf">From Online Softmax to FlashAttention(CSE599m, ML for ML System)</a></p>
        </figcaption>
</figure>

<p>åœ¨è¿™ä¸ªç®€å•çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸‰ä¸ªå¾ªç¯æ¥è¿›è¡Œè®¡ç®—ï¼Œè¿™è¦æ±‚æˆ‘ä»¬å¯¹$[1; N]$è¿›è¡Œä¸‰æ¬¡è¿­ä»£ã€‚è€ŒSelf-Attentionä¸­ï¼Œå› ä¸ºSRAMæ”¾ä¸ä¸‹é‚£ä¹ˆå¤šçš„æ•°æ®ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸‰æ¬¡è®¿é—®$Q$å’Œ $K$ï¼ˆå¹¶ä¸”é‡æ–°è®¡ç®—ï¼‰ï¼Œè¿™åœ¨$I/O$æ•ˆç‡ä¸Šæ˜¯ä¸åˆ©çš„ã€‚</p>
<p>é‚£ä¹ˆï¼Œæœ‰æ²¡æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥åˆå¹¶ä¸€äº›Passï¼Œå°±åƒæ˜¯æˆ‘ä»¬ç»å¸¸åœ¨Kernel Fusionä¸­åšçš„é‚£æ ·å‘¢ï¼Ÿåˆçœ‹ä¼¼ä¹å›°éš¾ï¼Œå› ä¸ºå…¬å¼(8)ä¾èµ–äºå…¬å¼(7)æ‰€å¾—åˆ°çš„è®¡ç®—ç»“æœï¼Œä½†æ˜¯ï¼Œä½¿ç”¨ä¸€äº›å˜æ¢ï¼Œå¯ä»¥å…è®¸æˆ‘ä»¬ä»¥é‡è®¡ç®—ä¸€éƒ¨åˆ†æ•°æ®ä¸ºä»£ä»·æ¥åˆå¹¶å…¬å¼(7, 8)ã€‚</p>
<p>ç°åœ¨ï¼Œæˆ‘ä»¬æ¥æ¨å¯¼ä¸‹å…¬å¼ï¼Œ</p>
<p>$$
\begin{aligned}
d_{i}^{\prime}&amp; =\sum_{j=1}^ie^{x_j-m_i} \\
&amp;= \left(\sum_{j=1}^{i-1} e^{x_j-m_i}\right)+e^{x_i-m_i} \\
&amp;= \left(\sum_{j=1}^{i-1} e^{x_j-m_{i-1}}\right)e^{m_{i-1}-m_i}+e^{x_i-m_i} \\
&amp;= d_{i-1}&rsquo; e^{m_{i-1}-m_i}+e^{x_i-m_i}
\end{aligned}
$$</p>
<p>æˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ä¸ªé€’æ¨çš„å…¬å¼ï¼Œå…¶ä¸­$d_N^{\prime}$ä¸ºæœ€åæˆ‘ä»¬éœ€è¦çš„åŠ å’Œï¼Œå³$\sum_{i=0}^{N}e^{x_i-m_N}$ã€‚åœ¨è¿™ä¸ªé€’æ¨å…¬å¼ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ–°çš„$m$æ¥ä¿®æ­£ä¹‹å‰çš„$d_i^{\prime}$ï¼Œä¹‹å‰é”™è¯¯çš„$m$å¯ä»¥é€šè¿‡å¹‚ç›¸ä¹˜çš„è®¡ç®—è§„åˆ™æ¶ˆå»ã€‚æ€»çš„è®¡ç®—æµç¨‹è¢«ç¼©å‡ä¸º2ä¸ªPassï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p>
<figure>
    <img loading="lazy" src="online-softmax-2-pass.png"
         alt="From From Online Softmax to FlashAttention(CSE599m, ML for ML System)"/> <figcaption>
            Online Softmax 2 passes ä¼ªä»£ç <p>From <a href="https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf">From Online Softmax to FlashAttention(CSE599m, ML for ML System)</a></p>
        </figcaption>
</figure>

<p>ä½†æ˜¯ï¼Œè¿™ä¸ªè®¡ç®—æ–¹å¼è¿˜æ˜¯æœ‰ä¸¤ä¸ªPassï¼Œæˆ‘ä»¬èƒ½ä¸èƒ½å°†æ‰€æœ‰çš„è®¡ç®—Fuseåˆ°ä¸€ä¸ªPassä¸­å»å‘¢ï¼Ÿ</p>
<p>åœ¨Online Softmaxä¸­å¾ˆéš¾åšåˆ°è¿™ä¸€ç‚¹ï¼Œå› ä¸º$a_i$æ‰€éœ€è¦çš„$m_N,d_N^{\prime}$ä¾èµ–äºå…¨å±€æ›´æ–°ã€‚è€Œ$a_i$æ˜¯ä¸€ä¸ªæ— æ³•å…¨å±€æ›´æ–°çš„å˜é‡ï¼Œé™¤éåœ¨ç¬¬ä¸€ä¸ªPassä¸­å†åµŒå¥—ä¸€ä¸ªå¾ªç¯ï¼Œè¿™æ ·è¿èƒŒäº†æˆ‘ä»¬ç®€åŒ–è®¡ç®—çš„åˆè¡·ã€‚ä½†æ˜¯ï¼Œå°†é—®é¢˜æ”¾åœ¨Self-Attentionçš„è®¡ç®—çš„æ—¶å€™ï¼Œå°±å˜å¾—ä¸ä¸€æ ·äº†ã€‚</p>
<p>æˆ‘ä»¬åœ¨è¿™é‡Œå†ç†è§£ä¸‹ï¼Œä¸ºä»€ä¹ˆ2Passçš„Online Safe Softmaxæ˜¯é‡è¦çš„ï¼Œåœ¨Self-Attentionçš„è®¡ç®—ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸‹é¢2ä¸ªä¸»è¦çš„é—®é¢˜ï¼š</p>
<blockquote>
<ol>
<li>éœ€è¦æå‰è®¡ç®—å¥½$QK^T$ï¼Œä¿å­˜åœ¨å…¨å±€æ˜¾å­˜ä¸­ï¼Œéœ€è¦$O(N^2)$çš„æ˜¾å­˜ï¼Œå®¹æ˜“çˆ†æ˜¾å­˜ã€‚</li>
<li>åœ¨ç®—æ³•ä¸­Onlineè®¡ç®—ï¼Œæ¯æ¬¡å¾ªç¯ä¸­å»åŠ è½½ä¸€éƒ¨åˆ†$Q,K$åˆ°ç‰‡ä¸Šå†…å­˜ï¼Œè®¡ç®—å¾—åˆ°éƒ¨åˆ†çš„$QK^T$ã€‚</li>
</ol>
</blockquote>
<p>æ€»çš„æ¥è¯´ï¼ŒOnline Softmaxè§£å†³çš„æ˜¯æ˜¾å­˜ä¸è¶³çš„é—®é¢˜ï¼Œä½†æ˜¯å› ä¸ºæœ‰ä¸¤ä¸ªPassï¼Œè¿˜æ˜¯å­˜åœ¨HBM R/Wæ¬¡æ•°è¾ƒå¤šï¼Œæœ‰Memory Boundï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ¶ˆé™¤è¿™ä¸ªç“¶é¢ˆã€‚è™½ç„¶ç°åœ¨æˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸€ä¸ª$d_i^{\prime}$åšScaleï¼Œä½†æ˜¯è€ƒè™‘åˆ°ç›®å‰æ˜¾å¡å¹¶ä¸æ˜¯Compute Boundï¼Œè¿™å¤šä½™çš„è®¡ç®—æ˜¯å¯ä»¥æš‚æ—¶ä¸å»è€ƒè™‘çš„ã€‚</p>
<h1 id="0x03-fa1">0x03 FA1<a hidden class="anchor" aria-hidden="true" href="#0x03-fa1">#</a></h1>
<p>è™½ç„¶åœ¨Online Softmaxä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰åŠæ³•å¾—åˆ°ä¸€ä¸ª1 Passçš„ç®—æ³•ï¼Œä½†æ˜¯åœ¨Self-Attentionä¸­ï¼Œæˆ‘ä»¬éœ€è¦çš„æ˜¯è®¡ç®—å‡º$O=A\times V$ï¼Œè€Œä¸æ˜¯$A$ï¼Œè¿™æœ‰ä»€ä¹ˆä¸åŒå‘¢ï¼Ÿæˆ‘ä»¬æ¥æ¨å¯¼ä¸‹å…¬å¼ï¼Œä¸è¿‡é¦–å…ˆï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹åŸå§‹çš„Self-Attentionæ˜¯æ€ä¹ˆæ±‚è§£çš„ï¼š</p>
<figure>
    <img loading="lazy" src="self-atten-raw.png"
         alt="From From Online Softmax to FlashAttention(CSE599m, ML for ML System)"/> <figcaption>
            åŸå§‹çš„Self-Attention ä¼ªä»£ç <p>From <a href="https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf">From Online Softmax to FlashAttention(CSE599m, ML for ML System)</a></p>
        </figcaption>
</figure>

<p>è¿™å¼ æœªæ‰“ç æµç¨‹å›¾ä»ç„¶æ˜¯ä»CSE 599mä¸­å€Ÿç”¨çš„ã€‚å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ç¬¬ä¸€ä¸ªPassä¸­ï¼Œå°±æ˜¯0x02ç« èŠ‚ä¸­æåŠçš„Online Softmaxï¼›åœ¨ç¬¬äºŒä¸ªPassä¸­ï¼Œ$o_i$çš„è®¡ç®—å¯èƒ½ç¨æœ‰ç‚¹éš¾ä»¥ç†è§£ï¼Œå¯ä»¥ç”»å¼ å›¾ã€‚å®é™…ä¸Šå°±æ˜¯éå†$a_i$å°±æ˜¯$\text{Attention}$çŸ©é˜µçš„ä¸€è¡Œï¼Œæ‹¿æ¯ä¸€è¡Œçš„æ¯ä¸ªå€¼$a_i$å»ä¹˜$V$çŸ©é˜µçš„æ¯ä¸€è¡Œï¼Œå°±æ˜¯è¡Œä¹˜åˆ—æ“ä½œã€‚è¿™ä¸ªæ“ä½œå¯ä»¥åŒæ—¶æŠŠ$O$çŸ©é˜µçš„ä¸€è¡Œç»™ç®—å‡ºæ¥ã€‚</p>
<p>$$o_i^{\prime}:=\left(\sum_{j=1}^i\frac{e^{x_j-m_i}}{d_i^{\prime}}V[j,:]\right)$$</p>
<p>ä¸Šé¢çš„å…¬å¼å°±æ˜¯æŠŠPass2å†…éƒ¨çš„è®¡ç®—æ•´åˆåœ¨äº†ä¸€èµ·ï¼Œå’Œ0x02ç« èŠ‚çš„æ¨å¯¼ä¸€æ ·ï¼Œæˆ‘ä»¬ä¹Ÿå»å°è¯•åšé€’æ¨ï¼š</p>
<p>
$$
\begin{aligned}
o_i^{\prime}& =\sum_{j=1}^i\frac{e^{x_j-m_i}}{d_i'}V[j,:] \\
&= \left(\sum_{j=1}^{i-1}\frac{e^{x_j-m_i}}{d_i'}V[j,:] \right)+\frac{e^{x_i-m_i}}{d_i'}V[i,: ] \\
&= \left(\sum_{j=1}^{i-1}\frac{e^{x_j-m_{i-1}}}{d_{i-1}^{\prime}}\frac{e^{x_j-m_i}}{e^{x_j-m_{i-1}}}\frac{d_{i-1}^{\prime}}{d_i^{\prime}}V[j,.]\right)+\frac{e^{x_i-m_i}}{d_i^{\prime}}V[i,.] \\
&= \left(\sum_{j=1}^{i-1}\frac{e^{x_j-m_{i-1}}}{d_{i-1}^{\prime}}V[j,:]\right)\frac{d_{i-1}^{\prime}}{d_i^{\prime}}e^{m_{i-1}-m_i}+\frac{e^{x_i-m_i}}{d_i^{\prime}}V[i,:] \\
&=\begin{array}{c}\boldsymbol{o}_{i-1}^{\prime}\frac{d_{i-1}^{\prime}e^{m_{i-1}-m_i}}{d_i^{\prime}}+\frac{e^{x_i-m_i}}{d_i^{\prime}}V[i,:]\end{array}
\end{aligned}
$$
</p>
<p>å¯ä»¥æ¨å¯¼å‡ºå’ŒOnline Softmaxç›¸ä¼¼çš„å½¢å¼ï¼Œè‡³æ­¤ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºäº†FAç®—æ³•ã€‚</p>
<figure>
    <img loading="lazy" src="fa.png"
         alt="From From Online Softmax to FlashAttention(CSE599m, ML for ML System)"/> <figcaption>
            FA1 ä¼ªä»£ç <p>From <a href="https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf">From Online Softmax to FlashAttention(CSE599m, ML for ML System)</a></p>
        </figcaption>
</figure>

<p>å¯ä»¥çœ‹å‡ºï¼Œåœ¨FAç®—æ³•ä¸­ï¼Œ$Q,K,V$éƒ½å¯ä»¥åˆ†å—è½½å…¥ï¼Œæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥å¾—åˆ°FAçš„Tilingæ–¹æ³•ï¼š</p>
<figure>
    <img loading="lazy" src="fa-tile.png"
         alt="From From Online Softmax to FlashAttention(CSE599m, ML for ML System)"/> <figcaption>
            FA1 Tiled<p>From <a href="https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf">From Online Softmax to FlashAttention(CSE599m, ML for ML System)</a></p>
        </figcaption>
</figure>

<p>åœ¨è¿™ç§æ”¹è¿›çš„TilingæŠ€æœ¯ä¸­ï¼ŒKçŸ©é˜µè¢«åˆ’åˆ†ä¸ºå¤šä¸ªè¾ƒå°çš„åŒºå—ï¼ŒåŒæ ·çš„æ–¹æ³•ä¹Ÿé€‚ç”¨äºQçŸ©é˜µã€‚è¿™äº›è¾ƒå°çš„åŒºå—å¯ä»¥è¢«åŠ è½½åˆ°SRAMä¸­ï¼Œä»¥ä¾¿äºè¿›è¡Œé«˜æ•ˆçš„è®¡ç®—ã€‚ä¸€æ—¦è¿™äº›åŒºå—è¢«åŠ è½½ï¼Œå°±å¯ä»¥åœ¨kernelå†…éƒ¨å®Œæˆæ•´ä¸ªæ³¨æ„åŠ›æœºåˆ¶çš„è®¡ç®—è¿‡ç¨‹ã€‚ä»ç®—æ³•çš„è§’åº¦æ¥çœ‹ï¼Œç°åœ¨åªéœ€è¦ä¸€æ¬¡æ€§åŠ è½½Qã€Kã€VçŸ©é˜µï¼Œå°±èƒ½åœ¨å†…æ ¸ä¸­å®Œæˆæ‰€æœ‰çš„æ³¨æ„åŠ›è®¡ç®—ã€‚è¿™ç§ä¼˜åŒ–æ–¹æ³•å°†åŸå§‹3-pass Self Attentionè½¬å˜ä¸º1-pass FlashAttentionï¼Œä¸ä»…èŠ‚çœäº†å­˜å‚¨ä¸­é—´çŸ©é˜µæ‰€éœ€çš„æ˜¾å­˜ï¼Œè¿˜å‡å°‘äº†å¯¹Qå’ŒKçŸ©é˜µçš„HBM R/Wçš„æ¬¡æ•°ã€‚</p>
<p>æœ€ç»ˆï¼ŒFAçš„ç®—æ³•å¯ä»¥è¢«ä¸‹é¢çš„ä¼ªä»£ç æ¥è¡¨ç¤ºï¼š</p>
<figure>
    <img loading="lazy" src="fa-tile-code.png"/> 
</figure>

<figure>
    <img loading="lazy" src="fa-tile-code-2.png"
         alt="From From Online Softmax to FlashAttention(CSE599m, ML for ML System)"/> <figcaption>
            FA1 tiled ä¼ªä»£ç <p>From <a href="https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf">From Online Softmax to FlashAttention(CSE599m, ML for ML System)</a></p>
        </figcaption>
</figure>

<p>æ­¤æ—¶ï¼Œæˆ‘ä»¬å†çœ‹FAçš„ç®—æ³•æµç¨‹å›¾ï¼Œå°±ä¸æ„Ÿè§‰é™Œç”Ÿäº†ã€‚å’Œä¸Šæ–‡ä¸­çš„æ¨å¯¼æ€è·¯ä¸€è‡´ï¼š</p>
<figure>
    <img loading="lazy" src="fa-code.png"
         alt="From FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"/> <figcaption>
            FA1 åŸæ–‡ ä¼ªä»£ç <p>From <a href="https://arxiv.org/pdf/2205.14135">FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a></p>
        </figcaption>
</figure>

<p>åœ¨ç¬¬6è¡Œï¼ŒFAè½½å…¥$K,V$åˆ†å—ï¼Œç„¶ååœ¨ç¬¬8è¡Œéå†å®Œæˆæ‰€æœ‰çš„$Q$ï¼ˆè¿™é‡Œæœ‰ä¸ªæ˜¾è€Œæ˜“è§çš„é—®é¢˜ï¼Œ$Q$çš„éå†æ”¾åœ¨æœ€å¤–é¢ä¼šå¥½å¾ˆå¤šï¼‰ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œå†æ¢è®¨ä¸‹ä¸ºä»€ä¹ˆåˆ†å—$B_c=\lceil \frac{M}{4d} \rceil, B_r=\min (\lceil \frac{M}{4d} \rceil, d)$ã€‚</p>
<p>è¿™æ ·è®¾ç½®çš„ç›®çš„æ˜¯ï¼Œä¸ºäº†ç¡®ä¿SRAMèƒ½å¤Ÿæ”¾ä¸‹æ‰€æœ‰$Q, K, V$çš„å°å—ï¼Œå…¶ä¸­$M$å°±æ˜¯ç³»ç»Ÿå¯ç”¨çš„SRAMä¸Šé™ã€‚é‚£ä¹ˆï¼Œå¯¹äºæ¯ä¸€ä¸ª$Q$çš„åˆ†å—$Q_i,O_i$ä»¥åŠ$K, V$çš„åˆ†å—$K_i, V_i$éœ€è¦çš„å…±äº«å†…å­˜ä¸ºï¼š</p>
<p>$$
\begin{gathered}
SRAM(Q_{i})=B_{r}\times d=\min\left(\left\lceil\frac{M}{4d}\right\rceil,d\right)\times d&lt;\lceil\frac{M}{4}\rceil \\
SRAM(O_i)=B_r\times d=\min\left(\left\lceil\frac{M}{4d}\right\rceil,d\right)\times d&lt;\lceil\frac{M}{4}\rceil \\
SRAM(K_{j},V_{j})=2\times B_{c}\times d=2\times\left\lceil\frac{M}{4d}\right\rceil\times d&lt;\lceil\frac{M}{2}\rceil
\end{gathered}
$$</p>
<p>åœ¨è¿™ä¸ªæƒ…å†µä¸‹ï¼ŒSRAMåŸºæœ¬ä¸Šå¯ä»¥è¢«å æ»¡ã€‚FA1åŸå§‹è®ºæ–‡ä¸­è¯´é“ï¼ŒBlock Size è¶Šå¤§ï¼ŒHBM Accesses è¶Šä½ï¼Œåœ¨256é™„è¿‘åŸºæœ¬å°±æ˜¯æ•ˆç‡æœ€ä¼˜çš„è½¬æŠ˜ç‚¹ã€‚</p>
<figure>
    <img loading="lazy" src="fa-block.png"
         alt="From FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"/> <figcaption>
            FA1 Block Size å®éªŒ<p>From <a href="https://arxiv.org/pdf/2205.14135">FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a></p>
        </figcaption>
</figure>

<p>æ–‡ä¸­çš„å®éªŒæ¡ä»¶æ˜¯A100GPUï¼ŒGPT-2 medium (seq. length 1024, head dim. 64, 16 heads, batch size 64)</p>
<h1 id="0x04-fa2">0x04 FA2<a hidden class="anchor" aria-hidden="true" href="#0x04-fa2">#</a></h1>
<p>åœ¨0x03ç« èŠ‚ä¸­æˆ‘ä»¬æåˆ°ï¼šç„¶ååœ¨ç¬¬8è¡Œéå†å®Œæˆæ‰€æœ‰çš„$Q$ï¼ˆè¿™é‡Œæœ‰ä¸ªæ˜¾è€Œæ˜“è§çš„é—®é¢˜ï¼Œ$Q$çš„éå†æ”¾åœ¨æœ€å¤–é¢ä¼šå¥½å¾ˆå¤šï¼‰ï¼Œè¿™ç‚¹å°±æ˜¯FA2ä¼˜åŒ–çš„å¾ˆé‡è¦çš„ä¸€ç‚¹ã€‚</p>
<p>FA2ä¸€å…±åšäº†ä¸»è¦çš„å‡ ç§ä¼˜åŒ–ï¼š</p>
<ol>
<li>
<p>ä¼˜åŒ–äº†Scaleçš„æ—¶æœºï¼Œä½¿å¾—é™¤æ³•çš„æ¬¡æ•°è¢«å¤§å¤§å‡å°‘</p>
</li>
<li>
<p>Forwardä¼˜åŒ–äº†å¾ªç¯çš„é¡ºåºï¼Œä½¿å¾—HBM Accessæ›´åŠ çš„é«˜æ•ˆã€‚Backwardæ²¡æœ‰</p>
</li>
<li>
<p>Forward/Backwardå‡å¢åŠ äº†Seqç»´åº¦çš„å¹¶è¡Œ</p>
</li>
<li>
<p>Warpçš„åˆ†é…æ›´åŠ çš„åˆç†ï¼Œé¿å…Split-K(ä¸æ˜¯å¾ˆç†è§£ï¼Ÿ)</p>
</li>
</ol>
<h2 id="ä¼˜åŒ–äº†scaleçš„æ—¶æœºä½¿å¾—é™¤æ³•çš„æ¬¡æ•°è¢«å¤§å¤§å‡å°‘">ä¼˜åŒ–äº†Scaleçš„æ—¶æœºï¼Œä½¿å¾—é™¤æ³•çš„æ¬¡æ•°è¢«å¤§å¤§å‡å°‘<a hidden class="anchor" aria-hidden="true" href="#ä¼˜åŒ–äº†scaleçš„æ—¶æœºä½¿å¾—é™¤æ³•çš„æ¬¡æ•°è¢«å¤§å¤§å‡å°‘">#</a></h2>
<p>è™½ç„¶ä¸€èˆ¬æ¥è¯´ï¼Œématmulè¿ç®—FLOPsè¦æ¯”matmulä½ï¼Œä½†æ˜¯ématmulè®¡ç®—ä½¿ç”¨çš„æ˜¯CUDA Coresï¼Œè€ŒçŸ©é˜µè®¡ç®—å¯ä»¥åˆ©ç”¨Tensor CoresåŠ é€Ÿã€‚åŸºäºTensor Coresçš„matmulè¿ç®—ååæ˜¯ä¸ä½¿ç”¨Tensor Coresçš„ématmulè¿ç®—ååçš„16xã€‚</p>
<p>ä¸FA1ç›¸æ¯”ï¼ŒFA2çš„ä¸»è¦ä¸åŒç‚¹æ˜¯è®¡ç®—æ¯ä¸€æ¬¡çš„$\boldsymbol{O}^{(n)}$çš„é€»è¾‘ï¼Œè¿™é‡Œä»¥$\boldsymbol{O}^{(1)},\boldsymbol{O}^{(2)}$ä¸ºä¾‹æ¥è¯´æ˜ï¼Œåœ¨FA2ä¸­ï¼š</p>
<p>$$
\begin{gathered}
\tilde{\mathbf{o}}^{(1)} =e^{s^{(1)}-m^{(1)}}\mathbf{V}^{(1)}\in\mathbb{R}^{B_{r}\times d} \\
\tilde{\mathrm{o}}^{(2)} =e^{s^{(1)}-m}\mathbf{V}^{(1)}+e^{s^{(2)}-m}\mathbf{V}^{(2)} \\
\mathrm{o}^{(2)} =\mathrm{diag}\left(\ell^{(2)}\right)^{-1}\tilde{\mathbf{O}}^{(2)}=\mathbf{O}
\end{gathered}
$$</p>
<p>å…¶ä¸­ï¼Œ$\tilde{\mathrm{o}}^{(2)} =e^{s^{(1)}-m}\mathbf{V}^{(1)}+e^{s^{(2)}-m}\mathbf{V}^{(2)}$åœ¨è®¡ç®—çš„æ—¶å€™ï¼Œ$e^{s^{(1)}-m}\mathbf{V}^{(1)}$è¿™ä¸€é¡¹æ˜¯å¯¹$\tilde{\mathbf{o}}^{(1)}$åšäº†ç¼©æ”¾ï¼Œç¼©æ”¾å› å­æ˜¯$e^{m^{(1)} - m}$ã€‚ä¹Ÿå°±æ˜¯ï¼š</p>
<p>$$\tilde{\mathrm{o}}^{(2)} = e^{m^{(1)} - m} \tilde{\mathbf{o}}^{(1)} +e^{s^{(2)}-m}\mathbf{V}^{(2)}$$</p>
<p>ç›¸æ¯”äºåŸæ¥çš„FA1ï¼Œæˆ‘ä»¬é¦–å…ˆè®¡ç®—Softmaxçš„åˆ†å­éƒ¨åˆ†ï¼Œåœ¨æœ€åæ‰ç®—ä¸Šåˆ†æ¯ã€‚è¿™æ ·å‡å°‘äº†æ¯æ¬¡è¿­ä»£è€Œå¿…é¡»çš„åˆ†æ¯ç¼©æ”¾ã€‚è€ŒåŸæœ¬çš„FA1çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹å¼æ‰€ç¤ºï¼š</p>
<p>
$$
\mathbf{O}_{i}\leftarrow\mathrm{diag}\left(\ell_{i}^{\mathrm{new}}\right)^{-1}\left(\mathrm{diag}(\ell_{i})e^{{m_{i}-m_{i}^{\mathrm{new}}}}\mathbf{O}_{i}+e^{{\tilde{m}_{ij}-m_{i}^{\mathrm{new}}}}\mathbf{\tilde{P}}_{ij}\mathbf{V}_{j}\right)
$$
</p>
<p>FA2çš„è®¡ç®—ä¸­ï¼Œå…ˆä¸åœ¨æ¯ä¸ªblockçš„æ¯æ¬¡è¿­ä»£è®¡ç®—ä¸­æ‰§è¡Œå…¨éƒ¨çš„rescaleæ“ä½œï¼Œè€Œæ˜¯æœ€åæ‰§è¡Œä¸€æ¬¡rescaleã€‚æ¯æ¬¡è®¡ç®—å¯ä»¥å‡å°‘ä¸€æ¬¡é™¤æ³•è¿ç®—ã€‚</p>
<figure>
    <img loading="lazy" src="fa2-code.png"
         alt="From From Online Softmax to FlashAttention(CSE599m, ML for ML System)"/> <figcaption>
            FA2 ä¼ªä»£ç <p>From <a href="https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf">From Online Softmax to FlashAttention(CSE599m, ML for ML System)</a></p>
        </figcaption>
</figure>

<p>å¯ä»¥çœ‹åˆ°åœ¨åŸæ–‡çš„ä¼ªä»£ç ä¸­ï¼Œåœ¨$T_c$å¾ªç¯ç»“æŸåï¼Œæ‰å»åšäº†åˆ†æ¯ä¸Šçš„è®¡ç®—ã€‚</p>
<p>ç¬¬åè¡Œçš„$\text{diag}^{-1}$æ˜¯é”™çš„ï¼ŒæŠŠ$^{-1}$å»æ‰ã€‚</p>
<h2 id="ä¼˜åŒ–äº†å¾ªç¯çš„é¡ºåºå¢åŠ äº†seqç»´åº¦çš„å¹¶è¡Œ">ä¼˜åŒ–äº†å¾ªç¯çš„é¡ºåºï¼Œå¢åŠ äº†Seqç»´åº¦çš„å¹¶è¡Œ<a hidden class="anchor" aria-hidden="true" href="#ä¼˜åŒ–äº†å¾ªç¯çš„é¡ºåºå¢åŠ äº†seqç»´åº¦çš„å¹¶è¡Œ">#</a></h2>
<p>FA1çš„ä¸¤é‡å¾ªç¯ä¸­ï¼Œæ˜¯å…ˆå¤–å±‚å¾ªç¯load K, Vï¼Œç„¶åå†…å±‚å¾ªç¯å†load Qã€‚è¿™å°±ä¼šå¯¼è‡´å†…å±‚å¾ªç¯ï¼Œæ¯æ¬¡è®¡ç®—çš„åªæ˜¯Qiçš„ä¸€éƒ¨åˆ†ï¼Œæ¯æ¬¡å†…å¾ªç¯çš„è¿­ä»£éƒ½éœ€è¦å¯¹Oiè¿›è¡Œå…¨å±€å†…å­˜çš„è¯»å†™ã€‚è€Œä¸”ï¼Œä¸€ä¸ªæ˜¾è€Œæ˜“è§çš„äº‹å®å°±æ˜¯ï¼Œåœ¨Attentionçš„è®¡ç®—ä¸­ï¼Œä¸åŒqueryçš„Attentionè®¡ç®—æ˜¯å®Œå…¨ç‹¬ç«‹çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœå¤–éƒ¨å¾ªç¯æ˜¯å…ˆload Qï¼Œé‚£ä¹ˆå°±å¯ä»¥æŠŠä¸åŒçš„queryå—çš„Attentionåˆ†é…ä¸åŒthread blockè¿›è¡Œè®¡ç®—ï¼Œè¿™äº›thread blockä¹‹é—´æ˜¯ä¸éœ€è¦é€šä¿¡çš„ã€‚æ²¡é”™ï¼Œåœ¨FA2ä¸­ï¼Œæ­£æ˜¯è¿™æ ·åšçš„ï¼Œå¯¹äºforward passï¼Œç®—æ³•è°ƒæ¢äº†å¾ªç¯çš„é¡ºåºï¼Œå…ˆload Qï¼Œå†load K, Vã€‚</p>
<p>FA2å¢åŠ seqlenå¹¶è¡Œï¼Œæé«˜äº†occupancyï¼Œå¹¶ä¸”å¯¹äºforward passï¼ŒQ*K^Tåœ¨ã€è¡Œã€‘æ–¹å‘çš„seqlenä¸Šå¤©ç„¶å¯ä»¥å¹¶è¡Œï¼Œthread blockä¹‹é—´ä¸éœ€è¦é¢å¤–çš„é€šä¿¡ã€‚</p>
<h2 id="warpçš„åˆ†é…æ›´åŠ çš„åˆç†é¿å…split-k">Warpçš„åˆ†é…æ›´åŠ çš„åˆç†ï¼Œé¿å…Split-K<a hidden class="anchor" aria-hidden="true" href="#warpçš„åˆ†é…æ›´åŠ çš„åˆç†é¿å…split-k">#</a></h2>
<p>æ‘˜è‡ª <a href="https://zhuanlan.zhihu.com/p/665170554">FlashAttentionæ ¸å¿ƒé€»è¾‘ä»¥åŠV1 V2å·®å¼‚æ€»ç»“</a></p>
<figure>
    <img loading="lazy" src="split-k.png"
         alt="From From Online Softmax to FlashAttention(CSE599m, ML for ML System)"/> <figcaption>
            Warp Split-K<p>From <a href="https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf">From Online Softmax to FlashAttention(CSE599m, ML for ML System)</a></p>
        </figcaption>
</figure>

<p>é¦–å…ˆçœ‹fwdï¼Œç›¸æ¯”V1ï¼ŒV2æ”¹è¿›äº†Warp Partitionï¼š4ä¸ªwarpä¼šä»smemçš„K/V tile loadåŒæ ·çš„æ•°æ®åšmmaè®¡ç®—ï¼Œä½†æ˜¯load ä¸åŒQï¼ŒæŠŠV1 sliced-K sliced-V æ”¹æˆäº†v2 sliced-Qï¼ŒV1çš„åšæ³•æ˜¯éœ€è¦warpä¹‹é—´äº§ç”ŸåŒæ­¥é€šä¿¡çš„ï¼Œå› ä¸ºåœ¨è®¡ç®—QKç»“æœä¹˜Vçš„æ—¶å€™ï¼Œå¦‚å›¾æ‰€ç¤ºéœ€è¦è·¨warp reductionå¾—åˆ°Oçš„ç»“æœï¼Œ<strong>è€Œä¸”fwdçš„ç›®çš„æ˜¯æ²¿ç€è¡Œæ–¹å‘è®¡ç®—softmaxï¼Œè¡Œæ–¹å‘ä¿¡æ¯æœ€åè¦æ±‡æ€»çš„ï¼Œè¿™ä¹Ÿéœ€è¦è·¨warpä¸åŒã€‚V2å°±ä¸éœ€è¦äº†ï¼Œè¿™æ ·å¯ä»¥å‡å°‘åŒæ­¥å¼€é”€ã€‚</strong></p>
<h1 id="0x05-causal-maskæ€ä¹ˆç”¨">0x05 Causal Maskæ€ä¹ˆç”¨ï¼Ÿ<a hidden class="anchor" aria-hidden="true" href="#0x05-causal-maskæ€ä¹ˆç”¨">#</a></h1>
<p>æ‘˜è‡ª <a href="https://zhuanlan.zhihu.com/p/668888063">[Attentionä¼˜åŒ–][2wå­—]ğŸ”¥åŸç†&amp;å›¾è§£: ä»Online-Softmaxåˆ°FlashAttention V1/V2/V3</a></p>
<p>éå¸¸ç®€å•çš„Early Exité€»è¾‘ï¼š</p>
<p>æƒ…å†µ0: å…¨Early Exitã€‚å…¨0çš„maskå¯ä»¥ç›´æ¥è¿”å›0ï¼Œæ— éœ€$Q\times K^T$ï¼Œæ— éœ€causal maskã€‚</p>
<p>æƒ…å†µ1: éƒ¨åˆ†Early Exitã€‚å…¨1çš„maskï¼Œåªéœ€$\text{Softmax}(Q\times K^T)$ï¼Œæ— éœ€causal maskã€‚</p>
<p>æƒ…å†µ3: æ— æ³•Early Exitã€‚0-1æ··åˆçš„causal maskï¼Œéœ€QxK^Tï¼Œéœ€è¦causal maskï¼Œç„¶å$\text{Softmax}(\text{Mask}(Q \times K^T))$ã€‚</p>
<figure>
    <img loading="lazy" src="mask.png"
         alt="[Attentionä¼˜åŒ–][2wå­—]ğŸ”¥åŸç†&amp;amp;å›¾è§£: ä»Online-Softmaxåˆ°FlashAttention V1/V2/V3"/> <figcaption>
            Masked ç¤ºæ„å›¾<p><a href="https://zhuanlan.zhihu.com/p/668888063">[Attentionä¼˜åŒ–][2wå­—]ğŸ”¥åŸç†&amp;å›¾è§£: ä»Online-Softmaxåˆ°FlashAttention V1/V2/V3</a></p>
        </figcaption>
</figure>

<h1 id="0x06-mhagqamqa">0x06 MHA/GQA/MQA<a hidden class="anchor" aria-hidden="true" href="#0x06-mhagqamqa">#</a></h1>
<p>åœ¨FlashAttentionä¸­ï¼Œä¹Ÿæ”¯æŒMQAå’ŒGQAã€‚å¯¹äºMQAå’ŒGQAçš„æƒ…å½¢ï¼ŒFlashAttentioné‡‡ç”¨Indexingçš„æ–¹å¼ï¼Œè€Œä¸æ˜¯ç›´æ¥å¤åˆ¶å¤šä»½KV Headçš„å†…å®¹åˆ°æ˜¾å­˜ç„¶åå†è¿›è¡Œè®¡ç®—ã€‚Indexingï¼Œå³é€šè¿‡ä¼ å…¥KV/KV Headç´¢å¼•åˆ°Kernelä¸­ï¼Œç„¶åè®¡ç®—å†…å­˜åœ°å€ï¼Œç›´æ¥ä»å†…å­˜ä¸­è¯»å–KVã€‚</p>
<h1 id="0x07-ioå¤æ‚åº¦åˆ†æ">0x07 IOå¤æ‚åº¦åˆ†æ<a hidden class="anchor" aria-hidden="true" href="#0x07-ioå¤æ‚åº¦åˆ†æ">#</a></h1>
<p>å› ä¸ºFAä¸»è¦æ˜¯ä¼˜åŒ–IO Accesï¼Œæ‰€ä»¥æˆ‘ä»¬åˆ†æä¸‹FAçš„IOå¤æ‚åº¦ã€‚æˆ‘ä»¬å‡è®¾Sequenceçš„é•¿åº¦æ˜¯$N$ï¼Œæ¯ä¸ªå¤´çš„ç»´åº¦æ˜¯$d$ï¼ŒSRAMçš„å¤§å°æ˜¯$M,d \le M \le Nd$ã€‚</p>
<p>ä½¿ç”¨åŸå§‹çš„Self Attentionç®—æ³•çš„IOå¤æ‚åº¦æ˜¯$\Theta(Nd + N^2)$ï¼ŒFA1çš„IOå¤æ‚åº¦æ˜¯$\Theta(N^2d^2M^{-1})$ï¼Œè€ƒè™‘åˆ°$d$ä¸€èˆ¬æ˜¯64-128ï¼Œè€Œ$M$ä¸€èˆ¬æ˜¯100KBï¼Œæ‰€ä»¥FA1çš„è®¿å­˜æ¬¡æ•°å°äºåŸå§‹çš„åšæ³•ã€‚</p>
<p>Memory Accesseså’Œdçš„å¹³æ–¹æˆæ­£æ¯”å…³ç³»ï¼Œå½“dè¶Šå¤§ï¼ŒFAçš„Memory Accessesä¼šå¢é•¿å‰§çƒˆã€‚æ¯”å¦‚å¯¹äºN=2K, M=192KB, å½“d=256æ—¶ï¼Œä¾ç„¶æ»¡è¶³ FA IO Acesses &lt; Naive Attentionï¼Œä½†æ˜¯<strong>å½“d=512æ—¶ï¼Œè¿™ä¸ªç»“è®ºå°±ä¼šåè¿‡æ¥</strong>ï¼Œå˜æˆæ˜¯ <strong>FA IO Acesses &gt; Naive Attention IO Acesses</strong>ï¼Œå¹¶ä¸”ç”±äºFAæœ¬èº«çš„FLOPSå°±æ˜¯æ¯”Naive Attentioné«˜çš„ï¼Œäºæ˜¯ï¼Œæ­¤æ—¶æ— è®ºæ˜¯IOè¿˜æ˜¯FLOPSï¼ŒFAéƒ½ä¼šæ¯”Naive Attentioné«˜ï¼Œæ— è®ºæ˜¯è®¿å­˜è¿˜æ˜¯è®¡ç®—é‡éƒ½æ²¡æœ‰ä¼˜åŠ¿ï¼Œå”¯ä¸€å‰©ä¸‹çš„ä¼˜åŠ¿ï¼Œåº”è¯¥å°±åªå‰©èŠ‚çœæ˜¾å­˜äº†ï¼ˆä¸éœ€è¦ä¿å­˜ä¸­é—´çš„Så’ŒPçŸ©é˜µï¼ŒO(N^2)çš„å†…å­˜å¤æ‚åº¦ï¼‰</p>
<h1 id="0x08-tritonä»£ç ">0x08 Tritonä»£ç <a hidden class="anchor" aria-hidden="true" href="#0x08-tritonä»£ç ">#</a></h1>
<p>å…ˆå†æ¥å¤ä¹ ä¸‹Blockæ˜¯æ€ä¹ˆåˆ‡å—çš„ï¼Œè¿™é‡Œçš„å›¾æ‘˜è‡ªBBufçš„ ç¬”è®°<a href="https://mp.weixin.qq.com/s/5K6yNj23NmNLcAQofHcT4Q">å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼šFlash Attention V2ï¼Œä»åŸç†åˆ°å¹¶è¡Œè®¡ç®—</a>ã€‚</p>
<figure>
    <img loading="lazy" src="tile-dir.webp"
         alt="å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼šFlash Attention V2ï¼Œä»åŸç†åˆ°å¹¶è¡Œè®¡ç®—"/> <figcaption>
            Blockåˆ‡å—æ–¹å‘<p><a href="https://mp.weixin.qq.com/s/5K6yNj23NmNLcAQofHcT4Q">å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼šFlash Attention V2ï¼Œä»åŸç†åˆ°å¹¶è¡Œè®¡ç®—</a></p>
        </figcaption>
</figure>

<p>å¢åŠ äº†Seqç»´åº¦çš„å¹¶è¡Œä»¥åï¼š</p>
<figure>
    <img loading="lazy" src="tile-dir-1.webp"
         alt="å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼šFlash Attention V2ï¼Œä»åŸç†åˆ°å¹¶è¡Œè®¡ç®—"/> <figcaption>
            Seqç»´åº¦åˆ‡å—æ–¹å‘<p><a href="https://mp.weixin.qq.com/s/5K6yNj23NmNLcAQofHcT4Q">å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼šFlash Attention V2ï¼Œä»åŸç†åˆ°å¹¶è¡Œè®¡ç®—</a></p>
        </figcaption>
</figure>

<p>ä¸V1ä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨Qçš„seq_lenç»´åº¦ä¸Šä¹Ÿåšäº†åˆ‡åˆ†ï¼Œå°†å…¶åˆ†æˆå››ä»½ï¼Œå³num_m_block = 4ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬å…±æœ‰1_2_4 = 8ä¸ªblockåœ¨è·‘ã€‚<strong>è¿™äº›blockä¹‹é—´çš„è¿ç®—ä¹Ÿæ˜¯ç‹¬ç«‹çš„ï¼Œ</strong> å› ä¸ºï¼š</p>
<ul>
<li><strong>headçš„è®¡ç®—æ˜¯ç‹¬ç«‹çš„ï¼Œæ‰€ä»¥çº¢è‰²blockå’Œè“è‰²blockäº’ä¸å¹²æ‰°</strong></li>
<li><strong>é‡‡ç”¨Qåšå¤–å¾ªç¯ï¼ŒKVåšå†…å¾ªç¯æ—¶ï¼Œè¡Œä¸è¡Œä¹‹é—´çš„blockæ˜¯ç‹¬ç«‹çš„ï¼Œå› æ­¤ä¸åŒè¡Œçš„blockäº’ç›¸ä¸å¹²æ‰°ã€‚</strong></li>
</ul>
<p>æ¯ä¸ªblockä»Qä¸ŠåŠ è½½å¯¹åº”ä½ç½®çš„åˆ‡å—ï¼ŒåŒæ—¶ä»KVä¸ŠåŠ è½½head0çš„åˆ‡å—ï¼Œè®¡ç®—å‡ºè‡ªå·±æ‰€ç»´æŠ¤çš„é‚£éƒ¨åˆ†Oï¼Œç„¶åå†™å…¥Oçš„å¯¹åº”ä½ç½®ã€‚</p>
<p>æˆ‘ä»¬ä½¿ç”¨<a href="https://triton-lang.org/main/getting-started/tutorials/06-fused-attention.html">OpenAI Tritonçš„FA2 Tutorialä»£ç </a>æ¥åˆ†æã€‚</p>
<p>ä¸‹é¢çš„ä»£ç æ˜¯æ¯ä¸€ä¸ªå­Blockä¸­çš„æœ€å†…å±‚çš„ä»£ç ï¼Œå…¶ä¸­<code>q</code>æ˜¯æœ€å¤–å±‚å¾ªç¯çš„å­å—ï¼›<code>K_block_ptr</code>ã€<code>V_block_ptr</code>æ˜¯$K$ã€$V$çš„å­å—ï¼Œéœ€è¦ä¸€æ¬¡forå¾ªç¯å®Œæ•´çš„éå†ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@triton.jit</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_attn_fwd_inner</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">l_i</span><span class="p">,</span> <span class="n">m_i</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                    <span class="n">K_block_ptr</span><span class="p">,</span> <span class="n">V_block_ptr</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                    <span class="n">start_m</span><span class="p">,</span> <span class="n">qk_scale</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                    <span class="n">BLOCK_M</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span> <span class="n">HEAD_DIM</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                    <span class="n">STAGE</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span> <span class="n">offs_m</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span> <span class="n">offs_n</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                    <span class="n">N_CTX</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span> <span class="n">fp8_v</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># range of values handled by this stage</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># æ ¹æ®STAGEçš„å€¼ï¼Œå‡½æ•°å®šä¹‰äº†å¤„ç†çš„é”®ï¼ˆKï¼‰å’Œå€¼ï¼ˆVï¼‰çš„èŒƒå›´ã€‚</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ä¸åŒçš„STAGEå¯¹åº”ä¸åŒçš„å¤„ç†èŒƒå›´ï¼Œæ”¯æŒå› æœï¼ˆcausalï¼‰å’Œéå› æœï¼ˆnon-causalï¼‰çš„è‡ªæ³¨æ„åŠ›ã€‚</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">STAGE</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="c1"># ä½¿ç”¨ Mask</span>
</span></span><span class="line"><span class="cl">        <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">start_m</span> <span class="o">*</span> <span class="n">BLOCK_M</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="n">STAGE</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span> <span class="c1"># ä½¿ç”¨ Mask</span>
</span></span><span class="line"><span class="cl">        <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span> <span class="o">=</span> <span class="n">start_m</span> <span class="o">*</span> <span class="n">BLOCK_M</span><span class="p">,</span> <span class="p">(</span><span class="n">start_m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">BLOCK_M</span>
</span></span><span class="line"><span class="cl">        <span class="n">lo</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">multiple_of</span><span class="p">(</span><span class="n">lo</span><span class="p">,</span> <span class="n">BLOCK_M</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># causal = Falseï¼Œä¸ä½¿ç”¨ Mask</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">N_CTX</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">    <span class="c1"># tl.advance æ ¹æ®æ­¥é•¿è°ƒæ•´K_block_ptrçš„æŒ‡å‘    </span>
</span></span><span class="line"><span class="cl">    <span class="n">K_block_ptr</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">advance</span><span class="p">(</span><span class="n">K_block_ptr</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">lo</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">V_block_ptr</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">advance</span><span class="p">(</span><span class="n">V_block_ptr</span><span class="p">,</span> <span class="p">(</span><span class="n">lo</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># å¯¹K,V Blockåšå®Œæ•´çš„éå†</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">start_n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">start_n</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">multiple_of</span><span class="p">(</span><span class="n">start_n</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># -- compute qk ----</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># åŠ è½½ K Block</span>
</span></span><span class="line"><span class="cl">        <span class="n">k</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">K_block_ptr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># ä¼ªä»£ç  line8: q x k</span>
</span></span><span class="line"><span class="cl">        <span class="n">qk</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">STAGE</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Mask</span>
</span></span><span class="line"><span class="cl">            <span class="n">mask</span> <span class="o">=</span> <span class="n">offs_m</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="n">start_n</span> <span class="o">+</span> <span class="n">offs_n</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># Mask åŒºåŸŸåŠ ä¸Š -INF</span>
</span></span><span class="line"><span class="cl">            <span class="n">qk</span> <span class="o">=</span> <span class="n">qk</span> <span class="o">*</span> <span class="n">qk_scale</span> <span class="o">+</span> <span class="n">tl</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0e6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># ä¼ªä»£ç  line 9: Safe online softmax çš„ max</span>
</span></span><span class="line"><span class="cl">            <span class="n">m_ij</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">m_i</span><span class="p">,</span> <span class="n">tl</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">qk</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># ä¼ªä»£ç  line 9: s - m</span>
</span></span><span class="line"><span class="cl">            <span class="n">qk</span> <span class="o">-=</span> <span class="n">m_ij</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># ä¼ªä»£ç  line 9: Safe online softmax çš„ maxï¼Œå’Œä¼ªä»£ç çš„åŒºåˆ«æ˜¯è¿™é‡Œæœ‰ qk_scaleï¼Œç¨åè§£é‡Š</span>
</span></span><span class="line"><span class="cl">            <span class="n">m_ij</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">m_i</span><span class="p">,</span> <span class="n">tl</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">qk</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">qk_scale</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># ä¼ªä»£ç  line 9: s - m. å’Œä¼ªä»£ç çš„åŒºåˆ«æ˜¯è¿™é‡Œæœ‰ qk_scaleï¼Œç¨åè§£é‡Š</span>
</span></span><span class="line"><span class="cl">            <span class="n">qk</span> <span class="o">=</span> <span class="n">qk</span> <span class="o">*</span> <span class="n">qk_scale</span> <span class="o">-</span> <span class="n">m_ij</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ä¼ªä»£ç  line 9: p = exp(s-m)</span>
</span></span><span class="line"><span class="cl">        <span class="n">p</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">exp2</span><span class="p">(</span><span class="n">qk</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># ä¼ªä»£ç  line 9: rowsum(p)</span>
</span></span><span class="line"><span class="cl">        <span class="n">l_ij</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># -- update m_i and l_i</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ä¼ªä»£ç  line 10</span>
</span></span><span class="line"><span class="cl">        <span class="n">alpha</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">exp2</span><span class="p">(</span><span class="n">m_i</span> <span class="o">-</span> <span class="n">m_ij</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">l_i</span> <span class="o">=</span> <span class="n">l_i</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">l_ij</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># -- update output accumulator --</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ä¼ªä»£ç  line 10: è¿™é‡Œçš„ acc æ˜¯ä¼ªä»£ç ä¸­çš„ O_i</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc</span> <span class="o">=</span> <span class="n">acc</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># update acc</span>
</span></span><span class="line"><span class="cl">        <span class="n">v</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">V_block_ptr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">fp8_v</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">float8e5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># ä¼ªä»£ç  line 10.</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># update m_i and l_i</span>
</span></span><span class="line"><span class="cl">        <span class="n">m_i</span> <span class="o">=</span> <span class="n">m_ij</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># æ›´æ–°ä¸‹ä¸€è½®çš„ K,V Blockçš„æŒ‡é’ˆ</span>
</span></span><span class="line"><span class="cl">        <span class="n">V_block_ptr</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">advance</span><span class="p">(</span><span class="n">V_block_ptr</span><span class="p">,</span> <span class="p">(</span><span class="n">BLOCK_N</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">K_block_ptr</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">advance</span><span class="p">(</span><span class="n">K_block_ptr</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">acc</span><span class="p">,</span> <span class="n">l_i</span><span class="p">,</span> <span class="n">m_i</span>
</span></span></code></pre></div><p>ä¸‹é¢æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹è°ƒç”¨è¿™ä¸ªå­å—å‡½æ•°çš„å‡½æ•°ã€‚</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@triton.autotune</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="n">keep</span><span class="p">,</span> <span class="n">configs</span><span class="p">)),</span> <span class="n">key</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;N_CTX&#34;</span><span class="p">,</span> <span class="s2">&#34;HEAD_DIM&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="nd">@triton.jit</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_attn_fwd</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">sm_scale</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">Out</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">              <span class="n">stride_qz</span><span class="p">,</span> <span class="n">stride_qh</span><span class="p">,</span> <span class="n">stride_qm</span><span class="p">,</span> <span class="n">stride_qk</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">              <span class="n">stride_kz</span><span class="p">,</span> <span class="n">stride_kh</span><span class="p">,</span> <span class="n">stride_kn</span><span class="p">,</span> <span class="n">stride_kk</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">              <span class="n">stride_vz</span><span class="p">,</span> <span class="n">stride_vh</span><span class="p">,</span> <span class="n">stride_vk</span><span class="p">,</span> <span class="n">stride_vn</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">              <span class="n">stride_oz</span><span class="p">,</span> <span class="n">stride_oh</span><span class="p">,</span> <span class="n">stride_om</span><span class="p">,</span> <span class="n">stride_on</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">              <span class="n">Z</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">N_CTX</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">              <span class="n">HEAD_DIM</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">              <span class="n">BLOCK_M</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">              <span class="n">BLOCK_N</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">              <span class="n">STAGE</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">              <span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">tl</span><span class="o">.</span><span class="n">static_assert</span><span class="p">(</span><span class="n">BLOCK_N</span> <span class="o">&lt;=</span> <span class="n">HEAD_DIM</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># è¾“å…¥å‚æ•°é‡Œçš„Zå’ŒHåˆ†åˆ«è¡¨ç¤ºbatch sizeå’Œæ³¨æ„åŠ›å¤´æ•°</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># q.shape is [Batch, Head, Seq, Dim]</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># å¯åŠ¨çš„æ—¶å€™ [grid] æ˜¯</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># grid = lambda args: (triton.cdiv(q.shape[2], args[&#34;BLOCK_M&#34;]), q.shape[0] * q.shape[1], 1)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># start_mè¡¨ç¤ºå½“å‰kernel program å®ä¾‹å¯¹åº”çš„seqç»´åº¦çš„åç§»ï¼Œè€Œoff_hzè¡¨ç¤ºçš„æ˜¯batch*headsç»´åº¦çš„åç§»ã€‚</span>
</span></span><span class="line"><span class="cl">    <span class="n">start_m</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># seq</span>
</span></span><span class="line"><span class="cl">    <span class="n">off_hz</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># batch * heads</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># è¿™ä¸¤è¡Œè®¡ç®—äº†ä¸¤ä¸ªåç§»é‡off_zå’Œoff_hï¼Œå®ƒä»¬åˆ†åˆ«ä»£è¡¨åœ¨batchï¼ˆæˆ–headsï¼‰ä¸­çš„ä½ç½®ã€‚</span>
</span></span><span class="line"><span class="cl">    <span class="n">off_z</span> <span class="o">=</span> <span class="n">off_hz</span> <span class="o">//</span> <span class="n">H</span> <span class="c1"># è¡¨ç¤ºåœ¨å“ªä¸ª Batch</span>
</span></span><span class="line"><span class="cl">    <span class="n">off_h</span> <span class="o">=</span> <span class="n">off_hz</span> <span class="o">%</span> <span class="n">H</span> <span class="c1"># è¡¨ç¤ºåœ¨å“ªä¸ª Head</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># è®¡ç®—ç”¨äºå®šä½Qã€Kå’ŒVå¼ é‡ä¸­å½“å‰å¤„ç†å—çš„åç§»é‡ã€‚è¿™æ˜¯åŸºäºå…ˆå‰è®¡ç®—çš„åç§»é‡å’Œæä¾›çš„æ­¥é•¿å‚æ•°ã€‚</span>
</span></span><span class="line"><span class="cl">    <span class="n">qvk_offset</span> <span class="o">=</span> <span class="n">off_z</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride_qz</span> <span class="o">+</span> <span class="n">off_h</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">tl</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride_qh</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># block pointers</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ä½¿ç”¨tl.make_block_ptråˆ›å»ºä¸€ä¸ªæŒ‡å‘Qå¼ é‡å½“å‰å¤„ç†å—çš„æŒ‡é’ˆã€‚è¿™ä¸ªå‡½æ•°è°ƒç”¨æŒ‡å®šäº†åŸºç¡€åœ°å€ã€å½¢çŠ¶ã€æ­¥é•¿ã€åç§»é‡å’Œå—å½¢çŠ¶ç­‰ï¼Œä»¥åŠå¦‚ä½•åœ¨å†…å­˜ä¸­è®¿é—®è¿™ä¸ªæ•°æ®å—ã€‚</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># N_CTX æ˜¯q.shape[2]ï¼Œè¡¨ç¤ºçš„æ˜¯åºåˆ—é•¿åº¦ï¼ŒBLOCK_DMODELæ˜¯Lkï¼Œè¡¨ç¤ºçš„æ˜¯æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„éšè—å±‚ç»´åº¦å¤§å°</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ä¸‹é¢å‡ ä¸ªmake_block_ptråˆ›å»ºçš„å¼ é‡ç±»ä¼¼ï¼Œåˆ†åˆ«æ˜¯å¯¹Kï¼ŒVä»¥åŠè¾“å‡ºOåˆ›å»ºæŒ‡å‘å½“å‰å¤„ç†å—çš„æŒ‡é’ˆ</span>
</span></span><span class="line"><span class="cl">    <span class="n">Q_block_ptr</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">make_block_ptr</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">base</span><span class="o">=</span><span class="n">Q</span> <span class="o">+</span> <span class="n">qvk_offset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N_CTX</span><span class="p">,</span> <span class="n">HEAD_DIM</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="n">stride_qm</span><span class="p">,</span> <span class="n">stride_qk</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">offsets</span><span class="o">=</span><span class="p">(</span><span class="n">start_m</span> <span class="o">*</span> <span class="n">BLOCK_M</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">block_shape</span><span class="o">=</span><span class="p">(</span><span class="n">BLOCK_M</span><span class="p">,</span> <span class="n">HEAD_DIM</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">v_order</span><span class="p">:</span> <span class="n">tl</span><span class="o">.</span><span class="n">constexpr</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">V</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">element_ty</span> <span class="o">==</span> <span class="n">tl</span><span class="o">.</span><span class="n">float8e5</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">V_block_ptr</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">make_block_ptr</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">base</span><span class="o">=</span><span class="n">V</span> <span class="o">+</span> <span class="n">qvk_offset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N_CTX</span><span class="p">,</span> <span class="n">HEAD_DIM</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="n">stride_vk</span><span class="p">,</span> <span class="n">stride_vn</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">offsets</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">block_shape</span><span class="o">=</span><span class="p">(</span><span class="n">BLOCK_N</span><span class="p">,</span> <span class="n">HEAD_DIM</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">order</span><span class="o">=</span><span class="n">v_order</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">K_block_ptr</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">make_block_ptr</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">base</span><span class="o">=</span><span class="n">K</span> <span class="o">+</span> <span class="n">qvk_offset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">HEAD_DIM</span><span class="p">,</span> <span class="n">N_CTX</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="n">stride_kk</span><span class="p">,</span> <span class="n">stride_kn</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">offsets</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">block_shape</span><span class="o">=</span><span class="p">(</span><span class="n">HEAD_DIM</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">O_block_ptr</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">make_block_ptr</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">base</span><span class="o">=</span><span class="n">Out</span> <span class="o">+</span> <span class="n">qvk_offset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N_CTX</span><span class="p">,</span> <span class="n">HEAD_DIM</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="n">stride_om</span><span class="p">,</span> <span class="n">stride_on</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">offsets</span><span class="o">=</span><span class="p">(</span><span class="n">start_m</span> <span class="o">*</span> <span class="n">BLOCK_M</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">block_shape</span><span class="o">=</span><span class="p">(</span><span class="n">BLOCK_M</span><span class="p">,</span> <span class="n">HEAD_DIM</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># initialize offsets</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># è®¡ç®—Mç»´åº¦ï¼ˆseqç»´åº¦ï¼‰ä¸Šæ¯ä¸ªçº¿ç¨‹åº”å¤„ç†çš„å…ƒç´ çš„èµ·å§‹åç§»é‡ã€‚</span>
</span></span><span class="line"><span class="cl">    <span class="n">offs_m</span> <span class="o">=</span> <span class="n">start_m</span> <span class="o">*</span> <span class="n">BLOCK_M</span> <span class="o">+</span> <span class="n">tl</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">BLOCK_M</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># è®¡ç®—Nç»´åº¦ï¼ˆbatch*headsç»´åº¦ï¼‰ä¸Šæ¯ä¸ªçº¿ç¨‹åº”å¤„ç†çš„å…ƒç´ çš„åç§»é‡ã€‚</span>
</span></span><span class="line"><span class="cl">    <span class="n">offs_n</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># initialize pointer to m and l</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># åˆå§‹åŒ–må‘é‡ï¼Œmç”¨äºå­˜å‚¨æ¯ä¸ªmç»´åº¦ä¸Šçš„æœ€å¤§logitï¼Œåˆå§‹åŒ–ä¸ºè´Ÿæ— ç©·å¤§ã€‚</span>
</span></span><span class="line"><span class="cl">    <span class="n">m_i</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">BLOCK_M</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">-</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&#34;inf&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># åˆå§‹åŒ–lå‘é‡ï¼Œlç”¨äºç´¯è®¡softmaxçš„åˆ†æ¯ï¼Œåˆå§‹åŒ–ä¸º1ã€‚</span>
</span></span><span class="line"><span class="cl">    <span class="n">l_i</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">BLOCK_M</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.0</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># åˆå§‹åŒ–ç´¯åŠ å™¨ï¼Œç”¨äºç´¯ç§¯æ³¨æ„åŠ›åŠ æƒå’Œã€‚æ³¨æ„è¿™é‡Œçš„shapeæ˜¯(BLOCK_M, BLOCK_DMODEL)</span>
</span></span><span class="line"><span class="cl">    <span class="n">acc</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">BLOCK_M</span><span class="p">,</span> <span class="n">HEAD_DIM</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tl</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># load scales</span>
</span></span><span class="line"><span class="cl">    <span class="n">qk_scale</span> <span class="o">=</span> <span class="n">sm_scale</span>
</span></span><span class="line"><span class="cl">    <span class="n">qk_scale</span> <span class="o">*=</span> <span class="mf">1.44269504</span>  <span class="c1"># 1/log(2)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># load q: it will stay in SRAM throughout</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># å°†QçŸ©é˜µçš„å½“å‰å—åŠ è½½åˆ°SRAMä¸­ï¼Œæ­¤æ•°æ®åœ¨æ•´ä¸ªè®¡ç®—è¿‡ç¨‹ä¸­ä¿æŒä¸å˜ã€‚</span>
</span></span><span class="line"><span class="cl">    <span class="n">q</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Q_block_ptr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># stage 1: off-band</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># For causal = True, STAGE = 3 and _attn_fwd_inner gets 1 as its STAGE</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># For causal = False, STAGE = 1, and _attn_fwd_inner gets 3 as its STAGE</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">STAGE</span> <span class="o">&amp;</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc</span><span class="p">,</span> <span class="n">l_i</span><span class="p">,</span> <span class="n">m_i</span> <span class="o">=</span> <span class="n">_attn_fwd_inner</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">l_i</span><span class="p">,</span> <span class="n">m_i</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">K_block_ptr</span><span class="p">,</span> <span class="n">V_block_ptr</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                                        <span class="n">start_m</span><span class="p">,</span> <span class="n">qk_scale</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                                        <span class="n">BLOCK_M</span><span class="p">,</span> <span class="n">HEAD_DIM</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                                        <span class="mi">4</span> <span class="o">-</span> <span class="n">STAGE</span><span class="p">,</span> <span class="n">offs_m</span><span class="p">,</span> <span class="n">offs_n</span><span class="p">,</span> <span class="n">N_CTX</span><span class="p">,</span> <span class="n">V</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">element_ty</span> <span class="o">==</span> <span class="n">tl</span><span class="o">.</span><span class="n">float8e5</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                                        <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># stage 2: on-band</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">STAGE</span> <span class="o">&amp;</span> <span class="mi">2</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># barrier makes it easier for compielr to schedule the</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># two loops independently</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc</span><span class="p">,</span> <span class="n">l_i</span><span class="p">,</span> <span class="n">m_i</span> <span class="o">=</span> <span class="n">_attn_fwd_inner</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">l_i</span><span class="p">,</span> <span class="n">m_i</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">K_block_ptr</span><span class="p">,</span> <span class="n">V_block_ptr</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                                        <span class="n">start_m</span><span class="p">,</span> <span class="n">qk_scale</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                                        <span class="n">BLOCK_M</span><span class="p">,</span> <span class="n">HEAD_DIM</span><span class="p">,</span> <span class="n">BLOCK_N</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                                        <span class="mi">2</span><span class="p">,</span> <span class="n">offs_m</span><span class="p">,</span> <span class="n">offs_n</span><span class="p">,</span> <span class="n">N_CTX</span><span class="p">,</span> <span class="n">V</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">element_ty</span> <span class="o">==</span> <span class="n">tl</span><span class="o">.</span><span class="n">float8e5</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">                                        <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># epilogue</span>
</span></span><span class="line"><span class="cl">    <span class="n">m_i</span> <span class="o">+=</span> <span class="n">tl</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">l_i</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">acc</span> <span class="o">=</span> <span class="n">acc</span> <span class="o">/</span> <span class="n">l_i</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">m_ptrs</span> <span class="o">=</span> <span class="n">M</span> <span class="o">+</span> <span class="n">off_hz</span> <span class="o">*</span> <span class="n">N_CTX</span> <span class="o">+</span> <span class="n">offs_m</span>
</span></span><span class="line"><span class="cl">    <span class="n">tl</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="n">m_ptrs</span><span class="p">,</span> <span class="n">m_i</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">tl</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="n">O_block_ptr</span><span class="p">,</span> <span class="n">acc</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">Out</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">element_ty</span><span class="p">))</span>
</span></span></code></pre></div><p>éœ€è¦ç‰¹åˆ«æ³¨æ„çš„æ˜¯è¿™æ®µä»£ç æœ€åçš„epilogueéƒ¨åˆ†å°±å¯¹åº”äº†FlashAttention V2ä¼ªä»£ç ä¸­çš„12è¡Œä»¥åçš„å†…å®¹ï¼Œæ ¹æ®softmaxçš„åˆ†æ¯éƒ¨åˆ†è¾ƒæ­£è¾“å‡ºã€‚æ­¤å¤–ï¼ŒTritonçš„å®ç°é‡Œé¢è€ƒè™‘äº†ä¸€äº›paperé‡Œé¢æ²¡æœ‰çš„ä¸œè¥¿æ¯”å¦‚<code>qk_scale</code>ï¼Œ<code>causal mask</code>ï¼Œå¯¹<code>Q*K</code>çš„ç»“æœ<code>S</code>åº”ç”¨äº†å‡æ‰mï¼Œä½¿å¾—æ•´ä¸ªå®ç°çœ‹èµ·æ¥è¦å¤æ‚ä¸å°‘ï¼Œä½†æ•´ä½“çš„ç®—æ³•é€»è¾‘å’Œå¹¶è¡Œè®¾ç½®å’Œpaperè¿˜æ˜¯ä¸€è‡´çš„ã€‚</p>
<p>æœ€ååœ¨Attentionä¸­ä½¿ç”¨è¿™ä¸ªå‡½æ•°</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">_attention</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nd">@staticmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">causal</span><span class="p">,</span> <span class="n">sm_scale</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># shape constraints</span>
</span></span><span class="line"><span class="cl">        <span class="n">HEAD_DIM_Q</span><span class="p">,</span> <span class="n">HEAD_DIM_K</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># when v is in float8_e5m2 it is transposed.</span>
</span></span><span class="line"><span class="cl">        <span class="n">HEAD_DIM_V</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">HEAD_DIM_Q</span> <span class="o">==</span> <span class="n">HEAD_DIM_K</span> <span class="ow">and</span> <span class="n">HEAD_DIM_K</span> <span class="o">==</span> <span class="n">HEAD_DIM_V</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">HEAD_DIM_K</span> <span class="ow">in</span> <span class="p">{</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">o</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">stage</span> <span class="o">=</span> <span class="mi">3</span> <span class="k">if</span> <span class="n">causal</span> <span class="k">else</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">        <span class="n">extra_kern_args</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Tuning for AMD target</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">is_hip</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="n">waves_per_eu</span> <span class="o">=</span> <span class="mi">3</span> <span class="k">if</span> <span class="n">HEAD_DIM_K</span> <span class="o">&lt;=</span> <span class="mi">64</span> <span class="k">else</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">            <span class="n">extra_kern_args</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;waves_per_eu&#34;</span><span class="p">:</span> <span class="n">waves_per_eu</span><span class="p">,</span> <span class="s2">&#34;allow_flush_denorm&#34;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># q.shape is [Batch, Head, Seq, Dim]</span>
</span></span><span class="line"><span class="cl">        <span class="n">grid</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">args</span><span class="p">:</span> <span class="p">(</span><span class="n">triton</span><span class="o">.</span><span class="n">cdiv</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="s2">&#34;BLOCK_M&#34;</span><span class="p">]),</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="n">device</span><span class="o">=</span><span class="n">q</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># Launch Kernel.</span>
</span></span><span class="line"><span class="cl">        <span class="n">_attn_fwd</span><span class="p">[</span><span class="n">grid</span><span class="p">](</span>
</span></span><span class="line"><span class="cl">            <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">sm_scale</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">            <span class="n">q</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">q</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">q</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">q</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">            <span class="n">k</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">k</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">k</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">k</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">            <span class="n">v</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">v</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">v</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">v</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">            <span class="n">o</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">o</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">o</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">o</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">            <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">            <span class="n">N_CTX</span><span class="o">=</span><span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">            <span class="n">HEAD_DIM</span><span class="o">=</span><span class="n">HEAD_DIM_K</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">            <span class="n">STAGE</span><span class="o">=</span><span class="n">stage</span><span class="p">,</span>  <span class="c1">#</span>
</span></span><span class="line"><span class="cl">            <span class="o">**</span><span class="n">extra_kern_args</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">ctx</span><span class="o">.</span><span class="n">grid</span> <span class="o">=</span> <span class="n">grid</span>
</span></span><span class="line"><span class="cl">        <span class="n">ctx</span><span class="o">.</span><span class="n">sm_scale</span> <span class="o">=</span> <span class="n">sm_scale</span>
</span></span><span class="line"><span class="cl">        <span class="n">ctx</span><span class="o">.</span><span class="n">HEAD_DIM</span> <span class="o">=</span> <span class="n">HEAD_DIM_K</span>
</span></span><span class="line"><span class="cl">        <span class="n">ctx</span><span class="o">.</span><span class="n">causal</span> <span class="o">=</span> <span class="n">causal</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">o</span>
</span></span></code></pre></div><h1 id="0x09-cudaä»£ç ">0x09 CUDAä»£ç <a hidden class="anchor" aria-hidden="true" href="#0x09-cudaä»£ç ">#</a></h1>
<h1 id="0x0a-fa-3">0x0A FA 3<a hidden class="anchor" aria-hidden="true" href="#0x0a-fa-3">#</a></h1>
<h1 id="0x0b-æ€è€ƒ">0x0B æ€è€ƒ<a hidden class="anchor" aria-hidden="true" href="#0x0b-æ€è€ƒ">#</a></h1>
<ul>
<li>CPUä¸Šä½¿ç”¨è¿™ä¸ªé è°±å—ï¼ŸCPUä¸Šå¹¶è¡Œåº¦è¾ƒä½ï¼Œç”¨è¿™ä¸ªæ²¡æœ‰å¿…è¦ï¼Œä½†æ˜¯å¯ä»¥è€ƒè™‘åˆ†å—å’ŒMaskæ··åˆçš„MatMulæ¥å‡å°‘è®¡ç®—é‡ï¼Œä¹Ÿå°±æ˜¯Early Exitã€‚</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/keep-moving-forward/tags/llm-server/">LLM Server</a></li>
      <li><a href="http://localhost:1313/keep-moving-forward/tags/llm/">LLM</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/keep-moving-forward/tech/fundamental_rope/">
    <span class="title">Â« Prev</span>
    <br>
    <span>[Fundamental] æ—‹è½¬ä½ç½®ç¼–ç (RoPE)</span>
  </a>
  <a class="next" href="http://localhost:1313/keep-moving-forward/tech/mllm-qwen/">
    <span class="title">Next Â»</span>
    <br>
    <span>mllmæ¡†æ¶æµ…æ(ä¸€)-ä»¥QWen0.5Bä¸ºä¾‹</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share [Fundamental] From Online Softmax to Flash Attention V3 on x"
            href="https://x.com/intent/tweet/?text=%5bFundamental%5d%20From%20Online%20Softmax%20to%20Flash%20Attention%20V3&amp;url=http%3a%2f%2flocalhost%3a1313%2fkeep-moving-forward%2ftech%2ffundamental_from_online_softmax_to_flash_attentionv3%2f&amp;hashtags=LLMServer%2cLLM">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share [Fundamental] From Online Softmax to Flash Attention V3 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fkeep-moving-forward%2ftech%2ffundamental_from_online_softmax_to_flash_attentionv3%2f&amp;title=%5bFundamental%5d%20From%20Online%20Softmax%20to%20Flash%20Attention%20V3&amp;summary=%5bFundamental%5d%20From%20Online%20Softmax%20to%20Flash%20Attention%20V3&amp;source=http%3a%2f%2flocalhost%3a1313%2fkeep-moving-forward%2ftech%2ffundamental_from_online_softmax_to_flash_attentionv3%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share [Fundamental] From Online Softmax to Flash Attention V3 on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fkeep-moving-forward%2ftech%2ffundamental_from_online_softmax_to_flash_attentionv3%2f&title=%5bFundamental%5d%20From%20Online%20Softmax%20to%20Flash%20Attention%20V3">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share [Fundamental] From Online Softmax to Flash Attention V3 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fkeep-moving-forward%2ftech%2ffundamental_from_online_softmax_to_flash_attentionv3%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share [Fundamental] From Online Softmax to Flash Attention V3 on whatsapp"
            href="https://api.whatsapp.com/send?text=%5bFundamental%5d%20From%20Online%20Softmax%20to%20Flash%20Attention%20V3%20-%20http%3a%2f%2flocalhost%3a1313%2fkeep-moving-forward%2ftech%2ffundamental_from_online_softmax_to_flash_attentionv3%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share [Fundamental] From Online Softmax to Flash Attention V3 on telegram"
            href="https://telegram.me/share/url?text=%5bFundamental%5d%20From%20Online%20Softmax%20to%20Flash%20Attention%20V3&amp;url=http%3a%2f%2flocalhost%3a1313%2fkeep-moving-forward%2ftech%2ffundamental_from_online_softmax_to_flash_attentionv3%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share [Fundamental] From Online Softmax to Flash Attention V3 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=%5bFundamental%5d%20From%20Online%20Softmax%20to%20Flash%20Attention%20V3&u=http%3a%2f%2flocalhost%3a1313%2fkeep-moving-forward%2ftech%2ffundamental_from_online_softmax_to_flash_attentionv3%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>Â© <a href="https://github.com/chenghuaWang">chenghua.wang</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a><script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js" integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script>
const images = Array.from(document.querySelectorAll(".post-content img"));
images.forEach(img => {
  mediumZoom(img, {
    margin: 0,  
    scrollOffset: 40,  
    container: null,  
    template: null,  
    background: 'rgba(0, 0, 0, 0.8)'
  });
});
</script>
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5j20jf9ml5x&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>


<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
