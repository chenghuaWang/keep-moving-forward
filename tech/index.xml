<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Teches on Ubios Home</title>
    <link>https://chenghuawang.github.io/keep-moving-forward/tech/</link>
    <description>Recent content in Teches on Ubios Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 12 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://chenghuawang.github.io/keep-moving-forward/tech/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>浅析 IREE</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/intro_to_iree/</link>
      <pubDate>Mon, 12 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/intro_to_iree/</guid>
      <description>最近在编写 NNCV(nerual network inference and comile framework for computer vision, 这是一个以工程驱动的学习 MLSys 的项目，可能作为一些课程作业/毕设使用。至于为什么是 for computer vision，只能说：时间有限，优先能跑起来 resnet 就行了) 的过程中在不断的调研各种推理框架和深度学习编译器的设计逻辑，算法实现等。我发现我在 NNCV 中的设计逻辑和 IREE 非常的相似，可能这个框架的形态大家都是这么想的吧，其实整个类型的框架设计是非常显然的。都是使用编译技术来对计算图做深层的优化，做 CodeGen，Schedule，等。最终生成目标平台的机器码和 vm(也可以说是 runtime)上的字节码。主要克服的难点仍然是 CodeGen，动态 Shape，Auto Schedule 上。
IREE 是什么？ 一如既往的，我们先来看下设计 iree 的团队对其作品的定义[1]：
IREE (Intermediate Representation Execution Environment) is an MLIR-based end-to-end compiler and runtime that lowers Machine Learning (ML) models to a unified IR that scales up to meet the needs of the datacenter and down to satisfy the constraints and special considerations of mobile and edge deployments.</description>
    </item>
    
    <item>
      <title>浅析机器学习中的并行模型和自动并行方法</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/introduction_mldistri/</link>
      <pubDate>Tue, 02 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/introduction_mldistri/</guid>
      <description>人工智能领域的许多最新进展都围绕着大规模神经网络展开，但训练大规模神经网络是一项艰巨的工程和研究挑战，需要协调GPU集群来执行单个同步计算。随着集群数和模型规模的增长，机器学习从业者开发了多项技术，让机器学习模型能在多个GPU上进行并行模型训练。
乍一看，这些并行技术令人生畏，但只需对计算结构进行一些假设，这些技术就会变得清晰：从某些角度来看，这也只是从 A 到 B 传递并不透明的位，就像数据包在网络交换机之间传递一样。
各种 Parallel 模型 不同的并行技术将训练过程划分为不同的维度，包括：
数据并行（Data Parallelism）在不同的GPU上运行同一批数据的不同子集 DP（Data Parallel） DDP（Distributed Data Parallel） FSDP（Fully Shared Data Parallel） 流水并行（Pipeline Parallelism）在不同的GPU上运行模型的不同层 模型并行（Tensor Parallelism）将单个数学运算（如矩阵乘法）拆分到不同的GPU上运行 专家混合（Mixture-of-Experts）只用模型每一层中的一小部分来处理数据。 Note：Tensor Parallelism 翻译成模型并行可能并不是非常的恰当🤣
1. 并行模型 1.1 数据并行 （Data Parallesim） 数据并行是指将相同的参数复制到多个工作节点上，并为每个工作节点分配不同的数据子集同时进行处理。每个工作节点拥有完整的神经网络模型，每次训练仅将一批数据输入模型，进行前向传播、计算误差、反向传播，最后进行参数的更新。储了参数的更新，其余的操作都是互相独立的，所以可以在多个节点上进行并发的执行。
每个工作节点都有自己的模型和输入，当属于自己的模型参数推理完成后（产生了梯度参数），所有的工作节点会把参数（梯度参数）发给一个 Master，这个 Master 会把所有节点传进来的参数做融合，通过这些梯度参数更新生成新的模型参数，然后把这个模型的参数再发送给每个工作节点，拱他们进行下一轮的计算。
在 Pytorch 中提供了DP（Data Parallel）、DDP（Distributed Data Parallel）、FSDP（Fully Shared Data Parallel）三种不同的数据并行方法。
1.1.1 DP（Data Parallel）Parameter Server DP 使用了 Parameter Server（PS） 作为理论依据。PS 结构是李沐老师提出来的方法，由server节点和worker节点组成。
[点击折叠] 李沐老师的 PS 讲解 Server 节点的主要功能是初始化和保存模型参数、接受worker节点计算出的局部梯度、汇总计算全局梯度，并更新模型参数。
Parameter Server Worker 节点的主要功能是各自保存部分训练数据，初始化模型，从 Server 节点拉取（Pull）最新的模型参数，再读取参数，根据训练数据计算局部梯度，上传（Push）给 Server 节点。ps：李沐老师说这个 Pull 和 Push 叫法来源于 Git。</description>
    </item>
    
    <item>
      <title>How to Optimize Convolution</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/how_to_optimize_convlution/</link>
      <pubDate>Fri, 21 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/how_to_optimize_convlution/</guid>
      <description>此篇文章记录了一个个人项目(NNCV，面向计算机视觉的神经网络编译推理框架) 中的 Conv 实现和加速过程
1. Algorithms 1.0 naive 首先，先祭出 [4] CS231n 中包浆的图，对于 naive 的做法，就是按照卷积的原理来做，不做任何的优化。
Conv from CS231n[4]. 1.1 img2col &amp;amp; img2row 1.2 Winograd 1.2.x winograd impl in NCNN 1.3 Conv on mobile device 1.4 Depth Wise Conv 2. Handcraft kernel impl 2.0 Data Layout 一般 4D-Tensor 数据布局的形式是 NCHW 和 NHWC，其中 N 表示 Batch size，C 表示 Channel，H 表示 Height，W 表示 Width。本文中所有的例子都是 NCHW 的 4D-Tensor。
NCHW Datalayout[5]. 使用上述图像 [5] 来展示数据排布。对于 NCHW 排列方法来说：</description>
    </item>
    
    <item>
      <title>CUDA: NSight System</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/cuda_nsight_system/</link>
      <pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/cuda_nsight_system/</guid>
      <description>NSight System Document
WSL 2 的 cudaMallocHost() 不能正常申请到 VM 的内存。也许是 WSL 2 上的 cuda 是 ubuntu20.04 的版本，不是 WSL 2 特供版。WSL 2 的 cuda 也有一些限制，详细见 WSL2 User guide 。
1. 什么是 Nsight System 我们先看下 Nsight System 官网对该工具的描述：
NVIDIA Nsight™ Systems is a system-wide performance analysis tool designed to visualize an application’s algorithms, help you identify the largest opportunities to optimize, and tune to scale efficiently across any quantity or size of CPUs and GPUs, from large servers to our smallest system on a chip (SoC).</description>
    </item>
    
    <item>
      <title>XV6 Lab 5: Copy On Write</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab5_cow/</link>
      <pubDate>Fri, 17 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab5_cow/</guid>
      <description>xv6 中的 fork() 系统调用将父进程的所有用户空间内存复制到子进程中。如果父进程很大，复制可能需要很长的时间。更糟糕的是，这项工作通常是无用的：fork() 之后通常是子进程的 exec()，它放弃了复制的内存，没有使用复制过来的大部分内存。如果父代和子代都使用了复制的页面，并且其中一个或两个都写了它，那么这个复制才是真正需要的。
所以写时复制(copy on write, cow) 这个技术变得十分的重要。在这个 lab 中，我们需要实现一个写时复制的 fork()。我们需要修改原本的 fork() 程序中做内存申请的模块，同时我们还需要实现 usertrap 来在写时(在实际写的时候碰到 cow flag，抛出分页错误)的时候处理这个 trap。
因为一个程序很可能被 fork() 了很多的分支，所以我们需要一个计数器来确定这个 page 是要被释放还是保留。
一般来说，一个正常运行的程序在写时复制的时候会有下面几个流程:
fork() 出一个子进程 child。 child 拥有父进程的页的引用，并且页的 flag 有 cow 标识。 并且要把 页 引用 ++ child 需要向自己的页中写入新的数据. 此时需要重新分配内存，页引用 &amp;ndash;。 当 child 返回的时候，可能有内存需要由 kernel 转换到 user。 当父进程销毁的时候，如果计数器为 0，则销毁，反之，不变。 每一页都需要一个计数器来进行计数，所以我们需要在 kernel 中加入一个数组来记录，查阅 xv6 book，我们发现有如下的图:
Fig 1. memlayout我们需要在 kernel data 之后的区域内申请一块内存来作为计数器存储的数组。我们可以在 kalloc.c 中实现。
// ./kernel/kalloc.c struct { struct spinlock lock; struct run *freelist; // lab 5 uint* ref_cnt; struct spinlock ref_cnt_lock; char * pa_start; } kmem; 在这个 kmem 结构体中加入了一个 ref_cnt_lock 来保证计数器的正确引用。一个 ref_cnt pointer 来指示 ref array 的起始位置，使用 pa_start 来表示实际的 free memory 的起始位置。我们还需要修改初始化程序来正确的申请计数器数组，并且对 free memory 填充上一个初始值。</description>
    </item>
    
    <item>
      <title>XV6 Lab 4: Traps</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab4_trap/</link>
      <pubDate>Sun, 05 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab4_trap/</guid>
      <description>RISC-V assembly Which registers contain arguments to functions? For example, which register holds 13 in main&amp;rsquo;s call to printf?
Register: a0, a1, a2&amp;hellip;, a7 for integer arguments. Register fa0, fa1, fa2&amp;hellip;, fa7 for float arguments.
Register a2 holds 13 when we call printf().
Where is the call to function f in the assembly code for main? Where is the call to g? (Hint: the compiler may inline functions.)
Compiler inlined f(8) and g() in printf() function.</description>
    </item>
    
    <item>
      <title>XV6 Lab 3: Page Table</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab3_pagetable/</link>
      <pubDate>Thu, 02 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab3_pagetable/</guid>
      <description>MIT 6.S081 Lab3 website
做 Lab 3 需要提前阅读 XV6 book，了解 RISC-V SR39 的地址格式，并且实验中大量用到了页表的准换函数，需要查阅 XV6 手册。不过，熟记 RISC-V 的地址说实在的没有什么用处，通过这个实验理解页表的工作方式并且 hands on 才是真的。
Speed up system calls 目前有很多的操作系统(Linux)在用户区和内核区之间共享一块数据(Read-Only for user)，这样用户在进行系统调用的时候就不需要陷入内核态后，由内核态拷贝数据进用户态，而是将数据写在这个共享的区块内。这样可以加快操作系统的运行速度(毕竟大部分系统调用需要的内存消耗是很小的，内存的消耗在当今已经不是问题)。
在本实验中我们需要使用 ugetpid() 来进行加速获得进程的 pid。
首先就是为每一个进程创建一个页表作为共享内存区块。我们发现在 kernel\memlayout.h 中已经为我们定义好了需要的数据结构:
struct usyscall { int pid; // Process ID }; 那么我们只需要在 kernel/proc.c /proc.h 中加入代码，来实现进程创建时创建页表，销毁时销毁页表的动作就行了。
在 proc.h 中，我们需要在进程的 PCB 中加入新的数据结构:
struct proc { ... struct usyscall *usyscall; // using read only shared data to accelerate. ... } 为了让进程的正常创建和释放，我们需要向进程创建和销毁函数中加入对应的页表操作代码。</description>
    </item>
    
    <item>
      <title>XV6 Lab 2: syscall</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab2_syscall/</link>
      <pubDate>Sat, 25 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab2_syscall/</guid>
      <description>MIT 6.S081 Lab2 website
为了完成 Syscall 作业，需要阅读:
XV6-book, Chapter 2, Sections 4.3 and 4.4
files: user/user.h, kernel/proc.c kernel/proc.h, kernel/syscall.c kernel/syscall.h
system call tracing system call tracing 需要我们补充 kernel 中的一些程序，将某程序中指定的 system call 打印出来。当然，这需要我们新增一个 system_trace 系统调用函数。题中，给定的 tracing 程序以 trace [system-call-number] [cmd] 的方式运行。我们首先去看 user/trace.c 中的内容，看看 system call number 是怎么传入系统调用的。
user/trace.c 的程序如下所示:
int main(int argc, char *argv[]) { int i; char *nargv[MAXARG]; if(argc &amp;lt; 3 || (argv[1][0] &amp;lt; &amp;#39;0&amp;#39; || argv[1][0] &amp;gt; &amp;#39;9&amp;#39;)){ fprintf(2, &amp;#34;Usage: %s mask command\n&amp;#34;, argv[0]); exit(1); } if (trace(atoi(argv[1])) &amp;lt; 0) { fprintf(2, &amp;#34;%s: trace failed\n&amp;#34;, argv[0]); exit(1); } for(i = 2; i &amp;lt; argc &amp;amp;&amp;amp; i &amp;lt; MAXARG; i++){ nargv[i-2] = argv[i]; } exec(nargv[0], nargv); exit(0); } 我们发现这个程序直接使用了 trace 系统调用来实现。所以接下来的任务是进行 trace 系统调用的实现。再次回顾 Lab 1 中的内容，在 Lab 1 中我们分析系统调用是通过在 usys.</description>
    </item>
    
    <item>
      <title>XV6 Lab 1: Xv6 and Unix utilities</title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab1_utility/</link>
      <pubDate>Thu, 23 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/xv6_lab1_utility/</guid>
      <description>MIT 6.S081 Lab1 website
本章节的实验是为了熟悉 XV6 环境和 interface 而准备的。包含了 interface 调用、多进程编程、Pipeline。
阅读 book-riscv-ref3 熟悉 XV6 的系统组织形式
sleep 通过调用 user.h 中的系统调用函数来完成 sleep 程序。主要是为了介绍 系统调用 的工作方式。
/** * @author chenghua.wang * @brief Lab1-utilities. sleep prog using syscall. * @time Feb 23, 2023 * */ #include &amp;#34;kernel/types.h&amp;#34; #include &amp;#34;kernel/stat.h&amp;#34; #include &amp;#34;user/user.h&amp;#34; int main(int argc, char *argv[]){ if (argc != 2){ printf(&amp;#34;[ error ] you should follow anw integer with sleep prog to indicate ticks times!</description>
    </item>
    
    <item>
      <title></title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/mlir_toy_1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/mlir_toy_1/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/nv-archs-introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/nv-archs-introduction/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/raft_cpp_impl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/raft_cpp_impl/</guid>
      <description>Try to implement a raft algorithm in c++. And binding python interface on it.
In this artical:
The original raft algorithm. Paper analyze. The cpp impl of raft. What&amp;rsquo;s new in my impl. Python binding, and wheel to official python libs(On both windows and debian linux). API reference. That&amp;rsquo;s quite a large project. Taking almost 9 month to finish it !!! Just do it.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/tensordock_interface_design/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/tensordock_interface_design/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://chenghuawang.github.io/keep-moving-forward/tech/xv6_overall/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chenghuawang.github.io/keep-moving-forward/tech/xv6_overall/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
